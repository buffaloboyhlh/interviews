{"config":{"lang":["en"],"separator":"[\\s\\u200b\\u3000\\-\u3001\u3002\uff0c\uff0e\uff1f\uff01\uff1b]+","pipeline":["stemmer"]},"docs":[{"location":"Vector%20Stores/Milvus/tutorial/","title":"PyMilvus \u4f7f\u7528\u6559\u7a0b\uff1a\u4ece\u5165\u95e8\u5230\u7cbe\u901a","text":""},{"location":"Vector%20Stores/Milvus/tutorial/#1-milvus","title":"1. Milvus \u7b80\u4ecb","text":"<p>Milvus \u662f\u4e00\u4e2a\u5f00\u6e90\u7684\u5411\u91cf\u6570\u636e\u5e93\uff0c\u4e13\u95e8\u7528\u4e8e\u5904\u7406\u5927\u89c4\u6a21\u5411\u91cf\u6570\u636e\u7684\u5b58\u50a8\u548c\u76f8\u4f3c\u5ea6\u641c\u7d22\u3002\u5b83\u652f\u6301\u591a\u79cd\u7d22\u5f15\u7c7b\u578b\u548c\u8ddd\u79bb\u5ea6\u91cf\u65b9\u5f0f\uff0c\u5e7f\u6cdb\u5e94\u7528\u4e8e\u63a8\u8350\u7cfb\u7edf\u3001\u56fe\u50cf\u68c0\u7d22\u3001\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7b49\u9886\u57df\u3002</p>"},{"location":"Vector%20Stores/Milvus/tutorial/#_1","title":"\u6838\u5fc3\u7279\u6027\uff1a","text":"<ul> <li>\u9ad8\u6027\u80fd\u5411\u91cf\u76f8\u4f3c\u5ea6\u641c\u7d22</li> <li>\u652f\u6301\u591a\u79cd\u7d22\u5f15\u7c7b\u578b\uff08IVF_FLAT\u3001HNSW\u3001ANNOY\u7b49\uff09</li> <li>\u53ef\u6269\u5c55\u7684\u5206\u5e03\u5f0f\u67b6\u6784</li> <li>\u652f\u6301\u591a\u79cd\u8ddd\u79bb\u5ea6\u91cf\uff08L2\u3001\u5185\u79ef\u3001\u4f59\u5f26\u7b49\uff09</li> <li>\u4e30\u5bcc\u7684 SDK \u652f\u6301</li> </ul>"},{"location":"Vector%20Stores/Milvus/tutorial/#2","title":"2. \u73af\u5883\u51c6\u5907","text":""},{"location":"Vector%20Stores/Milvus/tutorial/#pymilvus_1","title":"\u5b89\u88c5 PyMilvus","text":"<pre><code>pip install pymilvus\n</code></pre>"},{"location":"Vector%20Stores/Milvus/tutorial/#milvus","title":"\u542f\u52a8 Milvus \u670d\u52a1","text":"<p>\u4f7f\u7528 Docker \u542f\u52a8 Milvus \u5355\u673a\u7248\uff1a</p> <pre><code>docker run -d --name milvus-standalone \\\n  -p 19530:19530 \\\n  -p 9091:9091 \\\n  milvusdb/milvus:v2.3.4\n</code></pre>"},{"location":"Vector%20Stores/Milvus/tutorial/#3","title":"3. \u57fa\u7840\u6982\u5ff5","text":""},{"location":"Vector%20Stores/Milvus/tutorial/#_2","title":"\u6838\u5fc3\u7ec4\u4ef6","text":"<ol> <li>Collection\uff08\u96c6\u5408\uff09\uff1a\u7c7b\u4f3c\u5173\u7cfb\u6570\u636e\u5e93\u4e2d\u7684\u8868\uff0c\u5305\u542b\u591a\u4e2a\u5b9e\u4f53</li> <li>Field\uff08\u5b57\u6bb5\uff09\uff1a\u96c6\u5408\u4e2d\u7684\u5217\uff0c\u53ef\u4ee5\u662f\u6807\u91cf\u6216\u5411\u91cf</li> <li>Entity\uff08\u5b9e\u4f53\uff09\uff1a\u96c6\u5408\u4e2d\u7684\u4e00\u884c\u6570\u636e</li> <li>Partition\uff08\u5206\u533a\uff09\uff1a\u7528\u4e8e\u6570\u636e\u7ba1\u7406\u7684\u903b\u8f91\u5206\u7ec4</li> <li>Index\uff08\u7d22\u5f15\uff09\uff1a\u52a0\u901f\u5411\u91cf\u641c\u7d22\u7684\u6570\u636e\u7ed3\u6784</li> <li>Schema\uff08\u6a21\u5f0f\uff09\uff1a\u5b9a\u4e49\u96c6\u5408\u7684\u7ed3\u6784</li> </ol>"},{"location":"Vector%20Stores/Milvus/tutorial/#_3","title":"\u8ddd\u79bb\u5ea6\u91cf","text":"<ul> <li>L2\uff08\u6b27\u6c0f\u8ddd\u79bb\uff09\uff1a<code>\"L2\"</code></li> <li>\u5185\u79ef\uff1a<code>\"IP\"</code></li> <li>\u4f59\u5f26\u76f8\u4f3c\u5ea6\uff1a<code>\"COSINE\"</code></li> </ul>"},{"location":"Vector%20Stores/Milvus/tutorial/#4","title":"4. \u57fa\u7840\u64cd\u4f5c","text":""},{"location":"Vector%20Stores/Milvus/tutorial/#milvus_1","title":"\u8fde\u63a5 Milvus","text":"<pre><code>from pymilvus import connections, utility\n\n# \u8fde\u63a5 Milvus\nconnections.connect(\n    alias=\"default\",\n    host=\"localhost\",\n    port=\"19530\"\n)\n\n# \u68c0\u67e5\u8fde\u63a5\u72b6\u6001\nprint(f\"Milvus \u7248\u672c: {utility.get_server_version()}\")\n</code></pre>"},{"location":"Vector%20Stores/Milvus/tutorial/#_4","title":"\u521b\u5efa\u96c6\u5408","text":"<pre><code>from pymilvus import Collection, FieldSchema, CollectionSchema, DataType\n\n# \u5b9a\u4e49\u5b57\u6bb5\nfields = [\n    FieldSchema(name=\"id\", dtype=DataType.INT64, is_primary=True, auto_id=True),\n    FieldSchema(name=\"embedding\", dtype=DataType.FLOAT_VECTOR, dim=128),\n    FieldSchema(name=\"title\", dtype=DataType.VARCHAR, max_length=200),\n    FieldSchema(name=\"category\", dtype=DataType.VARCHAR, max_length=100)\n]\n\n# \u521b\u5efa\u6a21\u5f0f\nschema = CollectionSchema(\n    fields=fields,\n    description=\"\u793a\u4f8b\u96c6\u5408\",\n    enable_dynamic_field=True\n)\n\n# \u521b\u5efa\u96c6\u5408\ncollection_name = \"example_collection\"\ncollection = Collection(\n    name=collection_name,\n    schema=schema,\n    using=\"default\"\n)\n\nprint(f\"\u96c6\u5408 {collection_name} \u521b\u5efa\u6210\u529f\")\n</code></pre>"},{"location":"Vector%20Stores/Milvus/tutorial/#_5","title":"\u63d2\u5165\u6570\u636e","text":"<pre><code>import random\n\n# \u751f\u6210\u793a\u4f8b\u6570\u636e\nnum_entities = 1000\nembeddings = [[random.random() for _ in range(128)] for _ in range(num_entities)]\ntitles = [f\"\u6807\u9898_{i}\" for i in range(num_entities)]\ncategories = [f\"\u5206\u7c7b_{random.randint(1, 5)}\" for _ in range(num_entities)]\n\n# \u51c6\u5907\u63d2\u5165\u6570\u636e\ndata = [\n    embeddings,  # \u5411\u91cf\u6570\u636e\n    titles,      # \u6807\u91cf\u6570\u636e\n    categories   # \u6807\u91cf\u6570\u636e\n]\n\n# \u63d2\u5165\u6570\u636e\ninsert_result = collection.insert(data)\n\nprint(f\"\u63d2\u5165\u4e86 {len(insert_result.primary_keys)} \u6761\u6570\u636e\")\nprint(f\"\u4e3b\u952e: {insert_result.primary_keys[:5]}\")  # \u663e\u793a\u524d5\u4e2a\u4e3b\u952e\n</code></pre>"},{"location":"Vector%20Stores/Milvus/tutorial/#_6","title":"\u521b\u5efa\u7d22\u5f15","text":"<pre><code># \u5728\u63d2\u5165\u6570\u636e\u540e\u521b\u5efa\u7d22\u5f15\nindex_params = {\n    \"index_type\": \"IVF_FLAT\",\n    \"metric_type\": \"L2\",\n    \"params\": {\"nlist\": 128}\n}\n\n# \u4e3a\u5411\u91cf\u5b57\u6bb5\u521b\u5efa\u7d22\u5f15\ncollection.create_index(\n    field_name=\"embedding\",\n    index_params=index_params\n)\n\nprint(\"\u7d22\u5f15\u521b\u5efa\u6210\u529f\")\n</code></pre>"},{"location":"Vector%20Stores/Milvus/tutorial/#_7","title":"\u641c\u7d22\u5411\u91cf","text":"<pre><code># \u52a0\u8f7d\u96c6\u5408\u5230\u5185\u5b58\ncollection.load()\n\n# \u51c6\u5907\u641c\u7d22\u5411\u91cf\nsearch_vectors = [[random.random() for _ in range(128)] for _ in range(5)]\n\n# \u8bbe\u7f6e\u641c\u7d22\u53c2\u6570\nsearch_params = {\n    \"metric_type\": \"L2\",\n    \"params\": {\"nprobe\": 10}\n}\n\n# \u6267\u884c\u641c\u7d22\nresults = collection.search(\n    data=search_vectors,\n    anns_field=\"embedding\",\n    param=search_params,\n    limit=3,  # \u8fd4\u56detop-3\u7ed3\u679c\n    output_fields=[\"title\", \"category\"]  # \u8fd4\u56de\u7684\u5b57\u6bb5\n)\n\n# \u89e3\u6790\u641c\u7d22\u7ed3\u679c\nfor i, result in enumerate(results):\n    print(f\"\\n\u641c\u7d22\u5411\u91cf {i+1} \u7684\u7ed3\u679c:\")\n    for j, hit in enumerate(result):\n        print(f\"  \u7b2c {j+1} \u540d: ID={hit.id}, \u8ddd\u79bb={hit.distance:.4f}, \"\n              f\"\u6807\u9898={hit.entity.get('title')}, \u5206\u7c7b={hit.entity.get('category')}\")\n</code></pre>"},{"location":"Vector%20Stores/Milvus/tutorial/#_8","title":"\u67e5\u8be2\u6807\u91cf\u6570\u636e","text":"<pre><code># \u57fa\u4e8e\u6807\u91cf\u5b57\u6bb5\u67e5\u8be2\nquery_result = collection.query(\n    expr='category == \"\u5206\u7c7b_1\"',\n    output_fields=[\"id\", \"title\", \"category\"],\n    limit=5\n)\n\nprint(\"\\n\u5206\u7c7b\u4e3a '\u5206\u7c7b_1' \u7684\u6570\u636e:\")\nfor result in query_result:\n    print(f\"ID: {result['id']}, \u6807\u9898: {result['title']}, \u5206\u7c7b: {result['category']}\")\n</code></pre>"},{"location":"Vector%20Stores/Milvus/tutorial/#5","title":"5. \u8fdb\u9636\u529f\u80fd","text":""},{"location":"Vector%20Stores/Milvus/tutorial/#_9","title":"\u5206\u533a\u7ba1\u7406","text":"<pre><code># \u521b\u5efa\u5206\u533a\npartition_name = \"partition_1\"\ncollection.create_partition(partition_name)\n\n# \u5411\u5206\u533a\u63d2\u5165\u6570\u636e\npartition_data = [\n    [[random.random() for _ in range(128)] for _ in range(100)],\n    [f\"\u5206\u533a\u6807\u9898_{i}\" for i in range(100)],\n    [\"\u7279\u6b8a\u5206\u7c7b\" for _ in range(100)]\n]\n\npartition_insert_result = collection.insert(partition_data, partition_name=partition_name)\n\n# \u5728\u6307\u5b9a\u5206\u533a\u641c\u7d22\npartition_results = collection.search(\n    data=search_vectors,\n    anns_field=\"embedding\",\n    param=search_params,\n    limit=2,\n    partition_names=[partition_name],\n    output_fields=[\"title\", \"category\"]\n)\n</code></pre>"},{"location":"Vector%20Stores/Milvus/tutorial/#_10","title":"\u6df7\u5408\u641c\u7d22\uff08\u6807\u91cf + \u5411\u91cf\uff09","text":"<pre><code># \u7ed3\u5408\u6807\u91cf\u8fc7\u6ee4\u7684\u5411\u91cf\u641c\u7d22\nhybrid_search_results = collection.search(\n    data=search_vectors,\n    anns_field=\"embedding\",\n    param=search_params,\n    limit=5,\n    expr='category == \"\u5206\u7c7b_2\"',  # \u6807\u91cf\u8fc7\u6ee4\u6761\u4ef6\n    output_fields=[\"title\", \"category\"]\n)\n\nprint(\"\\n\u6df7\u5408\u641c\u7d22\u7ed3\u679c (\u5206\u7c7b\u4e3a '\u5206\u7c7b_2'):\")\nfor i, result in enumerate(hybrid_search_results):\n    print(f\"\u641c\u7d22\u5411\u91cf {i+1}:\")\n    for hit in result:\n        print(f\"  ID={hit.id}, \u8ddd\u79bb={hit.distance:.4f}, \"\n              f\"\u6807\u9898={hit.entity.get('title')}\")\n</code></pre>"},{"location":"Vector%20Stores/Milvus/tutorial/#_11","title":"\u6570\u636e\u5220\u9664","text":"<pre><code># \u5220\u9664\u7279\u5b9a\u6570\u636e\ndelete_expr = 'category == \"\u7279\u6b8a\u5206\u7c7b\"'\ncollection.delete(delete_expr)\n\nprint(\"\u6570\u636e\u5220\u9664\u5b8c\u6210\")\n</code></pre>"},{"location":"Vector%20Stores/Milvus/tutorial/#_12","title":"\u96c6\u5408\u7ba1\u7406","text":"<pre><code># \u83b7\u53d6\u96c6\u5408\u4fe1\u606f\ncollection_info = {\n    \"\u5b9e\u4f53\u6570\u91cf\": collection.num_entities,\n    \"\u5206\u533a\u5217\u8868\": collection.partitions\n}\n\nprint(\"\u96c6\u5408\u4fe1\u606f:\")\nfor key, value in collection_info.items():\n    print(f\"  {key}: {value}\")\n\n# \u91ca\u653e\u96c6\u5408\u5185\u5b58\ncollection.release()\n</code></pre>"},{"location":"Vector%20Stores/Milvus/tutorial/#6","title":"6. \u6027\u80fd\u4f18\u5316","text":""},{"location":"Vector%20Stores/Milvus/tutorial/#_13","title":"\u7d22\u5f15\u9009\u62e9\u7b56\u7565","text":"<pre><code>def create_optimized_index(collection, field_name, data_size):\n    \"\"\"\u6839\u636e\u6570\u636e\u91cf\u9009\u62e9\u6700\u4f18\u7d22\u5f15\"\"\"\n    if data_size &lt; 10000:\n        # \u5c0f\u6570\u636e\u91cf\u4f7f\u7528FLAT\n        index_params = {\n            \"index_type\": \"FLAT\",\n            \"metric_type\": \"L2\"\n        }\n    elif data_size &lt; 1000000:\n        # \u4e2d\u7b49\u6570\u636e\u91cf\u4f7f\u7528IVF_FLAT\n        index_params = {\n            \"index_type\": \"IVF_FLAT\",\n            \"metric_type\": \"L2\",\n            \"params\": {\"nlist\": 1024}\n        }\n    else:\n        # \u5927\u6570\u636e\u91cf\u4f7f\u7528HNSW\n        index_params = {\n            \"index_type\": \"HNSW\",\n            \"metric_type\": \"L2\",\n            \"params\": {\"M\": 16, \"efConstruction\": 200}\n        }\n\n    collection.create_index(field_name, index_params)\n    return index_params\n\n# \u4f7f\u7528\u4f18\u5316\u7d22\u5f15\noptimized_index = create_optimized_index(collection, \"embedding\", 100000)\nprint(f\"\u521b\u5efa\u7684\u7d22\u5f15\u53c2\u6570: {optimized_index}\")\n</code></pre>"},{"location":"Vector%20Stores/Milvus/tutorial/#_14","title":"\u6279\u91cf\u64cd\u4f5c\u4f18\u5316","text":"<pre><code>def batch_insert(collection, data, batch_size=1000):\n    \"\"\"\u6279\u91cf\u63d2\u5165\u6570\u636e\u4f18\u5316\"\"\"\n    total_records = len(data[0])\n    inserted_count = 0\n\n    for i in range(0, total_records, batch_size):\n        end_idx = min(i + batch_size, total_records)\n        batch_data = [field[i:end_idx] for field in data]\n\n        insert_result = collection.insert(batch_data)\n        inserted_count += len(insert_result.primary_keys)\n\n        print(f\"\u5df2\u63d2\u5165 {inserted_count}/{total_records} \u6761\u6570\u636e\")\n\n    return inserted_count\n\n# \u4f7f\u7528\u6279\u91cf\u63d2\u5165\nlarge_embeddings = [[random.random() for _ in range(128)] for _ in range(5000)]\nlarge_titles = [f\"\u6279\u91cf\u6807\u9898_{i}\" for i in range(5000)]\nlarge_categories = [f\"\u5206\u7c7b_{random.randint(1, 3)}\" for _ in range(5000)]\n\nlarge_data = [large_embeddings, large_titles, large_categories]\nbatch_insert(collection, large_data, batch_size=500)\n</code></pre>"},{"location":"Vector%20Stores/Milvus/tutorial/#7","title":"7. \u5b9e\u6218\u6848\u4f8b","text":""},{"location":"Vector%20Stores/Milvus/tutorial/#_15","title":"\u6848\u4f8b\uff1a\u56fe\u50cf\u68c0\u7d22\u7cfb\u7edf","text":"<pre><code>import numpy as np\nfrom PIL import Image\nimport requests\nfrom io import BytesIO\n\nclass ImageSearchSystem:\n    def __init__(self, collection_name=\"image_search\"):\n        self.collection_name = collection_name\n        self.setup_collection()\n\n    def setup_collection(self):\n        \"\"\"\u8bbe\u7f6e\u56fe\u50cf\u641c\u7d22\u96c6\u5408\"\"\"\n        if utility.has_collection(self.collection_name):\n            self.collection = Collection(self.collection_name)\n            return\n\n        fields = [\n            FieldSchema(name=\"id\", dtype=DataType.INT64, is_primary=True, auto_id=True),\n            FieldSchema(name=\"image_vector\", dtype=DataType.FLOAT_VECTOR, dim=512),\n            FieldSchema(name=\"image_url\", dtype=DataType.VARCHAR, max_length=500),\n            FieldSchema(name=\"tags\", dtype=DataType.VARCHAR, max_length=200),\n            FieldSchema(name=\"upload_time\", dtype=DataType.INT64)\n        ]\n\n        schema = CollectionSchema(fields, \"\u56fe\u50cf\u641c\u7d22\u96c6\u5408\")\n        self.collection = Collection(self.collection_name, schema)\n\n        # \u521b\u5efa\u7d22\u5f15\n        index_params = {\n            \"index_type\": \"IVF_FLAT\",\n            \"metric_type\": \"COSINE\",  # \u56fe\u50cf\u641c\u7d22\u901a\u5e38\u4f7f\u7528\u4f59\u5f26\u76f8\u4f3c\u5ea6\n            \"params\": {\"nlist\": 1024}\n        }\n        self.collection.create_index(\"image_vector\", index_params)\n\n    def add_image(self, image_vector, image_url, tags):\n        \"\"\"\u6dfb\u52a0\u56fe\u50cf\u5230\u7cfb\u7edf\"\"\"\n        current_time = int(time.time())\n        data = [\n            [image_vector],\n            [image_url],\n            [tags],\n            [current_time]\n        ]\n\n        result = self.collection.insert(data)\n        return result.primary_keys[0]\n\n    def search_similar_images(self, query_vector, top_k=10, tag_filter=None):\n        \"\"\"\u641c\u7d22\u76f8\u4f3c\u56fe\u50cf\"\"\"\n        self.collection.load()\n\n        search_params = {\n            \"metric_type\": \"COSINE\",\n            \"params\": {\"nprobe\": 16}\n        }\n\n        expr = None\n        if tag_filter:\n            expr = f'tags like \"%{tag_filter}%\"'\n\n        results = self.collection.search(\n            data=[query_vector],\n            anns_field=\"image_vector\",\n            param=search_params,\n            limit=top_k,\n            expr=expr,\n            output_fields=[\"image_url\", \"tags\", \"upload_time\"]\n        )\n\n        return results[0]\n\n    def demo_simulation(self):\n        \"\"\"\u6f14\u793a\u6a21\u62df\"\"\"\n        print(\"=== \u56fe\u50cf\u68c0\u7d22\u7cfb\u7edf\u6f14\u793a ===\")\n\n        # \u6a21\u62df\u6dfb\u52a0\u56fe\u50cf\u6570\u636e\n        print(\"\\n1. \u6dfb\u52a0\u56fe\u50cf\u6570\u636e...\")\n        for i in range(100):\n            # \u6a21\u62df512\u7ef4\u56fe\u50cf\u7279\u5f81\u5411\u91cf\n            fake_vector = [random.random() for _ in range(512)]\n            tags = f\"tag_{random.randint(1, 10)}\"\n            self.add_image(fake_vector, f\"http://example.com/image_{i}.jpg\", tags)\n\n        # \u6a21\u62df\u641c\u7d22\n        print(\"\\n2. \u6267\u884c\u76f8\u4f3c\u56fe\u50cf\u641c\u7d22...\")\n        query_vector = [random.random() for _ in range(512)]\n        results = self.search_similar_images(query_vector, top_k=5)\n\n        print(\"\u641c\u7d22\u7ed3\u679c:\")\n        for i, hit in enumerate(results):\n            print(f\"  {i+1}. \u76f8\u4f3c\u5ea6: {1 - hit.distance:.4f}, \"\n                  f\"URL: {hit.entity.get('image_url')}, \"\n                  f\"\u6807\u7b7e: {hit.entity.get('tags')}\")\n\n# \u8fd0\u884c\u6f14\u793a\nimage_system = ImageSearchSystem()\nimage_system.demo_simulation()\n</code></pre>"},{"location":"Vector%20Stores/Milvus/tutorial/#_16","title":"\u6848\u4f8b\uff1a\u63a8\u8350\u7cfb\u7edf","text":"<pre><code>class RecommendationSystem:\n    def __init__(self):\n        self.collection_name = \"user_embeddings\"\n        self.setup_collection()\n\n    def setup_collection(self):\n        \"\"\"\u8bbe\u7f6e\u7528\u6237\u5d4c\u5165\u5411\u91cf\u96c6\u5408\"\"\"\n        if utility.has_collection(self.collection_name):\n            self.collection = Collection(self.collection_name)\n            return\n\n        fields = [\n            FieldSchema(name=\"user_id\", dtype=DataType.INT64, is_primary=True),\n            FieldSchema(name=\"user_embedding\", dtype=DataType.FLOAT_VECTOR, dim=256),\n            FieldSchema(name=\"user_features\", dtype=DataType.VARCHAR, max_length=500),\n            FieldSchema(name=\"last_active\", dtype=DataType.INT64)\n        ]\n\n        schema = CollectionSchema(fields, \"\u7528\u6237\u63a8\u8350\u7cfb\u7edf\")\n        self.collection = Collection(self.collection_name, schema)\n\n        index_params = {\n            \"index_type\": \"HNSW\",\n            \"metric_type\": \"IP\",  # \u63a8\u8350\u7cfb\u7edf\u5e38\u7528\u5185\u79ef\n            \"params\": {\"M\": 16, \"efConstruction\": 200}\n        }\n        self.collection.create_index(\"user_embedding\", index_params)\n\n    def add_user(self, user_id, embedding, features):\n        \"\"\"\u6dfb\u52a0\u7528\u6237\"\"\"\n        current_time = int(time.time())\n        data = [\n            [user_id],\n            [embedding],\n            [features],\n            [current_time]\n        ]\n\n        self.collection.insert(data)\n\n    def find_similar_users(self, user_id, top_k=5):\n        \"\"\"\u67e5\u627e\u76f8\u4f3c\u7528\u6237\"\"\"\n        self.collection.load()\n\n        # \u5148\u83b7\u53d6\u76ee\u6807\u7528\u6237\u7684\u5411\u91cf\n        target_user = self.collection.query(\n            expr=f\"user_id == {user_id}\",\n            output_fields=[\"user_embedding\"]\n        )\n\n        if not target_user:\n            return []\n\n        target_embedding = target_user[0][\"user_embedding\"]\n\n        search_params = {\n            \"metric_type\": \"IP\",\n            \"params\": {\"ef\": 50}\n        }\n\n        results = self.collection.search(\n            data=[target_embedding],\n            anns_field=\"user_embedding\",\n            param=search_params,\n            limit=top_k + 1,  # \u5305\u542b\u81ea\u5df1\n            output_fields=[\"user_id\", \"user_features\"]\n        )\n\n        # \u8fc7\u6ee4\u6389\u81ea\u5df1\n        similar_users = []\n        for hit in results[0]:\n            if hit.id != user_id:\n                similar_users.append({\n                    \"user_id\": hit.id,\n                    \"score\": hit.distance,\n                    \"features\": hit.entity.get(\"user_features\")\n                })\n\n        return similar_users[:top_k]\n\n# \u4f7f\u7528\u793a\u4f8b\nrec_system = RecommendationSystem()\n\n# \u6dfb\u52a0\u793a\u4f8b\u7528\u6237\nfor i in range(1, 101):\n    embedding = [random.random() for _ in range(256)]\n    features = f\"age_{random.randint(18, 60)},interests_{random.randint(1, 10)}\"\n    rec_system.add_user(i, embedding, features)\n\n# \u67e5\u627e\u76f8\u4f3c\u7528\u6237\nsimilar_users = rec_system.find_similar_users(1, top_k=3)\nprint(\"\u76f8\u4f3c\u7528\u6237\u63a8\u8350:\")\nfor user in similar_users:\n    print(f\"\u7528\u6237ID: {user['user_id']}, \u76f8\u4f3c\u5ea6: {user['score']:.4f}\")\n</code></pre>"},{"location":"Vector%20Stores/Milvus/tutorial/#_17","title":"\u603b\u7ed3","text":"<p>\u672c\u6559\u7a0b\u6db5\u76d6\u4e86 PyMilvus \u4ece\u57fa\u7840\u5230\u8fdb\u9636\u7684\u5b8c\u6574\u4f7f\u7528\u6d41\u7a0b\uff1a</p> <ol> <li>\u57fa\u7840\u6982\u5ff5\uff1a\u7406\u89e3 Milvus \u7684\u6838\u5fc3\u7ec4\u4ef6\u548c\u6570\u636e\u6a21\u578b</li> <li>\u57fa\u7840\u64cd\u4f5c\uff1a\u8fde\u63a5\u3001\u96c6\u5408\u7ba1\u7406\u3001\u6570\u636e\u63d2\u5165\u3001\u641c\u7d22\u67e5\u8be2</li> <li>\u8fdb\u9636\u529f\u80fd\uff1a\u5206\u533a\u7ba1\u7406\u3001\u6df7\u5408\u641c\u7d22\u3001\u6570\u636e\u5220\u9664</li> <li>\u6027\u80fd\u4f18\u5316\uff1a\u7d22\u5f15\u9009\u62e9\u3001\u6279\u91cf\u64cd\u4f5c</li> <li>\u5b9e\u6218\u6848\u4f8b\uff1a\u56fe\u50cf\u68c0\u7d22\u3001\u63a8\u8350\u7cfb\u7edf\u7b49\u5b9e\u9645\u5e94\u7528</li> </ol> <p>\u901a\u8fc7\u638c\u63e1\u8fd9\u4e9b\u77e5\u8bc6\uff0c\u4f60\u53ef\u4ee5\u5728\u5b9e\u9645\u9879\u76ee\u4e2d\u9ad8\u6548\u5730\u4f7f\u7528 Milvus \u8fdb\u884c\u5411\u91cf\u6570\u636e\u7684\u7ba1\u7406\u548c\u76f8\u4f3c\u5ea6\u641c\u7d22\u3002\u8bb0\u5f97\u6839\u636e\u5177\u4f53\u4e1a\u52a1\u573a\u666f\u9009\u62e9\u5408\u9002\u7684\u7d22\u5f15\u7c7b\u578b\u548c\u641c\u7d22\u53c2\u6570\uff0c\u4ee5\u8fbe\u5230\u6700\u4f73\u7684\u6027\u80fd\u6548\u679c\u3002</p>"},{"location":"deeplearning/interview/","title":"\u6df1\u5ea6\u5b66\u4e60","text":""},{"location":"deeplearning/interview/#_2","title":"\u4e00\u3001\u795e\u7ecf\u7f51\u7edc","text":""},{"location":"deeplearning/interview/#_3","title":"\ud83e\udde0 \u4e00\u3001\u795e\u7ecf\u7f51\u7edc\u539f\u7406","text":"<p>\u795e\u7ecf\u7f51\u7edc\u662f\u4e00\u79cd\u6a21\u62df\u4eba\u8111\u795e\u7ecf\u5143\u7ed3\u6784\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u3002 \u6838\u5fc3\u601d\u60f3\u662f\uff1a</p> <p>\u901a\u8fc7\u591a\u5c42\u975e\u7ebf\u6027\u53d8\u6362\uff0c\u5c06\u8f93\u5165\u7279\u5f81\u6620\u5c04\u5230\u8f93\u51fa\u7ed3\u679c\u3002</p>"},{"location":"deeplearning/interview/#1-perceptron","title":"1\ufe0f\u20e3 \u795e\u7ecf\u5143\u6a21\u578b\uff08Perceptron\uff09","text":"<p>\u6bcf\u4e2a\u795e\u7ecf\u5143\u63a5\u53d7\u8f93\u5165 \\(x_1, x_2, \\dots, x_n\\)\uff0c\u8ba1\u7b97\u52a0\u6743\u548c\u518d\u52a0\u4e0a\u504f\u7f6e\uff1a</p> \\[ z = \\sum_{i=1}^n w_i x_i + b \\] <p>\u7136\u540e\u901a\u8fc7\u6fc0\u6d3b\u51fd\u6570 \\(f(z)\\) \u5f97\u5230\u8f93\u51fa\uff1a</p> \\[ a = f(z) \\] <p>\u5e38\u89c1\u6fc0\u6d3b\u51fd\u6570\uff1a</p> \u6fc0\u6d3b\u51fd\u6570 \u8868\u8fbe\u5f0f \u7279\u70b9 Sigmoid \\(f(z) = \\frac{1}{1+e^{-z}}\\) \u5e73\u6ed1\u3001\u9002\u5408\u4e8c\u5206\u7c7b\uff0c\u4f46\u53ef\u80fd\u68af\u5ea6\u6d88\u5931 ReLU \\(f(z) = \\max(0, z)\\) \u5e38\u7528\u3001\u6536\u655b\u5feb Tanh \\(f(z) = \\tanh(z)\\) \u8f93\u51fa\u8303\u56f4 \\((-1,1)\\)\uff0c\u5bf9\u79f0\u6027\u597d Softmax \\(f_i(z) = \\frac{e^{z_i}}{\\sum_j e^{z_j}}\\) \u591a\u5206\u7c7b\u8f93\u51fa"},{"location":"deeplearning/interview/#2-network-architecture","title":"2\ufe0f\u20e3 \u7f51\u7edc\u7ed3\u6784\uff08Network Architecture\uff09","text":"<p>\u5178\u578b\u524d\u9988\u795e\u7ecf\u7f51\u7edc\u7ed3\u6784\uff1a</p> \\[ \\text{Input} \\rightarrow \\text{Hidden Layers} \\rightarrow \\text{Output} \\] <p>\u6bcf\u4e00\u5c42\u7684\u8f93\u51fa\u4f5c\u4e3a\u4e0b\u4e00\u5c42\u7684\u8f93\u5165\u3002</p> <p>\u4f8b\u5982\u4e00\u4e2a\u4e24\u5c42\u795e\u7ecf\u7f51\u7edc\uff1a</p> <ul> <li>\u8f93\u5165\u5c42\uff1a\\(x \\in \\mathbb{R}^n\\)</li> <li>\u9690\u85cf\u5c42\uff1a\\(h = f(W_1 x + b_1)\\)</li> <li>\u8f93\u51fa\u5c42\uff1a\\(\\hat{y} = g(W_2 h + b_2)\\)</li> </ul>"},{"location":"deeplearning/interview/#_4","title":"\u2699\ufe0f \u4e8c\u3001\u6570\u5b66\u63a8\u5bfc\u8fc7\u7a0b","text":""},{"location":"deeplearning/interview/#1-forward-propagation","title":"1\ufe0f\u20e3 \u524d\u5411\u4f20\u64ad\uff08Forward Propagation\uff09","text":"<p>\u8f93\u5165 \\(x\\) \u7ecf\u5404\u5c42\u7ebf\u6027\u53d8\u6362 + \u6fc0\u6d3b\u51fd\u6570\uff1a $$ z^{(l)} = W^{(l)} a^{(l-1)} + b^{(l)} \\ a^{(l)} = f^{(l)}(z^{(l)}) $$</p> <p>\u6700\u7ec8\u8f93\u51fa\u9884\u6d4b\uff1a $$ \\hat{y} = a^{(L)} $$ \u5176\u4e2d \\(L\\) \u662f\u7f51\u7edc\u7684\u5c42\u6570\u3002</p>"},{"location":"deeplearning/interview/#2-loss-function","title":"2\ufe0f\u20e3 \u635f\u5931\u51fd\u6570\uff08Loss Function\uff09","text":""},{"location":"deeplearning/interview/#1","title":"\uff081\uff09\u56de\u5f52\u95ee\u9898","text":"<p>\u5e38\u7528\u5747\u65b9\u8bef\u5dee\uff08MSE\uff09\uff1a $$ L = \\frac{1}{2m}\\sum_{i=1}^{m} (\\hat{y}_i - y_i)^2 $$</p>"},{"location":"deeplearning/interview/#2","title":"\uff082\uff09\u5206\u7c7b\u95ee\u9898","text":"<p>\u5e38\u7528\u4ea4\u53c9\u71b5\u635f\u5931\uff08Cross-Entropy\uff09\uff1a $$ L = -\\frac{1}{m} \\sum_{i=1}^{m} \\sum_{k=1}^{K} y_{ik} \\log(\\hat{y}_{ik}) $$</p>"},{"location":"deeplearning/interview/#3-backpropagation","title":"3\ufe0f\u20e3 \u53cd\u5411\u4f20\u64ad\uff08Backpropagation\uff09","text":"<p>\u76ee\u6807\uff1a\u6700\u5c0f\u5316\u635f\u5931\u51fd\u6570 \\(L\\)\u3002 \u4f7f\u7528 \u68af\u5ea6\u4e0b\u964d\u6cd5\uff08Gradient Descent\uff09 \u66f4\u65b0\u53c2\u6570\u3002</p> <p>\u5bf9\u6743\u91cd\u6c42\u5bfc\uff1a $$ \\frac{\\partial L}{\\partial W^{(l)}} = \\frac{\\partial L}{\\partial a^{(l)}} \\cdot \\frac{\\partial a^{(l)}}{\\partial z^{(l)}} \\cdot \\frac{\\partial z^{(l)}}{\\partial W^{(l)}} $$</p> <p>\u66f4\u65b0\u53c2\u6570\uff1a $$ W^{(l)} := W^{(l)} - \\eta \\frac{\\partial L}{\\partial W^{(l)}}, \\quad b^{(l)} := b^{(l)} - \\eta \\frac{\\partial L}{\\partial b^{(l)}} $$</p> <p>\u5176\u4e2d \\(\\eta\\) \u4e3a\u5b66\u4e60\u7387\uff08learning rate\uff09\u3002</p>"},{"location":"deeplearning/interview/#_5","title":"\ud83d\udcca \u4e09\u3001\u8bc4\u4f30\u6307\u6807","text":"\u7c7b\u578b \u6307\u6807 \u516c\u5f0f \u5206\u7c7b \u51c6\u786e\u7387\uff08Accuracy\uff09 \\(\\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN}\\) \u5206\u7c7b \u7cbe\u786e\u7387\uff08Precision\uff09 \\(\\text{Precision} = \\frac{TP}{TP + FP}\\) \u5206\u7c7b \u53ec\u56de\u7387\uff08Recall\uff09 \\(\\text{Recall} = \\frac{TP}{TP + FN}\\) \u5206\u7c7b F1 \u5206\u6570 \\(F1 = 2 \\times \\frac{P \\times R}{P + R}\\) \u56de\u5f52 \u5747\u65b9\u8bef\u5dee\uff08MSE\uff09 \\(\\text{MSE} = \\frac{1}{n}\\sum(\\hat{y} - y)^2\\) \u56de\u5f52 \\(R^2\\) \\(R^2 = 1 - \\frac{\\sum(\\hat{y}-y)^2}{\\sum(y-\\bar{y})^2}\\)"},{"location":"deeplearning/interview/#pytorch","title":"\ud83d\udcbb \u56db\u3001\u5b9e\u73b0\u4ee3\u7801\uff08PyTorch\uff09","text":"<p>\u4ee5\u4e0b\u793a\u4f8b\u662f\u4e00\u4e2a\u7b80\u5355\u7684\u4e24\u5c42\u795e\u7ecf\u7f51\u7edc\u5b9e\u73b0\u4e8c\u5206\u7c7b\u4efb\u52a1\u3002</p> <pre><code>import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom sklearn.datasets import make_moons\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\n# 1. \u6570\u636e\u51c6\u5907\nX, y = make_moons(n_samples=1000, noise=0.2, random_state=42)\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nX_train = torch.FloatTensor(X_train)\ny_train = torch.LongTensor(y_train)\nX_test = torch.FloatTensor(X_test)\ny_test = torch.LongTensor(y_test)\n\n# 2. \u6a21\u578b\u5b9a\u4e49\nclass NeuralNetwork(nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim):\n        super(NeuralNetwork, self).__init__()\n        self.fc1 = nn.Linear(input_dim, hidden_dim)\n        self.relu = nn.ReLU()\n        self.fc2 = nn.Linear(hidden_dim, output_dim)\n\n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.relu(x)\n        x = self.fc2(x)\n        return x\n\nmodel = NeuralNetwork(2, 16, 2)\n\n# 3. \u635f\u5931\u51fd\u6570\u4e0e\u4f18\u5316\u5668\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.01)\n\n# 4. \u8bad\u7ec3\u8fc7\u7a0b\nfor epoch in range(200):\n    outputs = model(X_train)\n    loss = criterion(outputs, y_train)\n\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n\n    if (epoch+1) % 20 == 0:\n        print(f\"Epoch [{epoch+1}/200], Loss: {loss.item():.4f}\")\n\n# 5. \u8bc4\u4f30\nwith torch.no_grad():\n    y_pred = model(X_test)\n    acc = (y_pred.argmax(1) == y_test).float().mean()\n    print(f\"Test Accuracy: {acc:.4f}\")\n</code></pre>"},{"location":"deeplearning/interview/#_6","title":"\ud83e\udde9 \u4e94\u3001\u6a21\u578b\u4f18\u5316\u65b9\u6cd5","text":"\u65b9\u6cd5 \u8bf4\u660e \u5b66\u4e60\u7387\u8c03\u6574\uff08LR Scheduler\uff09 \u63a7\u5236\u5b66\u4e60\u7387\u8870\u51cf \u6743\u91cd\u521d\u59cb\u5316 Xavier\u3001He \u521d\u59cb\u5316\u80fd\u6539\u5584\u6536\u655b \u6b63\u5219\u5316 L2 \u6b63\u5219\u3001Dropout \u9632\u6b62\u8fc7\u62df\u5408 Batch Normalization \u7a33\u5b9a\u5206\u5e03\uff0c\u52a0\u901f\u8bad\u7ec3 \u65e9\u505c\u6cd5\uff08Early Stopping\uff09 \u9632\u6b62\u8fc7\u62df\u5408 \u6570\u636e\u589e\u5f3a\uff08Data Augmentation\uff09 \u6269\u5145\u6837\u672c\u96c6\uff0c\u63d0\u9ad8\u6cdb\u5316\u6027"},{"location":"deeplearning/interview/#_7","title":"\u26a0\ufe0f \u516d\u3001\u6ce8\u610f\u4e8b\u9879","text":"<ol> <li>\u8f93\u5165\u6570\u636e\u9700\u6807\u51c6\u5316\u6216\u5f52\u4e00\u5316\uff1b</li> <li>\u907f\u514d\u5b66\u4e60\u7387\u8fc7\u5927\u6216\u8fc7\u5c0f\uff1b</li> <li>ReLU \u53ef\u89e3\u51b3\u68af\u5ea6\u6d88\u5931\uff0c\u4f46\u6ce8\u610f \u201cReLU \u6b7b\u4ea1\u201d \u95ee\u9898\uff1b</li> <li>\u7f51\u7edc\u5c42\u6570\u8fc7\u591a\u53ef\u80fd\u5bfc\u81f4\u8fc7\u62df\u5408\uff1b</li> <li>\u4f7f\u7528 GPU \u53ef\u663e\u8457\u52a0\u901f\u8bad\u7ec3\uff1b</li> <li>\u5408\u7406\u9009\u62e9\u6279\u5927\u5c0f\uff08batch size\uff09\u3002</li> </ol>"},{"location":"deeplearning/interview/#_8","title":"\u2696\ufe0f \u4e03\u3001\u4f18\u7f3a\u70b9\u603b\u7ed3","text":"\u4f18\u70b9 \u7f3a\u70b9 \u80fd\u5b66\u4e60\u590d\u6742\u975e\u7ebf\u6027\u5173\u7cfb \u9700\u8981\u5927\u91cf\u6570\u636e\u548c\u8ba1\u7b97\u8d44\u6e90 \u6cdb\u5316\u80fd\u529b\u5f3a \u4e0d\u6613\u89e3\u91ca\uff08\u9ed1\u7bb1\uff09 \u9002\u7528\u8303\u56f4\u5e7f\uff08\u5206\u7c7b\u3001\u56de\u5f52\u3001\u751f\u6210\uff09 \u8d85\u53c2\u6570\u8c03\u8282\u56f0\u96be \u53ef\u7aef\u5230\u7aef\u5b66\u4e60 \u5bb9\u6613\u8fc7\u62df\u5408"},{"location":"deeplearning/interview/#_9","title":"\ud83e\udded \u516b\u3001\u5b66\u4e60\u5efa\u8bae\u4e0e\u8fdb\u9636\u8def\u7ebf","text":"\u9636\u6bb5 \u5b66\u4e60\u5185\u5bb9 \u5de5\u5177 \u5165\u95e8 \u611f\u77e5\u673a\u3001\u524d\u5411\u4f20\u64ad\u3001\u6fc0\u6d3b\u51fd\u6570 Numpy \u8fdb\u9636 \u53cd\u5411\u4f20\u64ad\u3001\u4f18\u5316\u5668\u3001\u6b63\u5219\u5316 PyTorch \u63d0\u5347 CNN\u3001RNN\u3001LSTM PyTorch / TensorFlow \u9ad8\u9636 Transformer\u3001\u9884\u8bad\u7ec3\u6a21\u578b HuggingFace Transformers \u90e8\u7f72 ONNX\u3001TensorRT\u3001Triton \u6df1\u5ea6\u5b66\u4e60\u90e8\u7f72\u6846\u67b6"},{"location":"deeplearning/interview/#cnn","title":"\u4e8c\u3001CNN","text":""},{"location":"deeplearning/interview/#cnn-convolutional-neural-network","title":"\ud83e\udde0 \u4e00\u3001CNN \u539f\u7406\uff08Convolutional Neural Network\uff09","text":"<p>\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08CNN\uff09\u662f\u4e00\u7c7b\u4e13\u4e3a\u5904\u7406\u5177\u6709\u7f51\u683c\u7ed3\u6784\u6570\u636e\uff08\u5982\u56fe\u50cf\uff09\u8bbe\u8ba1\u7684\u795e\u7ecf\u7f51\u7edc\u3002 \u4f20\u7edf\u795e\u7ecf\u7f51\u7edc\u5bf9\u8f93\u5165\u7279\u5f81\u5b8c\u5168\u8fde\u63a5\uff0c\u800c CNN \u901a\u8fc7 \u5c40\u90e8\u611f\u53d7\u91ce\uff08local receptive field\uff09 \u548c \u6743\u503c\u5171\u4eab\uff08weight sharing\uff09\uff0c\u663e\u8457\u51cf\u5c11\u53c2\u6570\u6570\u91cf\u5e76\u63d0\u5347\u7279\u5f81\u63d0\u53d6\u80fd\u529b\u3002</p>"},{"location":"deeplearning/interview/#1-cnn","title":"1\ufe0f\u20e3 CNN \u7684\u6838\u5fc3\u601d\u60f3","text":"<ol> <li>\u5377\u79ef\u5c42\uff08Convolution Layer\uff09\uff1a\u63d0\u53d6\u5c40\u90e8\u7279\u5f81</li> <li>\u6c60\u5316\u5c42\uff08Pooling Layer\uff09\uff1a\u964d\u7ef4\u4e0e\u9632\u6b62\u8fc7\u62df\u5408</li> <li>\u5168\u8fde\u63a5\u5c42\uff08Fully Connected Layer\uff09\uff1a\u6574\u5408\u7279\u5f81\u8fdb\u884c\u5206\u7c7b\u6216\u56de\u5f52</li> </ol> <p>\u5178\u578b\u7ed3\u6784\uff1a</p> \\[ \\text{Input} \\rightarrow [\\text{Conv + ReLU + Pool}]^n \\rightarrow \\text{FC} \\rightarrow \\text{Output} \\]"},{"location":"deeplearning/interview/#2-convolution-operation","title":"2\ufe0f\u20e3 \u5377\u79ef\u64cd\u4f5c\uff08Convolution Operation\uff09","text":"<p>\u4ee5\u4e8c\u7ef4\u5377\u79ef\u4e3a\u4f8b\uff0c\u7ed9\u5b9a\u8f93\u5165\u77e9\u9635 \\(X\\) \u548c\u5377\u79ef\u6838\uff08\u6743\u91cd\u77e9\u9635\uff09\\(K\\)\uff1a</p> \\[ Y(i,j) = \\sum_m \\sum_n X(i+m, j+n) \\cdot K(m,n) \\] <p>\u8be5\u64cd\u4f5c\u79f0\u4e3a\u5377\u79ef\uff08Convolution\uff09\u3002 \u5377\u79ef\u5c42\u901a\u8fc7\u6ed1\u52a8\u5377\u79ef\u6838\u5728\u8f93\u5165\u4e0a\u63d0\u53d6\u5c40\u90e8\u7279\u5f81\uff0c\u5982\u8fb9\u7f18\u3001\u7eb9\u7406\u7b49\u3002</p>"},{"location":"deeplearning/interview/#3-feature-map","title":"3\ufe0f\u20e3 \u7279\u5f81\u56fe\uff08Feature Map\uff09","text":"<p>\u6bcf\u4e2a\u5377\u79ef\u6838\u53ef\u5b66\u4e60\u4e00\u79cd\u7279\u5f81\u6a21\u5f0f\u3002 \u4e00\u4e2a\u5377\u79ef\u5c42\u53ef\u4ee5\u5305\u542b\u591a\u4e2a\u5377\u79ef\u6838\uff0c\u4ece\u800c\u751f\u6210\u591a\u4e2a\u7279\u5f81\u56fe\uff08Feature Map\uff09\u3002</p> <p>\u4f8b\u5982\u8f93\u5165\u5927\u5c0f\u4e3a \\((H, W, C_{\\text{in}})\\)\uff0c\u5377\u79ef\u6838\u5927\u5c0f\u4e3a \\((k, k, C_{\\text{in}}, C_{\\text{out}})\\)\uff0c\u5219\u8f93\u51fa\u7279\u5f81\u56fe\u5927\u5c0f\u4e3a\uff1a</p> \\[ H_{\\text{out}} = \\frac{H - k + 2p}{s} + 1, \\quad W_{\\text{out}} = \\frac{W - k + 2p}{s} + 1 \\] <p>\u5176\u4e2d\uff1a</p> <ul> <li>\\(p\\)\uff1apadding\uff08\u586b\u5145\uff09</li> <li>\\(s\\)\uff1astride\uff08\u6b65\u5e45\uff09</li> </ul>"},{"location":"deeplearning/interview/#4-pooling-layer","title":"4\ufe0f\u20e3 \u6c60\u5316\u5c42\uff08Pooling Layer\uff09","text":"<p>\u7528\u4e8e\u964d\u7ef4\u4e0e\u7279\u5f81\u4e0d\u53d8\u6027\u63d0\u53d6\u3002</p> <p>\u5e38\u89c1\u6c60\u5316\u65b9\u5f0f\uff1a</p> <ul> <li>\u6700\u5927\u6c60\u5316\uff08Max Pooling\uff09\uff1a\u53d6\u7a97\u53e3\u5185\u6700\u5927\u503c</li> <li>\u5e73\u5747\u6c60\u5316\uff08Average Pooling\uff09\uff1a\u53d6\u7a97\u53e3\u5185\u5747\u503c</li> </ul> <p>\u516c\u5f0f\uff1a</p> \\[ Y(i,j) = \\max_{m,n} X(i+m, j+n) \\]"},{"location":"deeplearning/interview/#5","title":"5\ufe0f\u20e3 \u6fc0\u6d3b\u51fd\u6570","text":"<p>\u5377\u79ef\u5c42\u8f93\u51fa\u540e\u901a\u5e38\u63a5 ReLU\uff1a $$ f(z) = \\max(0, z) $$</p> <p>ReLU \u89e3\u51b3\u4e86\u68af\u5ea6\u6d88\u5931\u95ee\u9898\uff0c\u52a0\u5feb\u7f51\u7edc\u6536\u655b\u3002</p>"},{"location":"deeplearning/interview/#6-fully-connected-layer","title":"6\ufe0f\u20e3 \u5168\u8fde\u63a5\u5c42\uff08Fully Connected Layer\uff09","text":"<p>\u5377\u79ef\u5c42\u8f93\u51fa\u7684\u7279\u5f81\u5c55\u5e73\u540e\u8f93\u5165\u5168\u8fde\u63a5\u5c42\u8fdb\u884c\u5206\u7c7b\uff1a $$ z = W \\cdot a + b, \\quad \\hat{y} = \\text{Softmax}(z) $$</p>"},{"location":"deeplearning/interview/#_10","title":"\ud83e\uddee \u4e8c\u3001\u6570\u5b66\u63a8\u5bfc\u4e0e\u635f\u5931\u51fd\u6570","text":""},{"location":"deeplearning/interview/#1-forward-propagation_1","title":"1\ufe0f\u20e3 \u524d\u5411\u4f20\u64ad\uff08Forward Propagation\uff09","text":"<p>\u5bf9\u4e8e\u5377\u79ef\u5c42\uff1a $$ z_{i,j}^{(l)} = \\sum_{m,n,c} a_{m+i, n+j, c}^{(l-1)} \\cdot w_{m,n,c}^{(l)} + b^{(l)} $$ $$ a_{i,j}^{(l)} = f(z_{i,j}^{(l)}) $$</p> <p>\u5bf9\u4e8e\u5168\u8fde\u63a5\u5c42\uff1a $$ a^{(L)} = f(W^{(L)}a^{(L-1)} + b^{(L)}) $$</p>"},{"location":"deeplearning/interview/#2-loss-function_1","title":"2\ufe0f\u20e3 \u635f\u5931\u51fd\u6570\uff08Loss Function\uff09","text":"<p>\u5206\u7c7b\u4efb\u52a1\u5e38\u7528\u4ea4\u53c9\u71b5\u635f\u5931\uff1a $$ L = -\\frac{1}{m}\\sum_{i=1}^{m}\\sum_{k=1}^{K}y_{ik}\\log(\\hat{y}_{ik}) $$</p>"},{"location":"deeplearning/interview/#3-backpropagation_1","title":"3\ufe0f\u20e3 \u53cd\u5411\u4f20\u64ad\uff08Backpropagation\uff09","text":"<p>\u53cd\u5411\u4f20\u64ad\u901a\u8fc7\u94fe\u5f0f\u6cd5\u5219\u8ba1\u7b97\u68af\u5ea6\u3002 \u5bf9\u4e8e\u5377\u79ef\u5c42\u4e2d\u7684\u6743\u91cd\u68af\u5ea6\uff1a</p> \\[ \\frac{\\partial L}{\\partial w_{m,n,c}} = \\sum_{i,j} \\frac{\\partial L}{\\partial z_{i,j}} \\cdot a_{i+m, j+n, c}^{(l-1)} \\] <p>\u5bf9\u4e8e\u504f\u7f6e\uff1a $$ \\frac{\\partial L}{\\partial b} = \\sum_{i,j} \\frac{\\partial L}{\\partial z_{i,j}} $$</p>"},{"location":"deeplearning/interview/#_11","title":"\ud83d\udcca \u4e09\u3001\u8bc4\u4f30\u6307\u6807","text":"\u4efb\u52a1\u7c7b\u578b \u5e38\u7528\u6307\u6807 \u5206\u7c7b Accuracy, Precision, Recall, F1, AUC \u56de\u5f52 MSE, RMSE, MAE, \\(R^2\\) \u76ee\u6807\u68c0\u6d4b mAP\uff08mean Average Precision\uff09 \u56fe\u50cf\u5206\u5272 IoU\uff08Intersection over Union\uff09"},{"location":"deeplearning/interview/#pytorch_1","title":"\ud83d\udcbb \u56db\u3001\u5b9e\u73b0\u4ee3\u7801\uff08PyTorch\uff09","text":"<p>\u4ee5\u4e0b\u662f\u4e00\u4e2a\u7ecf\u5178\u7684 CNN \u56fe\u50cf\u5206\u7c7b\u793a\u4f8b\uff08\u4f7f\u7528 MNIST \u6570\u636e\u96c6\uff09\uff1a</p> <pre><code>import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\n\n# 1. \u6570\u636e\u51c6\u5907\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,))\n])\ntrain_data = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\ntest_data = datasets.MNIST(root='./data', train=False, transform=transform)\ntrain_loader = DataLoader(train_data, batch_size=64, shuffle=True)\ntest_loader = DataLoader(test_data, batch_size=1000, shuffle=False)\n\n# 2. \u6a21\u578b\u5b9a\u4e49\nclass CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, 3, 1)   # 28x28 -&gt; 26x26\n        self.conv2 = nn.Conv2d(32, 64, 3, 1)  # 26x26 -&gt; 24x24\n        self.pool = nn.MaxPool2d(2)           # 24x24 -&gt; 12x12\n        self.fc1 = nn.Linear(64*12*12, 128)\n        self.fc2 = nn.Linear(128, 10)\n        self.relu = nn.ReLU()\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.pool(x)\n        x = torch.flatten(x, 1)\n        x = self.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n\nmodel = CNN()\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# 3. \u8bad\u7ec3\u8fc7\u7a0b\nfor epoch in range(5):\n    for data, target in train_loader:\n        optimizer.zero_grad()\n        output = model(data)\n        loss = criterion(output, target)\n        loss.backward()\n        optimizer.step()\n    print(f\"Epoch [{epoch+1}/5], Loss: {loss.item():.4f}\")\n\n# 4. \u6d4b\u8bd5\u8bc4\u4f30\ncorrect = 0\ntotal = 0\nwith torch.no_grad():\n    for data, target in test_loader:\n        output = model(data)\n        _, pred = torch.max(output.data, 1)\n        total += target.size(0)\n        correct += (pred == target).sum().item()\n\nprint(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n</code></pre>"},{"location":"deeplearning/interview/#_12","title":"\ud83e\udde9 \u4e94\u3001\u6a21\u578b\u4f18\u5316\u6280\u5de7","text":"\u4f18\u5316\u65b9\u6cd5 \u8bf4\u660e \u6570\u636e\u589e\u5f3a \u7ffb\u8f6c\u3001\u65cb\u8f6c\u3001\u88c1\u526a\u7b49\u65b9\u5f0f\u6269\u5145\u6570\u636e Dropout \u968f\u673a\u4e22\u5f03\u795e\u7ecf\u5143\uff0c\u9632\u6b62\u8fc7\u62df\u5408 Batch Normalization \u7a33\u5b9a\u8bad\u7ec3\uff0c\u63d0\u9ad8\u6536\u655b\u901f\u5ea6 \u5b66\u4e60\u7387\u8c03\u6574 \u4f7f\u7528\u8c03\u5ea6\u5668\uff08\u5982 StepLR\u3001ReduceLROnPlateau\uff09 \u6743\u91cd\u521d\u59cb\u5316 He \u521d\u59cb\u5316\u5e38\u7528\u4e8e ReLU \u8fc1\u79fb\u5b66\u4e60 \u4f7f\u7528\u9884\u8bad\u7ec3\u6a21\u578b\uff08\u5982 ResNet\u3001VGG\uff09\u5fae\u8c03"},{"location":"deeplearning/interview/#_13","title":"\u26a0\ufe0f \u516d\u3001\u6ce8\u610f\u4e8b\u9879","text":"<ol> <li>\u8f93\u5165\u6570\u636e\u9700 \u5f52\u4e00\u5316\uff08Normalization\uff09\uff1b</li> <li>\u5c0f\u5377\u79ef\u6838\uff08\u5982 3\u00d73\uff09\u901a\u5e38\u6548\u679c\u66f4\u597d\uff1b</li> <li>\u589e\u52a0\u5377\u79ef\u5c42\u6570\u53ef\u63d0\u53d6\u66f4\u62bd\u8c61\u7684\u7279\u5f81\uff1b</li> <li>\u907f\u514d\u5377\u79ef\u6838\u6570\u91cf\u8fc7\u5927\u5bfc\u81f4\u8ba1\u7b97\u91cf\u66b4\u589e\uff1b</li> <li>\u5c3d\u91cf\u4f7f\u7528 GPU \u52a0\u901f\u8bad\u7ec3\uff1b</li> <li>\u4f7f\u7528 Dropout \u548c BN \u9632\u6b62\u8fc7\u62df\u5408\u3002</li> </ol>"},{"location":"deeplearning/interview/#_14","title":"\u2696\ufe0f \u4e03\u3001\u4f18\u7f3a\u70b9","text":"\u4f18\u70b9 \u7f3a\u70b9 \u81ea\u52a8\u63d0\u53d6\u7279\u5f81\uff0c\u65e0\u9700\u624b\u5de5\u8bbe\u8ba1 \u8bad\u7ec3\u65f6\u95f4\u957f \u53c2\u6570\u5171\u4eab\uff0c\u51cf\u5c11\u53c2\u6570\u91cf \u5bf9\u5c0f\u6570\u636e\u96c6\u6613\u8fc7\u62df\u5408 \u5bf9\u5e73\u79fb\u3001\u7f29\u653e\u7b49\u5177\u6709\u9c81\u68d2\u6027 \u4e0d\u6613\u89e3\u91ca\uff08\u9ed1\u7bb1\uff09 \u9002\u5408\u56fe\u50cf\u3001\u8bed\u97f3\u3001\u89c6\u9891\u4efb\u52a1 \u7ed3\u6784\u8bbe\u8ba1\u4f9d\u8d56\u7ecf\u9a8c"},{"location":"deeplearning/interview/#cnn_1","title":"\ud83d\udcc8 \u516b\u3001\u7ecf\u5178 CNN \u67b6\u6784\u53d1\u5c55","text":"\u6a21\u578b \u5e74\u4efd \u7279\u70b9 LeNet-5 1998 \u6700\u65e9\u7684 CNN\uff0c\u624b\u5199\u6570\u5b57\u8bc6\u522b AlexNet 2012 ReLU + Dropout + GPU \u8bad\u7ec3 VGG 2014 \u4f7f\u7528\u5c0f\u5377\u79ef\u6838\u5806\u53e0 GoogLeNet 2014 \u5f15\u5165 Inception \u6a21\u5757 ResNet 2015 \u6b8b\u5dee\u8fde\u63a5\u89e3\u51b3\u68af\u5ea6\u6d88\u5931 DenseNet 2017 \u7279\u5f81\u590d\u7528\uff0c\u63d0\u9ad8\u68af\u5ea6\u6d41"},{"location":"deeplearning/interview/#_15","title":"\ud83e\udded \u4e5d\u3001\u5b66\u4e60\u4e0e\u8fdb\u9636\u8def\u7ebf","text":"\u9636\u6bb5 \u5b66\u4e60\u5185\u5bb9 \u5b9e\u8df5\u65b9\u5411 \u5165\u95e8 \u5377\u79ef\u3001\u6c60\u5316\u3001\u6fc0\u6d3b\u51fd\u6570 MNIST \u624b\u5199\u8bc6\u522b \u8fdb\u9636 BatchNorm\u3001Dropout\u3001\u4f18\u5316\u5668 CIFAR-10 \u5206\u7c7b \u63d0\u5347 ResNet\u3001VGG\u3001\u8fc1\u79fb\u5b66\u4e60 ImageNet \u9ad8\u9636 Faster R-CNN\u3001YOLO\u3001U-Net \u68c0\u6d4b\u4e0e\u5206\u5272"},{"location":"deeplearning/interview/#rnn","title":"\u4e09\u3001RNN","text":""},{"location":"deeplearning/interview/#rnn-recurrent-neural-network","title":"\ud83e\udde0 \u4e00\u3001RNN \u539f\u7406\uff08Recurrent Neural Network\uff09","text":""},{"location":"deeplearning/interview/#1_1","title":"1\ufe0f\u20e3 \u57fa\u672c\u601d\u60f3","text":"<p>\u4f20\u7edf\u524d\u9988\u795e\u7ecf\u7f51\u7edc\uff08\u5982 MLP\u3001CNN\uff09\u8f93\u5165\u4e0e\u8f93\u51fa\u72ec\u7acb\uff0c\u4f46\u5bf9\u4e8e\u5e8f\u5217\u6570\u636e\uff08\u5982\u6587\u672c\u3001\u8bed\u97f3\u3001\u65f6\u95f4\u5e8f\u5217\uff09\uff1a</p> <p>\u5f53\u524d\u65f6\u523b\u7684\u8f93\u51fa\u4e0d\u4ec5\u53d6\u51b3\u4e8e\u5f53\u524d\u8f93\u5165\uff0c\u8fd8\u4f9d\u8d56\u4e8e\u524d\u9762\u65f6\u523b\u7684\u72b6\u6001\u3002</p> <p>\u56e0\u6b64\uff0cRNN \u5f15\u5165\u4e86\u5faa\u73af\u7ed3\u6784\uff08Recurrent Structure\uff09\uff0c\u80fd\u591f\u201c\u8bb0\u4f4f\u201d\u524d\u4e00\u65f6\u523b\u7684\u4fe1\u606f\u3002</p>"},{"location":"deeplearning/interview/#2_1","title":"2\ufe0f\u20e3 \u7ed3\u6784\u56fe\uff08\u6838\u5fc3\u6982\u5ff5\uff09","text":"<p>RNN \u7684\u57fa\u672c\u5355\u5143\u53ef\u8868\u793a\u4e3a\uff1a</p> \\[ h_t = f(W_{xh}x_t + W_{hh}h_{t-1} + b_h) \\] \\[ \\hat{y}*t = g(W*{hy}h_t + b_y) \\] <p>\u5176\u4e2d\uff1a</p> <ul> <li>\\(x_t\\)\uff1a\u65f6\u523b \\(t\\) \u7684\u8f93\u5165</li> <li>\\(h_t\\)\uff1a\u9690\u85cf\u72b6\u6001\uff08\u9690\u542b\u8bb0\u5fc6\uff09</li> <li>\\(\\hat{y}_t\\)\uff1a\u8f93\u51fa</li> <li>\\(W_{xh}\\)\uff1a\u8f93\u5165\u5230\u9690\u85cf\u5c42\u7684\u6743\u91cd</li> <li>\\(W_{hh}\\)\uff1a\u9690\u85cf\u5c42\u5230\u9690\u85cf\u5c42\u7684\u6743\u91cd\uff08\u5faa\u73af\uff09</li> <li>\\(W_{hy}\\)\uff1a\u9690\u85cf\u5c42\u5230\u8f93\u51fa\u5c42\u7684\u6743\u91cd</li> </ul>"},{"location":"deeplearning/interview/#_16","title":"\u2699\ufe0f \u4e8c\u3001\u6570\u5b66\u63a8\u5bfc\u8fc7\u7a0b","text":""},{"location":"deeplearning/interview/#1-forward-propagation_2","title":"1\ufe0f\u20e3 \u524d\u5411\u4f20\u64ad\uff08Forward Propagation\uff09","text":"<p>\u8f93\u5165\u5e8f\u5217 \\(x = [x_1, x_2, ..., x_T]\\)\uff1a</p> <p>\u9690\u85cf\u72b6\u6001\u66f4\u65b0\uff1a $$ h_t = f(W_{xh}x_t + W_{hh}h_{t-1} + b_h) $$</p> <p>\u8f93\u51fa\uff1a $$ \\hat{y}t = g(W{hy}h_t + b_y) $$</p> <p>\u5176\u4e2d \\(f\\) \u901a\u5e38\u4e3a \\(\\tanh\\) \u6216 \\(\\text{ReLU}\\)\uff0c\\(g\\) \u5e38\u4e3a \\(\\text{Softmax}\\)\u3002</p>"},{"location":"deeplearning/interview/#2-loss-function_2","title":"2\ufe0f\u20e3 \u635f\u5931\u51fd\u6570\uff08Loss Function\uff09","text":"<p>\u5bf9\u4e8e\u5206\u7c7b\u4efb\u52a1\uff0c\u901a\u5e38\u4f7f\u7528 \u4ea4\u53c9\u71b5\u635f\u5931\uff1a</p> \\[ L = -\\frac{1}{T}\\sum_{t=1}^{T} y_t \\log(\\hat{y}_t) \\]"},{"location":"deeplearning/interview/#3-backpropagation-through-time-bptt","title":"3\ufe0f\u20e3 \u53cd\u5411\u4f20\u64ad\uff08Backpropagation Through Time, BPTT\uff09","text":"<p>RNN \u7684\u68af\u5ea6\u8981\u6cbf\u65f6\u95f4\u5c55\u5f00\uff0c\u53cd\u5411\u4f20\u64ad\u5230\u6bcf\u4e2a\u65f6\u95f4\u6b65\u3002</p> <p>\u68af\u5ea6\u8ba1\u7b97\u516c\u5f0f\uff1a</p> \\[ \\frac{\\partial L}{\\partial W_{hh}} = \\sum_{t=1}^{T} \\frac{\\partial L_t}{\\partial h_t} \\cdot \\frac{\\partial h_t}{\\partial W_{hh}} \\] <p>\u800c\u7531\u4e8e\u9690\u85cf\u72b6\u6001\u95f4\u5b58\u5728\u4f9d\u8d56\u5173\u7cfb\uff1a</p> \\[ \\frac{\\partial h_t}{\\partial W_{hh}} = \\frac{\\partial h_t}{\\partial h_{t-1}} \\cdot \\frac{\\partial h_{t-1}}{\\partial W_{hh}} + \\frac{\\partial h_t}{\\partial W_{hh}} \\] <p>\u56e0\u6b64\uff0c\u4f1a\u51fa\u73b0 \u68af\u5ea6\u6d88\u5931 / \u68af\u5ea6\u7206\u70b8 \u95ee\u9898\u3002 \u89e3\u51b3\u65b9\u6848\uff1a\u68af\u5ea6\u88c1\u526a\uff08Gradient Clipping\uff09\u3001LSTM\u3001GRU\u3002</p>"},{"location":"deeplearning/interview/#_17","title":"\ud83d\udcca \u4e09\u3001\u8bc4\u4f30\u6307\u6807","text":"\u4efb\u52a1\u7c7b\u578b \u5e38\u7528\u6307\u6807 \u5206\u7c7b\u4efb\u52a1 Accuracy, Precision, Recall, F1-score \u5e8f\u5217\u751f\u6210 Perplexity (\u56f0\u60d1\u5ea6) \u56de\u5f52\u4efb\u52a1 MSE, RMSE \u8bed\u8a00\u6a21\u578b BLEU, ROUGE\uff08\u81ea\u7136\u8bed\u8a00\u751f\u6210\uff09"},{"location":"deeplearning/interview/#pytorch_2","title":"\ud83d\udcbb \u56db\u3001\u5b9e\u73b0\u4ee3\u7801\uff08PyTorch\uff09","text":"<p>\u4ee5\u4e00\u4e2a\u5b57\u7b26\u5e8f\u5217\u5206\u7c7b\u4efb\u52a1\u4e3a\u4f8b\uff08RNN \u57fa\u672c\u7ed3\u6784\uff09\uff1a</p> <pre><code>import torch\nimport torch.nn as nn\nimport torch.optim as optim\n\n# \u6a21\u578b\u5b9a\u4e49\nclass RNNModel(nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim, num_layers=1):\n        super(RNNModel, self).__init__()\n        self.rnn = nn.RNN(input_dim, hidden_dim, num_layers, batch_first=True)\n        self.fc = nn.Linear(hidden_dim, output_dim)\n\n    def forward(self, x):\n        out, _ = self.rnn(x)\n        out = out[:, -1, :]  # \u53d6\u6700\u540e\u65f6\u523b\u7684\u8f93\u51fa\n        out = self.fc(out)\n        return out\n\n# \u6a21\u62df\u6570\u636e\nX = torch.randn(100, 10, 8)  # (batch, seq_len, input_dim)\ny = torch.randint(0, 2, (100,))\n\n# \u8d85\u53c2\u6570\ninput_dim = 8\nhidden_dim = 32\noutput_dim = 2\n\nmodel = RNNModel(input_dim, hidden_dim, output_dim)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.01)\n\n# \u8bad\u7ec3\nfor epoch in range(50):\n    optimizer.zero_grad()\n    outputs = model(X)\n    loss = criterion(outputs, y)\n    loss.backward()\n    optimizer.step()\n\n    if (epoch + 1) % 10 == 0:\n        print(f\"Epoch [{epoch+1}/50], Loss: {loss.item():.4f}\")\n</code></pre>"},{"location":"deeplearning/interview/#rnn_1","title":"\ud83e\udde9 \u4e94\u3001RNN \u7684\u5e38\u89c1\u53d8\u4f53","text":"\u6a21\u578b \u7279\u70b9 \u516c\u5f0f LSTM\uff08\u957f\u77ed\u671f\u8bb0\u5fc6\uff09 \u5f15\u5165\u201c\u95e8\u63a7\u673a\u5236\u201d\u9632\u6b62\u68af\u5ea6\u6d88\u5931 \\(f_t, i_t, o_t, c_t\\) GRU\uff08\u95e8\u63a7\u5faa\u73af\u5355\u5143\uff09 \u7b80\u5316 LSTM \u7ed3\u6784\uff0c\u53c2\u6570\u66f4\u5c11 \\(z_t, r_t\\) Bi-RNN\uff08\u53cc\u5411 RNN\uff09 \u540c\u65f6\u8003\u8651\u524d\u540e\u4fe1\u606f \\(h_t = [\\overrightarrow{h_t}, \\overleftarrow{h_t}]\\)"},{"location":"deeplearning/interview/#_18","title":"\ud83e\uddee \u516d\u3001\u6a21\u578b\u4f18\u5316\u65b9\u6cd5","text":"\u4f18\u5316\u624b\u6bb5 \u8bf4\u660e \u68af\u5ea6\u88c1\u526a\uff08Gradient Clipping\uff09 \u9650\u5236\u68af\u5ea6\u8303\u6570\uff0c\u9632\u6b62\u68af\u5ea6\u7206\u70b8 \u4f7f\u7528 LSTM / GRU \u89e3\u51b3\u957f\u671f\u4f9d\u8d56\u4e0e\u68af\u5ea6\u6d88\u5931\u95ee\u9898 Batch Normalization \u52a0\u901f\u6536\u655b Dropout \u9632\u6b62\u8fc7\u62df\u5408 \u5b66\u4e60\u7387\u8c03\u6574\uff08LR Scheduler\uff09 \u52a8\u6001\u8c03\u6574\u5b66\u4e60\u7387 Embedding \u5c42 \u5bf9\u79bb\u6563\u8f93\u5165\uff08\u5982\u8bcd\uff09\u505a\u7a20\u5bc6\u8868\u793a"},{"location":"deeplearning/interview/#_19","title":"\u26a0\ufe0f \u4e03\u3001\u6ce8\u610f\u4e8b\u9879","text":"<ol> <li>\u8f93\u5165\u5e8f\u5217\u9700\u7edf\u4e00\u957f\u5ea6\uff0c\u53ef\u4f7f\u7528 padding\uff1b</li> <li>\u8bad\u7ec3\u65f6\u53ef\u4f7f\u7528 PackedSequence \u63d0\u5347\u6548\u7387\uff1b</li> <li>\u907f\u514d\u65f6\u95f4\u6b65\u8fc7\u957f\uff0c\u5426\u5219\u68af\u5ea6\u4f20\u64ad\u56f0\u96be\uff1b</li> <li>\u9002\u5f53\u4f7f\u7528 Dropout / LayerNorm\uff1b</li> <li>\u82e5\u662f\u6587\u672c\u4efb\u52a1\uff0c\u63a8\u8350\u4f7f\u7528 LSTM / GRU\uff1b</li> <li>\u5efa\u8bae\u4f7f\u7528 GPU\uff08CUDA\uff09\u52a0\u901f\u3002</li> </ol>"},{"location":"deeplearning/interview/#_20","title":"\u2696\ufe0f \u516b\u3001\u4f18\u7f3a\u70b9","text":"\u4f18\u70b9 \u7f3a\u70b9 \u80fd\u6355\u83b7\u5e8f\u5217\u4f9d\u8d56\u5173\u7cfb \u957f\u5e8f\u5217\u4e2d\u68af\u5ea6\u6d88\u5931 \u53c2\u6570\u5171\u4eab\uff0c\u6a21\u578b\u89c4\u6a21\u8f83\u5c0f \u8bad\u7ec3\u65f6\u95f4\u957f \u80fd\u5904\u7406\u53d8\u957f\u8f93\u5165 \u65e0\u6cd5\u5e76\u884c\u8ba1\u7b97 \u5bf9\u65f6\u5e8f\u4efb\u52a1\u6548\u679c\u597d \u5bf9\u957f\u4f9d\u8d56\u5efa\u6a21\u6709\u9650\uff08\u9700 LSTM/GRU \u6539\u8fdb\uff09"},{"location":"deeplearning/interview/#_21","title":"\ud83d\udcc8 \u4e5d\u3001\u5178\u578b\u5e94\u7528\u573a\u666f","text":"\u5e94\u7528 \u4efb\u52a1\u7c7b\u578b \u793a\u4f8b \u8bed\u8a00\u5efa\u6a21 \u5e8f\u5217\u9884\u6d4b \u4e0b\u4e00\u4e2a\u8bcd\u9884\u6d4b \u6587\u672c\u5206\u7c7b \u5206\u7c7b \u60c5\u611f\u5206\u6790 \u5e8f\u5217\u6807\u6ce8 \u6807\u6ce8 \u547d\u540d\u5b9e\u4f53\u8bc6\u522b\uff08NER\uff09 \u8bed\u97f3\u8bc6\u522b \u5e8f\u5217\u5230\u5e8f\u5217 \u97f3\u9891\u8f6c\u6587\u5b57 \u65f6\u95f4\u5e8f\u5217\u9884\u6d4b \u56de\u5f52 \u80a1\u7968/\u5929\u6c14\u9884\u6d4b"},{"location":"deeplearning/interview/#_22","title":"\ud83e\udded \u5341\u3001\u5b66\u4e60\u8def\u7ebf\u5efa\u8bae","text":"\u9636\u6bb5 \u5185\u5bb9 \u5b9e\u8df5\u4efb\u52a1 \u5165\u95e8 \u57fa\u672c RNN \u7406\u8bba\u4e0e\u7ed3\u6784 \u7b80\u5355\u5e8f\u5217\u5206\u7c7b \u8fdb\u9636 LSTM\u3001GRU \u7406\u89e3\u4e0e\u5b9e\u73b0 \u6587\u672c\u5206\u7c7b \u63d0\u5347 \u53cc\u5411 RNN\u3001Seq2Seq \u673a\u5668\u7ffb\u8bd1 \u9ad8\u9636 Attention\u3001Transformer \u9ad8\u7ea7 NLP \u4efb\u52a1"},{"location":"deeplearning/interview/#lstm","title":"\u56db\u3001LSTM","text":""},{"location":"deeplearning/interview/#lstm-long-short-term-memory","title":"\ud83e\udde0 \u4e00\u3001LSTM \u539f\u7406\uff08Long Short-Term Memory\uff09","text":""},{"location":"deeplearning/interview/#1-lstm","title":"1\ufe0f\u20e3 \u4e3a\u4ec0\u4e48\u9700\u8981 LSTM\uff1f","text":"<p>\u5728\u666e\u901a RNN \u4e2d\uff1a $$ h_t = f(W_{xh}x_t + W_{hh}h_{t-1}) $$</p> <p>\u68af\u5ea6\u5728\u65f6\u95f4\u4e0a\u4f20\u9012\u65f6\u5bb9\u6613\uff1a</p> <ul> <li>\u68af\u5ea6\u6d88\u5931\uff08\u957f\u671f\u4f9d\u8d56\u4fe1\u606f\u65e0\u6cd5\u4fdd\u7559\uff09</li> <li>\u68af\u5ea6\u7206\u70b8\uff08\u8bad\u7ec3\u4e0d\u7a33\u5b9a\uff09</li> </ul> <p>\ud83d\udd39 LSTM \u901a\u8fc7\u5f15\u5165\u201c\u95e8\u63a7\u673a\u5236\uff08Gating Mechanism\uff09\u201d\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c \u4f7f\u5f97\u7f51\u7edc\u80fd\u591f\u201c\u51b3\u5b9a\u201d\u54ea\u4e9b\u4fe1\u606f\u4fdd\u7559\u3001\u54ea\u4e9b\u9057\u5fd8\u3002</p>"},{"location":"deeplearning/interview/#2-lstm","title":"2\ufe0f\u20e3 LSTM \u7ed3\u6784\u56fe","text":"<p>LSTM \u7684\u6bcf\u4e2a\u5355\u5143\u7531\u4e09\u4e2a\u95e8\uff08Gate\uff09\u548c\u4e00\u4e2a\u8bb0\u5fc6\u5355\u5143\uff08Cell State\uff09\u7ec4\u6210\uff1a</p> <pre><code>            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\nx_t \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6\u2502 \u8f93\u5165\u95e8 i_t   \u2502\nh_{t-1} \u2500\u2500\u2500\u25b6\u2502 \u9057\u5fd8\u95e8 f_t   \u2502\u2500\u2500\u2500\u2510\n            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n                               \u25bc\n                          c_{t-1}\n                               \u2502\n                               \u25bc\n                        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                        \u2502 \u7ec6\u80de\u72b6\u6001 c_t\u2502\n                        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                               \u2502\n                               \u25bc\n                        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                        \u2502 \u8f93\u51fa\u95e8 o_t  \u2502\n                        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                               \u2502\n                               \u25bc\n                              h_t\n</code></pre>"},{"location":"deeplearning/interview/#lstm_1","title":"\u2699\ufe0f \u4e8c\u3001LSTM \u6570\u5b66\u63a8\u5bfc\u8fc7\u7a0b","text":"<p>\u5728\u65f6\u95f4\u6b65 \\(t\\)\uff1a</p> <p>\u8f93\u5165\uff1a\\(x_t\\)\u3001\u524d\u4e00\u9690\u85cf\u72b6\u6001 \\(h_{t-1}\\)\u3001\u524d\u4e00\u7ec6\u80de\u72b6\u6001 \\(c_{t-1}\\)\u3002</p>"},{"location":"deeplearning/interview/#1_2","title":"1\ufe0f\u20e3 \u95e8\u63a7\u673a\u5236\u516c\u5f0f","text":""},{"location":"deeplearning/interview/#1forget-gate","title":"\uff081\uff09\u9057\u5fd8\u95e8\uff08Forget Gate\uff09","text":"<p>\u51b3\u5b9a\u8981\u201c\u5fd8\u8bb0\u201d\u591a\u5c11\u65e7\u4fe1\u606f\uff1a</p> \\[ f_t = \\sigma(W_f \\cdot [h_{t-1}, x_t] + b_f) \\]"},{"location":"deeplearning/interview/#2input-gate","title":"\uff082\uff09\u8f93\u5165\u95e8\uff08Input Gate\uff09","text":"<p>\u51b3\u5b9a\u8981\u6dfb\u52a0\u591a\u5c11\u65b0\u4fe1\u606f\uff1a</p> \\[ i_t = \\sigma(W_i \\cdot [h_{t-1}, x_t] + b_i) \\]"},{"location":"deeplearning/interview/#3candidate-cell","title":"\uff083\uff09\u5019\u9009\u72b6\u6001\uff08Candidate Cell\uff09","text":"<p>\u8ba1\u7b97\u5f53\u524d\u8f93\u5165\u7684\u5019\u9009\u8bb0\u5fc6\uff1a</p> \\[ \\tilde{c}*t = \\tanh(W_c \\cdot [h*{t-1}, x_t] + b_c) \\]"},{"location":"deeplearning/interview/#2_2","title":"2\ufe0f\u20e3 \u72b6\u6001\u66f4\u65b0","text":""},{"location":"deeplearning/interview/#4cell-state","title":"\uff084\uff09\u66f4\u65b0\u7ec6\u80de\u72b6\u6001\uff08Cell State\uff09","text":"<p>\u5c06\u65e7\u8bb0\u5fc6\u4e0e\u65b0\u8bb0\u5fc6\u7ed3\u5408\uff1a</p> \\[ c_t = f_t \\odot c_{t-1} + i_t \\odot \\tilde{c}_t \\]"},{"location":"deeplearning/interview/#5output-gate","title":"\uff085\uff09\u8f93\u51fa\u95e8\uff08Output Gate\uff09","text":"<p>\u51b3\u5b9a\u8f93\u51fa\u591a\u5c11\u5185\u90e8\u8bb0\u5fc6\uff1a</p> \\[ o_t = \\sigma(W_o \\cdot [h_{t-1}, x_t] + b_o) \\]"},{"location":"deeplearning/interview/#6hidden-state","title":"\uff086\uff09\u8ba1\u7b97\u9690\u85cf\u72b6\u6001\uff08Hidden State\uff09","text":"\\[ h_t = o_t \\odot \\tanh(c_t) \\]"},{"location":"deeplearning/interview/#3","title":"3\ufe0f\u20e3 \u635f\u5931\u51fd\u6570","text":"<p>\u5bf9\u4e8e\u5206\u7c7b\u4efb\u52a1\uff08\u5982\u6587\u672c\u5206\u7c7b\uff09\uff0c\u5e38\u4f7f\u7528\u4ea4\u53c9\u71b5\u635f\u5931\uff1a</p> \\[ L = -\\sum_{t=1}^{T} y_t \\log(\\hat{y}_t) \\] <p>\u82e5\u8f93\u51fa\u4e3a\u8fde\u7eed\u503c\uff08\u56de\u5f52\u4efb\u52a1\uff09\uff0c\u5219\u4f7f\u7528 MSE\uff1a</p> \\[ L = \\frac{1}{T} \\sum_{t=1}^{T} (y_t - \\hat{y}_t)^2 \\]"},{"location":"deeplearning/interview/#4-bptt","title":"4\ufe0f\u20e3 \u68af\u5ea6\u4f20\u64ad\uff08BPTT\uff09","text":"<p>LSTM \u4ecd\u901a\u8fc7\u201c\u65f6\u95f4\u53cd\u5411\u4f20\u64ad\uff08Backpropagation Through Time, BPTT\uff09\u201d\u8bad\u7ec3\u3002 \u4e0d\u540c\u4e8e RNN \u7684\u68af\u5ea6\u8fde\u4e58\uff0cLSTM \u7684 \u7ec6\u80de\u72b6\u6001 \\(c_t\\) \u80fd\u901a\u8fc7\u201c\u6052\u7b49\u4f20\u9012\u201d\u90e8\u5206\u68af\u5ea6\uff0c\u56e0\u6b64\u7f13\u89e3\u68af\u5ea6\u6d88\u5931\u3002</p>"},{"location":"deeplearning/interview/#_23","title":"\ud83d\udcca \u4e09\u3001\u8bc4\u4f30\u6307\u6807","text":"\u4efb\u52a1\u7c7b\u578b \u5e38\u7528\u6307\u6807 \u5206\u7c7b\u4efb\u52a1 Accuracy, Precision, Recall, F1-score \u56de\u5f52\u4efb\u52a1 MSE, MAE, RMSE \u5e8f\u5217\u9884\u6d4b Perplexity, BLEU, ROUGE"},{"location":"deeplearning/interview/#pytorch_3","title":"\ud83d\udcbb \u56db\u3001PyTorch \u5b9e\u73b0\u4ee3\u7801","text":"<p>\u4ee5\u4e0b\u662f\u4e00\u4e2a LSTM \u6587\u672c\u5206\u7c7b\u793a\u4f8b\uff1a</p> <pre><code>import torch\nimport torch.nn as nn\nimport torch.optim as optim\n\n# LSTM \u6a21\u578b\u5b9a\u4e49\nclass LSTMModel(nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim, num_layers=1):\n        super(LSTMModel, self).__init__()\n        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n        self.fc = nn.Linear(hidden_dim, output_dim)\n\n    def forward(self, x):\n        out, (h_n, c_n) = self.lstm(x)\n        out = self.fc(out[:, -1, :])  # \u53d6\u6700\u540e\u65f6\u523b\u8f93\u51fa\n        return out\n\n# \u6a21\u62df\u6570\u636e\nX = torch.randn(64, 10, 8)  # (batch, seq_len, input_dim)\ny = torch.randint(0, 2, (64,))\n\n# \u8d85\u53c2\u6570\nmodel = LSTMModel(input_dim=8, hidden_dim=32, output_dim=2)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.01)\n\n# \u8bad\u7ec3\u5faa\u73af\nfor epoch in range(30):\n    optimizer.zero_grad()\n    outputs = model(X)\n    loss = criterion(outputs, y)\n    loss.backward()\n    optimizer.step()\n\n    if (epoch + 1) % 5 == 0:\n        print(f\"Epoch [{epoch+1}/30], Loss: {loss.item():.4f}\")\n</code></pre>"},{"location":"deeplearning/interview/#lstm-rnn","title":"\ud83e\udde9 \u4e94\u3001LSTM \u4e0e RNN \u7684\u533a\u522b","text":"\u7279\u6027 RNN LSTM \u8bb0\u5fc6\u673a\u5236 \u5355\u4e00\u9690\u85cf\u72b6\u6001 \\(h_t\\) \u62e5\u6709\u7ec6\u80de\u72b6\u6001 \\(c_t\\) \u4e0e\u9690\u85cf\u72b6\u6001 \\(h_t\\) \u957f\u671f\u4f9d\u8d56\u80fd\u529b \u5dee\uff08\u68af\u5ea6\u6d88\u5931\uff09 \u5f3a\uff08\u901a\u8fc7\u95e8\u63a7\u673a\u5236\u63a7\u5236\uff09 \u53c2\u6570\u91cf \u5c11 \u591a \u8ba1\u7b97\u5f00\u9500 \u5c0f \u5927 \u9002\u7528\u573a\u666f \u77ed\u5e8f\u5217\u3001\u7b80\u5355\u5173\u7cfb \u957f\u5e8f\u5217\u3001\u590d\u6742\u4f9d\u8d56"},{"location":"deeplearning/interview/#_24","title":"\ud83e\uddee \u516d\u3001\u6a21\u578b\u4f18\u5316\u7b56\u7565","text":"\u65b9\u6cd5 \u8bf4\u660e \u68af\u5ea6\u88c1\u526a \u9650\u5236\u68af\u5ea6\u8303\u6570\uff0c\u9632\u6b62\u68af\u5ea6\u7206\u70b8 Dropout \u907f\u514d\u8fc7\u62df\u5408\uff08LSTM \u5185\u7f6e\u652f\u6301\uff09 \u53cc\u5411 LSTM \u540c\u65f6\u6355\u83b7\u524d\u540e\u6587\u4fe1\u606f \u591a\u5c42 LSTM \u63d0\u9ad8\u7279\u5f81\u8868\u8fbe\u80fd\u529b BatchNorm / LayerNorm \u52a0\u901f\u6536\u655b\u3001\u7a33\u5b9a\u8bad\u7ec3 \u5b66\u4e60\u7387\u8c03\u5ea6 \u4f7f\u7528 CosineAnnealing / StepLR \u7b49\u7b56\u7565 \u9884\u8bad\u7ec3\u8bcd\u5411\u91cf \u4f7f\u7528 Word2Vec\u3001GloVe\u3001BERT Embedding"},{"location":"deeplearning/interview/#_25","title":"\u26a0\ufe0f \u4e03\u3001\u6ce8\u610f\u4e8b\u9879","text":"<ol> <li>\u5e8f\u5217\u957f\u5ea6\u8fc7\u957f \u65f6\u8bad\u7ec3\u56f0\u96be\uff0c\u53ef\u4f7f\u7528\u622a\u65ad BPTT\uff1b</li> <li>Batch \u5185\u5e8f\u5217\u957f\u5ea6\u4e0d\u4e00 \u65f6\uff0c\u7528 <code>pack_padded_sequence</code>\uff1b</li> <li>\u82e5\u4efb\u52a1\u9700\u8981\u53cc\u5411\u4fe1\u606f\uff0c\u7528 <code>bidirectional=True</code>\uff1b</li> <li>\u8f93\u51fa\u7ef4\u5ea6\u8981\u5339\u914d\u4efb\u52a1\uff08\u5206\u7c7b vs \u56de\u5f52\uff09\uff1b</li> <li>\u5c3d\u91cf\u4f7f\u7528 GPU\uff1b</li> <li>\u907f\u514d\u5b66\u4e60\u7387\u8fc7\u5927\uff1b</li> <li>Dropout \u4e0d\u5b9c\u8fc7\u9ad8\uff08\u4e00\u822c 0.3\uff5e0.5\uff09\u3002</li> </ol>"},{"location":"deeplearning/interview/#_26","title":"\u2696\ufe0f \u516b\u3001\u4f18\u7f3a\u70b9\u603b\u7ed3","text":"\u4f18\u70b9 \u7f3a\u70b9 \u80fd\u6355\u6349\u957f\u8ddd\u79bb\u4f9d\u8d56 \u8bad\u7ec3\u6162\uff0c\u53c2\u6570\u591a \u89e3\u51b3\u68af\u5ea6\u6d88\u5931\u95ee\u9898 \u5bf9\u957f\u5e8f\u5217\u4ecd\u6709\u9650\u5236 \u6cdb\u5316\u80fd\u529b\u5f3a \u4e0d\u652f\u6301\u5e76\u884c\u8ba1\u7b97\uff08\u76f8\u8f83 Transformer\uff09 \u8868\u8fbe\u80fd\u529b\u9ad8 \u8c03\u53c2\u8f83\u590d\u6742"},{"location":"deeplearning/interview/#_27","title":"\ud83d\udcc8 \u4e5d\u3001\u5178\u578b\u5e94\u7528\u573a\u666f","text":"\u9886\u57df \u4efb\u52a1 \u793a\u4f8b NLP \u6587\u672c\u5206\u7c7b \u60c5\u611f\u5206\u6790 NLP \u5e8f\u5217\u751f\u6210 \u673a\u5668\u7ffb\u8bd1 \u8bed\u97f3 \u8bed\u97f3\u8bc6\u522b ASR \u65f6\u95f4\u5e8f\u5217 \u9884\u6d4b \u80a1\u7968\u3001\u5929\u6c14\u3001\u4f20\u611f\u5668 \u533b\u7597 \u751f\u7406\u4fe1\u53f7\u5206\u6790 ECG \u5fc3\u7535\u56fe\u9884\u6d4b"},{"location":"deeplearning/interview/#_28","title":"\ud83e\udded \u5341\u3001\u5b66\u4e60\u62d3\u5c55\u8def\u5f84","text":"\u9636\u6bb5 \u5185\u5bb9 \u63a8\u8350\u5b66\u4e60 \u5165\u95e8 LSTM \u7406\u8bba\u4e0e\u7ed3\u6784 \u7406\u89e3\u4e09\u95e8\u673a\u5236 \u8fdb\u9636 \u591a\u5c42 / \u53cc\u5411 LSTM \u6587\u672c\u5206\u7c7b\u4efb\u52a1 \u63d0\u5347 Seq2Seq + LSTM \u673a\u5668\u7ffb\u8bd1 \u9ad8\u9636 Attention + LSTM \u6587\u672c\u751f\u6210 / \u5bf9\u8bdd\u7cfb\u7edf \u62d3\u5c55 Transformer \u8d85\u8d8a LSTM \u7684\u5e8f\u5217\u5efa\u6a21"},{"location":"deeplearning/interview/#gan","title":"\u4e94\u3001GAN","text":""},{"location":"deeplearning/interview/#gan-generative-adversarial-network","title":"\ud83e\udde0 \u4e00\u3001GAN \u539f\u7406\uff08Generative Adversarial Network\uff09","text":""},{"location":"deeplearning/interview/#1_3","title":"1\ufe0f\u20e3 \u57fa\u672c\u601d\u60f3","text":"<p>GAN \u7531 \u751f\u6210\u5668\uff08Generator, G\uff09 \u548c \u5224\u522b\u5668\uff08Discriminator, D\uff09 \u7ec4\u6210\u3002</p> <ul> <li>\u751f\u6210\u5668 G\uff1a\u8bd5\u56fe\u4ece\u566a\u58f0\u4e2d\u751f\u6210\u903c\u771f\u7684\u6837\u672c\uff0c\u6b3a\u9a97\u5224\u522b\u5668\uff1b</li> <li>\u5224\u522b\u5668 D\uff1a\u8bd5\u56fe\u533a\u5206\u8f93\u5165\u6837\u672c\u662f\u771f\u5b9e\u6570\u636e\u8fd8\u662f\u751f\u6210\u6570\u636e\u3002</li> </ul> <p>\u4e24\u8005\u5f62\u6210\u4e00\u4e2a \u5bf9\u6297\u535a\u5f08\uff08minimax game\uff09\uff1a</p> <p>G \u60f3\u201c\u9a97\u8fc7\u201d D\uff0c\u800c D \u60f3\u201c\u8bc6\u7834\u201d G\u3002 \u6700\u7ec8\u8fbe\u5230\u4e00\u4e2a\u7eb3\u4ec0\u5e73\u8861\uff1aG \u751f\u6210\u7684\u6837\u672c\u4e0e\u771f\u5b9e\u6570\u636e\u51e0\u4e4e\u65e0\u6cd5\u533a\u5206\u3002</p>"},{"location":"deeplearning/interview/#2-gan","title":"2\ufe0f\u20e3 GAN \u7ed3\u6784\u793a\u610f\u56fe","text":"<pre><code>      \u968f\u673a\u566a\u58f0 z ~ p(z)\n               \u2502\n               \u25bc\n         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n         \u2502  \u751f\u6210\u5668 G   \u2502\u2500\u2500\u2500\u25b6 \u751f\u6210\u6837\u672c G(z)\n         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                 \u2502\n     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n     \u2502         \u5224\u522b\u5668 D          \u2502\n     \u2502  \u8f93\u51fa\uff1aP(\u771f\u5b9e or \u4f2a\u9020)   \u2502\n     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                 \u25b2\n         \u771f\u5b9e\u6837\u672c x ~ p_data(x)\n</code></pre>"},{"location":"deeplearning/interview/#_29","title":"\u2699\ufe0f \u4e8c\u3001\u6570\u5b66\u63a8\u5bfc\u8fc7\u7a0b","text":""},{"location":"deeplearning/interview/#1-minimax","title":"1\ufe0f\u20e3 \u76ee\u6807\u51fd\u6570\uff08Minimax \u5bf9\u6297\uff09","text":"<p>GAN \u7684\u6838\u5fc3\u4f18\u5316\u76ee\u6807\u4e3a\uff1a</p> \\[ \\min_G \\max_D V(D, G) = \\mathbb{E}*{x \\sim p*{\\text{data}}(x)}[\\log D(x)] + \\mathbb{E}_{z \\sim p_z(z)}[\\log(1 - D(G(z)))] \\] <p>\u5176\u4e2d\uff1a</p> <ul> <li>\\(D(x)\\) \u8868\u793a\u8f93\u5165\u4e3a\u771f\u5b9e\u6837\u672c\u7684\u6982\u7387\uff1b</li> <li>\\(G(z)\\) \u8868\u793a\u751f\u6210\u7684\u4f2a\u6837\u672c\uff1b</li> <li>\\(p_{\\text{data}}\\) \u662f\u771f\u5b9e\u6570\u636e\u5206\u5e03\uff1b</li> <li>\\(p_z\\) \u662f\u566a\u58f0\u5206\u5e03\uff08\u5982\u9ad8\u65af\u5206\u5e03\uff09\u3002</li> </ul>"},{"location":"deeplearning/interview/#2_3","title":"2\ufe0f\u20e3 \u5224\u522b\u5668\u76ee\u6807","text":"<p>\u56fa\u5b9a\u751f\u6210\u5668 \\(G\\) \u65f6\uff0c\u5224\u522b\u5668 \\(D\\) \u7684\u6700\u4f18\u89e3\u4e3a\uff1a</p> \\[ D^*(x) = \\frac{p_{\\text{data}}(x)}{p_{\\text{data}}(x) + p_g(x)} \\] <p>\u5176\u4e2d \\(p_g(x)\\) \u662f\u751f\u6210\u5668\u5206\u5e03\u3002</p>"},{"location":"deeplearning/interview/#3_1","title":"3\ufe0f\u20e3 \u6700\u4f18\u60c5\u51b5\u4e0b\u7684\u76ee\u6807\u503c","text":"<p>\u5c06 \\(D^*(x)\\) \u4ee3\u5165\u76ee\u6807\u51fd\u6570\uff0c\u6709\uff1a</p> \\[ V(G, D^*) = -\\log 4 + 2 \\cdot \\text{JSD}(p_{\\text{data}} \\parallel p_g) \\] <p>\u5373\uff0cGAN \u7684\u8bad\u7ec3\u7b49\u4ef7\u4e8e \u6700\u5c0f\u5316\u6570\u636e\u5206\u5e03\u4e0e\u751f\u6210\u5206\u5e03\u7684 Jensen\u2013Shannon \u6563\u5ea6\uff08JSD\uff09\u3002</p>"},{"location":"deeplearning/interview/#4","title":"4\ufe0f\u20e3 \u635f\u5931\u51fd\u6570\u5f62\u5f0f","text":"<p>\u8bad\u7ec3\u4e2d\u901a\u5e38\u4f7f\u7528\u4e24\u4e2a\u635f\u5931\u51fd\u6570\uff1a</p> <ul> <li> <p>\u5224\u522b\u5668\u635f\u5931\uff1a   $$   L_D = -\\mathbb{E}{x \\sim p{\\text{data}}}[\\log D(x)] - \\mathbb{E}_{z \\sim p_z}[\\log(1 - D(G(z)))]   $$</p> </li> <li> <p>\u751f\u6210\u5668\u635f\u5931\uff08\u539f\u59cb\u5f62\u5f0f\uff09\uff1a   $$   L_G = -\\mathbb{E}_{z \\sim p_z}[\\log(1 - D(G(z)))]   $$</p> </li> </ul> <p>\u4f46\u5b9e\u8df5\u4e2d\u5e38\u7528 \u975e\u9971\u548c\u5f62\u5f0f\uff1a $$ L_G = -\\mathbb{E}_{z \\sim p_z}[\\log D(G(z))] $$ \u8fd9\u6837\u53ef\u4ee5\u7f13\u89e3\u68af\u5ea6\u6d88\u5931\u95ee\u9898\u3002</p>"},{"location":"deeplearning/interview/#_30","title":"\ud83d\udcca \u4e09\u3001\u8bc4\u4f30\u6307\u6807","text":"\u6307\u6807 \u542b\u4e49 \u8bf4\u660e FID (Fr\u00e9chet Inception Distance) \u8861\u91cf\u751f\u6210\u56fe\u50cf\u4e0e\u771f\u5b9e\u56fe\u50cf\u7684\u7279\u5f81\u5206\u5e03\u5dee\u8ddd \u8d8a\u4f4e\u8d8a\u597d IS (Inception Score) \u8861\u91cf\u751f\u6210\u6837\u672c\u7684\u591a\u6837\u6027\u4e0e\u8d28\u91cf \u8d8a\u9ad8\u8d8a\u597d Precision / Recall for GANs \u8861\u91cf\u771f\u5b9e\u6027\u4e0e\u591a\u6837\u6027 \u5e73\u8861\u6307\u6807 \u89c6\u89c9\u8bc4\u4f30 \u4eba\u5de5\u4e3b\u89c2\u8d28\u91cf \u5e38\u7528\u4e8e\u56fe\u50cf\u4efb\u52a1"},{"location":"deeplearning/interview/#pytorch_4","title":"\ud83d\udcbb \u56db\u3001PyTorch \u5b9e\u73b0\u4ee3\u7801","text":"<p>\u4ee5\u4e0b\u4e3a\u4e00\u4e2a\u6700\u5c0f\u53ef\u8fd0\u884c\u7684 GAN \u5b9e\u4f8b\uff08MNIST \u6570\u636e\u96c6\uff09\uff1a</p> <pre><code>import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\n\n# 1. \u5b9a\u4e49\u751f\u6210\u5668\nclass Generator(nn.Module):\n    def __init__(self, noise_dim=100, output_dim=784):\n        super(Generator, self).__init__()\n        self.net = nn.Sequential(\n            nn.Linear(noise_dim, 256),\n            nn.ReLU(),\n            nn.Linear(256, 512),\n            nn.ReLU(),\n            nn.Linear(512, output_dim),\n            nn.Tanh()\n        )\n\n    def forward(self, z):\n        return self.net(z)\n\n# 2. \u5b9a\u4e49\u5224\u522b\u5668\nclass Discriminator(nn.Module):\n    def __init__(self, input_dim=784):\n        super(Discriminator, self).__init__()\n        self.net = nn.Sequential(\n            nn.Linear(input_dim, 512),\n            nn.LeakyReLU(0.2),\n            nn.Linear(512, 256),\n            nn.LeakyReLU(0.2),\n            nn.Linear(256, 1),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        return self.net(x)\n\n# 3. \u521d\u59cb\u5316\u6a21\u578b\u4e0e\u4f18\u5316\u5668\nG = Generator()\nD = Discriminator()\ncriterion = nn.BCELoss()\noptimizer_G = optim.Adam(G.parameters(), lr=0.0002)\noptimizer_D = optim.Adam(D.parameters(), lr=0.0002)\n\n# 4. \u6570\u636e\u52a0\u8f7d\ntransform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\ndata_loader = torch.utils.data.DataLoader(\n    datasets.MNIST('.', train=True, download=True, transform=transform),\n    batch_size=64, shuffle=True\n)\n\n# 5. \u8bad\u7ec3\u5faa\u73af\nfor epoch in range(10):\n    for real_imgs, _ in data_loader:\n        bs = real_imgs.size(0)\n        real_imgs = real_imgs.view(bs, -1)\n        z = torch.randn(bs, 100)\n        fake_imgs = G(z)\n\n        # \u6807\u7b7e\n        real_label = torch.ones(bs, 1)\n        fake_label = torch.zeros(bs, 1)\n\n        # --- \u5224\u522b\u5668\u8bad\u7ec3 ---\n        optimizer_D.zero_grad()\n        real_loss = criterion(D(real_imgs), real_label)\n        fake_loss = criterion(D(fake_imgs.detach()), fake_label)\n        d_loss = real_loss + fake_loss\n        d_loss.backward()\n        optimizer_D.step()\n\n        # --- \u751f\u6210\u5668\u8bad\u7ec3 ---\n        optimizer_G.zero_grad()\n        g_loss = criterion(D(fake_imgs), real_label)\n        g_loss.backward()\n        optimizer_G.step()\n\n    print(f\"Epoch [{epoch+1}/10]  D Loss: {d_loss.item():.4f}  G Loss: {g_loss.item():.4f}\")\n</code></pre>"},{"location":"deeplearning/interview/#gan_1","title":"\ud83e\udde9 \u4e94\u3001\u5e38\u89c1 GAN \u53d8\u4f53","text":"\u6a21\u578b \u7279\u70b9 \u635f\u5931\u51fd\u6570\u6539\u8fdb DCGAN \u5377\u79ef\u7ed3\u6784\uff08\u56fe\u50cf\u751f\u6210\uff09 \u7a33\u5b9a\u8bad\u7ec3 WGAN \u4f7f\u7528 Wasserstein \u8ddd\u79bb \u6539\u5584\u6a21\u5f0f\u5d29\u6e83 WGAN-GP \u52a0\u5165\u68af\u5ea6\u60e9\u7f5a \u6536\u655b\u66f4\u7a33\u5b9a Conditional GAN (cGAN) \u6761\u4ef6\u751f\u6210 \\(G(z, y), D(x, y)\\) CycleGAN \u65e0\u9700\u914d\u5bf9\u6837\u672c\u7684\u56fe\u50cf\u8f6c\u6362 \u7528\u5faa\u73af\u4e00\u81f4\u6027\u635f\u5931 StyleGAN \u63a7\u5236\u751f\u6210\u56fe\u50cf\u98ce\u683c \u9ad8\u8d28\u91cf\u56fe\u50cf\u751f\u6210"},{"location":"deeplearning/interview/#_31","title":"\ud83e\uddee \u516d\u3001\u6a21\u578b\u4f18\u5316\u6280\u5de7","text":"\u65b9\u6cd5 \u8bf4\u660e \u6807\u7b7e\u5e73\u6ed1\uff08Label Smoothing\uff09 \u5c06\u771f\u5b9e\u6807\u7b7e\u4ece 1 \u6539\u4e3a 0.9\uff0c\u7a33\u5b9a\u8bad\u7ec3 \u7279\u5f81\u5339\u914d\uff08Feature Matching\uff09 \u7528\u4e2d\u95f4\u7279\u5f81\u5c42\u8bad\u7ec3\u751f\u6210\u5668 \u4f7f\u7528 Wasserstein \u635f\u5931 \u7f13\u89e3\u68af\u5ea6\u6d88\u5931\u3001\u6a21\u5f0f\u5d29\u6e83 \u68af\u5ea6\u60e9\u7f5a\uff08Gradient Penalty\uff09 \u4fdd\u8bc1 1-Lipschitz \u6761\u4ef6 \u8c31\u5f52\u4e00\u5316\uff08Spectral Norm\uff09 \u9650\u5236\u6743\u91cd\u8303\u6570 \u5b66\u4e60\u7387\u5206\u79bb G \u7684\u5b66\u4e60\u7387\u7565\u9ad8\u4e8e D"},{"location":"deeplearning/interview/#_32","title":"\u26a0\ufe0f \u4e03\u3001\u6ce8\u610f\u4e8b\u9879","text":"<ol> <li>GAN \u8bad\u7ec3 \u6781\u4e0d\u7a33\u5b9a\uff1b</li> <li>D \u592a\u5f3a \u21d2 G \u65e0\u68af\u5ea6\uff1bD \u592a\u5f31 \u21d2 G \u6b3a\u9a97\u5bb9\u6613\uff1b</li> <li>\u521d\u59cb\u5b66\u4e60\u7387\u9700\u5c0f\uff1b</li> <li>\u9700\u540c\u65f6\u76d1\u63a7 D \u4e0e G \u7684\u635f\u5931\uff1b</li> <li>\u5efa\u8bae\u4f7f\u7528 WGAN / WGAN-GP\uff1b</li> <li>\u5bf9\u56fe\u50cf\u751f\u6210\u4efb\u52a1\uff0c\u63a8\u8350 DCGAN \u67b6\u6784\uff1b</li> <li>\u8bad\u7ec3\u4e2d\u53ef\u52a8\u6001\u8c03\u6574\u5224\u522b\u5668\u8bad\u7ec3\u6b21\u6570\u3002</li> </ol>"},{"location":"deeplearning/interview/#_33","title":"\u2696\ufe0f \u516b\u3001\u4f18\u7f3a\u70b9","text":"\u4f18\u70b9 \u7f3a\u70b9 \u751f\u6210\u8d28\u91cf\u9ad8 \u8bad\u7ec3\u4e0d\u7a33\u5b9a \u65e0\u9700\u663e\u5f0f\u5efa\u6a21\u6982\u7387\u5bc6\u5ea6 \u6a21\u5f0f\u5d29\u6e83\uff08\u751f\u6210\u6837\u672c\u5355\u4e00\uff09 \u7406\u8bba\u4e0a\u53ef\u751f\u6210\u4efb\u610f\u5206\u5e03 \u8bc4\u4ef7\u6307\u6807\u4e0d\u5b8c\u7f8e \u5e94\u7528\u5e7f\u6cdb \u5bf9\u8d85\u53c2\u6570\u654f\u611f"},{"location":"deeplearning/interview/#_34","title":"\ud83d\udcc8 \u4e5d\u3001\u5178\u578b\u5e94\u7528\u573a\u666f","text":"\u9886\u57df \u5e94\u7528 \u793a\u4f8b \u56fe\u50cf\u751f\u6210 \u624b\u5199\u6570\u5b57\u3001\u4eba\u8138\u751f\u6210 DCGAN, StyleGAN \u56fe\u50cf\u5230\u56fe\u50cf\u8f6c\u6362 \u9a6c\u2194\u6591\u9a6c\u3001\u590f\u2194\u51ac CycleGAN \u8d85\u5206\u8fa8\u7387\u91cd\u5efa SRGAN \u56fe\u50cf\u6e05\u6670\u5316 \u6570\u636e\u589e\u5f3a \u533b\u5b66\u5f71\u50cf\u3001\u8bed\u97f3\u751f\u6210 cGAN \u6587\u672c\u5230\u56fe\u50cf Text2Image GAN \u6587\u672c\u751f\u6210\u56fe\u50cf"},{"location":"deeplearning/interview/#_35","title":"\ud83e\udded \u5341\u3001\u5b66\u4e60\u62d3\u5c55\u8def\u7ebf","text":"\u9636\u6bb5 \u5b66\u4e60\u76ee\u6807 \u793a\u4f8b \u5165\u95e8 \u7406\u89e3 GAN \u5bf9\u6297\u673a\u5236 \u8bad\u7ec3\u539f\u59cb GAN \u8fdb\u9636 DCGAN / WGAN-GP \u7406\u89e3 \u56fe\u50cf\u751f\u6210\u4efb\u52a1 \u63d0\u5347 \u6761\u4ef6\u751f\u6210\u3001CycleGAN \u98ce\u683c\u8fc1\u79fb \u9ad8\u9636 StyleGAN, Diffusion \u9ad8\u5206\u8fa8\u7387\u4eba\u8138\u751f\u6210 \u7814\u7a76\u65b9\u5411 \u7406\u8bba\u7a33\u5b9a\u6027\u3001\u5bf9\u6297\u9c81\u68d2\u6027 GAN \u7406\u8bba\u5206\u6790"},{"location":"llm/deploy/Gradio/tutorial/","title":"Gradio","text":""},{"location":"llm/deploy/Gradio/tutorial/#gradio","title":"\ud83d\ude80 \u7b2c\u4e00\u7ae0\uff1aGradio \u662f\u4ec0\u4e48\uff1f","text":"<p>Gradio \u662f\u4e00\u4e2a Python \u5e93\uff0c\u7528\u6781\u5c11\u4ee3\u7801\u5c31\u80fd\u7ed9\u4f60\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u6216\u4efb\u610f\u51fd\u6570\u521b\u5efa\u4ea4\u4e92\u5f0f Web \u754c\u9762\u3002 \u65e0\u9700\u524d\u7aef\u77e5\u8bc6\uff0c\u4e0d\u7528\u642d\u670d\u52a1\u5668\uff0c\u4e0d\u9700\u8981 React \u7684\u7075\u9b42\u51fa\u7a8d\u3002</p> <p>\u4e00\u53e5\u8bdd\uff1a\u8ba9\u522b\u4eba\u7528\u9f20\u6807\u70b9\u70b9\u4f60\u7684 AI\uff01</p> <p>\u793a\u610f\u4f8b\u5b50\uff1a</p> <pre><code>import gradio as gr\n\ndef hello(name):\n    return f\"\u4f60\u597d\uff0c{name}\uff01\"\n\ngr.Interface(fn=hello, inputs=\"text\", outputs=\"text\").launch()\n</code></pre> <p>\u8fd0\u884c\u540e\uff0c\u5b83\u4f1a\u81ea\u52a8\u5728\u672c\u5730\u5f00\u4e00\u4e2a Web \u754c\u9762\uff0c\u53ef\u80fd\u8fd8\u987a\u4fbf\u9001\u4f60\u4e00\u4e2a\u516c\u7f51\u5206\u4eab\u94fe\u63a5\u3002</p>"},{"location":"llm/deploy/Gradio/tutorial/#inputs-outputs","title":"\ud83d\udd2e \u7b2c\u4e8c\u7ae0\uff1a\u57fa\u7840\u7ec4\u4ef6\uff08inputs / outputs\uff09","text":"<p>\u5e38\u89c1\u8f93\u5165\u63a7\u4ef6\uff1a</p> \u7c7b\u578b \u540d\u5b57 \u793a\u4f8b \u6587\u672c <code>\"text\"</code> \u8f93\u5165\u4e00\u53e5\u8bdd \u56fe\u50cf <code>\"image\"</code> \u4e0a\u4f20\u6216\u62cd\u7167 \u6570\u5b57 <code>\"number\"</code> \u8f93\u5165\u6570\u503c \u6ed1\u6761 <code>\"slider\"</code> \u9009\u62e9\u8303\u56f4\u503c \u4e0b\u62c9\u83dc\u5355 <code>\"dropdown\"</code> \u591a\u9009\u4e00 <p>\u5e38\u89c1\u8f93\u51fa\u63a7\u4ef6\uff1a</p> \u7c7b\u578b \u540d\u5b57 \u793a\u4f8b <code>\"text\"</code> \u6587\u672c\u7ed3\u679c <code>\"label\"</code> \u5206\u7c7b\u6807\u7b7e <code>\"image\"</code> \u56fe\u50cf\u8f93\u51fa <code>\"plot\"</code> \u7ed8\u56fe <p>\u7b80\u5355\u793a\u4f8b\uff1a</p> <pre><code>import gradio as gr\nimport numpy as np\n\ndef invert(image):\n    return 255 - image\n\ngr.Interface(fn=invert, inputs=\"image\", outputs=\"image\").launch()\n</code></pre> <p>AI \u7167\u76f8\u9986\uff1a\u628a\u56fe\u7247\u53d8\u6210\u53cd\u8272\u4e16\u754c\u3002</p>"},{"location":"llm/deploy/Gradio/tutorial/#blocks","title":"\ud83c\udf9b \u7b2c\u4e09\u7ae0\uff1aBlocks \u2014\u2014 \u5b9a\u5236\u5316\u754c\u9762","text":"<p>Interface \u662f\u50bb\u74dc\u5f0f\u4e00\u628a\u68ad\u3002 Blocks \u5219\u662f\u79ef\u6728\uff1a\u4f60\u60f3\u600e\u4e48\u642d\u90fd\u884c\u3002</p> <p>\u4f8b\u5b50\uff1a\u4e24\u4e2a\u8f93\u5165\uff0c\u4e00\u4e2a\u8f93\u51fa\uff0c\u4e00\u9897\u6309\u94ae\u638c\u63a7\u4e7e\u5764\u3002</p> <pre><code>import gradio as gr\n\ndef calculate(a, b):\n    return a + b\n\nwith gr.Blocks() as demo:\n    gr.Markdown(\"# \u7b80\u6613\u52a0\u6cd5\u5668\")\n    x = gr.Number(label=\"\u6570\u5b57 A\")\n    y = gr.Number(label=\"\u6570\u5b57 B\")\n    btn = gr.Button(\"\u5f00\u59cb\u8ba1\u7b97\")\n    result = gr.Textbox(label=\"\u7ed3\u679c\")\n\n    btn.click(fn=calculate, inputs=[x, y], outputs=result)\n\ndemo.launch()\n</code></pre> <p>Blocks \u8ba9\u4f60\u53ef\u4ee5\u6dfb\u52a0\u6392\u7248\u3001\u4e8b\u4ef6\u89e6\u53d1\u3001\u8fdb\u5ea6\u6761\u3001\u804a\u5929\u754c\u9762\u7b49\u3002</p>"},{"location":"llm/deploy/Gradio/tutorial/#ai","title":"\ud83e\udd16 \u7b2c\u56db\u7ae0\uff1a\u6587\u672c\u751f\u6210 / AI \u6a21\u578b\u793a\u4f8b","text":"<p>\u63a5\u4e00\u4e2a Hugging Face Transformers \u6587\u672c\u751f\u6210\u6a21\u578b\uff1a</p> <pre><code>import gradio as gr\nfrom transformers import pipeline\n\ngenerator = pipeline(\"text-generation\", model=\"gpt2\")\n\ndef generate(prompt):\n    return generator(prompt, max_length=50)[0][\"generated_text\"]\n\ngr.Interface(fn=generate, inputs=\"text\", outputs=\"text\").launch()\n</code></pre> <p>\u4f60\u505a\u4e86\u4e00\u4e2a\u8ff7\u4f60 ChatGPT\uff08\u8bed\u8a00\u80fd\u529b\u5c0f\u5b66\u751f\u7248\uff09\u3002</p>"},{"location":"llm/deploy/Gradio/tutorial/#_1","title":"\ud83c\udfa8 \u7b2c\u4e94\u7ae0\uff1a\u56fe\u50cf\u5904\u7406\u793a\u4f8b\uff08\u4e0a\u4f20+\u663e\u793a\u7ed3\u679c\uff09","text":"<pre><code>import gradio as gr\nfrom PIL import Image\n\ndef flip(img):\n    return img.transpose(Image.FLIP_LEFT_RIGHT)\n\ngr.Interface(fn=flip, inputs=\"image\", outputs=\"image\").launch()\n</code></pre> <p>\u955c\u50cf\u7ffb\u8f6c\uff0c\u81ea\u62cd\u7684\u5de6\u8138\u548c\u53f3\u8138\u4e92\u6362\u547d\u8fd0\u3002</p>"},{"location":"llm/deploy/Gradio/tutorial/#_2","title":"\ud83d\udce1 \u7b2c\u516d\u7ae0\uff1a\u90e8\u7f72\u5206\u4eab","text":"<p>Gradio \u4f1a\u81ea\u52a8\u751f\u6210\uff1a</p> <ul> <li>\u672c\u673a URL\uff08localhost\uff09</li> <li>\u53ef\u516c\u7f51\u8bbf\u95ee\u7684 share \u94fe\u63a5</li> </ul> <p>\u547d\u4ee4\u884c\u90e8\u7f72\uff1a</p> <pre><code>gradio app.py\n</code></pre> <p>\u60f3\u7ed9\u670b\u53cb\u70ab\u4e00\u4e0b\u6a21\u578b\uff0c\u5c31\u50cf\u53d1\u5916\u94fe\u4e00\u6837\u7b80\u5355\u3002</p> <p>\u7ebf\u4e0a\u90e8\u7f72\u53ef\u4ee5\u7528 Hugging Face Spaces\uff08\u514d\u8d39\uff09\u3002</p>"},{"location":"llm/deploy/Gradio/tutorial/#chatbot","title":"\ud83e\udde0 \u7b2c\u4e03\u7ae0\uff1a\u591a\u8f6e\u5bf9\u8bdd\uff08Chatbot\uff09","text":"<p>\u4f8b\u5b50\uff1a\u5e26\u804a\u5929\u8bb0\u5f55\u7684\u56de\u58f0\u673a\u5668\u4eba\u3002</p> <pre><code>import gradio as gr\n\ndef chat(message, history):\n    history = history or []\n    response = f\"\u4f60\u8bf4\u7684\u662f\uff1a{message}\"\n    history.append((message, response))\n    return history, history\n\nwith gr.Blocks() as demo:\n    chatbot = gr.Chatbot()\n    msg = gr.Textbox()\n    btn = gr.Button(\"\u53d1\u9001\")\n    btn.click(chat, [msg, chatbot], [chatbot, chatbot])\n\ndemo.launch()\n</code></pre> <p>\u7b80\u5355\u5374\u5145\u6ee1\u65e0\u9650\u53ef\u80fd\u3002</p>"},{"location":"llm/deploy/Gradio/tutorial/#_3","title":"\ud83d\udd25 \u7b2c\u516b\u7ae0\uff1a\u6587\u4ef6\u8f93\u5165 / \u8f93\u51fa","text":"<pre><code>import gradio as gr\n\ndef file_info(file):\n    return f\"\u6587\u4ef6\u540d\uff1a{file.name}\"\n\ninterface = gr.Interface(fn=file_info, inputs=\"file\", outputs=\"text\")\ninterface.launch()\n</code></pre> <p>\u63a5\u6536\u6587\u4ef6 \u2192 \u8f93\u51fa\u4fe1\u606f\u3002</p>"},{"location":"llm/deploy/Gradio/tutorial/#_4","title":"\ud83c\udf93 \u8fdb\u9636\u6280\u5de7","text":"<ol> <li>\u81ea\u5b9a\u4e49 CSS</li> <li>\u5b9e\u65f6\u66f4\u65b0\uff08live=True\uff09</li> <li>\u5e76\u53d1\u63a7\u5236 queue()</li> <li>\u4e8b\u4ef6\u94fe\u63a5\uff1achange / submit</li> <li>\u6743\u91cd\u7f13\u5b58 + GPU \u52a0\u901f</li> </ol> <p>\u793a\u610f queue\uff1a</p> <pre><code>demo.queue().launch()\n</code></pre> <p>\u907f\u514d\u9ad8\u5e76\u53d1\u201c\u70b8\u673a\u201d\u3002</p>"},{"location":"llm/deploy/Gradio/tutorial/#_5","title":"\ud83e\udde9 \u5c0f\u6311\u6218\uff08\u82e5\u4f60\u60f3\u7ee7\u7eed\u5347\u7ea7\uff09","text":"<p>\u4f60\u53ef\u4ee5\u8bd5\u8bd5\uff1a</p> <ul> <li>\u505a\u4e00\u4e2a\u8bed\u97f3\u8bc6\u522b + \u8bed\u97f3\u56de\u590d\u7684 AI \u52a9\u624b</li> <li>\u505a\u4e00\u4e2a\u56fe\u50cf\u5206\u7c7b\u5668\u5e76\u52a0\u4e0a Grad-CAM \u53ef\u89e3\u91ca\u6027\u53ef\u89c6\u5316</li> <li>\u505a\u4e00\u4e2a\u804a\u5929\u5927\u6a21\u578b\u7684 UI\uff0c\u652f\u6301\u601d\u7ef4\u94fe\u5c55\u793a</li> </ul> <p>\u6bcf\u4e2a\u65b9\u5411\u90fd\u662f\u65b0\u7684\u5192\u9669\u5c9b\u3002</p>"},{"location":"llm/deploy/Gradio/tutorial/#_6","title":"\u2705 \u603b\u7ed3","text":"<p>Gradio \u8ba9\u6a21\u578b\u201c\u53ef\u89c1\u3001\u53ef\u89e6\u3001\u53ef\u73a9\u201d\u3002 \u5b83\u5c31\u50cf\u7ed9\u4f60\u7684\u4ee3\u7801\u63d2\u4e0a UI \u7684\u7fc5\u8180\uff0c\u8ba9\u522b\u4eba\u770b\u89c1\u4f60\u7684\u8111\u6d1e\u3002</p> <p>\u5982\u679c\u4f60\u613f\u610f\uff0c\u6211\u53ef\u4ee5\u7ee7\u7eed\u6269\u5c55\uff1a</p> <ul> <li>\u6df1\u5ea6 Blocks \u6280\u5de7</li> <li>\u66f4\u590d\u6742\u5e03\u5c40\uff08Tabs\u3001Column\u3001Row\uff09</li> <li>\u4e0a\u4f20\u5230 Hugging Face Spaces \u90e8\u7f72\u5b8c\u6574\u9879\u76ee</li> <li>\u52a0\u5b89\u5168\u8ba4\u8bc1\u3001\u6570\u636e\u5e93\u3001\u7528\u6237\u7ba1\u7406</li> </ul> <p>\u7ee7\u7eed\u73a9\u4e0b\u53bb\uff0c\u4f60\u4f1a\u62e5\u6709\u81ea\u5df1\u7684 AI \u5e94\u7528\u5546\u5e97\u3002</p>"},{"location":"llm/deploy/Streamlit/tutorial/","title":"Streamlit \u5b8c\u6574\u6559\u7a0b\uff1a\u4ece\u57fa\u7840\u5230\u9ad8\u7ea7","text":""},{"location":"llm/deploy/Streamlit/tutorial/#_1","title":"\u6982\u5ff5\u4ecb\u7ecd","text":""},{"location":"llm/deploy/Streamlit/tutorial/#streamlit_1","title":"\u4ec0\u4e48\u662f Streamlit\uff1f","text":"<p>Streamlit \u662f\u4e00\u4e2a\u5f00\u6e90\u7684 Python \u6846\u67b6\uff0c\u4e13\u95e8\u7528\u4e8e\u5feb\u901f\u6784\u5efa\u548c\u5206\u4eab\u6570\u636e\u79d1\u5b66\u548c\u673a\u5668\u5b66\u4e60 Web \u5e94\u7528\u3002\u5b83\u8ba9\u6570\u636e\u79d1\u5b66\u5bb6\u548c\u5de5\u7a0b\u5e08\u80fd\u591f\u7528\u7b80\u5355\u7684 Python \u811a\u672c\u521b\u5efa\u4ea4\u4e92\u5f0f\u3001\u7f8e\u89c2\u7684 Web \u5e94\u7528\uff0c\u800c\u65e0\u9700\u524d\u7aef\u5f00\u53d1\u7ecf\u9a8c\u3002</p>"},{"location":"llm/deploy/Streamlit/tutorial/#_2","title":"\u6838\u5fc3\u7279\u70b9","text":"<ul> <li>\u7b80\u5355\u6613\u7528\uff1a\u53ea\u9700\u51e0\u884c Python \u4ee3\u7801</li> <li>\u5b9e\u65f6\u66f4\u65b0\uff1a\u4ee3\u7801\u4fdd\u5b58\u540e\u5e94\u7528\u7acb\u5373\u66f4\u65b0</li> <li>\u4e30\u5bcc\u7ec4\u4ef6\uff1a\u5185\u7f6e\u591a\u79cd\u4ea4\u4e92\u5f0f\u7ec4\u4ef6</li> <li>\u65e0\u9700\u524d\u7aef\uff1a\u7eaf Python\uff0c\u65e0\u9700 HTML/CSS/JavaScript</li> <li>\u6570\u636e\u96c6\u6210\uff1a\u5b8c\u7f8e\u652f\u6301 Pandas\u3001Matplotlib\u3001Plotly \u7b49</li> </ul>"},{"location":"llm/deploy/Streamlit/tutorial/#_3","title":"\u57fa\u7840\u4ee3\u7801\u793a\u4f8b","text":""},{"location":"llm/deploy/Streamlit/tutorial/#1","title":"1. \u5b89\u88c5\u548c\u57fa\u7840\u5e94\u7528","text":"<pre><code># \u5b89\u88c5 streamlit\n# pip install streamlit\n\nimport streamlit as st\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# \u8bbe\u7f6e\u9875\u9762\u914d\u7f6e\uff08\u5fc5\u987b\u5728\u6700\u524d\u9762\uff09\nst.set_page_config(\n    page_title=\"\u6211\u7684 Streamlit \u5e94\u7528\",\n    page_icon=\"\ud83d\ude80\",\n    layout=\"wide\",  # \"wide\" \u6216 \"centered\"\n    initial_sidebar_state=\"expanded\",  # \"auto\", \"expanded\", \"collapsed\"\n    menu_items={\n        'Get Help': 'https://docs.streamlit.io/',\n        'Report a bug': \"https://github.com/streamlit/streamlit/issues\",\n        'About': \"# \u8fd9\u662f\u6211\u7684\u7b2c\u4e00\u4e2a Streamlit \u5e94\u7528!\"\n    }\n)\n\n# \u6807\u9898\u548c\u6587\u672c\nst.title(\"\ud83c\udfaf \u6211\u7684 Streamlit \u6559\u7a0b\u5e94\u7528\")\nst.header(\"\u8fd9\u662f\u4e3b\u6807\u9898\")\nst.subheader(\"\u8fd9\u662f\u526f\u6807\u9898\")\n\n# Markdown \u652f\u6301\nst.markdown(\"\"\"\n\u8fd9\u662f **\u7c97\u4f53** \u548c *\u659c\u4f53* \u6587\u672c\n- \u5217\u8868\u9879 1\n- \u5217\u8868\u9879 2\n- \u5217\u8868\u9879 3\n\n[\u8fd9\u662f\u4e00\u4e2a\u94fe\u63a5](https://streamlit.io)\n\"\"\")\n\n# \u4ee3\u7801\u5757\nst.code(\"\"\"\nimport streamlit as st\nst.write('Hello World!')\n\"\"\", language='python')\n</code></pre>"},{"location":"llm/deploy/Streamlit/tutorial/#_4","title":"\u9875\u9762\u5e03\u5c40\u8be6\u89e3","text":""},{"location":"llm/deploy/Streamlit/tutorial/#2","title":"2. \u4fa7\u8fb9\u680f\u5e03\u5c40","text":"<pre><code># \u4fa7\u8fb9\u680f - \u6240\u6709\u4ee5 st.sidebar \u5f00\u5934\u7684\u7ec4\u4ef6\u90fd\u4f1a\u663e\u793a\u5728\u4fa7\u8fb9\u680f\nst.sidebar.title(\"\ud83c\udf9b\ufe0f \u63a7\u5236\u9762\u677f\")\nst.sidebar.markdown(\"\u8fd9\u91cc\u662f\u5e94\u7528\u7684\u914d\u7f6e\u9009\u9879\")\n\n# \u4fa7\u8fb9\u680f\u7ec4\u4ef6\nsidebar_option = st.sidebar.radio(\n    \"\u9009\u62e9\u529f\u80fd\",\n    [\"\u6570\u636e\u67e5\u770b\", \"\u6570\u636e\u5206\u6790\", \"\u6570\u636e\u53ef\u89c6\u5316\"]\n)\n\n# \u4fa7\u8fb9\u680f\u6587\u4ef6\u4e0a\u4f20\nuploaded_file = st.sidebar.file_uploader(\n    \"\u4e0a\u4f20\u6570\u636e\u6587\u4ef6\",\n    type=['csv', 'xlsx', 'txt']\n)\n\n# \u4fa7\u8fb9\u680f\u4e0b\u8f7d\u6309\u94ae\nif st.sidebar.button(\"\u4e0b\u8f7d\u793a\u4f8b\u6570\u636e\"):\n    # \u521b\u5efa\u793a\u4f8b\u6570\u636e\u4f9b\u4e0b\u8f7d\n    sample_data = pd.DataFrame({\n        'x': range(100),\n        'y': np.random.randn(100)\n    })\n    csv = sample_data.to_csv(index=False)\n    st.sidebar.download_button(\n        label=\"\u4e0b\u8f7d CSV\",\n        data=csv,\n        file_name=\"sample_data.csv\",\n        mime=\"text/csv\"\n    )\n</code></pre>"},{"location":"llm/deploy/Streamlit/tutorial/#3","title":"3. \u5217\u5e03\u5c40","text":"<pre><code># \u5217\u5e03\u5c40\u793a\u4f8b\nst.header(\"\ud83d\udcd0 \u5217\u5e03\u5c40\u793a\u4f8b\")\n\n# \u521b\u5efa\u7b49\u5bbd\u5217\ncol1, col2, col3 = st.columns(3)\n\nwith col1:\n    st.subheader(\"\u7b2c\u4e00\u5217\")\n    st.metric(\"\u6e29\u5ea6\", \"25\u00b0C\", \"1.2\u00b0C\")\n    st.button(\"\u52171\u6309\u94ae\", key=\"btn1\")\n\nwith col2:\n    st.subheader(\"\u7b2c\u4e8c\u5217\")\n    st.metric(\"\u6e7f\u5ea6\", \"60%\", \"-5%\")\n    st.button(\"\u52172\u6309\u94ae\", key=\"btn2\")\n\nwith col3:\n    st.subheader(\"\u7b2c\u4e09\u5217\")\n    st.metric(\"\u538b\u529b\", \"1013 hPa\", \"2 hPa\")\n    st.button(\"\u52173\u6309\u94ae\", key=\"btn3\")\n\n# \u521b\u5efa\u4e0d\u7b49\u5bbd\u5217\nst.header(\"\u4e0d\u7b49\u5bbd\u5217\u5e03\u5c40\")\nwide_col, narrow_col = st.columns([3, 1])\n\nwith wide_col:\n    st.subheader(\"\u4e3b\u8981\u5185\u5bb9\u533a\")\n    # \u751f\u6210\u793a\u4f8b\u6570\u636e\n    data = pd.DataFrame({\n        '\u59d3\u540d': ['\u5f20\u4e09', '\u674e\u56db', '\u738b\u4e94', '\u8d75\u516d'],\n        '\u5e74\u9f84': [25, 30, 35, 28],\n        '\u57ce\u5e02': ['\u5317\u4eac', '\u4e0a\u6d77', '\u5e7f\u5dde', '\u6df1\u5733'],\n        '\u5206\u6570': [85, 92, 78, 96]\n    })\n    st.dataframe(data, use_container_width=True)\n\nwith narrow_col:\n    st.subheader(\"\u63a7\u5236\u533a\")\n    show_age = st.checkbox(\"\u663e\u793a\u5e74\u9f84\")\n    show_city = st.checkbox(\"\u663e\u793a\u57ce\u5e02\")\n    theme = st.selectbox(\"\u4e3b\u9898\", [\"\u6d45\u8272\", \"\u6df1\u8272\"])\n</code></pre>"},{"location":"llm/deploy/Streamlit/tutorial/#4","title":"4. \u5bb9\u5668\u548c\u6269\u5c55\u5668","text":"<pre><code># \u5bb9\u5668\u793a\u4f8b\nst.header(\"\ud83d\udce6 \u5bb9\u5668\u548c\u6269\u5c55\u5668\")\n\n# \u4f7f\u7528\u5bb9\u5668\u7ec4\u7ec7\u76f8\u5173\u5185\u5bb9\nwith st.container():\n    st.subheader(\"\u76f8\u5173\u529f\u80fd\u7ec4\")\n    col1, col2 = st.columns(2)\n\n    with col1:\n        name = st.text_input(\"\u59d3\u540d\")\n        email = st.text_input(\"\u90ae\u7bb1\")\n\n    with col2:\n        phone = st.text_input(\"\u7535\u8bdd\")\n        department = st.selectbox(\"\u90e8\u95e8\", [\"\u6280\u672f\", \"\u5e02\u573a\", \"\u9500\u552e\", \"\u4eba\u4e8b\"])\n\n    st.info(\"\u8fd9\u662f\u4e00\u4e2a\u4fe1\u606f\u5bb9\u5668\uff0c\u76f8\u5173\u7684\u5185\u5bb9\u53ef\u4ee5\u653e\u5728\u4e00\u8d77\")\n\n# \u6269\u5c55\u5668\uff08\u53ef\u6298\u53e0\u5185\u5bb9\uff09\nwith st.expander(\"\ud83d\udcca \u70b9\u51fb\u67e5\u770b\u8be6\u7ec6\u7edf\u8ba1\u4fe1\u606f\", expanded=False):\n    st.write(\"### \u6570\u636e\u7edf\u8ba1\")\n    if 'data' in locals():\n        st.write(f\"\u6570\u636e\u884c\u6570: {len(data)}\")\n        st.write(f\"\u6570\u636e\u5217\u6570: {len(data.columns)}\")\n        st.write(\"\u6570\u636e\u7c7b\u578b:\")\n        st.write(data.dtypes)\n\n    # \u5728\u6269\u5c55\u5668\u5185\u90e8\u8fd8\u53ef\u4ee5\u6709\u56fe\u8868\n    fig, ax = plt.subplots()\n    if 'data' in locals() and '\u5e74\u9f84' in data.columns:\n        ax.hist(data['\u5e74\u9f84'], bins=10, alpha=0.7, color='skyblue')\n        ax.set_title('\u5e74\u9f84\u5206\u5e03')\n        st.pyplot(fig)\n\n# \u591a\u4e2a\u6269\u5c55\u5668\nexpander1 = st.expander(\"\ud83d\udcdd \u4f7f\u7528\u8bf4\u660e\")\nwith expander1:\n    st.write(\"\"\"\n    \u8fd9\u662f\u4e00\u4e2a Streamlit \u5e94\u7528\u7684\u4f7f\u7528\u8bf4\u660e\uff1a\n    1. \u9996\u5148\u5728\u4fa7\u8fb9\u680f\u4e0a\u4f20\u6570\u636e\n    2. \u7136\u540e\u9009\u62e9\u5206\u6790\u529f\u80fd\n    3. \u67e5\u770b\u7ed3\u679c\u548c\u53ef\u89c6\u5316\n    \"\"\")\n\nexpander2 = st.expander(\"\u2699\ufe0f \u9ad8\u7ea7\u8bbe\u7f6e\")\nwith expander2:\n    precision = st.slider(\"\u8ba1\u7b97\u7cbe\u5ea6\", 1, 10, 2)\n    auto_refresh = st.checkbox(\"\u81ea\u52a8\u5237\u65b0\")\n    refresh_interval = st.number_input(\"\u5237\u65b0\u95f4\u9694(\u79d2)\", 1, 60, 5)\n</code></pre>"},{"location":"llm/deploy/Streamlit/tutorial/#5","title":"5. \u6807\u7b7e\u9875\u5e03\u5c40","text":"<pre><code># \u6807\u7b7e\u9875\u5e03\u5c40 (Streamlit 1.23.0+)\nst.header(\"\ud83d\udcd1 \u6807\u7b7e\u9875\u5e03\u5c40\")\n\ntab1, tab2, tab3, tab4 = st.tabs([\"\ud83d\udcca \u6570\u636e\", \"\ud83d\udcc8 \u56fe\u8868\", \"\ud83d\udd27 \u8bbe\u7f6e\", \"\u2139\ufe0f \u5173\u4e8e\"])\n\nwith tab1:\n    st.subheader(\"\u6570\u636e\u7ba1\u7406\")\n    if 'data' in locals():\n        st.dataframe(data, use_container_width=True)\n\n        # \u6570\u636e\u7f16\u8f91\u529f\u80fd\n        st.subheader(\"\u6570\u636e\u7f16\u8f91\")\n        edited_data = st.data_editor(data, num_rows=\"dynamic\")\n        if st.button(\"\u4fdd\u5b58\u66f4\u6539\"):\n            st.success(\"\u6570\u636e\u5df2\u66f4\u65b0\uff01\")\n\nwith tab2:\n    st.subheader(\"\u6570\u636e\u53ef\u89c6\u5316\")\n\n    if 'data' in locals():\n        chart_type = st.selectbox(\"\u9009\u62e9\u56fe\u8868\u7c7b\u578b\", [\"\u6298\u7ebf\u56fe\", \"\u67f1\u72b6\u56fe\", \"\u6563\u70b9\u56fe\"])\n\n        if chart_type == \"\u6298\u7ebf\u56fe\":\n            st.line_chart(data.set_index('\u59d3\u540d')['\u5206\u6570'])\n        elif chart_type == \"\u67f1\u72b6\u56fe\":\n            st.bar_chart(data.set_index('\u59d3\u540d')['\u5206\u6570'])\n        elif chart_type == \"\u6563\u70b9\u56fe\":\n            fig = px.scatter(data, x='\u5e74\u9f84', y='\u5206\u6570', text='\u59d3\u540d')\n            st.plotly_chart(fig, use_container_width=True)\n\nwith tab3:\n    st.subheader(\"\u5e94\u7528\u8bbe\u7f6e\")\n\n    # \u4e3b\u9898\u8bbe\u7f6e\n    theme = st.selectbox(\"\u9009\u62e9\u4e3b\u9898\", [\"\u6d45\u8272\", \"\u6df1\u8272\", \"\u7cfb\u7edf\u9ed8\u8ba4\"])\n\n    # \u6570\u636e\u8bbe\u7f6e\n    st.subheader(\"\u6570\u636e\u8bbe\u7f6e\")\n    decimal_places = st.slider(\"\u5c0f\u6570\u4f4d\u6570\", 0, 6, 2)\n    date_format = st.selectbox(\"\u65e5\u671f\u683c\u5f0f\", [\"YYYY-MM-DD\", \"DD/MM/YYYY\", \"MM/DD/YYYY\"])\n\n    # \u4fdd\u5b58\u8bbe\u7f6e\n    if st.button(\"\u5e94\u7528\u8bbe\u7f6e\"):\n        st.success(\"\u8bbe\u7f6e\u5df2\u4fdd\u5b58\uff01\")\n\nwith tab4:\n    st.subheader(\"\u5173\u4e8e\u5e94\u7528\")\n    st.write(\"\"\"\n    ## Streamlit \u6570\u636e\u4eea\u8868\u677f\n\n    **\u7248\u672c**: 1.0.0\n    **\u4f5c\u8005**: Your Name\n    **\u63cf\u8ff0**: \u8fd9\u662f\u4e00\u4e2a\u7528\u4e8e\u6570\u636e\u5206\u6790\u548c\u53ef\u89c6\u5316\u7684 Streamlit \u5e94\u7528\n\n    ### \u529f\u80fd\u7279\u6027\n    - \u6570\u636e\u4e0a\u4f20\u548c\u67e5\u770b\n    - \u4ea4\u4e92\u5f0f\u6570\u636e\u5206\u6790\n    - \u591a\u79cd\u53ef\u89c6\u5316\u56fe\u8868\n    - \u53ef\u81ea\u5b9a\u4e49\u7684\u8bbe\u7f6e\n    \"\"\")\n</code></pre>"},{"location":"llm/deploy/Streamlit/tutorial/#session-state","title":"Session State \u8be6\u89e3","text":""},{"location":"llm/deploy/Streamlit/tutorial/#6-session-state","title":"6. Session State \u57fa\u7840","text":"<pre><code># Session State \u7ba1\u7406\u5e94\u7528\u72b6\u6001\nst.header(\"\ud83d\udcbe Session State \u7ba1\u7406\")\n\n# \u521d\u59cb\u5316 session state\nif 'counter' not in st.session_state:\n    st.session_state.counter = 0\nif 'user_data' not in st.session_state:\n    st.session_state.user_data = {}\nif 'app_state' not in st.session_state:\n    st.session_state.app_state = {\n        'theme': 'light',\n        'language': 'zh',\n        'data_loaded': False\n    }\n\n# \u8ba1\u6570\u5668\u793a\u4f8b\ncol1, col2, col3 = st.columns(3)\n\nwith col1:\n    if st.button(\"\u589e\u52a0\u8ba1\u6570\"):\n        st.session_state.counter += 1\n\nwith col2:\n    if st.button(\"\u51cf\u5c11\u8ba1\u6570\"):\n        st.session_state.counter -= 1\n\nwith col3:\n    if st.button(\"\u91cd\u7f6e\u8ba1\u6570\"):\n        st.session_state.counter = 0\n\nst.metric(\"\u5f53\u524d\u8ba1\u6570\", st.session_state.counter)\n\n# \u663e\u793a\u6240\u6709 session state\nwith st.expander(\"\u67e5\u770b\u6240\u6709 Session State\"):\n    st.write(\"\u8ba1\u6570\u5668:\", st.session_state.counter)\n    st.write(\"\u7528\u6237\u6570\u636e:\", st.session_state.user_data)\n    st.write(\"\u5e94\u7528\u72b6\u6001:\", st.session_state.app_state)\n</code></pre>"},{"location":"llm/deploy/Streamlit/tutorial/#7-session-state","title":"7. Session State \u9ad8\u7ea7\u7528\u6cd5","text":"<pre><code># \u590d\u6742\u72b6\u6001\u7ba1\u7406\nst.header(\"\ud83d\udd04 \u590d\u6742\u72b6\u6001\u7ba1\u7406\")\n\n# \u7528\u6237\u4f1a\u8bdd\u7ba1\u7406\nif 'user_session' not in st.session_state:\n    st.session_state.user_session = {\n        'logged_in': False,\n        'username': '',\n        'preferences': {},\n        'history': []\n    }\n\n# \u767b\u5f55\u7cfb\u7edf\nst.subheader(\"\u7528\u6237\u4f1a\u8bdd\u7ba1\u7406\")\n\nif not st.session_state.user_session['logged_in']:\n    with st.form(\"login_form\"):\n        username = st.text_input(\"\u7528\u6237\u540d\")\n        password = st.text_input(\"\u5bc6\u7801\", type=\"password\")\n        submit = st.form_submit_button(\"\u767b\u5f55\")\n\n        if submit:\n            if username and password:  # \u7b80\u5355\u9a8c\u8bc1\n                st.session_state.user_session.update({\n                    'logged_in': True,\n                    'username': username,\n                    'login_time': pd.Timestamp.now()\n                })\n                st.success(f\"\u6b22\u8fce {username}!\")\n                st.rerun()\nelse:\n    st.success(f\"\u5df2\u767b\u5f55\u4e3a: {st.session_state.user_session['username']}\")\n\n    # \u7528\u6237\u504f\u597d\u8bbe\u7f6e\n    with st.form(\"preferences_form\"):\n        st.subheader(\"\u7528\u6237\u504f\u597d\u8bbe\u7f6e\")\n        theme = st.selectbox(\"\u4e3b\u9898\", [\"\u6d45\u8272\", \"\u6df1\u8272\", \"\u81ea\u52a8\"])\n        language = st.selectbox(\"\u8bed\u8a00\", [\"\u4e2d\u6587\", \"\u82f1\u6587\"])\n        notifications = st.checkbox(\"\u542f\u7528\u901a\u77e5\")\n\n        if st.form_submit_button(\"\u4fdd\u5b58\u504f\u597d\"):\n            st.session_state.user_session['preferences'] = {\n                'theme': theme,\n                'language': language,\n                'notifications': notifications\n            }\n            st.success(\"\u504f\u597d\u8bbe\u7f6e\u5df2\u4fdd\u5b58!\")\n\n    # \u9000\u51fa\u767b\u5f55\n    if st.button(\"\u9000\u51fa\u767b\u5f55\"):\n        # \u4fdd\u5b58\u5386\u53f2\u8bb0\u5f55\n        if 'history' not in st.session_state.user_session:\n            st.session_state.user_session['history'] = []\n\n        st.session_state.user_session['history'].append({\n            'action': 'logout',\n            'time': pd.Timestamp.now()\n        })\n\n        st.session_state.user_session['logged_in'] = False\n        st.info(\"\u5df2\u9000\u51fa\u767b\u5f55\")\n        st.rerun()\n\n# \u8d2d\u7269\u8f66\u793a\u4f8b\nst.subheader(\"\u8d2d\u7269\u8f66\u793a\u4f8b\")\n\nif 'shopping_cart' not in st.session_state:\n    st.session_state.shopping_cart = []\n\nproducts = [\n    {\"id\": 1, \"name\": \"\u7b14\u8bb0\u672c\u7535\u8111\", \"price\": 5999},\n    {\"id\": 2, \"name\": \"\u65e0\u7ebf\u9f20\u6807\", \"price\": 199},\n    {\"id\": 3, \"name\": \"\u673a\u68b0\u952e\u76d8\", \"price\": 599},\n    {\"id\": 4, \"name\": \"\u663e\u793a\u5668\", \"price\": 1299},\n]\n\n# \u663e\u793a\u5546\u54c1\u5217\u8868\nst.write(\"### \u5546\u54c1\u5217\u8868\")\nfor product in products:\n    col1, col2, col3 = st.columns([3, 1, 1])\n    with col1:\n        st.write(f\"**{product['name']}** - \u00a5{product['price']}\")\n    with col2:\n        if st.button(f\"\u52a0\u5165\u8d2d\u7269\u8f66\", key=f\"add_{product['id']}\"):\n            st.session_state.shopping_cart.append(product)\n            st.success(f\"\u5df2\u6dfb\u52a0 {product['name']} \u5230\u8d2d\u7269\u8f66\")\n    with col3:\n        if st.button(f\"\u79fb\u9664\", key=f\"remove_{product['id']}\"):\n            # \u79fb\u9664\u6700\u540e\u4e00\u4e2a\u5339\u914d\u7684\u5546\u54c1\n            for i in range(len(st.session_state.shopping_cart)-1, -1, -1):\n                if st.session_state.shopping_cart[i]['id'] == product['id']:\n                    st.session_state.shopping_cart.pop(i)\n                    st.info(f\"\u5df2\u79fb\u9664 {product['name']}\")\n                    break\n\n# \u663e\u793a\u8d2d\u7269\u8f66\nst.write(\"### \u8d2d\u7269\u8f66\")\nif st.session_state.shopping_cart:\n    cart_df = pd.DataFrame(st.session_state.shopping_cart)\n    st.dataframe(cart_df)\n\n    total_price = sum(item['price'] for item in st.session_state.shopping_cart)\n    st.metric(\"\u603b\u4ef7\", f\"\u00a5{total_price}\")\n\n    if st.button(\"\u6e05\u7a7a\u8d2d\u7269\u8f66\"):\n        st.session_state.shopping_cart = []\n        st.rerun()\nelse:\n    st.info(\"\u8d2d\u7269\u8f66\u4e3a\u7a7a\")\n</code></pre>"},{"location":"llm/deploy/Streamlit/tutorial/#8","title":"8. \u8868\u5355\u548c\u72b6\u6001\u7ed3\u5408","text":"<pre><code># \u8868\u5355\u72b6\u6001\u7ba1\u7406\nst.header(\"\ud83d\udcdd \u8868\u5355\u72b6\u6001\u7ba1\u7406\")\n\n# \u591a\u6b65\u9aa4\u8868\u5355\nif 'form_step' not in st.session_state:\n    st.session_state.form_step = 1\nif 'form_data' not in st.session_state:\n    st.session_state.form_data = {}\n\n# \u6b65\u9aa4\u6307\u793a\u5668\nsteps = [\"\u57fa\u672c\u4fe1\u606f\", \"\u8be6\u7ec6\u8d44\u6599\", \"\u786e\u8ba4\u4fe1\u606f\"]\ncurrent_step = st.session_state.form_step\n\n# \u663e\u793a\u8fdb\u5ea6\nprogress = current_step / len(steps)\nst.progress(progress)\nst.write(f\"\u6b65\u9aa4 {current_step}/{len(steps)}: {steps[current_step-1]}\")\n\n# \u591a\u6b65\u9aa4\u8868\u5355\u5185\u5bb9\nif current_step == 1:\n    with st.form(\"step1_form\"):\n        st.subheader(\"\u57fa\u672c\u4fe1\u606f\")\n        name = st.text_input(\"\u59d3\u540d\", value=st.session_state.form_data.get('name', ''))\n        email = st.text_input(\"\u90ae\u7bb1\", value=st.session_state.form_data.get('email', ''))\n\n        if st.form_submit_button(\"\u4e0b\u4e00\u6b65\"):\n            st.session_state.form_data.update({\n                'name': name,\n                'email': email\n            })\n            st.session_state.form_step = 2\n            st.rerun()\n\nelif current_step == 2:\n    with st.form(\"step2_form\"):\n        st.subheader(\"\u8be6\u7ec6\u8d44\u6599\")\n        age = st.number_input(\"\u5e74\u9f84\", min_value=0, max_value=150, \n                             value=st.session_state.form_data.get('age', 25))\n        city = st.selectbox(\"\u57ce\u5e02\", [\"\u5317\u4eac\", \"\u4e0a\u6d77\", \"\u5e7f\u5dde\", \"\u6df1\u5733\", \"\u5176\u4ed6\"],\n                           index=st.session_state.form_data.get('city_index', 0))\n\n        col1, col2 = st.columns(2)\n        with col1:\n            if st.form_submit_button(\"\u4e0a\u4e00\u6b65\"):\n                st.session_state.form_step = 1\n                st.rerun()\n        with col2:\n            if st.form_submit_button(\"\u4e0b\u4e00\u6b65\"):\n                st.session_state.form_data.update({\n                    'age': age,\n                    'city': city\n                })\n                st.session_state.form_step = 3\n                st.rerun()\n\nelif current_step == 3:\n    st.subheader(\"\u786e\u8ba4\u4fe1\u606f\")\n    st.write(\"\u8bf7\u786e\u8ba4\u60a8\u8f93\u5165\u7684\u4fe1\u606f:\")\n    st.json(st.session_state.form_data)\n\n    col1, col2 = st.columns(2)\n    with col1:\n        if st.button(\"\u8fd4\u56de\u4fee\u6539\"):\n            st.session_state.form_step = 2\n            st.rerun()\n    with col2:\n        if st.button(\"\u63d0\u4ea4\"):\n            st.success(\"\u8868\u5355\u63d0\u4ea4\u6210\u529f!\")\n            # \u91cd\u7f6e\u8868\u5355\n            st.session_state.form_step = 1\n            st.session_state.form_data = {}\n            st.rerun()\n</code></pre>"},{"location":"llm/deploy/Streamlit/tutorial/#9","title":"9. \u7f13\u5b58\u548c\u6027\u80fd\u4f18\u5316","text":"<pre><code># \u7f13\u5b58\u673a\u5236\nst.header(\"\u26a1 \u7f13\u5b58\u548c\u6027\u80fd\u4f18\u5316\")\n\n# \u6570\u636e\u7f13\u5b58\n@st.cache_data(ttl=3600)  # \u7f13\u5b581\u5c0f\u65f6\ndef load_large_dataset(file_path):\n    \"\"\"\u6a21\u62df\u52a0\u8f7d\u5927\u578b\u6570\u636e\u96c6\"\"\"\n    st.info(\"\u6b63\u5728\u52a0\u8f7d\u6570\u636e...\")\n    time.sleep(2)  # \u6a21\u62df\u8017\u65f6\u64cd\u4f5c\n    return pd.DataFrame({\n        'id': range(1000),\n        'value': np.random.randn(1000),\n        'category': np.random.choice(['A', 'B', 'C'], 1000)\n    })\n\n# \u8d44\u6e90\u7f13\u5b58\n@st.cache_resource\ndef get_expensive_model():\n    \"\"\"\u6a21\u62df\u52a0\u8f7d\u6602\u8d35\u6a21\u578b\"\"\"\n    st.info(\"\u6b63\u5728\u52a0\u8f7d\u6a21\u578b...\")\n    time.sleep(3)\n    return \"\u6a21\u62df\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\"\n\n# \u7f13\u5b58\u4f7f\u7528\u793a\u4f8b\nif st.button(\"\u52a0\u8f7d\u6570\u636e(\u4f7f\u7528\u7f13\u5b58)\"):\n    data = load_large_dataset(\"dummy_path.csv\")\n    st.write(f\"\u6570\u636e\u52a0\u8f7d\u5b8c\u6210\uff0c\u5171 {len(data)} \u884c\")\n\nif st.button(\"\u52a0\u8f7d\u6a21\u578b(\u4f7f\u7528\u7f13\u5b58)\"):\n    model = get_expensive_model()\n    st.success(f\"\u6a21\u578b\u52a0\u8f7d\u5b8c\u6210: {model}\")\n\n# \u6e05\u7a7a\u7f13\u5b58\nif st.button(\"\u6e05\u7a7a\u6240\u6709\u7f13\u5b58\"):\n    st.cache_data.clear()\n    st.cache_resource.clear()\n    st.success(\"\u7f13\u5b58\u5df2\u6e05\u7a7a!\")\n</code></pre>"},{"location":"llm/deploy/Streamlit/tutorial/#_5","title":"\u5b8c\u6574\u5e94\u7528\u793a\u4f8b","text":""},{"location":"llm/deploy/Streamlit/tutorial/#10","title":"10. \u7efc\u5408\u5e94\u7528\uff1a\u6570\u636e\u5206\u6790\u4eea\u8868\u677f","text":"<pre><code>import streamlit as st\nimport pandas as pd\nimport numpy as np\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom datetime import datetime, timedelta\n\n# \u5e94\u7528\u914d\u7f6e\nst.set_page_config(\n    page_title=\"\u9ad8\u7ea7\u6570\u636e\u5206\u6790\u4eea\u8868\u677f\",\n    page_icon=\"\ud83d\udcca\",\n    layout=\"wide\",\n    initial_sidebar_state=\"expanded\"\n)\n\n# \u521d\u59cb\u5316 session state\nif 'dashboard' not in st.session_state:\n    st.session_state.dashboard = {\n        'data_loaded': False,\n        'current_view': 'overview',\n        'filters': {},\n        'charts_config': {}\n    }\n\ndef main():\n    # \u6807\u9898\u548c\u63cf\u8ff0\n    st.title(\"\ud83d\udcca \u9ad8\u7ea7\u6570\u636e\u5206\u6790\u4eea\u8868\u677f\")\n    st.markdown(\"---\")\n\n    # \u4fa7\u8fb9\u680f\n    with st.sidebar:\n        st.header(\"\u63a7\u5236\u9762\u677f\")\n\n        # \u6570\u636e\u4e0a\u4f20\n        uploaded_file = st.file_uploader(\n            \"\u4e0a\u4f20\u6570\u636e\u6587\u4ef6 (CSV)\",\n            type=['csv'],\n            key=\"file_uploader\"\n        )\n\n        if uploaded_file is not None:\n            try:\n                data = pd.read_csv(uploaded_file)\n                st.session_state.dashboard['data'] = data\n                st.session_state.dashboard['data_loaded'] = True\n                st.success(f\"\u6570\u636e\u52a0\u8f7d\u6210\u529f! \u5171 {len(data)} \u884c, {len(data.columns)} \u5217\")\n            except Exception as e:\n                st.error(f\"\u6570\u636e\u52a0\u8f7d\u5931\u8d25: {e}\")\n\n        # \u89c6\u56fe\u9009\u62e9\n        if st.session_state.dashboard['data_loaded']:\n            view_options = {\n                \"overview\": \"\u6570\u636e\u6982\u89c8\",\n                \"explore\": \"\u6570\u636e\u63a2\u7d22\", \n                \"visualize\": \"\u6570\u636e\u53ef\u89c6\u5316\",\n                \"analyze\": \"\u9ad8\u7ea7\u5206\u6790\"\n            }\n\n            selected_view = st.radio(\n                \"\u9009\u62e9\u89c6\u56fe\",\n                options=list(view_options.keys()),\n                format_func=lambda x: view_options[x]\n            )\n            st.session_state.dashboard['current_view'] = selected_view\n\n    # \u4e3b\u5185\u5bb9\u533a\n    if st.session_state.dashboard['data_loaded']:\n        data = st.session_state.dashboard['data']\n        current_view = st.session_state.dashboard['current_view']\n\n        if current_view == 'overview':\n            show_data_overview(data)\n        elif current_view == 'explore':\n            show_data_exploration(data)\n        elif current_view == 'visualize':\n            show_data_visualization(data)\n        elif current_view == 'analyze':\n            show_advanced_analysis(data)\n    else:\n        show_welcome_screen()\n\ndef show_welcome_screen():\n    \"\"\"\u6b22\u8fce\u754c\u9762\"\"\"\n    st.header(\"\u6b22\u8fce\u4f7f\u7528\u6570\u636e\u5206\u6790\u4eea\u8868\u677f\")\n\n    col1, col2 = st.columns(2)\n\n    with col1:\n        st.info(\"\"\"\n        ### \ud83d\ude80 \u529f\u80fd\u7279\u6027\n        - \u6570\u636e\u4e0a\u4f20\u548c\u9884\u89c8\n        - \u4ea4\u4e92\u5f0f\u6570\u636e\u63a2\u7d22\n        - \u591a\u79cd\u53ef\u89c6\u5316\u56fe\u8868\n        - \u9ad8\u7ea7\u7edf\u8ba1\u5206\u6790\n        - \u5b9e\u65f6\u6570\u636e\u8fc7\u6ee4\n        \"\"\")\n\n    with col2:\n        st.warning(\"\"\"\n        ### \ud83d\udcdd \u4f7f\u7528\u8bf4\u660e\n        1. \u5728\u5de6\u4fa7\u8fb9\u680f\u4e0a\u4f20 CSV \u6587\u4ef6\n        2. \u9009\u62e9\u4e0d\u540c\u7684\u89c6\u56fe\u6a21\u5f0f\n        3. \u4f7f\u7528\u4ea4\u4e92\u5f0f\u63a7\u4ef6\u63a2\u7d22\u6570\u636e\n        4. \u4fdd\u5b58\u548c\u5bfc\u51fa\u5206\u6790\u7ed3\u679c\n        \"\"\")\n\n    # \u793a\u4f8b\u6570\u636e\n    if st.button(\"\u52a0\u8f7d\u793a\u4f8b\u6570\u636e\"):\n        # \u751f\u6210\u793a\u4f8b\u6570\u636e\n        np.random.seed(42)\n        sample_data = pd.DataFrame({\n            '\u65e5\u671f': pd.date_range('2023-01-01', periods=100),\n            '\u9500\u552e\u989d': np.random.normal(1000, 200, 100).cumsum(),\n            '\u5ba2\u6237\u6570': np.random.poisson(50, 100),\n            '\u4ea7\u54c1\u7c7b\u522b': np.random.choice(['\u7535\u5b50\u4ea7\u54c1', '\u670d\u88c5', '\u98df\u54c1', '\u5bb6\u5c45'], 100),\n            '\u5730\u533a': np.random.choice(['\u534e\u5317', '\u534e\u4e1c', '\u534e\u5357', '\u897f\u90e8'], 100)\n        })\n        st.session_state.dashboard['data'] = sample_data\n        st.session_state.dashboard['data_loaded'] = True\n        st.rerun()\n\ndef show_data_overview(data):\n    \"\"\"\u6570\u636e\u6982\u89c8\u89c6\u56fe\"\"\"\n    st.header(\"\ud83d\udcc8 \u6570\u636e\u6982\u89c8\")\n\n    # \u5173\u952e\u6307\u6807\n    col1, col2, col3, col4 = st.columns(4)\n\n    with col1:\n        st.metric(\"\u603b\u884c\u6570\", len(data))\n    with col2:\n        st.metric(\"\u603b\u5217\u6570\", len(data.columns))\n    with col3:\n        st.metric(\"\u7f3a\u5931\u503c\", data.isnull().sum().sum())\n    with col4:\n        st.metric(\"\u5185\u5b58\u4f7f\u7528\", f\"{data.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n\n    # \u6570\u636e\u9884\u89c8\n    st.subheader(\"\u6570\u636e\u9884\u89c8\")\n    tab1, tab2, tab3 = st.tabs([\"\u524d\u51e0\u884c\", \"\u540e\u51e0\u884c\", \"\u968f\u673a\u6837\u672c\"])\n\n    with tab1:\n        st.dataframe(data.head(10), use_container_width=True)\n    with tab2:\n        st.dataframe(data.tail(10), use_container_width=True)\n    with tab3:\n        st.dataframe(data.sample(10), use_container_width=True)\n\n    # \u6570\u636e\u7c7b\u578b\u4fe1\u606f\n    st.subheader(\"\u6570\u636e\u7c7b\u578b\u4fe1\u606f\")\n    dtype_info = pd.DataFrame({\n        '\u5217\u540d': data.columns,\n        '\u6570\u636e\u7c7b\u578b': data.dtypes,\n        '\u975e\u7a7a\u503c\u6570\u91cf': data.count(),\n        '\u7a7a\u503c\u6570\u91cf': data.isnull().sum()\n    })\n    st.dataframe(dtype_info, use_container_width=True)\n\ndef show_data_exploration(data):\n    \"\"\"\u6570\u636e\u63a2\u7d22\u89c6\u56fe\"\"\"\n    st.header(\"\ud83d\udd0d \u6570\u636e\u63a2\u7d22\")\n\n    # \u5217\u9009\u62e9\u5668\n    col1, col2 = st.columns(2)\n\n    with col1:\n        selected_columns = st.multiselect(\n            \"\u9009\u62e9\u8981\u5206\u6790\u7684\u5217\",\n            options=data.columns.tolist(),\n            default=data.columns.tolist()[:3] if len(data.columns) &gt;= 3 else data.columns.tolist()\n        )\n\n    with col2:\n        # \u6570\u636e\u8fc7\u6ee4\n        st.subheader(\"\u6570\u636e\u8fc7\u6ee4\")\n        filter_col = st.selectbox(\"\u8fc7\u6ee4\u5217\", [None] + data.select_dtypes(include=[np.number]).columns.tolist())\n        if filter_col:\n            min_val, max_val = float(data[filter_col].min()), float(data[filter_col].max())\n            filter_range = st.slider(\n                f\"\u9009\u62e9 {filter_col} \u8303\u56f4\",\n                min_val, max_val, (min_val, max_val)\n            )\n            filtered_data = data[(data[filter_col] &gt;= filter_range[0]) &amp; (data[filter_col] &lt;= filter_range[1])]\n        else:\n            filtered_data = data\n\n    if selected_columns:\n        # \u663e\u793a\u9009\u4e2d\u7684\u5217\u6570\u636e\n        st.subheader(\"\u9009\u4e2d\u7684\u6570\u636e\")\n        st.dataframe(filtered_data[selected_columns], use_container_width=True)\n\n        # \u63cf\u8ff0\u6027\u7edf\u8ba1\n        st.subheader(\"\u63cf\u8ff0\u6027\u7edf\u8ba1\")\n        st.dataframe(filtered_data[selected_columns].describe(), use_container_width=True)\n\n        # \u76f8\u5173\u6027\u5206\u6790\uff08\u5982\u679c\u6709\u591a\u5217\u6570\u503c\u6570\u636e\uff09\n        numeric_cols = filtered_data[selected_columns].select_dtypes(include=[np.number]).columns\n        if len(numeric_cols) &gt; 1:\n            st.subheader(\"\u76f8\u5173\u6027\u77e9\u9635\")\n            corr_matrix = filtered_data[numeric_cols].corr()\n            fig = px.imshow(corr_matrix, text_auto=True, aspect=\"auto\")\n            st.plotly_chart(fig, use_container_width=True)\n\ndef show_data_visualization(data):\n    \"\"\"\u6570\u636e\u53ef\u89c6\u5316\u89c6\u56fe\"\"\"\n    st.header(\"\ud83d\udcca \u6570\u636e\u53ef\u89c6\u5316\")\n\n    # \u56fe\u8868\u7c7b\u578b\u9009\u62e9\n    chart_type = st.selectbox(\n        \"\u9009\u62e9\u56fe\u8868\u7c7b\u578b\",\n        [\"\u6563\u70b9\u56fe\", \"\u6298\u7ebf\u56fe\", \"\u67f1\u72b6\u56fe\", \"\u76f4\u65b9\u56fe\", \"\u7bb1\u7ebf\u56fe\", \"\u70ed\u529b\u56fe\"]\n    )\n\n    col1, col2 = st.columns(2)\n\n    with col1:\n        # X \u8f74\u9009\u62e9\n        x_axis = st.selectbox(\"X \u8f74\", data.columns.tolist())\n\n    with col2:\n        # Y \u8f74\u9009\u62e9\uff08\u5982\u679c\u662f\u6570\u503c\u578b\u56fe\u8868\uff09\n        if chart_type in [\"\u6563\u70b9\u56fe\", \"\u6298\u7ebf\u56fe\", \"\u67f1\u72b6\u56fe\"]:\n            y_axis = st.selectbox(\"Y \u8f74\", data.select_dtypes(include=[np.number]).columns.tolist())\n        else:\n            y_axis = None\n\n    # \u989c\u8272\u5206\u7ec4\n    color_by = st.selectbox(\"\u6309\u989c\u8272\u5206\u7ec4\", [None] + data.select_dtypes(include=['object']).columns.tolist())\n\n    # \u751f\u6210\u56fe\u8868\n    if chart_type == \"\u6563\u70b9\u56fe\" and y_axis:\n        fig = px.scatter(data, x=x_axis, y=y_axis, color=color_by, hover_data=data.columns)\n        st.plotly_chart(fig, use_container_width=True)\n\n    elif chart_type == \"\u6298\u7ebf\u56fe\" and y_axis:\n        # \u5982\u679c x \u8f74\u662f\u65e5\u671f\uff0c\u81ea\u52a8\u6392\u5e8f\n        if pd.api.types.is_datetime64_any_dtype(data[x_axis]):\n            sorted_data = data.sort_values(x_axis)\n        else:\n            sorted_data = data\n        fig = px.line(sorted_data, x=x_axis, y=y_axis, color=color_by)\n        st.plotly_chart(fig, use_container_width=True)\n\n    elif chart_type == \"\u67f1\u72b6\u56fe\" and y_axis:\n        fig = px.bar(data, x=x_axis, y=y_axis, color=color_by)\n        st.plotly_chart(fig, use_container_width=True)\n\n    elif chart_type == \"\u76f4\u65b9\u56fe\":\n        fig = px.histogram(data, x=x_axis, color=color_by, nbins=20)\n        st.plotly_chart(fig, use_container_width=True)\n\n    elif chart_type == \"\u7bb1\u7ebf\u56fe\" and y_axis:\n        fig = px.box(data, x=x_axis, y=y_axis, color=color_by)\n        st.plotly_chart(fig, use_container_width=True)\n\n    elif chart_type == \"\u70ed\u529b\u56fe\":\n        numeric_data = data.select_dtypes(include=[np.number])\n        if len(numeric_data.columns) &gt; 1:\n            fig = px.imshow(numeric_data.corr(), text_auto=True, aspect=\"auto\")\n            st.plotly_chart(fig, use_container_width=True)\n        else:\n            st.warning(\"\u9700\u8981\u81f3\u5c11\u4e24\u4e2a\u6570\u503c\u5217\u6765\u751f\u6210\u70ed\u529b\u56fe\")\n\ndef show_advanced_analysis(data):\n    \"\"\"\u9ad8\u7ea7\u5206\u6790\u89c6\u56fe\"\"\"\n    st.header(\"\ud83e\udde0 \u9ad8\u7ea7\u5206\u6790\")\n\n    # \u65f6\u95f4\u5e8f\u5217\u5206\u6790\uff08\u5982\u679c\u6570\u636e\u5305\u542b\u65e5\u671f\u5217\uff09\n    date_columns = data.select_dtypes(include=['datetime64']).columns\n    if len(date_columns) &gt; 0:\n        st.subheader(\"\u65f6\u95f4\u5e8f\u5217\u5206\u6790\")\n\n        date_col = st.selectbox(\"\u9009\u62e9\u65e5\u671f\u5217\", date_columns)\n        value_col = st.selectbox(\"\u9009\u62e9\u6570\u503c\u5217\", data.select_dtypes(include=[np.number]).columns)\n\n        if date_col and value_col:\n            # \u786e\u4fdd\u6570\u636e\u6309\u65e5\u671f\u6392\u5e8f\n            time_series_data = data.sort_values(date_col).set_index(date_col)\n\n            # \u79fb\u52a8\u5e73\u5747\n            window = st.slider(\"\u79fb\u52a8\u5e73\u5747\u7a97\u53e3\", 1, 30, 7)\n            time_series_data[f'{value_col}_MA'] = time_series_data[value_col].rolling(window=window).mean()\n\n            # \u7ed8\u5236\u65f6\u95f4\u5e8f\u5217\u548c\u79fb\u52a8\u5e73\u5747\n            fig = go.Figure()\n            fig.add_trace(go.Scatter(\n                x=time_series_data.index,\n                y=time_series_data[value_col],\n                name='\u539f\u59cb\u6570\u636e',\n                line=dict(color='blue')\n            ))\n            fig.add_trace(go.Scatter(\n                x=time_series_data.index,\n                y=time_series_data[f'{value_col}_MA'],\n                name=f'{window}\u671f\u79fb\u52a8\u5e73\u5747',\n                line=dict(color='red', dash='dash')\n            ))\n            fig.update_layout(title=f\"{value_col} \u65f6\u95f4\u5e8f\u5217\u5206\u6790\")\n            st.plotly_chart(fig, use_container_width=True)\n\n    # \u805a\u7c7b\u5206\u6790\n    st.subheader(\"\u805a\u7c7b\u5206\u6790\")\n    if st.checkbox(\"\u542f\u7528\u805a\u7c7b\u5206\u6790\"):\n        numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()\n        if len(numeric_cols) &gt;= 2:\n            from sklearn.cluster import KMeans\n            from sklearn.preprocessing import StandardScaler\n\n            selected_cluster_cols = st.multiselect(\n                \"\u9009\u62e9\u805a\u7c7b\u7279\u5f81\",\n                numeric_cols,\n                default=numeric_cols[:2]\n            )\n\n            n_clusters = st.slider(\"\u805a\u7c7b\u6570\u91cf\", 2, 10, 3)\n\n            if len(selected_cluster_cols) &gt;= 2:\n                # \u51c6\u5907\u6570\u636e\n                cluster_data = data[selected_cluster_cols].dropna()\n                scaler = StandardScaler()\n                scaled_data = scaler.fit_transform(cluster_data)\n\n                # \u6267\u884c\u805a\u7c7b\n                kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n                clusters = kmeans.fit_predict(scaled_data)\n\n                # \u53ef\u89c6\u5316\u7ed3\u679c\n                cluster_data['Cluster'] = clusters\n                fig = px.scatter(\n                    cluster_data, \n                    x=selected_cluster_cols[0], \n                    y=selected_cluster_cols[1],\n                    color='Cluster',\n                    title=\"K-means \u805a\u7c7b\u7ed3\u679c\"\n                )\n                st.plotly_chart(fig, use_container_width=True)\n        else:\n            st.warning(\"\u9700\u8981\u81f3\u5c11\u4e24\u4e2a\u6570\u503c\u5217\u8fdb\u884c\u805a\u7c7b\u5206\u6790\")\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"llm/deploy/Streamlit/tutorial/#_6","title":"\u8fd0\u884c\u5e94\u7528","text":"<p>\u8981\u8fd0\u884c Streamlit \u5e94\u7528\uff0c\u5728\u7ec8\u7aef\u4e2d\u6267\u884c\uff1a</p> <pre><code>streamlit run your_app.py\n</code></pre>"},{"location":"llm/deploy/Streamlit/tutorial/#_7","title":"\u90e8\u7f72\u5e94\u7528","text":""},{"location":"llm/deploy/Streamlit/tutorial/#_8","title":"\u672c\u5730\u90e8\u7f72","text":"<pre><code>streamlit run app.py\n</code></pre>"},{"location":"llm/deploy/Streamlit/tutorial/#streamlit-cloud","title":"\u90e8\u7f72\u5230 Streamlit Cloud","text":"<ol> <li>\u5c06\u4ee3\u7801\u63a8\u9001\u5230 GitHub</li> <li>\u8bbf\u95ee share.streamlit.io</li> <li>\u8fde\u63a5 GitHub \u4ed3\u5e93</li> <li>\u9009\u62e9\u5206\u652f\u548c\u6587\u4ef6\u8def\u5f84</li> </ol>"},{"location":"llm/deploy/Streamlit/tutorial/#_9","title":"\u90e8\u7f72\u5230\u5176\u4ed6\u5e73\u53f0","text":"<ul> <li>Heroku: \u4f7f\u7528 Procfile \u548c requirements.txt</li> <li>AWS/Azure: \u4f7f\u7528 Docker \u5bb9\u5668</li> <li>Hugging Face: \u652f\u6301 Streamlit \u7a7a\u95f4</li> </ul>"},{"location":"llm/deploy/Streamlit/tutorial/#_10","title":"\u603b\u7ed3","text":"<p>\u8fd9\u4e2a\u5b8c\u6574\u6559\u7a0b\u6db5\u76d6\u4e86 Streamlit \u7684\u6240\u6709\u91cd\u8981\u6982\u5ff5\uff1a</p>"},{"location":"llm/deploy/Streamlit/tutorial/#_11","title":"\u6838\u5fc3\u6982\u5ff5\u638c\u63e1\uff1a","text":"<ol> <li>\u9875\u9762\u5e03\u5c40\uff1a\u4fa7\u8fb9\u680f\u3001\u5217\u3001\u5bb9\u5668\u3001\u6807\u7b7e\u9875\u3001\u6269\u5c55\u5668</li> <li>Session State\uff1a\u72b6\u6001\u7ba1\u7406\u3001\u7528\u6237\u4f1a\u8bdd\u3001\u8868\u5355\u72b6\u6001\u3001\u8d2d\u7269\u8f66\u6a21\u5f0f</li> <li>\u6570\u636e\u5c55\u793a\uff1a\u8868\u683c\u3001\u56fe\u8868\u3001\u6307\u6807\u3001\u4ea4\u4e92\u7ec4\u4ef6</li> <li>\u6027\u80fd\u4f18\u5316\uff1a\u7f13\u5b58\u673a\u5236\u3001\u61d2\u52a0\u8f7d</li> <li>\u90e8\u7f72\u53d1\u5e03\uff1a\u591a\u5e73\u53f0\u90e8\u7f72\u9009\u9879</li> </ol>"},{"location":"llm/deploy/Streamlit/tutorial/#_12","title":"\u6700\u4f73\u5b9e\u8df5\uff1a","text":"<ul> <li>\u5408\u7406\u4f7f\u7528 Session State \u7ba1\u7406\u5e94\u7528\u72b6\u6001</li> <li>\u4f7f\u7528\u7f13\u5b58\u4f18\u5316\u6027\u80fd</li> <li>\u91c7\u7528\u6a21\u5757\u5316\u8bbe\u8ba1\u7ec4\u7ec7\u4ee3\u7801</li> <li>\u63d0\u4f9b\u6e05\u6670\u7684\u7528\u6237\u5f15\u5bfc\u548c\u53cd\u9988</li> <li>\u8003\u8651\u54cd\u5e94\u5f0f\u5e03\u5c40\u8bbe\u8ba1</li> </ul> <p>\u8fd9\u4e2a\u6559\u7a0b\u63d0\u4f9b\u4e86\u4ece\u57fa\u7840\u5230\u9ad8\u7ea7\u7684\u5b8c\u6574\u5b66\u4e60\u8def\u5f84\uff0c\u4f60\u53ef\u4ee5\u57fa\u4e8e\u8fd9\u4e9b\u6a21\u5f0f\u6784\u5efa\u590d\u6742\u7684\u6570\u636e\u5e94\u7528\uff01</p>"},{"location":"llm/tunning/peft/chinese%20peft/","title":"\u4e2d\u6587PEFT\u5fae\u8c03\u5b9e\u6218","text":"<p>\u592a\u597d\u4e86\uff0c\u51fa\u53d1\uff01 \u6211\u4eec\u7ed9\u4f60\u4e00\u4e2a\u5b8c\u6574\u3001\u5b9e\u7528\u7684 \u4e2d\u6587\u4efb\u52a1\uff1a\u60c5\u611f\u5206\u7c7b + LoRA \u53c2\u6570\u9ad8\u6548\u5fae\u8c03\uff08PEFT\uff09 \u7684\u793a\u8303\u5de5\u7a0b\u3002\u4f60\u53ef\u4ee5\u5728\u81ea\u5df1\u7684\u7535\u8111\u6216 Colab \u4e0a\u5b8c\u6210\u8bad\u7ec3\uff0c\u5e76\u6700\u7ec8\u628a\u6a21\u578b\u90e8\u7f72\u51fa\u6765\u3002</p>"},{"location":"llm/tunning/peft/chinese%20peft/#peft","title":"\u2705 \u4e2d\u6587 PEFT \u5fae\u8c03\u5b8c\u6574\u6559\u7a0b","text":"<p>\u4efb\u52a1\u9009\u62e9\uff1a\u4e2d\u6587\u60c5\u611f\u5206\u6790\uff08\u6b63\u5411 / \u8d1f\u5411\uff09 \u6a21\u578b\u9009\u62e9\uff1aChinese-BERT\uff08\u5982 bert-base-chinese\uff09 \u65b9\u6cd5\u9009\u62e9\uff1aLoRA\uff08PEFT\uff09</p> <p>\u8fd9\u4efd\u6559\u7a0b\u8be6\u7ec6\u89e3\u91ca\u6bcf\u4e00\u6b65\uff0c\u4fbf\u4e8e\u7406\u89e3\u548c\u62d3\u5c55\u3002</p>"},{"location":"llm/tunning/peft/chinese%20peft/#_1","title":"\u7b2c\u4e00\u6b65\uff1a\u5b89\u88c5\u4f9d\u8d56","text":"<pre><code>pip install torch transformers datasets peft accelerate\n</code></pre> <p>\u5982\u6709 GPU \u73af\u5883\u66f4\u4f73\u3002</p>"},{"location":"llm/tunning/peft/chinese%20peft/#_2","title":"\u7b2c\u4e8c\u6b65\uff1a\u51c6\u5907\u6570\u636e\u96c6\uff08\u4e2d\u6587\u60c5\u611f\u5206\u7c7b\uff09","text":"<p>\u793a\u4f8b\u4f7f\u7528 Hugging Face \u81ea\u5e26\u7684\u4e2d\u6587\u8bc4\u8bba\u6570\u636e\u96c6\uff08ChnSentiCorp\uff09\u3002</p> <pre><code>from datasets import load_dataset\n\ndataset = load_dataset(\"chnsenticorp\")\ndataset\n</code></pre> <p>\u6570\u636e\u683c\u5f0f\uff1a</p> <ul> <li><code>text</code>\uff1a\u8bc4\u8bba\u5185\u5bb9</li> <li><code>label</code>\uff1a0 = \u8d1f\u9762\uff0c1 = \u6b63\u9762</li> </ul> <p>\u4e3a\u4e86\u66f4\u5feb\u6f14\u793a\uff0c\u4f60\u4e5f\u53ef\u4ee5\uff1a</p> <pre><code>dataset = dataset.shuffle(seed=42).select(range(3000))  # \u5c0f\u6837\u672c\u6d4b\u8bd5\n</code></pre>"},{"location":"llm/tunning/peft/chinese%20peft/#tokenizer","title":"\u7b2c\u4e09\u6b65\uff1a\u52a0\u8f7d\u6a21\u578b\u548c tokenizer","text":"<pre><code>from transformers import AutoModelForSequenceClassification, AutoTokenizer\n\nmodel_name = \"bert-base-chinese\"\n\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    model_name,\n    num_labels=2\n)\n</code></pre>"},{"location":"llm/tunning/peft/chinese%20peft/#tokenize","title":"\u7b2c\u56db\u6b65\uff1a\u6570\u636e\u9884\u5904\u7406\uff08tokenize\uff09","text":"<pre><code>def tokenize_fn(batch):\n    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n\nencoded = dataset.map(tokenize_fn, batched=True)\nencoded = encoded.remove_columns([\"text\"])\nencoded.set_format(\"torch\")\n</code></pre>"},{"location":"llm/tunning/peft/chinese%20peft/#peftlora","title":"\u7b2c\u4e94\u6b65\uff1a\u914d\u7f6e PEFT\uff08LoRA\uff09","text":"<pre><code>from peft import LoraConfig, TaskType, get_peft_model\n\npeft_config = LoraConfig(\n    task_type=TaskType.SEQUENCE_CLASSIFICATION,  \n    r=8,\n    lora_alpha=16,\n    lora_dropout=0.05,\n    bias=\"none\"\n)\n\nmodel = get_peft_model(model, peft_config)\nmodel.print_trainable_parameters()\n</code></pre> <p>\u8f93\u51fa\u793a\u4f8b\uff1a \u53ef\u8bad\u7ec3\u53c2\u6570 &lt; \u603b\u53c2\u6570\u7684 1% \u8fd9\u5c31\u662f\u7701\u8d44\u6e90\u7684\u9b54\u6cd5\uff01</p>"},{"location":"llm/tunning/peft/chinese%20peft/#trainer","title":"\u7b2c\u516d\u6b65\uff1a\u8bad\u7ec3\uff08Trainer\uff09","text":"<pre><code>from transformers import TrainingArguments, Trainer\n\ntraining_args = TrainingArguments(\n    output_dir=\"./peft-bert-chinese\",\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    per_device_train_batch_size=16,\n    num_train_epochs=2,\n    logging_steps=50,\n    load_best_model_at_end=True,\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=encoded[\"train\"],\n    eval_dataset=encoded[\"validation\"]\n)\n\ntrainer.train()\n</code></pre>"},{"location":"llm/tunning/peft/chinese%20peft/#_3","title":"\u7b2c\u4e03\u6b65\uff1a\u8bc4\u4f30\u6a21\u578b","text":"<pre><code>metrics = trainer.evaluate(encoded[\"test\"])\nmetrics\n</code></pre> <p>\u5982\u679c\u8bad\u7ec3\u6b63\u5e38\uff0c\u51c6\u786e\u7387\u901a\u5e38\u80fd &gt; 90%</p>"},{"location":"llm/tunning/peft/chinese%20peft/#lora-adapter","title":"\u7b2c\u516b\u6b65\uff1a\u4fdd\u5b58 LoRA adapter","text":"<pre><code>model.save_pretrained(\"peft_lora_chnsentic\")\ntokenizer.save_pretrained(\"peft_lora_chnsentic\")\n</code></pre> <p>\u5f97\u5230\u7684\u5c0f\u76ee\u5f55\u5c31\u662f LoRA \u6a21\u5757\uff0c\u5b83\u6781\u8f7b\u91cf\u53ef\u90e8\u7f72\u3002</p>"},{"location":"llm/tunning/peft/chinese%20peft/#adapter","title":"\u7b2c\u4e5d\u6b65\uff1a\u63a8\u7406\u6d4b\u8bd5\uff08\u52a0\u8f7d Adapter\uff09","text":"<pre><code>from peft import PeftModel\n\nbase_model = AutoModelForSequenceClassification.from_pretrained(model_name)\nlora_model = PeftModel.from_pretrained(base_model, \"peft_lora_chnsentic\")\n\ntext = \"\u8fd9\u5bb6\u9910\u5385\u7684\u83dc\u592a\u96be\u5403\u4e86\uff01\"\ntokens = tokenizer(text, return_tensors=\"pt\")\noutput = lora_model(**tokens)\nprint(output.logits.argmax().item())  # 0 \u2192 \u8d1f\u9762\n</code></pre> <p>\u6d4b\u8bd5\u6210\u529f \u2705</p>"},{"location":"llm/tunning/peft/chinese%20peft/#bonus-web-gradio","title":"\u2705 Bonus\uff1a\u90e8\u7f72\u6210 Web \u5e94\u7528\uff08\u914d Gradio\uff09","text":"<pre><code>import gradio as gr\nimport torch\n\ndef classify(text):\n    inputs = tokenizer(text, return_tensors=\"pt\")\n    logits = lora_model(**inputs).logits\n    label_id = logits.argmax().item()\n    return \"\u6b63\u9762\ud83d\udc4d\" if label_id == 1 else \"\u8d1f\u9762\ud83d\udc4e\"\n\niface = gr.Interface(fn=classify, inputs=\"text\", outputs=\"text\", title=\"\u4e2d\u6587\u60c5\u611f\u8bc6\u522b LoRA \u6a21\u578b\")\niface.launch()\n</code></pre> <p>\u7acb\u523b\u4f53\u9a8c\uff1a\u201c\u8fd9\u4e2a\u6a21\u578b\u771f\u68d2\uff01\u201d vs \u201c\u8fa3\u9e21\u9879\u76ee\uff01\u201d</p>"},{"location":"llm/tunning/peft/chinese%20peft/#_4","title":"\ud83c\udf1f\u4f60\u53ef\u4ee5\u5ef6\u4f38\u7684\u5b9e\u9a8c\u65b9\u5411","text":"<ul> <li>\u6362\u4efb\u52a1\uff1a\u6458\u8981\u3001\u7ffb\u8bd1\u3001\u5bf9\u8bdd\u3001\u5173\u952e\u8bcd\u63d0\u53d6</li> <li>\u6362\u57fa\u7840\u6a21\u578b\uff1aRoBERTa\u3001BERT-wwm-ext\u3001Chinese-LLM</li> <li>\u52a0\u901f\u7b56\u7565\uff1a\u91cf\u5316 8bit/4bit + LoRA\uff08\u8d85\u7701\u663e\u5b58\uff09</li> <li>\u90e8\u7f72\uff1aHugging Face Spaces + CI/CD</li> </ul> <p>\u901a\u8fc7 PEFT\uff0c\u4f60\u5df2\u7ecf\u638c\u63e1\u4e86 \u201c\u5c0f\u6210\u672c\u9a6f\u670d\u5927\u6a21\u578b\u201d \u7684\u6280\u80fd\u3002\u672a\u6765\u4e0d\u7528\u671b\u7740 130B \u53c2\u6570\u6a21\u578b\u6d41\u6cea\uff1a</p> <p>\u4f60\u6709 Adapter\uff0c\u5b83\u8f7b\uff0c\u4e5f\u806a\u660e\u3002</p> <p>\u5982\u679c\u4f60\u60f3\uff0c\u6211\u8fd8\u53ef\u4ee5\u7ed9\u4f60\uff1a</p> <p>\u2705 \u4e2d\u6587\u6458\u8981\u751f\u6210 \u2014 PEFT + T5 \u2705 \u4e2d\u6587\u5bf9\u8bdd\u6a21\u578b \u2014 PEFT + LLaMA/Mistral/Qwen \u2705 \u591a\u6a21\u6001\uff08\u56fe\u50cf+\u6587\u672c\uff09 PEFT \u2705 \u5b8c\u6574\u9879\u76ee\u7ed3\u6784\uff08\u5305\u542b\u6570\u636e\u6e05\u6d17\u3001\u65e5\u5fd7\u3001\u5b9e\u9a8c\u8bb0\u5f55\uff09</p> <p>\u4f60\u5bf9\u54ea\u4e2a\u65b9\u5411\u66f4\u6709\u5174\u8da3\uff1f\u6211\u53ef\u4ee5\u7ee7\u7eed\u4e3a\u4f60\u5b9a\u5236\u5b8c\u6574\u5b66\u4e60\u8def\u7ebf\u3002</p>"},{"location":"llm/tunning/peft/quick%20start/","title":"\u5feb\u901f\u5165\u95e8","text":""},{"location":"llm/tunning/peft/quick%20start/#peft","title":"\u7b2c\u4e00\u90e8\u5206\uff1aPEFT \u662f\u4ec0\u4e48\uff1f\u4e3a\u4ec0\u4e48\u8981\u7528\uff1f","text":""},{"location":"llm/tunning/peft/quick%20start/#_1","title":"\u6982\u5ff5","text":"<ul> <li>PEFT \u662f\u4e00\u4e2a\u7531 Transformers\uff08Hugging Face \u51fa\u54c1\uff09\u751f\u6001\uff0f\u793e\u533a\u7ef4\u62a4\u7684\u5e93\uff0c\u4e13\u7528\u4e8e \u964d\u4f4e\u5fae\u8c03\u5927\u578b\u9884\u8bad\u7ec3\u6a21\u578b\uff08LLM\uff09\u65f6\u6240\u9700\u8bad\u7ec3\u53c2\u6570\uff0f\u663e\u5b58\uff0f\u5b58\u50a8\u6210\u672c\u3002 (Hugging Face)</li> <li>\u5b83\u7684\u6838\u5fc3\u601d\u8def\uff1a\u4e0d\u8981\u53bb\u66f4\u65b0\u6a21\u578b\u4e2d\u6240\u6709\u7684\u6743\u91cd\uff0c\u800c\u662f\u201c\u51bb\u7ed3\u201d\u4e3b\u8981\u7684\u9884\u8bad\u7ec3\u6a21\u578b\u90e8\u5206\uff0c\u4ec5\u589e\u52a0\uff0f\u5fae\u8c03\u4e00\u4e2a\u5c0f\u6a21\u5757\uff0fAdapter\uff0f\u63d0\u793a\uff08Prompt\uff09\u7b49\uff0c\u4ece\u800c\u8ba9\u6a21\u578b\u9002\u914d\u4e0b\u6e38\u4efb\u52a1\u3002 (Hugging Face)</li> <li>\u4e3e\u4f8b\u6765\u8bf4\uff0c\u539f\u672c\u4f60\u53ef\u80fd\u8981\u5bf9\u4e00\u4e2a 100 \u4ebf\u53c2\u6570\u7684\u6a21\u578b\u505a\u5fae\u8c03\uff0c\u4f46\u7528 PEFT \u65b9\u6cd5\uff0c\u4f60\u53ef\u80fd\u53ea\u8bad\u7ec3\u51e0\u767e\u4e07\u3001\u51e0\u5343\u4e07\u53c2\u6570\u3002 (GitHub)</li> </ul>"},{"location":"llm/tunning/peft/quick%20start/#_2","title":"\u4e3a\u4ec0\u4e48\u7528\uff1f\u4f18\u70b9","text":"<ul> <li>\u8282\u7701\u8d44\u6e90\uff1a\u663e\u5b58\uff0b\u5b58\u50a8\u90fd\u5c11\u5f88\u591a\u3002\u6bd4\u5982\u6587\u6863\u4e2d\u63d0\u5230\uff1a\u4f7f\u7528 LoRA (\u4e00\u79cd PEFT \u65b9\u6cd5) \u5bf9 12 B \u53c2\u6570\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\u65f6\uff0c\u663e\u5b58\uff0f\u5b58\u50a8\u8fdc\u4f4e\u4e8e\u5168\u5fae\u8c03\u3002 (GitHub)</li> <li>\u5feb\u901f\u8fed\u4ee3\uff1a\u56e0\u4e3a\u8bad\u7ec3\u53c2\u6570\u5c11\uff0c\u4f60\u53ef\u4ee5\u66f4\u5feb\u505a\u5b9e\u9a8c\u3002</li> <li>\u591a\u4efb\u52a1\uff0f\u591a\u57df\u9002\u914d\u66f4\u7075\u6d3b\uff1a\u4f60\u53ef\u4ee5\u4e00\u4e2a\u57fa\u7840\u6a21\u578b + \u591a\u4e2a\u5c0f Adapter\uff0c\u4e3a\u4e0d\u540c\u4efb\u52a1\u5207\u6362\u3002</li> <li>\u907f\u514d\u201c\u707e\u96be\u6027\u9057\u5fd8\u201d\uff08catastrophic forgetting\uff09\uff1a\u57fa\u7840\u6a21\u578b\u7684\u6743\u91cd\u88ab\u51bb\u7ed3\uff0c\u51cf\u5c11\u6539\u53d8\u5176\u9884\u8bad\u7ec3\u77e5\u8bc6\u7684\u98ce\u9669\u3002 (Hugging Face)</li> </ul>"},{"location":"llm/tunning/peft/quick%20start/#_3","title":"\u4f55\u65f6\u9002\u5408\u7528\uff1f","text":"<ul> <li>\u5f53\u4f60\u624b\u5934\u786c\u4ef6\u6709\u9650\uff08\u663e\u5b58/\u8d44\u6e90\u5c11\uff09\u3002</li> <li>\u5f53\u4f60\u6709\u591a\u4e2a\u4efb\u52a1\u90fd\u60f3\u57fa\u4e8e\u540c\u4e00\u4e2a\u5927\u578b\u6a21\u578b\uff0c\u4f46\u4e0d\u60f3\u6bcf\u4e2a\u90fd\u505a\u5b8c\u6574\u5fae\u8c03\u3002</li> <li>\u5f53\u4f60\u5e0c\u671b\u5fae\u8c03\u540e\u7684\u6a21\u578b\u4f53\u79ef\uff0f\u5b58\u50a8\uff0f\u90e8\u7f72\u6210\u672c\u4f4e\u3002</li> <li>\u5f53\u6570\u636e\u91cf\u53ef\u80fd\u8f83\u5c11\uff0c\u8bad\u7ec3\u6574\u4e2a\u6a21\u578b\u5bb9\u6613\u8fc7\u62df\u5408\u3002</li> </ul>"},{"location":"llm/tunning/peft/quick%20start/#_4","title":"\u7b2c\u4e8c\u90e8\u5206\uff1a\u5b89\u88c5\u4e0e\u5feb\u901f\u4e0a\u624b","text":""},{"location":"llm/tunning/peft/quick%20start/#_5","title":"\u5b89\u88c5","text":"<pre><code>pip install peft\n</code></pre> <p>\uff08\u786e\u4fdd\u4f60\u540c\u65f6\u5b89\u88c5\u4e86 Transformers\u3001Datasets\u3001Accelerate \u7b49\u6839\u636e\u4efb\u52a1\u53ef\u80fd\u9700\u8981\u7684\u5e93\uff09 (GitHub)</p>"},{"location":"llm/tunning/peft/quick%20start/#_6","title":"\u5feb\u901f\u542f\u52a8\u4ee3\u7801\u793a\u4f8b","text":"<p>\u5047\u8bbe\u4f60\u52a0\u8f7d\u4e00\u4e2a\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\uff0c\u7136\u540e\u7528 LoRA\uff08Low-Rank Adaptation\uff09\u8fd9\u79cd PEFT \u65b9\u6cd5\u3002</p> <pre><code>import torch\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\nfrom peft import LoraConfig, TaskType, get_peft_model\n\nmodel_name = \"your-base-model-name\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(model_name)\n\npeft_config = LoraConfig(\n    task_type=TaskType.CAUSAL_LM,\n    r=16,\n    lora_alpha=32,\n    lora_dropout=0.1\n)\n\nmodel = get_peft_model(model, peft_config)\nmodel.print_trainable_parameters()\n</code></pre> <p>\u5982\u6587\u6863\u4e2d\u6240\u793a\uff0c\u8fd9\u6837\u505a\u540e\uff0c\u201c\u53ef\u8bad\u7ec3\u53c2\u6570 / \u603b\u53c2\u6570\u201d\u7684\u6bd4\u4f8b\u4f1a\u975e\u5e38\u4f4e\u3002 (GitHub)</p>"},{"location":"llm/tunning/peft/quick%20start/#_7","title":"\u7b80\u5355\u8bf4\u660e","text":"<ul> <li><code>LoraConfig</code> \u5b9a\u4e49\u4e86 LoRA \u7684\u8d85\u53c2\u6570\uff0c\u6bd4\u5982 r\uff08\u79e9\u6570\uff09\u3001alpha\u3001dropout \u7b49\u3002</li> <li><code>get_peft_model()</code> \u628a\u57fa\u7840\u6a21\u578b\u5305\u8d77\u6765\uff0c\u5f62\u6210\u4e00\u4e2a\u5e26 Adapter \u7684\u6a21\u578b\uff1b\u57fa\u7840\u6a21\u578b\u5927\u90e8\u5206\u6743\u91cd\u88ab \u201c\u51bb\u7ed3\u201d\u3002</li> <li>\u4e4b\u540e\u4f60\u53ef\u4ee5\u50cf\u6807\u51c6\u8bad\u7ec3\u6d41\u7a0b\u90a3\u6837\uff08\u5b9a\u4e49\u8bad\u7ec3\u53c2\u6570\u3001Trainer\u3001Dataset \u7b49\uff09\u8fdb\u884c\u5fae\u8c03\u3002</li> </ul>"},{"location":"llm/tunning/peft/quick%20start/#peft_1","title":"\u7b2c\u4e09\u90e8\u5206\uff1a\u4e3b\u8981 PEFT \u65b9\u6cd5 &amp; \u5185\u90e8\u673a\u5236","text":""},{"location":"llm/tunning/peft/quick%20start/#_8","title":"\u5e38\u89c1\u65b9\u6cd5","text":"<p>\u4ee5\u4e0b\u662f\u5f53\u524d\u6bd4\u8f83\u5e38\u89c1\u7684\u6280\u672f\uff08PEFT \u6240\u652f\u6301\uff0f\u6587\u6863\u63d0\u5230\u7684\uff09\uff1a</p> \u65b9\u6cd5 \u7c7b\u578b \u7b80\u5355\u8bf4\u660e LoRA (Low-Rank Adaptation) \u589e\u6dfb\u5c11\u91cf\u53ef\u8bad\u7ec3\u4f4e\u79e9\u77e9\u9635 \u5c06\u6ce8\u610f\u529b\u5c42\u6216\u7ebf\u6027\u5c42\u4e2d\u7684\u66f4\u65b0\u53c2\u6570\u5206\u89e3\u4e3a\u4f4e\u79e9\u77e9\u9635\uff0c\u4ece\u800c\u6781\u5927\u7f29\u51cf\u53ef\u8bad\u7ec3\u53c2\u6570\u6570\u3002 (Hugging Face) Prompt Tuning / Soft-Prompting \u5728\u8f93\u5165\u5c42\u6216 embedding \u5c42\u6dfb\u52a0\u53ef\u8bad\u7ec3 prompt \u5411\u91cf \u6a21\u578b\u6743\u91cd\u57fa\u672c\u51bb\u7ed3\uff0c\u4ec5\u8bad\u7ec3\u201c\u63d0\u793a\u201d\u90e8\u5206\u3002 (Hugging Face) Prefix-Tuning \u5728 Transformer \u6a21\u578b\u524d\u52a0\u5165\u53ef\u8bad\u7ec3 prefix\uff08\u524d\u7f00\uff09 \u7c7b\u4f3c prompt\uff0c\u4f46\u66f4\u591a\u5730\u4f5c\u7528\u4e8e\u5185\u90e8\u9690\u85cf\u5c42\u3002 Adapter\uff08\u74f6\u9888\u9002\u914d\u5668\uff09 \u63d2\u5165\u5c0f\u6a21\u5757\u5230\u7f51\u7edc\u4e2d\uff0c\u4e2d\u95f4\u51bb\u7ed3\u4e3b\u5e72\u7f51\u7edc \u8bad\u7ec3\u5c11\u91cf\u53c2\u6570\u5373\u53ef\u9002\u914d\u4efb\u52a1\u3002"},{"location":"llm/tunning/peft/quick%20start/#lora","title":"LoRA \u7684\u5de5\u4f5c\u673a\u5236\uff08\u7565\u5fae\u6df1\u5165\uff09","text":"<p>\u8fd9\u662f\u4e00\u4e2a\u201c\u7406\u8bba\u80cc\u666f\u201d\u90e8\u5206\uff0c\u867d\u975e\u5fc5\u8981\u4f46\u6709\u52a9\u4e8e\u7406\u89e3\u3002</p> <ul> <li>\u5728 Transformer \u7684\u81ea\u6ce8\u610f\u529b (Self-Attention) \u6216\u524d\u9988 (Feed-Forward) \u7ebf\u6027\u5c42\u4e2d\uff0cLoRA \u63d2\u5165\u4e24\u4e2a\u53ef\u8bad\u7ec3\u77e9\u9635 A \u548c B\uff0c\u4f7f\u5f97\u539f\u6743\u91cd W \u66f4\u65b0\u4e3a W + B \u00d7 A\u3002</li> <li>\u56e0\u4e3a A \u548c B \u7684\u79e9(r)\u5f88\u5c0f\uff0c\u6240\u4ee5\u4f60\u5b9e\u9645\u4e0a\u53ea\u8bad\u7ec3 A \u548c B\uff0c\u800c\u4e0d\u662f W \u7684\u6240\u6709\u5143\u7d20\u3002\u8fd9\u6837\u53ef\u8bad\u7ec3\u53c2\u6570\u6570\u91cf\u5927\u5e45\u51cf\u5c11\u3002 (Hugging Face)</li> <li>\u5728\u63a8\u7406\u9636\u6bb5\uff0c\u53ef\u4ee5\u628a B \u00d7 A \u4e0e\u539f W \u5408\u5e76\uff0c\u4ece\u800c\u201c\u65e0\u989d\u5916\u5f00\u9500\u201d\u5730\u8fd0\u884c\u3002 (Hugging Face)</li> </ul>"},{"location":"llm/tunning/peft/quick%20start/#_9","title":"\u603b\u7ed3\u673a\u5236\u8981\u70b9","text":"<ul> <li>\u5927\u6a21\u578b\u7684\u4e3b\u4f53\u6743\u91cd\u57fa\u672c\u51bb\u7ed3 \u2192 \u8bad\u7ec3\u5c0f\u6a21\u5757</li> <li>\u6a21\u578b\u4f53\u79ef\u4fdd\u5b58\u5c0f\u3001\u5207\u6362\u4efb\u52a1\u5feb\u3001\u8d44\u6e90\u6d88\u8017\u5c11</li> <li>\u67d0\u4e9b\u65b9\u6cd5\u53ef\u591a\u4efb\u52a1\u5171\u4eab\u540c\u4e00\u4e3b\u5e72\u6a21\u578b + \u591a\u4e2a Adapter</li> </ul>"},{"location":"llm/tunning/peft/quick%20start/#_10","title":"\u7b2c\u56db\u90e8\u5206\uff1a\u5b8c\u6574\u4ee3\u7801\u793a\u4f8b \u2014 \u4efb\u52a1\u5fae\u8c03","text":"<p>\u4e0b\u9762\u6211\u4eec\u7528\u4e00\u4e2a\u7a0d\u5b8c\u6574\uff08\u4f46\u8fd8\u7b80\u5316\u7248\uff09\u7684\u793a\u4f8b\uff1a\u7528 PEFT \u7684 LoRA \u65b9\u6cd5\uff0c\u5bf9\u4e00\u4e2a\u56e0\u679c\u8bed\u8a00\u6a21\u578b\uff08CausalLM\uff09\u8fdb\u884c\u5fae\u8c03\u3002</p>"},{"location":"llm/tunning/peft/quick%20start/#_11","title":"\u4ee3\u7801\uff08\u7565\u7b80\u5316\uff09","text":"<pre><code>import torch\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\nfrom peft import LoraConfig, TaskType, get_peft_model\n\n# 1. \u52a0\u8f7d\u6570\u636e\u96c6\uff08\u4f8b\u5982\u67d0\u5bf9\u8bdd\uff0f\u6587\u672c\u751f\u6210\u4efb\u52a1\uff09\ndataset = load_dataset(\"wikitext\", \"wikitext-2-v1\")  # \u4e3e\u4f8b\n\n# 2. \u52a0\u8f7d tokenizer \u548c\u6a21\u578b\nmodel_name = \"gpt2\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(model_name)\n\n# 3. \u9884\u5904\u7406\u6570\u636e\uff08tokenize\uff09\ndef tokenize_fn(examples):\n    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=128)\n\ntokenized = dataset.map(tokenize_fn, batched=True)\ntrain_dataset = tokenized[\"train\"]\n\n# 4. \u914d\u7f6e PEFT\npeft_config = LoraConfig(\n    task_type=TaskType.CAUSAL_LM,\n    r=8,\n    lora_alpha=16,\n    lora_dropout=0.05\n)\n\nmodel = get_peft_model(model, peft_config)\nmodel.print_trainable_parameters()\n\n# 5. \u8bad\u7ec3\u53c2\u6570\ntraining_args = TrainingArguments(\n    output_dir=\"peft_lora_gpt2\",\n    num_train_epochs=1,\n    per_device_train_batch_size=4,\n    save_steps=500,\n    logging_steps=100\n)\n\n# 6. Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n)\n\n# 7. \u8bad\u7ec3\ntrainer.train()\n\n# 8. \u4fdd\u5b58\nmodel.save_pretrained(\"peft_lora_gpt2_adapter\")\ntokenizer.save_pretrained(\"peft_lora_gpt2_adapter\")\n</code></pre>"},{"location":"llm/tunning/peft/quick%20start/#_12","title":"\u8bf4\u660e","text":"<ul> <li>\u6211\u7528\u4e86 GPT-2 \u4f5c\u4e3a\u201c\u57fa\u7840\u6a21\u578b\u201d\uff08\u53ea\u662f\u6f14\u793a\u7528\uff0c\u5c0f\u6a21\u578b\uff09\u3002</li> <li>\u6570\u636e\u96c6\u7528\u7684\u662f WikiText2\uff08\u4e5f\u662f\u6f14\u793a\uff09\u3002</li> <li>\u6ce8\u610f <code>model.print_trainable_parameters()</code> \u80fd\u5e2e\u4f60\u786e\u8ba4\u201c\u8bad\u7ec3\u53c2\u6570 vs \u603b\u53c2\u6570\u201d\u7684\u6bd4\u4f8b\u3002</li> <li>\u6700\u540e\u4f60\u4fdd\u5b58\u7684\u76ee\u5f55\u4e3b\u8981\u5305\u542b Adapter \u6743\u91cd\uff08\u800c\u4e0d\u662f\u6574\u4e2a\u5927\u578b\u6a21\u578b\u539a\u91cd\u7684\u68c0\u67e5\u70b9\uff09\u3002</li> <li>\u63a8\u7406\u6216\u90e8\u7f72\u65f6\uff0c\u4f60\u53ef\u4ee5\u52a0\u8f7d\u57fa\u7840\u6a21\u578b + adapter \u6743\u91cd\u3002\u6587\u6863\u4e2d\u6709\u76f8\u5e94\u8bf4\u660e\u3002 (Hugging Face)</li> </ul>"},{"location":"llm/tunning/peft/quick%20start/#_13","title":"\u7b2c\u4e94\u90e8\u5206\uff1a\u8fdb\u9636\u6280\u5de7 &amp;\u90e8\u7f72\u8981\u70b9","text":""},{"location":"llm/tunning/peft/quick%20start/#adapter","title":"\u5408\u5e76 Adapter\u3001\u90e8\u7f72","text":"<ul> <li>\u8bad\u7ec3\u5b8c\u540e\uff0c\u5982\u679c\u4f60\u4e0d\u5e0c\u671b\u5728\u6bcf\u6b21\u63a8\u7406\u65f6\u90fd\u52a0\u8f7d adapter \u548c\u57fa\u7840\u6a21\u578b\u5206\u79bb\u7ed3\u6784\uff0c\u53ef\u4ee5\u5c06 adapter \u201c\u5408\u5e76\u201d\u56de\u57fa\u7840\u6a21\u578b\u3002\u6587\u6863\u4e2d\u4ecb\u7ecd\u4e86 <code>merge_and_unload()</code> \u7b49\u65b9\u6cd5\u3002 (Hugging Face)</li> <li>\u5408\u5e76\u540e\u4f60\u5f97\u5230\u4e00\u4e2a\u201c\u666e\u901a\u6a21\u578b\u201d\u4f46\u4ecd\u7136\u4fdd\u7559\u4e86\u4efb\u52a1-\u7279\u5b9a\u7684\u6743\u91cd\u4fee\u6539\uff0c\u90e8\u7f72\u66f4\u7b80\u4fbf\u3002</li> </ul>"},{"location":"llm/tunning/peft/quick%20start/#_14","title":"\u4e0e\u91cf\u5316\uff0f\u4f4e\u7cbe\u5ea6\uff0f\u5927\u6a21\u578b\u534f\u4f5c","text":"<ul> <li>PEFT \u65b9\u6cd5\u975e\u5e38\u9002\u5408\u4e0e\u91cf\u5316\uff08Quantization\uff0c\u4f8b\u5982 4-bit\uff0f8-bit\uff09\u7ed3\u5408\u4f7f\u7528\uff0c\u4ece\u800c\u5728\u8d44\u6e90\u6781\u9650\u73af\u5883\uff08\u5982\u5c0f\u663e\u5b58 GPU\uff09\u4e5f\u80fd\u5fae\u8c03\uff0f\u90e8\u7f72\u3002 (GitHub)</li> <li>\u5982\u679c\u6a21\u578b\u975e\u5e38\u5de8\u5927\uff0c\u4f60\u53ef\u80fd\u8fd8\u8981\u7528\u5206\u5e03\u5f0f\u8bad\u7ec3\u3001\u6df7\u5408\u7cbe\u5ea6\u3001Gradient Checkpointing \u7b49\u6280\u672f\uff0c\u8fd9\u91cc PEFT \u51cf\u5c11\u8bad\u7ec3\u53c2\u6570\u662f\u4e00\u4e2a\u5f88\u597d\u7684\u52a9\u529b\u3002</li> </ul>"},{"location":"llm/tunning/peft/quick%20start/#adapter_1","title":"\u591a\u4efb\u52a1 &amp;\u5207\u6362 Adapter","text":"<ul> <li>\u57fa\u7840\u6a21\u578b + \u591a\u4e2a Adapter\uff1a\u4f60\u53ef\u4ee5\u9488\u5bf9\u4e0d\u540c\u4efb\u52a1\u8bad\u7ec3\u591a\u4e2a\u5c0f\u6a21\u5757\uff0c\u90e8\u7f72\u65f6\u53ea\u52a0\u8f7d\u5bf9\u5e94 adapter\u3002</li> <li>\u8fd9\u6837\u4f60\u53ef\u4ee5\u7528\u4e00\u5957\u57fa\u7840\u6a21\u578b\u670d\u52a1\u591a\u79cd\u4efb\u52a1\uff0c\u51cf\u5c11\u91cd\u590d\u5b58\u50a8\u3002</li> </ul>"},{"location":"llm/tunning/peft/quick%20start/#_15","title":"\u6ce8\u610f\u4e8b\u9879\uff0f\u5c40\u9650\u6027","text":"<ul> <li>\u867d\u7136 PEFT \u5728\u5f88\u591a\u573a\u666f\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5e76\u975e\u603b\u80fd\u5b8c\u5168\u8fbe\u5230\u201c\u5168\u5fae\u8c03\u201d\u7684\u6027\u80fd\u3002\u4f60\u9700\u8981\u505a\u9a8c\u8bc1\u3002</li> <li>\u9009\u53d6\u5408\u9002\u7684\u8d85\u53c2\u6570\uff08\u6bd4\u5982 r\u3001alpha\u3001dropout\uff09\u4ecd\u65e7\u5f88\u91cd\u8981\u3002</li> <li>\u67d0\u4e9b\u6a21\u578b\u7ed3\u6784\u53ef\u80fd\u4e0d\u5b8c\u5168\u517c\u5bb9\u6240\u6709 PEFT \u65b9\u6cd5\uff0c\u9700\u67e5\u6587\u6863\u6216\u505a\u5b9e\u9a8c\u3002</li> <li>\u90e8\u7f72\u65f6\u8981\u6ce8\u610f Adapter \u548c\u57fa\u7840\u6a21\u578b\u7684\u7248\u672c\u4e00\u81f4\u3001tokenizer \u914d\u7f6e\u4e00\u81f4\u3001\u8bbe\u5907\uff0f\u7cbe\u5ea6\u4e00\u81f4\u3002</li> </ul>"},{"location":"llm/tunning/peft/quick%20start/#_16","title":"\u7b2c\u516d\u90e8\u5206\uff1a\u603b\u7ed3 +\u4e0b\u4e00\u6b65\u5efa\u8bae","text":""},{"location":"llm/tunning/peft/quick%20start/#_17","title":"\u603b\u7ed3","text":"<p>PEFT \u662f\u4e00\u4e2a\u975e\u5e38\u5f3a\u5927\u7684\u6280\u672f\u5de5\u5177\uff0c\u5e2e\u52a9\u6211\u4eec\u7528\u66f4\u5c11\u7684\u8d44\u6e90\u3001\u4ee5\u66f4\u7075\u6d3b\u7684\u65b9\u5f0f\u9002\u914d\u5927\u6a21\u578b\u3002\u5b83\u9002\u5408\uff1a\u8d44\u6e90\u53d7\u9650\u3001\u4efb\u52a1\u591a\u6837\u3001\u5feb\u901f\u8fed\u4ee3\u8fd9\u4e9b\u573a\u666f\u3002 \u901a\u8fc7\u672c\u6559\u7a0b\uff0c\u4f60\u5e94\u5f53\u7406\u89e3\u4e86\uff1a</p> <ul> <li>\u4ec0\u4e48\u662f PEFT\u3001\u4e3a\u4ec0\u4e48\u8981\u7528\uff1b</li> <li>\u5982\u4f55\u5b89\u88c5\u5e76\u505a\u7b80\u5355\u4e0a\u624b\uff1b</li> <li>\u5e38\u89c1\u65b9\u6cd5\uff08LoRA\u3001Prompt Tuning \u7b49\uff09\u53ca\u5176\u4f5c\u7528\u673a\u5236\uff1b</li> <li>\u5982\u4f55\u7528\u4e00\u6bb5\u4ee3\u7801\u5fae\u8c03\u6a21\u578b\uff1b</li> <li>\u8fdb\u9636\u90e8\u7f72\uff0f\u91cf\u5316\uff0f\u591a\u4efb\u52a1\u4e0b\u7684\u5b9e\u7528\u6280\u5de7\u3002</li> </ul>"},{"location":"llm/tunning/peft/quick%20start/#_18","title":"\u4e0b\u4e00\u6b65\u5efa\u8bae","text":"<ul> <li>\u9009\u4e00\u4e2a\u4f60\u5173\u5fc3\u7684\u4efb\u52a1\uff08\u4f8b\u5982\u4e2d\u6587\u6587\u672c\u751f\u6210\u3001\u6458\u8981\u3001\u5206\u7c7b\u3001\u95ee\u7b54\uff09\uff0c\u5c1d\u8bd5\u7528 PEFT \u65b9\u6cd5\u5fae\u8c03\u4e00\u4e2a\u57fa\u7840\u6a21\u578b\u3002</li> <li>\u5b9e\u9a8c\u4e0d\u540c\u7684\u8d85\u53c2\u6570\uff1a\u6bd4\u5982 LoRA \u7684 r \u503c\u3001dropout \u7387\u3001\u8bad\u7ec3\u6279\u6b21\u3001\u6570\u636e\u91cf\uff0c\u770b\u54ea\u4e2a\u7ec4\u5408\u6548\u679c\u597d\u3002</li> <li>\u63a2\u7d22\u5c06\u91cf\u5316\uff08\u4f8b\u5982 8-bit\uff09\u4e0e PEFT \u7ed3\u5408\u4f7f\u7528\uff0c\u5728\u8f83\u4f4e\u663e\u5b58\u7684 GPU \u4e0a\u5fae\u8c03\u3002</li> <li>\u90e8\u7f72\u4e00\u4e2a\u7b80\u5355 demo\uff1a\u5c06\u5fae\u8c03\u540e\u7684\u6a21\u578b\u5305\u88c5\u5728\u4e00\u4e2a Web UI\uff08\u6bd4\u5982\u7528 Gradio\uff09\u91cc\uff0c\u4f53\u9a8c\u771f\u5b9e\u4ea4\u4e92\u3002</li> <li>\u9605\u8bfb PEFT \u7684 \u201cConceptual guides\u201d \u548c \u201cHow-to guides\u201d \u6765\u6df1\u5165\u4e86\u89e3\u4e0d\u540c\u4efb\u52a1\uff08\u56fe\u50cf\u3001\u97f3\u9891\u3001\u591a\u6a21\u6001\uff09\u4e0b\u7684\u5e94\u7528\u3002 (Hugging Face)</li> </ul> <p>\u5982\u679c\u4f60\u613f\u610f\uff0c\u6211\u53ef\u4ee5 \u4e3a\u4f60\u751f\u6210\u4e00\u4e2a\u4e13\u95e8\u9488\u5bf9\u4e2d\u6587\u4efb\u52a1\uff08\u5982\u4e2d\u6587\u60c5\u611f\u5206\u6790\u6216\u4e2d\u6587\u6458\u8981\u751f\u6210\uff09\u7684 PEFT \u5fae\u8c03\u4ee3\u7801\u6a21\u677f\uff0c\u8fd8\u53ef\u4ee5\u914d\u4e0a \u201c\u6570\u636e\u51c6\u5907 \u2192 \u5fae\u8c03 \u2192\u90e8\u7f72\u201d \u5168\u6d41\u7a0b\u3002\u8981\u5417\uff1f</p>"},{"location":"llm/tunning/transformers/quick%20start/","title":"\u5feb\u901f\u5165\u95e8","text":""},{"location":"llm/tunning/transformers/quick%20start/#transformers","title":"\u7b2c\u4e00\u90e8\u5206\uff1a\u4ec0\u4e48\u662f Transformers\uff1f","text":""},{"location":"llm/tunning/transformers/quick%20start/#_1","title":"\u6982\u5ff5\u8bf4\u660e","text":"<ul> <li>Transformers \u5e93\u662f\u4e00\u4e2a\u7edf\u4e00\u63a5\u53e3\uff0c\u7528\u6765\u8c03\u7528 \u201c\u5df2\u9884\u8bad\u7ec3\uff08pre-trained\uff09\u201d \u7684 Transformer \u6a21\u578b\uff08\u4f8b\u5982\u6587\u672c\u3001\u56fe\u50cf\u3001\u97f3\u9891\u3001\u591a\u6a21\u6001\u7b49\uff09\u7528\u4e8e \u63a8\u7406\uff08inference\uff09 \u6216 \u8bad\u7ec3\uff0f\u5fae\u8c03\uff08training/fine-tuning\uff09\u3002(Hugging Face)</li> <li>\u5b83\u7684\u8bbe\u8ba1\u539f\u5219\u5305\u62ec\uff1a\u5feb\u901f\u4e0a\u624b\u3001\u517c\u5bb9\u4e3b\u6d41\u6846\u67b6\uff08\u5982 PyTorch\uff09\u3001\u63d0\u4f9b\u4e30\u5bcc\u7684\u9884\u8bad\u7ec3\u6a21\u578b\u4ee5\u8282\u7701\u7b97\u529b/\u65f6\u95f4\u6210\u672c\u3002(Hugging Face)</li> <li>\u5b83\u63d0\u4f9b\u4e86\u8bb8\u591a\u9ad8\u5c42 API\uff08\u4f8b\u5982 <code>Pipeline</code>\u3001<code>Trainer</code>\u3001<code>generate</code> \u7b49\uff09\u6765\u7b80\u5316\u5e38\u89c1\u4efb\u52a1\u3002(Hugging Face)</li> </ul>"},{"location":"llm/tunning/transformers/quick%20start/#_2","title":"\u4e3a\u4ec0\u4e48\u7528\u5b83\uff1f","text":"<ul> <li>\u5982\u679c\u4f60\u4e0d\u60f3\u4ece\u5934\u8bad\u7ec3\u4e00\u4e2a\u6a21\u578b\uff0c\u800c\u662f\u60f3\u62ff\u4e00\u4e2a\u9884\u8bad\u7ec3\u597d\u7684\u6a21\u578b\uff08\u6bd4\u5982 BERT\u3001GPT\u3001T5\u3001Vision Transformer\uff09\u7acb\u523b\u7528\u8d77\u6765\uff0c\u8fd9\u4e2a\u5e93\u975e\u5e38\u65b9\u4fbf\u3002</li> <li>\u5b83\u5e2e\u4f60\u8de8\u8d8a \u201c\u6a21\u578b\u5b9a\u4e49\u201d\u201c\u9884\u5904\u7406\u201d\u201c\u63a8\u7406\u201d\u201c\u8bad\u7ec3\u5faa\u73af\u201d \u8fd9\u4e9b\u7e41\u6742\u7ec6\u8282\u3002</li> <li>\u793e\u533a\u6a21\u578b\u8d44\u6e90\u4e30\u5bcc\uff0c\u4f60\u53ef\u4ee5\u76f4\u63a5\u4ece Hugging Face Hub \u88c5\u8f7d\u4e00\u4e2a\u6a21\u578b\u3002(Hugging Face)</li> </ul>"},{"location":"llm/tunning/transformers/quick%20start/#_3","title":"\u7b2c\u4e8c\u90e8\u5206\uff1a\u5b89\u88c5\u4e0e\u73af\u5883\u51c6\u5907","text":""},{"location":"llm/tunning/transformers/quick%20start/#_4","title":"\u5b89\u88c5","text":"<p>\u9996\u5148\uff0c\u4f60\u9700\u8981\u5b89\u88c5 Transformers \u5e93\uff08\u4ee5\u53ca\u53ef\u80fd\u7684\u4f9d\u8d56\uff0c\u6bd4\u5982 <code>torch</code>\uff09\u3002\u4f8b\u5982\uff1a</p> <pre><code>pip install transformers\n</code></pre> <p>\u6216\u5982\u679c\u4f60\u8fd8\u6ca1\u88c5 PyTorch\uff1a</p> <pre><code>pip install torch transformers\n</code></pre> <p>\u6839\u636e\u5b98\u65b9\u6587\u6863\u3002(Hugging Face)</p>"},{"location":"llm/tunning/transformers/quick%20start/#_5","title":"\u79bb\u7ebf\uff0f\u7f13\u5b58\u6a21\u5f0f\uff08\u53ef\u9009\uff09","text":"<p>\u5982\u679c\u4f60\u662f\u5728\u65e0\u7f51\u7edc\u6216\u79bb\u7ebf\u73af\u5883\uff0c\u53ef\u4ee5\u8bbe\u7f6e\u7f13\u5b58\u6216\u4f7f\u7528 <code>local_files_only=True</code> \u53c2\u6570\u6765\u52a0\u8f7d\u5df2\u4e0b\u8f7d\u597d\u7684\u6a21\u578b\u3002(Hugging Face)</p>"},{"location":"llm/tunning/transformers/quick%20start/#quickstart","title":"\u7b2c\u4e09\u90e8\u5206\uff1a\u5feb\u901f\u4e0a\u624b\uff08Quickstart\uff09","text":"<p>\u6211\u4eec\u6765\u505a\u4e00\u4e2a\u975e\u5e38\u7b80\u5355\u7684\u4f8b\u5b50\uff1a\u52a0\u8f7d\u4e00\u4e2a\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u7528 <code>Pipeline</code> \u505a\u6587\u672c\u751f\u6210\uff08\u6216\u6587\u672c\u5206\u7c7b\uff09\u2014\u2014\u5148\u8bd5 \u201c\u63a8\u7406\u201d \u800c\u4e0d\u662f\u8bad\u7ec3\u3002</p>"},{"location":"llm/tunning/transformers/quick%20start/#_6","title":"\u4ee3\u7801\u793a\u4f8b\uff08\u6587\u672c\u751f\u6210\uff09\uff1a","text":"<pre><code>from transformers import pipeline\n\ngenerator = pipeline(\"text-generation\", model=\"gpt2\")\n\nprompt = \"Once upon a time\"\nresult = generator(prompt, max_length=50, num_return_sequences=1)\n\nprint(result[0][\"generated_text\"])\n</code></pre> <p>\u89e3\u91ca\uff1a</p> <ul> <li><code>pipeline(\"text-generation\", model=\"gpt2\")</code> \u4f1a\u81ea\u52a8\u4e0b\u8f7d\u6a21\u578b \u201cgpt2\u201d \u53ca\u5176 tokenizer\u3002</li> <li><code>generator(prompt, max_length=50)</code> \u8868\u793a\u4ece prompt \u5f00\u59cb\u751f\u6210\u76f4\u5230\u603b\u957f\u5ea6 50\u3002</li> <li>\u8f93\u51fa\u662f\u4e00\u4e2a\u5b57\u5178\u7684\u5217\u8868\uff0c\u53d6\u7b2c\u4e00\u4e2a\u7684 <code>\"generated_text\"</code>\u3002</li> </ul>"},{"location":"llm/tunning/transformers/quick%20start/#_7","title":"\u4ee3\u7801\u793a\u4f8b\uff08\u6587\u672c\u5206\u7c7b\uff09\uff1a","text":"<pre><code>from transformers import pipeline\n\nclassifier = pipeline(\"sentiment-analysis\")\n\nresult = classifier(\"I love using Hugging Face Transformers!\")\nprint(result)\n</code></pre> <p>\u8fd9\u6837\u4f60\u5c31\u53ef\u4ee5\u7acb\u523b\u5f00\u59cb\u4f53\u9a8c\uff1a\u8f93\u5165\u4e00\u53e5\u8bdd\uff0c\u5f97\u5230\u60c5\u611f\u5206\u7c7b\u7ed3\u679c\u3002</p>"},{"location":"llm/tunning/transformers/quick%20start/#_8","title":"\u5feb\u901f\u4e0a\u624b\u8bf4\u660e","text":"<p>\u5b98\u65b9\u79f0\uff0c\u5728 Quickstart \u90e8\u5206\u4f60\u53ea\u8981\u505a\u4e24\u4ef6\u4e3b\u8981\u4e8b\u60c5\uff1a</p> <ul> <li>\u52a0\u8f7d\u4e00\u4e2a\u9884\u8bad\u7ec3\u6a21\u578b</li> <li>\u7528 Pipeline \u6216\u8005\u7528\u7b80\u5355\u7684\u6a21\u578b + tokenizer \u6765\u8fd0\u884c\u63a8\u7406\u3002(Hugging Face)</li> </ul> <p>\u6240\u4ee5\uff0c\u4e0a\u9762\u5c31\u662f\u5165\u95e8\u6b65\u9aa4\u3002</p>"},{"location":"llm/tunning/transformers/quick%20start/#_9","title":"\u7b2c\u56db\u90e8\u5206\uff1a\u57fa\u7840\u6784\u6210 \u2013 \u6a21\u578b\uff0f\u914d\u7f6e\uff0f\u9884\u5904\u7406\u5668","text":"<p>\u5728\u4f60\u6df1\u5165\u8bad\u7ec3\u6216\u81ea\u5b9a\u4e49\u6a21\u578b\u4e4b\u524d\uff0c\u7406\u89e3 Transformers \u7684\u4e09\u5927\u6838\u5fc3\u7c7b\u7ed3\u6784\u4f1a\u5f88\u6709\u5e2e\u52a9\uff08\u5b98\u65b9\u4e5f\u5f3a\u8c03\u8fd9\u4e00\u70b9\uff09\u3002(Hugging Face)</p> <ul> <li>Configuration\uff08\u914d\u7f6e\uff09\uff1a\u4fdd\u5b58\u6a21\u578b\u7ed3\u6784\u3001\u8d85\u53c2\u6570\u3001\u8bcd\u6c47\u8868\u5927\u5c0f\u7b49\u4fe1\u606f\u3002</li> <li>Tokenizer\uff0fPreprocessor\uff08\u9884\u5904\u7406\u5668\uff09\uff1a\u8d1f\u8d23\u628a\u539f\u59cb\u8f93\u5165\uff08\u5982\u6587\u672c\uff09\u8f6c\u4e3a\u6a21\u578b\u80fd\u7406\u89e3\u7684 \u201ctoken ids\u201d \u4ee5\u53ca\u505a padding/truncation \u7b49\u3002</li> <li>Model\uff08\u6a21\u578b\uff09\uff1a\u5b9e\u9645\u7684\u795e\u7ecf\u7f51\u7edc\u6743\u91cd\uff0b\u7ed3\u6784\uff0c\u6bd4\u5982 <code>BertForSequenceClassification</code>\uff0c\u6216\u8005 <code>AutoModelForCausalLM</code>\u3002</li> </ul> <p>\u7406\u89e3\u8fd9\u4e09\u7c7b\uff0c\u4f1a\u8ba9\u4f60\u77e5\u9053\uff1a\u4ece \u201c\u539f\u59cb\u6570\u636e\u201d \u2192 \u201ctokenizer\u201d \u2192 \u201c\u8f93\u5165\u6a21\u578b\u201d \u2192 \u201c\u8f93\u51fa\u7ed3\u679c\u201d \u7684\u6d41\u7a0b\u3002</p>"},{"location":"llm/tunning/transformers/quick%20start/#fine-tuning","title":"\u7b2c\u4e94\u90e8\u5206\uff1a\u5fae\u8c03 (Fine-Tuning) \u4e0e\u8bad\u7ec3","text":"<p>\u5f53\u4f60\u60f3\u8ba9\u6a21\u578b\u9002\u5e94 \u7279\u5b9a\u4efb\u52a1\uff08\u800c\u4e0d\u4ec5\u4ec5\u901a\u7528\u63a8\u7406\uff09\u65f6\uff0c\u5c31\u4f1a\u7528\u5230\u5fae\u8c03\u3002\u5b98\u65b9\u6587\u6863\u8bf4\u660e\uff1a\u201c\u5fae\u8c03\u8ba9\u9884\u8bad\u7ec3\u6a21\u578b\u9002\u7528\u4e8e\u4e00\u4e2a\u66f4\u5177\u4f53\u7684\u5c0f\u6570\u636e\u96c6\u4efb\u52a1\uff0c\u8017\u65f6\uff0f\u786c\u4ef6 \u6bd4\u4ece\u5934\u8bad\u7ec3\u5c11\u5f88\u591a\u3002\u201d(Hugging Face)</p>"},{"location":"llm/tunning/transformers/quick%20start/#_10","title":"\u5fae\u8c03\u6d41\u7a0b\uff08\u5927\u81f4\u6b65\u9aa4\uff09","text":"<ol> <li>\u52a0\u8f7d\u6570\u636e\u96c6\uff08\u4f8b\u5982\u6587\u672c\u5206\u7c7b\u3001\u95ee\u7b54\u3001\u6458\u8981\u7b49\u4efb\u52a1\uff09</li> </ol> <pre><code>from datasets import load_dataset\ndataset = load_dataset(\"yelp_review_full\")\n</code></pre> <ol> <li>\u52a0\u8f7d tokenizer</li> </ol> <pre><code>from transformers import AutoTokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-cased\")\n</code></pre> <ol> <li>\u5bf9\u6570\u636e\u505a\u9884\u5904\u7406\uff08tokenize\u3001padding\u3001truncation\uff09</li> </ol> <pre><code>def tokenize_fn(examples):\n    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\ndataset = dataset.map(tokenize_fn, batched=True)\n</code></pre> <ol> <li>\u52a0\u8f7d\u6a21\u578b\uff08\u4efb\u52a1\u7279\u5b9a\uff0c\u6bd4\u5982\u5206\u7c7b\u4efb\u52a1\uff09</li> </ol> <pre><code>from transformers import AutoModelForSequenceClassification\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    \"google-bert/bert-base-cased\", num_labels=5\n)\n</code></pre> <p>\uff08\u6ce8\u610f\uff1a\u9884\u8bad\u7ec3\u6a21\u578b\u7684 head \u901a\u5e38\u88ab\u66ff\u6362\u4e3a\u4e0e\u4f60\u4efb\u52a1\u5bf9\u5e94\u7684 head\u3002\uff09(Hugging Face) 5. \u5b9a\u4e49\u8bad\u7ec3\u53c2\u6570\uff08<code>TrainingArguments</code>\uff09</p> <pre><code>from transformers import TrainingArguments\ntraining_args = TrainingArguments(\n    output_dir=\"yelp_review_classifier\",\n    eval_strategy=\"epoch\",\n    push_to_hub=True\n)\n</code></pre> <ol> <li>\u521b\u5efa Trainer \u5e76\u8bad\u7ec3</li> </ol> <pre><code>from transformers import Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=dataset[\"train\"],\n    eval_dataset=dataset[\"test\"]\n)\ntrainer.train()\n</code></pre> <ol> <li>\u8bc4\u4f30\uff0f\u4fdd\u5b58\uff0f\u4e0a\u4f20\u6a21\u578b</li> </ol>"},{"location":"llm/tunning/transformers/quick%20start/#_11","title":"\u6ce8\u610f\u4e8b\u9879","text":"<ul> <li>\u5fae\u8c03\u4ecd\u7136\u9700\u8981 GPU\uff0f\u5927\u91cf\u5185\u5b58\uff0c\u5426\u5219\u8bad\u7ec3\u4f1a\u975e\u5e38\u6162\u3002</li> <li>\u6570\u636e\u9884\u5904\u7406\uff08tokenization\uff09\u5f80\u5f80\u662f\u74f6\u9888\uff0c\u9700\u8981\u4f18\u5316\u3002</li> <li>\u5982\u679c\u6a21\u578b\u5f88\u5927\uff08\u5982\u6570\u5341\u4ebf\u53c2\u6570\uff09\uff0c\u63a8\u8350\u4f7f\u7528 \u201c\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\uff08PEFT\uff09\u201d \u7b49\u6280\u672f\u3002(OpenAI Cookbook)</li> </ul>"},{"location":"llm/tunning/transformers/quick%20start/#_12","title":"\u7b2c\u516d\u90e8\u5206\uff1a\u5b9e\u6218\u793a\u4f8b\uff1a\u6587\u672c\u5206\u7c7b + \u6587\u672c\u751f\u6210","text":"<p>\u6211\u4eec\u6765\u5199\u4e24\u4e2a\u7a0d\u590d\u6742\u4e00\u70b9\u7684\u5b8c\u6574\u793a\u4f8b\u4ee3\u7801\u7247\u6bb5\u3002</p>"},{"location":"llm/tunning/transformers/quick%20start/#a","title":"\u793a\u4f8b A\uff1a\u6587\u672c\u5206\u7c7b\u5fae\u8c03\uff08\u60c5\u611f\u5206\u6790\uff09","text":"<pre><code>from datasets import load_dataset\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n\n# 1. \u6570\u636e\u96c6\ndataset = load_dataset(\"yelp_review_full\")\n\n# 2. tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-cased\")\n\n# 3. \u9884\u5904\u7406\ndef tokenize_fn(examples):\n    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n\ndataset = dataset.map(tokenize_fn, batched=True)\ndataset = dataset.shuffle(seed=42).select(range(2000))  # \u5c0f\u6837\u672c\u505a\u6d4b\u8bd5\n\n# 4. \u6a21\u578b\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    \"google-bert/bert-base-cased\", num_labels=5\n)\n\n# 5. \u8bad\u7ec3\u53c2\u6570\ntraining_args = TrainingArguments(\n    output_dir=\"yelp_classifier\",\n    evaluation_strategy=\"epoch\",\n    push_to_hub=False,\n    num_train_epochs=1,\n    per_device_train_batch_size=8\n)\n\n# 6. Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=dataset[\"train\"],\n    eval_dataset=dataset[\"test\"]\n)\n\n# 7. \u8bad\u7ec3\ntrainer.train()\n</code></pre>"},{"location":"llm/tunning/transformers/quick%20start/#b-prompt","title":"\u793a\u4f8b B\uff1a\u6587\u672c\u751f\u6210\uff0b\u5b9a\u5236 prompt","text":"<pre><code>from transformers import pipeline\n\ngenerator = pipeline(\"text-generation\", model=\"gpt2\")\n\nprompt = \"In a distant future, humanity has colonized Mars. The first Martian city was built on \"\nresult = generator(prompt, max_length=100, num_return_sequences=1)\nprint(result[0][\"generated_text\"])\n</code></pre> <p>\u4f60\u53ef\u4ee5\u628a\u8fd9\u4e2a\u4f5c\u4e3a \u201c\u751f\u6210\u6545\u4e8b\u201d\u201c\u5199\u8bd7\u201d\u201c\u751f\u6210\u5bf9\u8bdd\u201d \u7684\u8d77\u70b9\u3002</p>"},{"location":"llm/tunning/transformers/quick%20start/#_13","title":"\u7b2c\u4e03\u90e8\u5206\uff1a\u8fdb\u9636\u4e3b\u9898\uff0f\u5b9e\u7528\u6280\u5de7","text":"<ul> <li>\u5bfc\u51fa\u6a21\u578b\uff0f\u90e8\u7f72\uff1a \u8bad\u7ec3\u5b8c\u4e4b\u540e\uff0c\u4f60\u53ef\u80fd\u60f3\u628a\u6a21\u578b\u5bfc\u51fa\uff08\u4f8b\u5982 ONNX\u3001TorchScript\uff09\u6216\u90e8\u7f72\u5230\u751f\u4ea7\u73af\u5883\u3002</li> <li>\u91cf\u5316\uff0f\u526a\u679d\uff08Quantization/Pruning\uff09\uff1a \u5bf9\u6a21\u578b\u505a\u8f7b\u91cf\u5316\u5904\u7406\uff0c\u4ee5\u4fbf\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u8fd0\u884c\u3002</li> <li>\u591a\u6a21\u6001\uff0f\u89c6\u89c9\uff0f\u97f3\u9891\u4efb\u52a1\uff1a Transformers \u4e0d\u4ec5\u7528\u4e8e\u6587\u672c\uff0c\u8fd8\u652f\u6301\u56fe\u50cf\u3001\u97f3\u9891\u3001\u591a\u6a21\u6001\u3002</li> <li>\u5927\u89c4\u6a21\u8bad\u7ec3\uff0f\u5206\u5e03\u5f0f\u8bad\u7ec3\uff1a \u4f7f\u7528 <code>Trainer</code> \u652f\u6301\u591aGPU\uff0f\u6df7\u5408\u7cbe\u5ea6\u8bad\u7ec3\u3002</li> <li>\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\uff08PEFT\uff09\u7b49\uff1a \u5982\u679c\u6a21\u578b\u592a\u5927\uff0c\u8bad\u7ec3\u6210\u672c\u592a\u9ad8\uff0c\u53ef\u4ee5\u7528 LoRA\u3001Adapter\u3001Prefix-tuning \u7b49\u6280\u672f\u3002(OpenAI Cookbook)</li> <li>\u5229\u7528 Hub\uff1a \u628a\u4f60\u7684\u8bad\u7ec3\u7ed3\u679c\u4e0a\u4f20\u5230 Hugging Face Hub \u4e0e\u793e\u533a\u5171\u4eab\u3002</li> </ul>"},{"location":"llm/tunning/transformers/quick%20start/#_14","title":"\u7b2c\u516b\u90e8\u5206\uff1a\u603b\u7ed3 + \u4e0b\u4e00\u6b65\u5efa\u8bae","text":""},{"location":"llm/tunning/transformers/quick%20start/#_15","title":"\u603b\u7ed3","text":"<ul> <li>Transformers \u662f\u5f3a\u5927\u4e14\u901a\u7528\u7684\u5e93\uff0c\u80fd\u5e2e\u4f60\u5feb\u901f\u7528\u9884\u8bad\u7ec3\u6a21\u578b\u505a\u63a8\u7406\u6216\u8bad\u7ec3\uff0f\u5fae\u8c03\u3002</li> <li>\u5165\u95e8\u975e\u5e38\u5bb9\u6613\uff08\u5b89\u88c5 + pipeline + model\uff09\uff0c\u4f46\u8981\u73a9\u5f97\u6e9c\uff0c\u5c31\u9700\u8981\u7406\u89e3\u9884\u5904\u7406\u3001tokenizer\u3001\u8bad\u7ec3\u5faa\u73af\u8fd9\u4e9b\u7ec6\u8282\u3002</li> <li>\u5b9e\u6218\u65b9\u5411\u5f88\u591a\uff1a\u6587\u672c\u5206\u7c7b\u3001\u751f\u6210\u3001\u6458\u8981\u3001\u95ee\u7b54\u3001\u7ffb\u8bd1\u3001\u591a\u6a21\u6001\u2026</li> <li>\u8d44\u6e90\u4e30\u5bcc\uff0c\u793e\u533a\u6d3b\u8dc3\u3002\u4f60\u53ef\u4ee5\u57fa\u4e8e\u5df2\u6709\u6a21\u578b\u6539\u9020\u3002</li> </ul>"},{"location":"llm/tunning/transformers/quick%20start/#_16","title":"\u4e0b\u4e00\u6b65\u5efa\u8bae","text":"<ul> <li>\u6311\u9009\u4e00\u4e2a\u4efb\u52a1\uff1a\u6bd4\u5982 \u95ee\u7b54 \u6216 \u6458\u8981\uff0c\u7136\u540e\u52a8\u624b\u5fae\u8c03\u4e00\u4e2a\u6a21\u578b\u3002</li> <li>\u9605\u8bfb\u5b98\u65b9\u300cTasks\u300d\uff08\u4efb\u52a1\uff09\u9875\u9762\uff0c\u770b\u770b \u201c\u95ee\u7b54\uff08QA\uff09\u201d\u201c\u6458\u8981\uff08Summarization\uff09\u201d\u201c\u7ffb\u8bd1\uff08Translation\uff09\u201d \u7b49\u5177\u4f53\u573a\u666f\u3002</li> <li>\u5c1d\u8bd5\u5728\u81ea\u5df1\u7684\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\uff1b\u5c06\u7ed3\u679c\u90e8\u7f72\u6210 Web \u5e94\u7528\uff08\u53ef\u4ee5\u7ed3\u5408\u50cf Gradio \u8fd9\u6837\u7684\u5de5\u5177\uff09\u3002</li> <li>\u5b66\u4e60\u66f4\u9ad8\u7ea7\u6280\u5de7\uff1a\u6bd4\u5982\u591a\u6a21\u6001\u3001\u91cf\u5316\u3001PEFT\u3001\u5206\u5e03\u5f0f\u8bad\u7ec3\u3002</li> </ul> <p>\u5982\u679c\u4f60\u613f\u610f\uff0c\u6211\u53ef\u4ee5\u4e3a\u4f60 \u751f\u6210\u4e00\u4e2a\u4e13\u95e8\u9488\u5bf9\u4e2d\u6587\u6587\u672c\u4efb\u52a1\uff08\u4f8b\u5982\u60c5\u611f\u5206\u6790\u6216\u6458\u8981\u751f\u6210\uff09\u7684\u5b8c\u6574\u4ee3\u7801 notebook \u6a21\u677f\uff0c\u4f60\u8981\u4e0d\u8981\uff1f</p>"},{"location":"llmapps/apps/langchain/RAG%20agent/","title":"\u57fa\u4e8eLangChain\u521b\u5efaRAG agent","text":""},{"location":"llmapps/apps/langchain/RAG%20agent/#_1","title":"\u9879\u76ee\u6982\u8ff0","text":"<p>\u57fa\u4e8e\u8fd9\u7bc7\u535a\u5ba2 https://lilianweng.github.io/posts/2023-06-23-agent/ \u4f5c\u4e3a\u6570\u636e\u6e90\uff0c\u5efa\u7acbRAG agent\u3002</p>"},{"location":"llmapps/apps/langchain/RAG%20agent/#_2","title":"\u9879\u76ee\u5b9e\u73b0","text":""},{"location":"llmapps/apps/langchain/RAG%20agent/#1","title":"1\ufe0f\u20e3 \u642d\u5efa\u57fa\u7840\u73af\u5883","text":"<pre><code>import os\n\nos.environ['LANGSMITH_TRACING'] ='true'\nos.environ['LANGSMITH_API_KEY'] = ''\n</code></pre>"},{"location":"llmapps/apps/langchain/RAG%20agent/#2","title":"2\ufe0f\u20e3 \u52a0\u8f7d\u6587\u6863","text":"<pre><code>import bs4\nfrom langchain_community.document_loaders import WebBaseLoader\n\n# \u53ea\u4fdd\u7559 \u6587\u7ae0\u7684\u540d\u79f0\u3001\u6807\u9898\u548c\u5185\u5bb9\nbs4_strainer = bs4.SoupStrainer(class_=(\"post-title\", \"post-header\", \"post-content\"))\nloader = WebBaseLoader(\n    web_path=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n    bs_kwargs={\"parse_only\": bs4_strainer},\n)\n\ndocs = loader.load() # \u52a0\u8f7d\u6587\u6863\n\nassert len(docs) == 1\nprint(f\"\u603b\u5b57\u6570\uff1a{len(docs[0].page_content)}\")\nprint(f\"\u524d500\u4e2a\u5b57\u7684\u5185\u5bb9\uff1a{docs[0].page_content[:500]}\")\n</code></pre>"},{"location":"llmapps/apps/langchain/RAG%20agent/#3","title":"3\ufe0f\u20e3 \u6587\u6863\u5206\u5272","text":"<pre><code>from langchain_text_splitters import RecursiveCharacterTextSplitter\n\ntext_spliter = RecursiveCharacterTextSplitter(\n    chunk_size=1000,\n    chunk_overlap=200,\n    add_start_index=True\n)\n\nall_splits = text_spliter.split_documents(docs)\nprint(f\"\u628a\u6587\u6863\u62c6\u5206\u6210{len(all_splits)}\u4e2a\u5b50\u6587\u6863\")\n</code></pre>"},{"location":"llmapps/apps/langchain/RAG%20agent/#4","title":"4\ufe0f\u20e3 \u5b58\u50a8\u6587\u6863","text":"<pre><code>from langchain_milvus import Milvus\nfrom langchain_ollama import OllamaEmbeddings\n\n# \u5d4c\u5165\nembeddings = OllamaEmbeddings(model=\"llama3.2:latest\") # \u5d4c\u5165\n\n# \u5411\u91cf\u6570\u636e\u5e93\nuri = 'http://localhost:19530'\nvector_store = Milvus(\n    embedding_function=embeddings,\n    connection_args={'uri':uri}\n)\n\n# \u5b58\u5165\u5230\u5411\u91cf\u5e93\u4e2d\ndocument_ids = vector_store.add_documents(documents=all_splits)\nprint(f\"\u524d\u4e09\u4e2adocument_ids:{document_ids[:3]}\")\n</code></pre>"},{"location":"llmapps/apps/langchain/RAG%20agent/#5-agent","title":"5\ufe0f\u20e3 \u521b\u5efaAgent","text":""},{"location":"llmapps/apps/langchain/RAG%20agent/#51","title":"5.1 \u5b9a\u4e49\u5de5\u5177","text":"<pre><code>from langchain.tools import tool\n\n@tool(response_format=\"content_and_artifact\")\ndef retrieve_context(query:str):\n    '''\u68c0\u7d22\u4e0a\u4e0b\u6587\u5e2e\u52a9\u95ee\u9898\u56de\u7b54'''\n    retrieved_docs = vector_store.similarity_search(query=query,k=2) # \u68c0\u7d22\u6587\u7ae0\uff0c\u5e76\u8fd4\u56de2\u4e2a\u6587\u6863\n    serialized = \"\\n\\n\".join([\n        (f\"Source:{doc.metadata}\\nContent:{doc.page_content}\")\n        for doc in retrieved_docs\n    ])\n    return serialized,retrieved_docs\n</code></pre>"},{"location":"llmapps/apps/langchain/RAG%20agent/#52","title":"5.2 \u521b\u5efa\u667a\u80fd\u4f53","text":"<pre><code>from langchain.agents import create_agent\nfrom langchain_ollama import ChatOllama\nfrom langchain.messages import HumanMessage\n# \u5de5\u5177\u96c6\ntools = [retrieve_context]\n# \u7cfb\u7edf\u63d0\u793a\u8bcd\nsystem_prompt = (\n    \"You have access to a tool that retrieves context from a blog post. \"\n    \"Use the tool to help answer user queries.\"\n)\n\n# \u9009\u62e9\u6a21\u578b\nmodel = ChatOllama(\n    model=\"qwen3:1.7b\",\n    temperature=0.8\n)\n\n# \u521b\u5efaagent\nagent = create_agent(model=model, system_prompt=system_prompt,tools=tools)\n\nquery = (\n    \"What is the standard method for Task Decomposition?\\n\\n\"\n    \"Once you get the answer, look up common extensions of that method.\"\n)\n\nfor event in agent.stream(\n    {\"messages\": [{\"role\": \"user\", \"content\": query}]},\n    stream_mode=\"values\",\n):\n    event[\"messages\"][-1].pretty_print()\n</code></pre>"},{"location":"llmapps/apps/langchain/humain_middleware/","title":"\u4eba\u5de5\u5ba1\u6838","text":"<pre><code>import streamlit as st\nfrom langchain_ollama import ChatOllama\nfrom langchain.agents import create_agent\nfrom langchain.tools import tool\nfrom langchain.messages import HumanMessage\nfrom langchain.agents.middleware import HumanInTheLoopMiddleware\nfrom langgraph.types import Command\nfrom langgraph.checkpoint.memory import InMemorySaver\n\n@tool\ndef add_num(a: int, b: int) -&gt; int:\n    '''\u52a0\u6cd5'''\n    return a + b\n\n@tool\ndef minus_num(a: int, b: int) -&gt; int:\n    '''\u51cf\u6cd5'''\n    return a - b\n\nmodel = ChatOllama(\n    model='qwen3:4b'\n)\n\nsystem_prompt = '''\n        \u4f60\u662f\u4e00\u4e2a\u6570\u5b66\u8ba1\u7b97\u52a9\u624b\u3002\u4f60\u53ef\u4ee5\u5e2e\u52a9\u7528\u6237\u8fdb\u884c\u52a0\u6cd5\u548c\u51cf\u6cd5\u8fd0\u7b97\u3002\n        \u5f53\u7528\u6237\u8bf7\u6c42\u8ba1\u7b97\u65f6\uff0c\u9009\u62e9\u5408\u9002\u7684\u5de5\u5177\u5e76\u6267\u884c\u8ba1\u7b97\u3002\n        \u6240\u6709\u8ba1\u7b97\u64cd\u4f5c\u90fd\u9700\u8981\u4eba\u5de5\u5ba1\u6838\u786e\u8ba4\u3002\n'''\n\nagent = create_agent(\n    model=model,\n    tools=[add_num, minus_num],\n    system_prompt=system_prompt,\n    middleware=[\n        HumanInTheLoopMiddleware(\n            interrupt_on={'add_num':True, 'minus_num':True},\n            description_prefix=\"\u8ba1\u7b97\u5f85\u5ba1\u6838\",\n        ),\n    ],\n    checkpointer=InMemorySaver(),\n)\n\n## \u4f7f\u7528streamlit\u5e03\u5c40\u9875\u9762\n\nst.set_page_config(page_title=\"SQL Agent Demo\", page_icon=\"\ud83e\udde0\")\nst.title('LangChain\u4eba\u5de5\u5ba1\u6838\u793a\u4f8b')\n\nif \"thread_id\" not in st.session_state:\n    st.session_state.thread_id = \"thread-1\"\n\nconfig = {\"configurable\": {\"thread_id\": st.session_state.thread_id}}\n\nquestion = st.text_input('\u8bf7\u8f93\u5165\u8981\u8ba1\u7b97\u7684\u6570\u5b66\u516c\u5f0f\uff1a')\n\nif st.button(\"\u5f00\u59cb\u8ba1\u7b97\"):\n    st.session_state.result = []\n    st.session_state.pending = None\n\n    for step in agent.stream({'messages':[HumanMessage(question)]},config=config,stream_mode='values'):\n\n        # \u4e2d\u65ad\u7b49\u5f85\u5ba1\u6838\n        if '__interrupt__' in step:\n            interrupt = step['__interrupt__'][0]\n            st.session_state.pending = interrupt\n            st.error('\u8ba1\u7b97\u5df2\u6682\u505c\uff0c\u7b49\u5f85\u4eba\u5de5\u5ba1\u6838')\n            break\n\n        if 'messages' in step:\n            st.session_state.result.append(step['messages'][-1].content)\n\n# \u2705 \u4eba\u5de5\u6279\u51c6\u7ee7\u7eed\u6267\u884c\nif \"pending\" in st.session_state and st.session_state.pending:\n    if st.button(\"\u2705 \u6279\u51c6\u6267\u884c\u8ba1\u7b97\"):\n        for step in agent.stream(\n            Command(resume={\"decisions\": [{\"type\": \"approve\"}]}),\n            config=config,\n            stream_mode=\"values\"\n        ):\n            if \"messages\" in step:\n                st.session_state.result.append(step[\"messages\"][-1].content)\n\n        st.session_state.pending = None\n        st.success(\"\u2705 \u5ba1\u6838\u5b8c\u6210\uff0c\u6267\u884c\u6210\u529f\")\n\n# \u8f93\u51fa\u7ed3\u679c\nif \"result\" in st.session_state:\n    for r in st.session_state.result:\n        st.write(f'\u8fd0\u7b97\u7ed3\u679c\uff1a{r}')\n</code></pre>"},{"location":"llmapps/apps/langchain/semantic%20search/","title":"\u4f7f\u7528LangChain\u6784\u5efa\u8bed\u4e49\u641c\u7d22\u5f15\u64ce\u6559\u7a0b","text":""},{"location":"llmapps/apps/langchain/semantic%20search/#_1","title":"\u6982\u8ff0","text":"<p>\u672c\u6559\u7a0b\u5c06\u5e2e\u52a9\u60a8\u719f\u6089LangChain\u7684\u6587\u6863\u52a0\u8f7d\u5668\u3001\u5d4c\u5165\u6a21\u578b\u548c\u5411\u91cf\u5b58\u50a8\u62bd\u8c61\u3002\u8fd9\u4e9b\u62bd\u8c61\u7ec4\u4ef6\u65e8\u5728\u652f\u6301\u4ece\uff08\u5411\u91cf\uff09\u6570\u636e\u5e93\u548c\u5176\u4ed6\u6765\u6e90\u68c0\u7d22\u6570\u636e\uff0c\u4ee5\u4fbf\u4e0eLLM\u5de5\u4f5c\u6d41\u96c6\u6210\u3002\u5bf9\u4e8e\u9700\u8981\u83b7\u53d6\u6570\u636e\u8fdb\u884c\u63a8\u7406\u7684\u5e94\u7528\u7a0b\u5e8f\uff08\u5982\u68c0\u7d22\u589e\u5f3a\u751f\u6210RAG\uff09\u6765\u8bf4\uff0c\u8fd9\u4e9b\u7ec4\u4ef6\u975e\u5e38\u91cd\u8981\u3002</p> <p>\u6211\u4eec\u5c06\u6784\u5efa\u4e00\u4e2a\u57fa\u4e8ePDF\u6587\u6863\u7684\u641c\u7d22\u5f15\u64ce\uff0c\u4f7f\u6211\u4eec\u80fd\u591f\u68c0\u7d22\u4e0e\u8f93\u5165\u67e5\u8be2\u76f8\u4f3c\u7684PDF\u6bb5\u843d\u3002\u672c\u6307\u5357\u8fd8\u5305\u62ec\u5728\u641c\u7d22\u5f15\u64ce\u57fa\u7840\u4e0a\u5b9e\u73b0\u4e00\u4e2a\u6700\u5c0f\u5316\u7684RAG\u5e94\u7528\u3002</p>"},{"location":"llmapps/apps/langchain/semantic%20search/#_2","title":"\u6838\u5fc3\u6982\u5ff5","text":"<p>\u672c\u6307\u5357\u4e13\u6ce8\u4e8e\u6587\u672c\u6570\u636e\u68c0\u7d22\uff0c\u6db5\u76d6\u4ee5\u4e0b\u6982\u5ff5\uff1a</p> <ul> <li>\u6587\u6863\u548c\u6587\u6863\u52a0\u8f7d\u5668</li> <li>\u6587\u672c\u5206\u5272\u5668</li> <li>\u5d4c\u5165\u6a21\u578b</li> <li>\u5411\u91cf\u5b58\u50a8\u548c\u68c0\u7d22\u5668</li> </ul>"},{"location":"llmapps/apps/langchain/semantic%20search/#_3","title":"\u73af\u5883\u8bbe\u7f6e","text":""},{"location":"llmapps/apps/langchain/semantic%20search/#_4","title":"\u5b89\u88c5\u4f9d\u8d56","text":"<p>\u672c\u6559\u7a0b\u9700\u8981\u5b89\u88c5<code>langchain-community</code>\u548c<code>pypdf</code>\u5305\uff1a</p> <pre><code>pip install langchain-community pypdf\n</code></pre>"},{"location":"llmapps/apps/langchain/semantic%20search/#langsmith","title":"LangSmith\u914d\u7f6e\uff08\u53ef\u9009\uff09","text":"<p>\u4e3a\u4e86\u66f4\u597d\u5730\u8c03\u8bd5\u548c\u76d1\u63a7LangChain\u5e94\u7528\u7a0b\u5e8f\uff0c\u5efa\u8bae\u8bbe\u7f6eLangSmith\uff1a</p> <pre><code>import getpass\nimport os\n\nos.environ[\"LANGSMITH_TRACING\"] = \"true\"\nos.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"\u8bf7\u8f93\u5165LangSmith API\u5bc6\u94a5\uff1a\")\n</code></pre>"},{"location":"llmapps/apps/langchain/semantic%20search/#_5","title":"\u6559\u7a0b\u6b65\u9aa4","text":""},{"location":"llmapps/apps/langchain/semantic%20search/#1","title":"1. \u6587\u6863\u548c\u6587\u6863\u52a0\u8f7d\u5668","text":"<p>LangChain\u4f7f\u7528Document\u62bd\u8c61\u6765\u8868\u793a\u6587\u672c\u5355\u5143\u53ca\u5176\u5143\u6570\u636e\uff0c\u5305\u542b\u4e09\u4e2a\u5c5e\u6027\uff1a - <code>page_content</code>\uff1a\u6587\u672c\u5185\u5bb9\u5b57\u7b26\u4e32 - <code>metadata</code>\uff1a\u5305\u542b\u4efb\u610f\u5143\u6570\u636e\u7684\u5b57\u5178 - <code>id</code>\uff1a\uff08\u53ef\u9009\uff09\u6587\u6863\u6807\u8bc6\u7b26</p>"},{"location":"llmapps/apps/langchain/semantic%20search/#pdf","title":"\u52a0\u8f7dPDF\u6587\u6863","text":"<pre><code>from langchain_community.document_loaders import PyPDFLoader\n\n# \u52a0\u8f7dPDF\u6587\u4ef6\nfile_path = \"nke-10k-2023.pdf\"\nloader = PyPDFLoader(file_path)\ndocs = loader.load()\n\nprint(f\"\u52a0\u8f7d\u4e86 {len(docs)} \u9875\u6587\u6863\")\n</code></pre>"},{"location":"llmapps/apps/langchain/semantic%20search/#_6","title":"\u6587\u6863\u5206\u5272","text":"<p>\u4e3a\u4e86\u63d0\u9ad8\u68c0\u7d22\u7cbe\u5ea6\uff0c\u6211\u4eec\u9700\u8981\u5c06\u6587\u6863\u5206\u5272\u6210\u66f4\u5c0f\u7684\u5757\uff1a</p> <pre><code>from langchain_text_splitters import RecursiveCharacterTextSplitter\n\ntext_splitter = RecursiveCharacterTextSplitter(\n    chunk_size=1000,  # \u6bcf\u4e2a\u57571000\u5b57\u7b26\n    chunk_overlap=200,  # \u5757\u95f4\u91cd\u53e0200\u5b57\u7b26\n    add_start_index=True  # \u4fdd\u7559\u8d77\u59cb\u7d22\u5f15\n)\nall_splits = text_splitter.split_documents(docs)\n\nprint(f\"\u5206\u5272\u6210 {len(all_splits)} \u4e2a\u6587\u672c\u5757\")\n</code></pre>"},{"location":"llmapps/apps/langchain/semantic%20search/#2","title":"2. \u5d4c\u5165\u6a21\u578b","text":"<p>\u5d4c\u5165\u6a21\u578b\u5c06\u6587\u672c\u8f6c\u6362\u4e3a\u6570\u503c\u5411\u91cf\uff0c\u7528\u4e8e\u76f8\u4f3c\u6027\u641c\u7d22\u3002\u4ee5\u4e0b\u662f\u4f7f\u7528OpenAI\u5d4c\u5165\u6a21\u578b\u7684\u793a\u4f8b\uff1a</p> <pre><code>import getpass\nimport os\nfrom langchain_openai import OpenAIEmbeddings\n\n# \u8bbe\u7f6eAPI\u5bc6\u94a5\nif not os.environ.get(\"OPENAI_API_KEY\"):\n    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"\u8bf7\u8f93\u5165OpenAI API\u5bc6\u94a5\uff1a\")\n\n# \u521d\u59cb\u5316\u5d4c\u5165\u6a21\u578b\nembeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n\n# \u6d4b\u8bd5\u5d4c\u5165\nvector_1 = embeddings.embed_query(all_splits[0].page_content)\nprint(f\"\u751f\u6210\u7684\u957f\u5ea6\u4e3a {len(vector_1)} \u7684\u5411\u91cf\")\n</code></pre>"},{"location":"llmapps/apps/langchain/semantic%20search/#3","title":"3. \u5411\u91cf\u5b58\u50a8","text":"<p>\u9009\u62e9\u9002\u5408\u7684\u5411\u91cf\u5b58\u50a8\u65b9\u6848\uff0c\u8fd9\u91cc\u4ee5\u5185\u5b58\u5411\u91cf\u5b58\u50a8\u4e3a\u4f8b\uff1a</p> <pre><code>from langchain_core.vectorstores import InMemoryVectorStore\n\n# \u521d\u59cb\u5316\u5411\u91cf\u5b58\u50a8\nvector_store = InMemoryVectorStore(embeddings)\n\n# \u6dfb\u52a0\u6587\u6863\u5230\u5411\u91cf\u5b58\u50a8\nids = vector_store.add_documents(documents=all_splits)\n</code></pre>"},{"location":"llmapps/apps/langchain/semantic%20search/#_7","title":"\u67e5\u8be2\u5411\u91cf\u5b58\u50a8","text":"<pre><code># \u57fa\u4e8e\u76f8\u4f3c\u6027\u7684\u641c\u7d22\nresults = vector_store.similarity_search(\n    \"\u8010\u514b\u5728\u7f8e\u56fd\u6709\u591a\u5c11\u4e2a\u5206\u9500\u4e2d\u5fc3\uff1f\"\n)\n\nprint(results[0].page_content)\n\n# \u5e26\u5206\u6570\u7684\u641c\u7d22\nresults_with_score = vector_store.similarity_search_with_score(\n    \"\u8010\u514b2023\u5e74\u7684\u6536\u5165\u662f\u591a\u5c11\uff1f\"\n)\ndoc, score = results_with_score[0]\nprint(f\"\u76f8\u4f3c\u5ea6\u5206\u6570\uff1a{score}\")\n</code></pre>"},{"location":"llmapps/apps/langchain/semantic%20search/#4","title":"4. \u68c0\u7d22\u5668","text":"<p>\u68c0\u7d22\u5668\u662fRunnable\u5bf9\u8c61\uff0c\u53ef\u4ee5\u8f7b\u677e\u96c6\u6210\u5230\u66f4\u590d\u6742\u7684\u5e94\u7528\u4e2d\uff1a</p> <pre><code># \u4ece\u5411\u91cf\u5b58\u50a8\u521b\u5efa\u68c0\u7d22\u5668\nretriever = vector_store.as_retriever(\n    search_type=\"similarity\",\n    search_kwargs={\"k\": 1}  # \u8fd4\u56de\u6700\u76f8\u4f3c\u76841\u4e2a\u6587\u6863\n)\n\n# \u6279\u91cf\u67e5\u8be2\nresults = retriever.batch([\n    \"\u8010\u514b\u5728\u7f8e\u56fd\u6709\u591a\u5c11\u4e2a\u5206\u9500\u4e2d\u5fc3\uff1f\",\n    \"\u8010\u514b\u662f\u4ec0\u4e48\u65f6\u5019\u6210\u7acb\u7684\uff1f\"\n])\n</code></pre>"},{"location":"llmapps/apps/langchain/semantic%20search/#_8","title":"\u6784\u5efa\u5b8c\u6574\u7684\u8bed\u4e49\u641c\u7d22\u5f15\u64ce","text":"<p>\u4ee5\u4e0b\u662f\u5b8c\u6574\u7684\u4ee3\u7801\u793a\u4f8b\uff1a</p> <pre><code>import os\nfrom langchain_community.document_loaders import PyPDFLoader\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter\nfrom langchain_openai import OpenAIEmbeddings\nfrom langchain_core.vectorstores import InMemoryVectorStore\n\ndef build_semantic_search_engine(pdf_path, api_key):\n    \"\"\"\u6784\u5efa\u8bed\u4e49\u641c\u7d22\u5f15\u64ce\"\"\"\n\n    # 1. \u8bbe\u7f6eAPI\u5bc6\u94a5\n    os.environ[\"OPENAI_API_KEY\"] = api_key\n\n    # 2. \u52a0\u8f7d\u6587\u6863\n    print(\"\u6b63\u5728\u52a0\u8f7dPDF\u6587\u6863...\")\n    loader = PyPDFLoader(pdf_path)\n    docs = loader.load()\n\n    # 3. \u5206\u5272\u6587\u6863\n    print(\"\u6b63\u5728\u5206\u5272\u6587\u6863...\")\n    text_splitter = RecursiveCharacterTextSplitter(\n        chunk_size=1000,\n        chunk_overlap=200,\n        add_start_index=True\n    )\n    all_splits = text_splitter.split_documents(docs)\n\n    # 4. \u521d\u59cb\u5316\u5d4c\u5165\u6a21\u578b\n    print(\"\u6b63\u5728\u521d\u59cb\u5316\u5d4c\u5165\u6a21\u578b...\")\n    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n\n    # 5. \u521b\u5efa\u5411\u91cf\u5b58\u50a8\n    print(\"\u6b63\u5728\u6784\u5efa\u5411\u91cf\u7d22\u5f15...\")\n    vector_store = InMemoryVectorStore(embeddings)\n    vector_store.add_documents(documents=all_splits)\n\n    # 6. \u521b\u5efa\u68c0\u7d22\u5668\n    retriever = vector_store.as_retriever(\n        search_type=\"similarity\",\n        search_kwargs={\"k\": 3}  # \u8fd4\u56de\u6700\u76f8\u4f3c\u76843\u4e2a\u6587\u6863\n    )\n\n    print(\"\u8bed\u4e49\u641c\u7d22\u5f15\u64ce\u6784\u5efa\u5b8c\u6210\uff01\")\n    return retriever\n\n# \u4f7f\u7528\u793a\u4f8b\nif __name__ == \"__main__\":\n    # \u6784\u5efa\u641c\u7d22\u5f15\u64ce\n    search_engine = build_semantic_search_engine(\n        pdf_path=\"nke-10k-2023.pdf\",\n        api_key=\"your-openai-api-key\"\n    )\n\n    # \u8fdb\u884c\u67e5\u8be2\n    query = \"\u8010\u514b2023\u5e74\u7684\u8d22\u52a1\u8868\u73b0\u5982\u4f55\uff1f\"\n    results = search_engine.invoke(query)\n\n    print(f\"\u67e5\u8be2\uff1a{query}\")\n    print(\"\u68c0\u7d22\u7ed3\u679c\uff1a\")\n    for i, doc in enumerate(results, 1):\n        print(f\"\\n--- \u7ed3\u679c {i} ---\")\n        print(doc.page_content[:500] + \"...\")  # \u663e\u793a\u524d500\u4e2a\u5b57\u7b26\n        print(f\"\u6765\u6e90\uff1a{doc.metadata.get('source', '\u672a\u77e5')}\")\n</code></pre>"},{"location":"llmapps/apps/langchain/semantic%20search/#_9","title":"\u8fdb\u9636\u529f\u80fd","text":""},{"location":"llmapps/apps/langchain/semantic%20search/#_10","title":"\u6700\u5927\u8fb9\u9645\u76f8\u5173\u6027\u641c\u7d22","text":"<p>\u4e3a\u4e86\u907f\u514d\u8fd4\u56de\u8fc7\u4e8e\u76f8\u4f3c\u7684\u7ed3\u679c\uff0c\u53ef\u4ee5\u4f7f\u7528MMR\u641c\u7d22\uff1a</p> <pre><code>retriever = vector_store.as_retriever(\n    search_type=\"mmr\",\n    search_kwargs={\"k\": 3, \"fetch_k\": 10}  # \u4ece10\u4e2a\u5019\u9009\u4e2d\u9009\u62e93\u4e2a\u6700\u4e0d\u540c\u7684\n)\n</code></pre>"},{"location":"llmapps/apps/langchain/semantic%20search/#_11","title":"\u76f8\u4f3c\u5ea6\u9608\u503c\u8fc7\u6ee4","text":"<pre><code>retriever = vector_store.as_retriever(\n    search_type=\"similarity_score_threshold\",\n    search_kwargs={\"k\": 3, \"score_threshold\": 0.7}  # \u53ea\u8fd4\u56de\u76f8\u4f3c\u5ea6\u5927\u4e8e0.7\u7684\u6587\u6863\n)\n</code></pre>"},{"location":"llmapps/apps/langchain/semantic%20search/#_12","title":"\u6545\u969c\u6392\u9664","text":"<ol> <li>\u5185\u5b58\u4e0d\u8db3\uff1a\u5bf9\u4e8e\u5927\u578b\u6587\u6863\uff0c\u8003\u8651\u4f7f\u7528\u6301\u4e45\u5316\u5411\u91cf\u5b58\u50a8\uff08\u5982Chroma\u3001FAISS\uff09</li> <li>API\u9650\u5236\uff1a\u6ce8\u610f\u5d4c\u5165\u6a21\u578b\u7684API\u8c03\u7528\u9650\u5236\u548c\u6210\u672c</li> <li>\u5206\u5272\u7b56\u7565\uff1a\u6839\u636e\u6587\u6863\u7c7b\u578b\u8c03\u6574chunk_size\u548cchunk_overlap\u53c2\u6570</li> </ol>"},{"location":"llmapps/langchain/advanced-usage/Guardrails/","title":"\u4f7f\u7528 Guardrails \u6784\u5efa\u5b89\u5168\u5408\u89c4\u7684 AI \u5e94\u7528\u6559\u7a0b","text":""},{"location":"llmapps/langchain/advanced-usage/Guardrails/#guardrails","title":"\u4ec0\u4e48\u662f Guardrails\uff1f","text":"<p>Guardrails\uff08\u5b89\u5168\u62a4\u680f\uff09\u662f\u5728 AI \u4ee3\u7406\u6267\u884c\u7684\u5173\u952e\u8282\u70b9\u8fdb\u884c\u5185\u5bb9\u9a8c\u8bc1\u548c\u8fc7\u6ee4\u7684\u5b89\u5168\u68c0\u67e5\u673a\u5236\u3002\u5b83\u4eec\u5e2e\u52a9\u5f00\u53d1\u8005\u6784\u5efa\u5b89\u5168\u3001\u5408\u89c4\u7684 AI \u5e94\u7528\uff0c\u80fd\u591f\u5728\u95ee\u9898\u53d1\u751f\u524d\u68c0\u6d4b\u654f\u611f\u4fe1\u606f\u3001\u6267\u884c\u5185\u5bb9\u7b56\u7565\u3001\u9a8c\u8bc1\u8f93\u51fa\u5e76\u9632\u6b62\u4e0d\u5b89\u5168\u884c\u4e3a\u3002</p>"},{"location":"llmapps/langchain/advanced-usage/Guardrails/#_1","title":"\u4e3b\u8981\u5e94\u7528\u573a\u666f","text":"<ul> <li>\u9632\u6b62 PII \u6cc4\u9732 - \u4fdd\u62a4\u4e2a\u4eba\u8eab\u4efd\u4fe1\u606f</li> <li>\u68c0\u6d4b\u548c\u963b\u6b62\u63d0\u793a\u6ce8\u5165\u653b\u51fb - \u9632\u8303\u6076\u610f\u8f93\u5165</li> <li>\u963b\u6b62\u4e0d\u5f53\u6216\u6709\u5bb3\u5185\u5bb9 - \u8fc7\u6ee4\u8fdd\u89c4\u5185\u5bb9</li> <li>\u6267\u884c\u4e1a\u52a1\u89c4\u5219\u548c\u5408\u89c4\u8981\u6c42 - \u6ee1\u8db3\u884c\u4e1a\u89c4\u8303</li> <li>\u9a8c\u8bc1\u8f93\u51fa\u8d28\u91cf\u548c\u51c6\u786e\u6027 - \u786e\u4fdd\u54cd\u5e94\u53ef\u9760\u6027</li> </ul>"},{"location":"llmapps/langchain/advanced-usage/Guardrails/#guardrails_1","title":"Guardrails \u7684\u4e24\u79cd\u5b9e\u73b0\u65b9\u5f0f","text":""},{"location":"llmapps/langchain/advanced-usage/Guardrails/#1-guardrails","title":"1. \u786e\u5b9a\u6027 Guardrails","text":"<p>\u4f7f\u7528\u57fa\u4e8e\u89c4\u5219\u7684\u903b\u8f91\uff0c\u5982\u6b63\u5219\u8868\u8fbe\u5f0f\u3001\u5173\u952e\u8bcd\u5339\u914d\u6216\u663e\u5f0f\u68c0\u67e5\u3002\u901f\u5ea6\u5feb\u3001\u53ef\u9884\u6d4b\u4e14\u6210\u672c\u4f4e\uff0c\u4f46\u53ef\u80fd\u9057\u6f0f\u590d\u6742\u8fdd\u89c4\u60c5\u51b5\u3002</p>"},{"location":"llmapps/langchain/advanced-usage/Guardrails/#2-guardrails","title":"2. \u57fa\u4e8e\u6a21\u578b\u7684 Guardrails","text":"<p>\u4f7f\u7528 LLM \u6216\u5206\u7c7b\u5668\u8fdb\u884c\u8bed\u4e49\u7406\u89e3\u8bc4\u4f30\u3002\u80fd\u6355\u83b7\u89c4\u5219\u53ef\u80fd\u9057\u6f0f\u7684\u7ec6\u5fae\u95ee\u9898\uff0c\u4f46\u901f\u5ea6\u8f83\u6162\u4e14\u6210\u672c\u66f4\u9ad8\u3002</p>"},{"location":"llmapps/langchain/advanced-usage/Guardrails/#guardrails_2","title":"\u4f7f\u7528\u5185\u7f6e Guardrails","text":""},{"location":"llmapps/langchain/advanced-usage/Guardrails/#pii","title":"PII \u68c0\u6d4b\u4e2d\u95f4\u4ef6","text":"<p>LangChain \u63d0\u4f9b\u4e86\u5185\u7f6e\u7684 PII \u68c0\u6d4b\u4e2d\u95f4\u4ef6\uff0c\u53ef\u8bc6\u522b\u7535\u5b50\u90ae\u4ef6\u3001\u4fe1\u7528\u5361\u3001IP \u5730\u5740\u7b49\u5e38\u89c1\u654f\u611f\u4fe1\u606f\u3002</p> <pre><code>from langchain.agents import create_agent\nfrom langchain.agents.middleware import PIIMiddleware\n\nagent = create_agent(\n    model=\"openai:gpt-4o\",\n    tools=[customer_service_tool, email_tool],\n    middleware=[\n        # \u5728\u53d1\u9001\u7ed9\u6a21\u578b\u524d\u5bf9\u7528\u6237\u8f93\u5165\u4e2d\u7684\u7535\u5b50\u90ae\u4ef6\u8fdb\u884c\u8131\u654f\n        PIIMiddleware(\n            \"email\",\n            strategy=\"redact\",\n            apply_to_input=True,\n        ),\n        # \u5bf9\u7528\u6237\u8f93\u5165\u4e2d\u7684\u4fe1\u7528\u5361\u8fdb\u884c\u63a9\u7801\u5904\u7406\n        PIIMiddleware(\n            \"credit_card\",\n            strategy=\"mask\",\n            apply_to_input=True,\n        ),\n        # \u68c0\u6d4b\u5230 API \u5bc6\u94a5\u65f6\u629b\u51fa\u9519\u8bef\n        PIIMiddleware(\n            \"api_key\",\n            detector=r\"sk-[a-zA-Z0-9]{32}\",\n            strategy=\"block\",\n            apply_to_input=True,\n        ),\n    ],\n)\n\n# \u5f53\u7528\u6237\u63d0\u4f9b PII \u65f6\uff0c\u5c06\u6839\u636e\u7b56\u7565\u8fdb\u884c\u5904\u7406\nresult = agent.invoke({\n    \"messages\": [{\"role\": \"user\", \"content\": \"My email is john.doe@example.com and card is 4532-1234-5678-9010\"}]\n})\n</code></pre> <p>PII \u5904\u7406\u7b56\u7565\uff1a</p> <ul> <li><code>redact</code> - \u66ff\u6362\u4e3a <code>[REDACTED_TYPE]</code></li> <li><code>mask</code> - \u90e8\u5206\u906e\u853d\uff08\u5982\u663e\u793a\u6700\u540e4\u4f4d\uff09</li> <li><code>hash</code> - \u66ff\u6362\u4e3a\u786e\u5b9a\u6027\u54c8\u5e0c\u503c</li> <li><code>block</code> - \u68c0\u6d4b\u5230\u65f6\u629b\u51fa\u5f02\u5e38</li> </ul>"},{"location":"llmapps/langchain/advanced-usage/Guardrails/#_2","title":"\u4eba\u5de5\u4ecb\u5165\u4e2d\u95f4\u4ef6","text":"<p>\u5bf9\u4e8e\u9ad8\u98ce\u9669\u64cd\u4f5c\uff0c\u53ef\u4ee5\u8981\u6c42\u4eba\u5de5\u5ba1\u6279\u540e\u518d\u6267\u884c\u3002</p> <pre><code>from langchain.agents import create_agent\nfrom langchain.agents.middleware import HumanInTheLoopMiddleware\nfrom langgraph.checkpoint.memory import InMemorySaver\nfrom langgraph.types import Command\n\nagent = create_agent(\n    model=\"openai:gpt-4o\",\n    tools=[search_tool, send_email_tool, delete_database_tool],\n    middleware=[\n        HumanInTheLoopMiddleware(\n            interrupt_on={\n                # \u654f\u611f\u64cd\u4f5c\u9700\u8981\u5ba1\u6279\n                \"send_email\": True,\n                \"delete_database\": True,\n                # \u5b89\u5168\u64cd\u4f5c\u81ea\u52a8\u6279\u51c6\n                \"search\": False,\n            }\n        ),\n    ],\n    checkpointer=InMemorySaver(),  # \u6301\u4e45\u5316\u72b6\u6001\n)\n\nconfig = {\"configurable\": {\"thread_id\": \"some_id\"}}\n\n# \u4ee3\u7406\u5c06\u5728\u6267\u884c\u654f\u611f\u5de5\u5177\u524d\u6682\u505c\u5e76\u7b49\u5f85\u6279\u51c6\nresult = agent.invoke(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"Send an email to the team\"}]},\n    config=config\n)\n\n# \u4eba\u5de5\u6279\u51c6\u540e\u7ee7\u7eed\u6267\u884c\nresult = agent.invoke(\n    Command(resume={\"decisions\": [{\"type\": \"approve\"}]}),\n    config=config\n)\n</code></pre>"},{"location":"llmapps/langchain/advanced-usage/Guardrails/#guardrails_3","title":"\u521b\u5efa\u81ea\u5b9a\u4e49 Guardrails","text":""},{"location":"llmapps/langchain/advanced-usage/Guardrails/#before-agent-guardrails","title":"Before Agent Guardrails","text":"<p>\u5728\u4ee3\u7406\u5f00\u59cb\u6267\u884c\u524d\u9a8c\u8bc1\u8bf7\u6c42\uff0c\u9002\u7528\u4e8e\u4f1a\u8bdd\u7ea7\u68c0\u67e5\uff0c\u5982\u8eab\u4efd\u9a8c\u8bc1\u3001\u901f\u7387\u9650\u5236\u6216\u963b\u6b62\u4e0d\u5f53\u8bf7\u6c42\u3002</p> <p>\u7c7b\u8bed\u6cd5\uff1a</p> <pre><code>from typing import Any\nfrom langchain.agents.middleware import AgentMiddleware, AgentState, hook_config\nfrom langgraph.runtime import Runtime\n\nclass ContentFilterMiddleware(AgentMiddleware):\n    \"\"\"\u786e\u5b9a\u6027\u62a4\u680f\uff1a\u963b\u6b62\u5305\u542b\u7981\u7528\u5173\u952e\u8bcd\u7684\u8bf7\u6c42\"\"\"\n\n    def __init__(self, banned_keywords: list[str]):\n        super().__init__()\n        self.banned_keywords = [kw.lower() for kw in banned_keywords]\n\n    @hook_config(can_jump_to=[\"end\"])\n    def before_agent(self, state: AgentState, runtime: Runtime) -&gt; dict[str, Any] | None:\n        if not state[\"messages\"]:\n            return None\n\n        first_message = state[\"messages\"][0]\n        if first_message.type != \"human\":\n            return None\n\n        content = first_message.content.lower()\n\n        for keyword in self.banned_keywords:\n            if keyword in content:\n                return {\n                    \"messages\": [{\n                        \"role\": \"assistant\",\n                        \"content\": \"I cannot process requests containing inappropriate content.\"\n                    }],\n                    \"jump_to\": \"end\"\n                }\n        return None\n\n# \u4f7f\u7528\u81ea\u5b9a\u4e49\u62a4\u680f\nagent = create_agent(\n    model=\"openai:gpt-4o\",\n    tools=[search_tool, calculator_tool],\n    middleware=[ContentFilterMiddleware([\"hack\", \"exploit\", \"malware\"])],\n)\n</code></pre> <p>\u88c5\u9970\u5668\u8bed\u6cd5\uff1a</p> <pre><code>from typing import Any\nfrom langchain.agents.middleware import before_agent, AgentState, hook_config\nfrom langgraph.runtime import Runtime\n\nbanned_keywords = [\"hack\", \"exploit\", \"malware\"]\n\n@before_agent(can_jump_to=[\"end\"])\ndef content_filter(state: AgentState, runtime: Runtime) -&gt; dict[str, Any] | None:\n    \"\"\"\u786e\u5b9a\u6027\u62a4\u680f\uff1a\u963b\u6b62\u5305\u542b\u7981\u7528\u5173\u952e\u8bcd\u7684\u8bf7\u6c42\"\"\"\n    if not state[\"messages\"]:\n        return None\n\n    first_message = state[\"messages\"][0]\n    if first_message.type != \"human\":\n        return None\n\n    content = first_message.content.lower()\n\n    for keyword in banned_keywords:\n        if keyword in content:\n            return {\n                \"messages\": [{\n                    \"role\": \"assistant\",\n                    \"content\": \"I cannot process requests containing inappropriate content.\"\n                }],\n                \"jump_to\": \"end\"\n            }\n    return None\n</code></pre>"},{"location":"llmapps/langchain/advanced-usage/Guardrails/#after-agent-guardrails","title":"After Agent Guardrails","text":"<p>\u5728\u8fd4\u56de\u7ed9\u7528\u6237\u524d\u9a8c\u8bc1\u6700\u7ec8\u8f93\u51fa\uff0c\u9002\u7528\u4e8e\u57fa\u4e8e\u6a21\u578b\u7684\u5b89\u5168\u68c0\u67e5\u3001\u8d28\u91cf\u9a8c\u8bc1\u6216\u6700\u7ec8\u5408\u89c4\u626b\u63cf\u3002</p> <p>\u7c7b\u8bed\u6cd5\uff1a</p> <pre><code>from langchain.agents.middleware import AgentMiddleware, AgentState, hook_config\nfrom langgraph.runtime import Runtime\nfrom langchain_core.messages import AIMessage\nfrom langchain.chat_models import init_chat_model\nfrom typing import Any\n\nclass SafetyGuardrailMiddleware(AgentMiddleware):\n    \"\"\"\u57fa\u4e8e\u6a21\u578b\u7684\u62a4\u680f\uff1a\u4f7f\u7528 LLM \u8bc4\u4f30\u54cd\u5e94\u5b89\u5168\u6027\"\"\"\n\n    def __init__(self):\n        super().__init__()\n        self.safety_model = init_chat_model(\"openai:gpt-4o-mini\")\n\n    @hook_config(can_jump_to=[\"end\"])\n    def after_agent(self, state: AgentState, runtime: Runtime) -&gt; dict[str, Any] | None:\n        if not state[\"messages\"]:\n            return None\n\n        last_message = state[\"messages\"][-1]\n        if not isinstance(last_message, AIMessage):\n            return None\n\n        # \u4f7f\u7528\u6a21\u578b\u8bc4\u4f30\u5b89\u5168\u6027\n        safety_prompt = f\"\"\"\u8bc4\u4f30\u6b64\u54cd\u5e94\u662f\u5426\u5b89\u5168\u9002\u5f53\u3002\n        \u4ec5\u56de\u590d 'SAFE' \u6216 'UNSAFE'\u3002\n\n        \u54cd\u5e94\uff1a{last_message.content}\"\"\"\n\n        result = self.safety_model.invoke([{\"role\": \"user\", \"content\": safety_prompt}])\n\n        if \"UNSAFE\" in result.content:\n            return {\n                \"messages\": [{\n                    \"role\": \"assistant\", \n                    \"content\": \"I cannot provide that response.\"\n                }],\n                \"jump_to\": \"end\"\n            }\n        return None\n</code></pre>"},{"location":"llmapps/langchain/advanced-usage/Guardrails/#guardrails_4","title":"\u7ec4\u5408\u591a\u4e2a Guardrails","text":"<p>\u4f60\u53ef\u4ee5\u901a\u8fc7\u5c06\u591a\u4e2a Guardrails \u6dfb\u52a0\u5230\u4e2d\u95f4\u4ef6\u6570\u7ec4\u4e2d\u6765\u5806\u53e0\u5b83\u4eec\uff0c\u6784\u5efa\u5206\u5c42\u4fdd\u62a4\uff1a</p> <pre><code>agent = create_agent(\n    model=\"openai:gpt-4o\",\n    tools=[search_tool, send_email_tool],\n    middleware=[\n        # \u7b2c1\u5c42\uff1a\u786e\u5b9a\u6027\u8f93\u5165\u8fc7\u6ee4\u5668\uff08\u4ee3\u7406\u524d\uff09\n        ContentFilterMiddleware(banned_keywords=[\"hack\", \"exploit\"]),\n\n        # \u7b2c2\u5c42\uff1aPII \u4fdd\u62a4\uff08\u6a21\u578b\u524d\u540e\uff09\n        PIIMiddleware(\"email\", strategy=\"redact\", apply_to_input=True),\n        PIIMiddleware(\"email\", strategy=\"redact\", apply_to_output=True),\n\n        # \u7b2c3\u5c42\uff1a\u654f\u611f\u5de5\u5177\u7684\u4eba\u5de5\u5ba1\u6279\n        HumanInTheLoopMiddleware(interrupt_on={\"send_email\": True}),\n\n        # \u7b2c4\u5c42\uff1a\u57fa\u4e8e\u6a21\u578b\u7684\u5b89\u5168\u68c0\u67e5\uff08\u4ee3\u7406\u540e\uff09\n        SafetyGuardrailMiddleware(),\n    ],\n)\n</code></pre>"},{"location":"llmapps/langchain/advanced-usage/Guardrails/#_3","title":"\u6700\u4f73\u5b9e\u8df5","text":"<ol> <li>\u5206\u5c42\u9632\u5fa1\uff1a\u7ed3\u5408\u786e\u5b9a\u6027\u548c\u57fa\u4e8e\u6a21\u578b\u7684 Guardrails</li> <li>\u65e9\u671f\u62e6\u622a\uff1a\u5728\u4ee3\u7406\u6267\u884c\u524d\u5c3d\u53ef\u80fd\u65e9\u5730\u62e6\u622a\u95ee\u9898</li> <li>\u6210\u672c\u5e73\u8861\uff1a\u5bf9\u9ad8\u9891\u7387\u64cd\u4f5c\u4f7f\u7528\u786e\u5b9a\u6027\u68c0\u67e5\uff0c\u5bf9\u5173\u952e\u51b3\u7b56\u4f7f\u7528\u6a21\u578b\u68c0\u67e5</li> <li>\u6301\u7eed\u6d4b\u8bd5\uff1a\u5b9a\u671f\u6d4b\u8bd5\u5b89\u5168\u673a\u5236\u7684\u6709\u6548\u6027</li> <li>\u4eba\u5de5\u76d1\u7763\uff1a\u5bf9\u9ad8\u98ce\u9669\u64cd\u4f5c\u4fdd\u7559\u4eba\u5de5\u5ba1\u6279\u73af\u8282</li> </ol> <p>\u901a\u8fc7\u5408\u7406\u914d\u7f6e Guardrails\uff0c\u4f60\u53ef\u4ee5\u663e\u8457\u63d0\u5347 AI \u5e94\u7528\u7684\u5b89\u5168\u6027\u548c\u5408\u89c4\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u7528\u6237\u4f53\u9a8c\u7684\u6d41\u7545\u6027\u3002</p>"},{"location":"llmapps/langchain/advanced-usage/Human-in-the-loop/","title":"\ud83e\udded Human-in-the-Loop\uff08\u4eba\u7c7b\u5728\u73af\uff09\u6559\u7a0b","text":""},{"location":"llmapps/langchain/advanced-usage/Human-in-the-loop/#_1","title":"\u4e00\u3001\u6982\u5ff5\u7b80\u4ecb","text":"<p>\u5728\u81ea\u52a8\u5316\u667a\u80fd\u7cfb\u7edf\u4e2d\uff0c\u6211\u4eec\u5e0c\u671b AI \u5177\u5907\u5f3a\u5927\u7684\u81ea\u4e3b\u51b3\u7b56\u80fd\u529b\uff0c\u4f46\u5728\u4e00\u4e9b\u5173\u952e\u64cd\u4f5c\u4e0a\uff08\u4f8b\u5982\u5220\u9664\u6570\u636e\u5e93\u8bb0\u5f55\u3001\u5199\u5165\u6587\u4ef6\u3001\u53d1\u9001\u90ae\u4ef6\uff09\uff0c\u5b8c\u5168\u4ea4\u7531\u6a21\u578b\u81ea\u52a8\u6267\u884c\u662f\u4e0d\u5b89\u5168\u7684\u3002 \u8fd9\u65f6\u5c31\u9700\u8981 Human-in-the-Loop\uff08HITL\uff09 \u673a\u5236\u3002</p> <p>HITL \u4e2d\u95f4\u4ef6 \u5141\u8bb8\u4f60\u5728 Agent \u6267\u884c\u5de5\u5177\u8c03\u7528\uff08Tool Call\uff09\u4e4b\u524d\uff0c\u63d2\u5165\u4e00\u4e2a\u4eba\u5de5\u5ba1\u67e5\u73af\u8282\u3002 \u5f53\u6a21\u578b\u8ba1\u5212\u6267\u884c\u9ad8\u98ce\u9669\u6216\u654f\u611f\u64cd\u4f5c\u65f6\uff0c\u5b83\u4f1a\u6682\u505c\u6267\u884c\uff0c\u7b49\u5f85\u4eba\u5de5\u6279\u51c6\u3001\u4fee\u6539\u6216\u62d2\u7edd\u3002</p> <p>\u6362\u53e5\u8bdd\u8bf4\uff0cHITL \u662f AI \u7cfb\u7edf\u7684\u201c\u5b89\u5168\u9600\u201d \u2014\u2014 \u5b83\u8ba9\u4f60\u51b3\u5b9a\u4f55\u65f6\u8ba9\u4eba\u7c7b\u4ecb\u5165\u3001\u5982\u4f55\u6062\u590d\u6267\u884c\u3002</p>"},{"location":"llmapps/langchain/advanced-usage/Human-in-the-loop/#hitl","title":"\u4e8c\u3001HITL \u7684\u5de5\u4f5c\u539f\u7406","text":"<ol> <li>\u6a21\u578b\u751f\u6210\u8ba1\u5212\uff1aAgent \u8f93\u51fa\u4e00\u4e2a\u5de5\u5177\u8c03\u7528\u8bf7\u6c42\uff08\u4f8b\u5982\u6267\u884c SQL\uff09\u3002</li> <li>\u4e2d\u95f4\u4ef6\u68c0\u67e5\uff1aHITL \u4e2d\u95f4\u4ef6\u6839\u636e\u9884\u5148\u8bbe\u5b9a\u7684\u7b56\u7565\u68c0\u67e5\u8fd9\u4e2a\u8c03\u7528\u3002</li> <li>\u89e6\u53d1\u4e2d\u65ad\uff1a\u82e5\u8be5\u64cd\u4f5c\u9700\u8981\u4eba\u5de5\u5e72\u9884\uff0c\u4e2d\u95f4\u4ef6\u4f1a\u53d1\u51fa\u4e00\u4e2a interrupt\uff08\u4e2d\u65ad\uff09 \u4fe1\u53f7\uff0c\u6682\u505c\u6267\u884c\u3002</li> <li>\u4fdd\u5b58\u72b6\u6001\uff1a\u5f53\u524d\u5bf9\u8bdd\u72b6\u6001\u901a\u8fc7 LangGraph \u7684\u6301\u4e45\u5316\u5c42\uff08Persistence Layer\uff09\u4fdd\u5b58\u3002</li> <li> <p>\u4eba\u5de5\u5ba1\u67e5\uff1a\u4eba\u7c7b\u53ef\u4ee5\u9009\u62e9\uff1a</p> </li> <li> <p>\u2705 <code>approve</code>\uff08\u6279\u51c6\u6267\u884c\uff09</p> </li> <li>\u270f\ufe0f <code>edit</code>\uff08\u4fee\u6539\u6267\u884c\u53c2\u6570\uff09</li> <li>\u274c <code>reject</code>\uff08\u62d2\u7edd\u5e76\u53cd\u9988\u539f\u56e0\uff09</li> <li>\u6062\u590d\u6267\u884c\uff1a\u7cfb\u7edf\u6839\u636e\u4eba\u5de5\u51b3\u7b56\u7ee7\u7eed\u8fd0\u884c\u6216\u653e\u5f03\u8be5\u64cd\u4f5c\u3002</li> </ol>"},{"location":"llmapps/langchain/advanced-usage/Human-in-the-loop/#_2","title":"\u4e09\u3001\u4e09\u79cd\u4eba\u5de5\u51b3\u7b56\u7c7b\u578b","text":"\u51b3\u7b56\u7c7b\u578b \u8bf4\u660e \u793a\u4f8b \u2705 approve \u6279\u51c6\u64cd\u4f5c\u5e76\u6267\u884c \u53d1\u9001\u90ae\u4ef6\u8349\u7a3f\u539f\u6837\u53d1\u9001 \u270f\ufe0f edit \u4fee\u6539\u53c2\u6570\u540e\u518d\u6267\u884c \u6539\u52a8\u90ae\u4ef6\u6536\u4ef6\u4eba\u540e\u518d\u53d1\u9001 \u274c reject \u62d2\u7edd\u6267\u884c\u5e76\u53cd\u9988 \u62d2\u7edd\u8349\u7a3f\u5e76\u8bf4\u660e\u6539\u8fdb\u5efa\u8bae <p>\u63d0\u793a\uff1a \u4fee\u6539\u5de5\u5177\u53c2\u6570\uff08<code>edit</code>\uff09\u65f6\u5efa\u8bae\u5c0f\u5e45\u8c03\u6574\u3002\u8fc7\u5927\u6539\u52a8\u53ef\u80fd\u5bfc\u81f4\u6a21\u578b\u91cd\u65b0\u89c4\u5212\uff0c\u5f15\u53d1\u591a\u6b21\u6267\u884c\u6216\u4e0d\u53ef\u9884\u671f\u884c\u4e3a\u3002</p>"},{"location":"llmapps/langchain/advanced-usage/Human-in-the-loop/#hitl_1","title":"\u56db\u3001HITL \u914d\u7f6e\u793a\u4f8b","text":"<p>\u5728\u521b\u5efa Agent \u65f6\uff0c\u5c06 <code>HumanInTheLoopMiddleware</code> \u6dfb\u52a0\u5230 <code>middleware</code> \u5217\u8868\u4e2d\u5373\u53ef\u542f\u7528 HITL\u3002 \u901a\u8fc7 <code>interrupt_on</code> \u5b57\u5178\u6765\u5b9a\u4e49\u54ea\u4e9b\u5de5\u5177\u9700\u8981\u4eba\u5de5\u5ba1\u6279\uff0c\u4ee5\u53ca\u5141\u8bb8\u7684\u51b3\u7b56\u7c7b\u578b\u3002</p> <pre><code>from langchain.agents import create_agent\nfrom langchain.agents.middleware import HumanInTheLoopMiddleware\nfrom langgraph.checkpoint.memory import InMemorySaver\n\nagent = create_agent(\n    model=\"openai:gpt-4o\",\n    tools=[write_file_tool, execute_sql_tool, read_data_tool],\n    middleware=[\n        HumanInTheLoopMiddleware(\n            interrupt_on={\n                \"write_file\": True,  # \u5141\u8bb8approve/edit/reject\u4e09\u79cd\u64cd\u4f5c\n                \"execute_sql\": {\"allowed_decisions\": [\"approve\", \"reject\"]},  # \u7981\u6b62edit\u4fee\u6539\n                \"read_data\": False,  # \u5b89\u5168\u64cd\u4f5c\uff0c\u4e0d\u9700\u8981\u4eba\u5de5\u5ba1\u6279\n            },\n            description_prefix=\"\u5de5\u5177\u8c03\u7528\u7b49\u5f85\u4eba\u5de5\u5ba1\u6279\",\n        ),\n    ],\n    # HITL \u4f9d\u8d56\u68c0\u67e5\u70b9\u673a\u5236\u6765\u5728\u4e2d\u65ad\u540e\u6062\u590d\u72b6\u6001\n    checkpointer=InMemorySaver(),  # \u6d4b\u8bd5\u7528\u5185\u5b58\u4fdd\u5b58\u5668\n)\n</code></pre> <p>\u2699\ufe0f \u5728\u751f\u4ea7\u73af\u5883\u4e2d\uff0c\u8bf7\u4f7f\u7528\u6301\u4e45\u5316\u7684\u4fdd\u5b58\u5668\uff08\u5982 <code>AsyncPostgresSaver</code>\uff09\u4ee5\u4fdd\u8bc1\u5728\u670d\u52a1\u91cd\u542f\u540e\u4ecd\u80fd\u6062\u590d\u6267\u884c\u72b6\u6001\u3002 \u8be6\u89c1 LangGraph Checkpoint \u6587\u6863\u3002</p>"},{"location":"llmapps/langchain/advanced-usage/Human-in-the-loop/#_3","title":"\u4e94\u3001\u89e6\u53d1\u4e2d\u65ad\u4e0e\u4eba\u5de5\u5ba1\u67e5\u6d41\u7a0b","text":"<p>\u5f53\u4f60\u8fd0\u884c Agent \u65f6\uff0c\u5b83\u4f1a\u4e00\u76f4\u6267\u884c\uff0c\u76f4\u5230\u9047\u5230\u9700\u8981\u4eba\u5de5\u5e72\u9884\u7684\u5de5\u5177\u8c03\u7528\u3002 \u6b64\u65f6\uff0c\u8fd4\u56de\u7ed3\u679c\u4f1a\u5305\u542b\u4e00\u4e2a <code>__interrupt__</code> \u5b57\u6bb5\uff0c\u5176\u4e2d\u5217\u51fa\u6240\u6709\u5f85\u5ba1\u67e5\u7684\u64cd\u4f5c\u3002</p>"},{"location":"llmapps/langchain/advanced-usage/Human-in-the-loop/#_4","title":"\u793a\u4f8b","text":"<pre><code>from langgraph.types import Command\n\nconfig = {\"configurable\": {\"thread_id\": \"user_session_001\"}}\n\n# \u8c03\u7528\u89e6\u53d1\u6f5c\u5728\u5371\u9669\u64cd\u4f5c\nresult = agent.invoke(\n    {\n        \"messages\": [\n            {\"role\": \"user\", \"content\": \"Delete old records from the database\"}\n        ]\n    },\n    config=config\n)\n\nprint(result['__interrupt__'])\n</code></pre> <p>\u8f93\u51fa\u4e2d\u65ad\u8bf7\u6c42\uff0c\u5185\u5bb9\u7c7b\u4f3c\uff1a</p> <pre><code>[\n  Interrupt(\n    value={\n      \"action_requests\": [\n        {\n          \"name\": \"execute_sql\",\n          \"arguments\": {\"query\": \"DELETE FROM records WHERE created_at &lt; NOW() - INTERVAL '30 days';\"},\n          \"description\": \"\u5de5\u5177\u8c03\u7528\u7b49\u5f85\u4eba\u5de5\u5ba1\u6279\\n\\nTool: execute_sql\\nArgs: {...}\"\n        }\n      ],\n      \"review_configs\": [\n        {\n          \"action_name\": \"execute_sql\",\n          \"allowed_decisions\": [\"approve\", \"reject\"]\n        }\n      ]\n    }\n  )\n]\n</code></pre>"},{"location":"llmapps/langchain/advanced-usage/Human-in-the-loop/#_5","title":"\u516d\u3001\u63d0\u4f9b\u4eba\u5de5\u51b3\u7b56\uff08\u6062\u590d\u6267\u884c\uff09","text":"<p>\u6267\u884c\u88ab\u4e2d\u65ad\u540e\uff0c\u4f60\u53ef\u4ee5\u4f7f\u7528 <code>Command(resume=...)</code> \u63d0\u4f9b\u4eba\u5de5\u51b3\u7b56\u5e76\u6062\u590d\u6d41\u7a0b\u3002</p>"},{"location":"llmapps/langchain/advanced-usage/Human-in-the-loop/#_6","title":"\u2705 \u6279\u51c6\u6267\u884c","text":"<pre><code>agent.invoke(\n    Command(\n        resume={\n            \"decisions\": [{\"type\": \"approve\"}]\n        }\n    ),\n    config=config\n)\n</code></pre>"},{"location":"llmapps/langchain/advanced-usage/Human-in-the-loop/#_7","title":"\u270f\ufe0f \u4fee\u6539\u53c2\u6570\u540e\u6267\u884c","text":"<pre><code>agent.invoke(\n    Command(\n        resume={\n            \"decisions\": [\n                {\n                    \"type\": \"edit\",\n                    \"edited_action\": {\n                        \"name\": \"execute_sql\",\n                        \"args\": {\"query\": \"DELETE FROM records WHERE created_at &lt; NOW() - INTERVAL '60 days';\"}\n                    }\n                }\n            ]\n        }\n    ),\n    config=config\n)\n</code></pre>"},{"location":"llmapps/langchain/advanced-usage/Human-in-the-loop/#_8","title":"\u274c \u62d2\u7edd\u6267\u884c\u5e76\u63d0\u4f9b\u53cd\u9988","text":"<pre><code>agent.invoke(\n    Command(\n        resume={\n            \"decisions\": [\n                {\n                    \"type\": \"reject\",\n                    \"message\": \"\u4e0d\u5141\u8bb8\u5220\u9664\u6570\u636e\uff0c\u8bf7\u4ec5\u5f52\u6863\u65e7\u8bb0\u5f55\u3002\"\n                }\n            ]\n        }\n    ),\n    config=config\n)\n</code></pre>"},{"location":"llmapps/langchain/advanced-usage/Human-in-the-loop/#_9","title":"\u591a\u4e2a\u64cd\u4f5c\u540c\u65f6\u4e2d\u65ad\u65f6","text":"<p>\u5fc5\u987b\u6309\u4e2d\u65ad\u8bf7\u6c42\u4e2d\u64cd\u4f5c\u51fa\u73b0\u7684\u987a\u5e8f\u4f9d\u6b21\u63d0\u4f9b\u51b3\u7b56\uff1a</p> <pre><code>{\n  \"decisions\": [\n    {\"type\": \"approve\"},\n    {\n      \"type\": \"edit\",\n      \"edited_action\": {\"name\": \"tool_name\", \"args\": {\"param\": \"new_value\"}}\n    },\n    {\n      \"type\": \"reject\",\n      \"message\": \"\u8be5\u64cd\u4f5c\u672a\u83b7\u6279\u51c6\"\n    }\n  ]\n}\n</code></pre>"},{"location":"llmapps/langchain/advanced-usage/Human-in-the-loop/#hitl_2","title":"\u4e03\u3001HITL \u6267\u884c\u751f\u547d\u5468\u671f\u8be6\u89e3","text":"<ol> <li>Agent \u5411\u6a21\u578b\u8bf7\u6c42\u54cd\u5e94\u3002</li> <li>\u6a21\u578b\u8fd4\u56de\u5305\u542b\u5de5\u5177\u8c03\u7528\u7684\u54cd\u5e94\u3002</li> <li>HITL \u4e2d\u95f4\u4ef6\u5728 <code>after_model</code> \u9636\u6bb5\u68c0\u67e5\u8fd9\u4e9b\u8c03\u7528\u3002</li> <li>\u82e5\u53d1\u73b0\u9700\u8981\u5ba1\u67e5\u7684\u64cd\u4f5c\uff0c\u6784\u5efa <code>HITLRequest</code> \u5e76\u89e6\u53d1 <code>interrupt</code>\u3002</li> <li>Agent \u6682\u505c\uff0c\u7b49\u5f85\u4eba\u5de5\u5ba1\u67e5\u8f93\u5165\u3002</li> <li> <p>\u6839\u636e\u4eba\u5de5\u51b3\u7b56\uff1a</p> </li> <li> <p>\u6267\u884c\u6279\u51c6\u6216\u4fee\u6539\u540e\u7684\u5de5\u5177\u8c03\u7528\uff1b</p> </li> <li>\u5bf9\u62d2\u7edd\u7684\u8c03\u7528\u751f\u6210\u53cd\u9988\u6d88\u606f\uff1b</li> <li>\u6062\u590d\u7ee7\u7eed\u6267\u884c\u6a21\u578b\u63a8\u7406\u3002</li> </ol>"},{"location":"llmapps/langchain/advanced-usage/Human-in-the-loop/#hitl_3","title":"\u516b\u3001\u81ea\u5b9a\u4e49 HITL \u903b\u8f91","text":"<p>\u5982\u679c\u4f60\u5e0c\u671b\u5b9e\u73b0\u66f4\u590d\u6742\u7684\u4eba\u673a\u4ea4\u4e92\u6d41\u7a0b\uff08\u4f8b\u5982\u591a\u7ea7\u5ba1\u6279\u6216\u6761\u4ef6\u89e6\u53d1\uff09\uff0c\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528\uff1a</p> <ul> <li><code>interrupt</code> \u539f\u8bed\uff08LangGraph \u63d0\u4f9b\uff09</li> <li>\u81ea\u5b9a\u4e49\u4e2d\u95f4\u4ef6\uff08\u7ee7\u627f <code>BaseMiddleware</code>\uff09</li> </ul> <p>\u53ef\u53c2\u8003 LangChain Middleware \u6587\u6863 \u4e86\u89e3\u6269\u5c55\u65b9\u5f0f\u3002</p>"},{"location":"llmapps/langchain/advanced-usage/Human-in-the-loop/#_10","title":"\u4e5d\u3001\u603b\u7ed3","text":"<p>Human-in-the-Loop\uff08HITL\uff09 \u662f\u8ba9 AI \u5177\u5907\u201c\u53ef\u63a7\u81ea\u6cbb\u201d\u7684\u5173\u952e\u673a\u5236\u3002 \u5b83\u5e26\u6765\u7684\u597d\u5904\u5305\u62ec\uff1a</p> <ul> <li>\u2705 \u5b89\u5168\u6027\uff1a\u907f\u514d\u6a21\u578b\u81ea\u52a8\u6267\u884c\u5371\u9669\u64cd\u4f5c</li> <li>\ud83e\udde0 \u53ef\u89e3\u91ca\u6027\uff1a\u4eba\u5de5\u5ba1\u67e5\u8fc7\u7a0b\u63d0\u4f9b\u51b3\u7b56\u4f9d\u636e</li> <li>\ud83d\udd04 \u53ef\u6062\u590d\u6027\uff1a\u901a\u8fc7 checkpoint \u80fd\u5b89\u5168\u6682\u505c\u4e0e\u7ee7\u7eed\u6267\u884c</li> </ul> <p>\u672a\u6765\uff0cHITL \u5c06\u6210\u4e3a\u4f01\u4e1a\u7ea7\u667a\u80fd\u4ee3\u7406\u7cfb\u7edf\u7684\u6807\u51c6\u7ec4\u6210\u90e8\u5206\uff0c\u4f7f AI \u65e2\u80fd\u81ea\u4e3b\u6267\u884c\uff0c\u53c8\u4e0d\u5931\u4eba\u7c7b\u638c\u63a7\u3002</p> <p>\u662f\u5426\u5e0c\u671b\u6211\u7ee7\u7eed\u5199\u4e00\u7bc7\u300a\u5b9e\u6218\u7bc7\uff1a\u7528 HITL \u5ba1\u67e5 SQL + \u6587\u4ef6\u5199\u5165\u64cd\u4f5c\u300b\u7684\u8fdb\u9636\u6559\u7a0b\uff1f\u6211\u53ef\u4ee5\u5c55\u793a\u5b8c\u6574\u4ee3\u7801\u4e0e\u4e2d\u65ad\u5904\u7406\u6d41\u7a0b\u3002</p>"},{"location":"llmapps/langchain/advanced-usage/Long-term%20memory/","title":"\ud83e\udde0 LangChain \u957f\u671f\u8bb0\u5fc6\uff08Long-term Memory\uff09\u6559\u7a0b","text":""},{"location":"llmapps/langchain/advanced-usage/Long-term%20memory/#_1","title":"\u4e00\u3001\u6982\u5ff5\u7b80\u4ecb","text":"<p>\u5728 LangChain \u6846\u67b6\u4e2d\uff0c\u957f\u671f\u8bb0\u5fc6\uff08Long-term Memory\uff09 \u901a\u8fc7 LangGraph \u6301\u4e45\u5316\u673a\u5236\uff08Persistence\uff09 \u5b9e\u73b0\u3002 \u5b83\u5141\u8bb8\u667a\u80fd\u4f53\uff08Agent\uff09\u5728\u591a\u4e2a\u4f1a\u8bdd\u4e4b\u95f4\u4fdd\u5b58\u548c\u68c0\u7d22\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u800c\u4e0d\u4ec5\u4ec5\u4f9d\u8d56\u4e8e\u77ed\u671f\u5bf9\u8bdd\u4e0a\u4e0b\u6587\u3002</p> <p>\u6362\u53e5\u8bdd\u8bf4\uff0c\u8fd9\u8ba9\u4f60\u7684 Agent \u62e5\u6709\u201c\u8bb0\u5fc6\u529b\u201d\uff1a \u5b83\u80fd\u8bb0\u4f4f\u7528\u6237\u7684\u504f\u597d\u3001\u5386\u53f2\u64cd\u4f5c\u6216\u8d44\u6599\uff0c\u5e76\u5728\u672a\u6765\u7684\u5bf9\u8bdd\u4e2d\u5f15\u7528\u8fd9\u4e9b\u5185\u5bb9\u3002</p>"},{"location":"llmapps/langchain/advanced-usage/Long-term%20memory/#_2","title":"\u4e8c\u3001\u8bb0\u5fc6\u7684\u5b58\u50a8\u7ed3\u6784","text":"<p>LangGraph \u4f7f\u7528\u7c7b\u4f3c\u6587\u4ef6\u7cfb\u7edf\u7684\u7ed3\u6784\u6765\u7ec4\u7ec7\u8bb0\u5fc6\u6570\u636e\u3002 \u6bcf\u4e00\u6761\u8bb0\u5fc6\u7531\u4e24\u4e2a\u5173\u952e\u90e8\u5206\u7ec4\u6210\uff1a</p> <ul> <li>namespace\uff08\u547d\u540d\u7a7a\u95f4\uff09\uff1a\u76f8\u5f53\u4e8e\u6587\u4ef6\u5939\uff0c\u7528\u4e8e\u5206\u7ec4\u3002\u4f8b\u5982\u53ef\u4ee5\u7528\u7528\u6237ID\u3001\u5e94\u7528\u573a\u666f\u533a\u5206\u3002</li> <li>key\uff08\u952e\uff09\uff1a\u7c7b\u4f3c\u6587\u4ef6\u540d\uff0c\u7528\u4e8e\u552f\u4e00\u6807\u8bc6\u67d0\u6761\u5177\u4f53\u8bb0\u5fc6\u3002</li> </ul> <p>\u6bcf\u6761\u8bb0\u5fc6\u7684\u5185\u5bb9\u4ee5 JSON \u6587\u6863\u5f62\u5f0f\u4fdd\u5b58\u3002 \u793a\u4f8b\u7ed3\u6784\u5982\u4e0b\uff1a</p> <pre><code>from langgraph.store.memory import InMemoryStore\n\ndef embed(texts: list[str]) -&gt; list[list[float]]:\n    # \u5b9e\u9645\u4f7f\u7528\u65f6\u5e94\u66ff\u6362\u4e3a\u771f\u5b9e\u5d4c\u5165\u51fd\u6570\n    return [[1.0, 2.0] * len(texts)]\n\n# \u521b\u5efa\u4e00\u4e2a\u5185\u5b58\u578b\u5b58\u50a8\uff08\u5f00\u53d1\u9636\u6bb5\u4f7f\u7528\uff0c\u751f\u4ea7\u5e94\u6362\u6210\u6570\u636e\u5e93\uff09\nstore = InMemoryStore(index={\"embed\": embed, \"dims\": 2})\n\nuser_id = \"my-user\"\napp_context = \"chitchat\"\nnamespace = (user_id, app_context)\n\n# \u5199\u5165\u4e00\u6761\u8bb0\u5fc6\nstore.put(\n    namespace,\n    \"a-memory\",\n    {\n        \"rules\": [\n            \"User likes short, direct language\",\n            \"User only speaks English &amp; Python\",\n        ],\n        \"my-key\": \"my-value\",\n    },\n)\n\n# \u6839\u636e key \u83b7\u53d6\u8bb0\u5fc6\nitem = store.get(namespace, \"a-memory\")\n\n# \u5728\u547d\u540d\u7a7a\u95f4\u5185\u641c\u7d22\u8bb0\u5fc6\uff08\u6839\u636e\u5185\u5bb9\u8fc7\u6ee4\u5e76\u6309\u5411\u91cf\u76f8\u4f3c\u5ea6\u6392\u5e8f\uff09\nitems = store.search(\n    namespace, filter={\"my-key\": \"my-value\"}, query=\"language preferences\"\n)\n</code></pre> <p>\u5728\u751f\u4ea7\u73af\u5883\u4e2d\uff0c\u4f60\u53ef\u4ee5\u5c06 <code>InMemoryStore</code> \u66ff\u6362\u4e3a\u6570\u636e\u5e93\u540e\u7aef\uff0c\u4ee5\u6301\u4e45\u5316\u5b58\u50a8\u8bb0\u5fc6\u3002</p>"},{"location":"llmapps/langchain/advanced-usage/Long-term%20memory/#_3","title":"\u4e09\u3001\u5728\u5de5\u5177\u4e2d\u8bfb\u53d6\u957f\u671f\u8bb0\u5fc6","text":"<p>\u5728 LangChain \u4e2d\uff0cAgent \u7684\u5de5\u5177\uff08Tool\uff09\u53ef\u4ee5\u76f4\u63a5\u8bbf\u95ee\u957f\u671f\u8bb0\u5fc6\uff0c\u7528\u4e8e\u5728\u6267\u884c\u4efb\u52a1\u65f6\u67e5\u627e\u7528\u6237\u4fe1\u606f\u3002 \u4e0b\u9762\u7684\u4f8b\u5b50\u5c55\u793a\u4e86\u4e00\u4e2a\u53ef\u4ee5\u8bfb\u53d6\u7528\u6237\u8d44\u6599\u7684\u5de5\u5177\uff1a</p> <pre><code>from dataclasses import dataclass\nfrom langchain.agents import create_agent\nfrom langchain.tools import tool, ToolRuntime\nfrom langgraph.store.memory import InMemoryStore\n\n@dataclass\nclass Context:\n    user_id: str\n\nstore = InMemoryStore()\n\n# \u9884\u5148\u5199\u5165\u4e00\u6761\u793a\u4f8b\u6570\u636e\nstore.put(\n    (\"users\",), \n    \"user_123\", \n    {\"name\": \"John Smith\", \"language\": \"English\"}\n)\n\n@tool\ndef get_user_info(runtime: ToolRuntime[Context]) -&gt; str:\n    \"\"\"\u67e5\u627e\u7528\u6237\u4fe1\u606f\"\"\"\n    store = runtime.store\n    user_id = runtime.context.user_id\n    user_info = store.get((\"users\",), user_id)\n    return str(user_info.value) if user_info else \"Unknown user\"\n\nagent = create_agent(\n    model=\"anthropic:claude-sonnet-4-5\",\n    tools=[get_user_info],\n    store=store,\n    context_schema=Context\n)\n\n# \u8fd0\u884c Agent\nagent.invoke(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"look up user information\"}]},\n    context=Context(user_id=\"user_123\")\n)\n</code></pre> <p>\u8fd0\u884c\u540e\uff0cAgent \u4f1a\u901a\u8fc7\u5de5\u5177\u4ece\u8bb0\u5fc6\u5b58\u50a8\u4e2d\u8bfb\u53d6\u7528\u6237\u8d44\u6599\u3002</p>"},{"location":"llmapps/langchain/advanced-usage/Long-term%20memory/#_4","title":"\u56db\u3001\u5728\u5de5\u5177\u4e2d\u5199\u5165\u957f\u671f\u8bb0\u5fc6","text":"<p>\u9664\u4e86\u8bfb\u53d6\u5916\uff0cAgent \u4e5f\u53ef\u4ee5\u901a\u8fc7\u5de5\u5177\u52a8\u6001\u5199\u5165\u8bb0\u5fc6\uff0c\u8fd9\u8ba9\u5b83\u80fd\u5728\u5bf9\u8bdd\u8fc7\u7a0b\u4e2d\u66f4\u65b0\u7528\u6237\u4fe1\u606f\u3002</p> <p>\u4e0b\u9762\u662f\u4e00\u4e2a\u4fdd\u5b58\u7528\u6237\u4fe1\u606f\u7684\u793a\u4f8b\uff1a</p> <pre><code>from dataclasses import dataclass\nfrom typing_extensions import TypedDict\nfrom langchain.agents import create_agent\nfrom langchain.tools import tool, ToolRuntime\nfrom langgraph.store.memory import InMemoryStore\n\nstore = InMemoryStore()\n\n@dataclass\nclass Context:\n    user_id: str\n\nclass UserInfo(TypedDict):\n    name: str\n\n@tool\ndef save_user_info(user_info: UserInfo, runtime: ToolRuntime[Context]) -&gt; str:\n    \"\"\"\u4fdd\u5b58\u7528\u6237\u4fe1\u606f\"\"\"\n    store = runtime.store\n    user_id = runtime.context.user_id\n    store.put((\"users\",), user_id, user_info)\n    return \"Successfully saved user info.\"\n\nagent = create_agent(\n    model=\"anthropic:claude-sonnet-4-5\",\n    tools=[save_user_info],\n    store=store,\n    context_schema=Context\n)\n\n# \u8fd0\u884c Agent\uff0c\u52a8\u6001\u66f4\u65b0\u8bb0\u5fc6\nagent.invoke(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"My name is John Smith\"}]},\n    context=Context(user_id=\"user_123\")\n)\n\n# \u9a8c\u8bc1\u662f\u5426\u5199\u5165\u6210\u529f\nstore.get((\"users\",), \"user_123\").value\n</code></pre> <p>\u7ed3\u679c\u4e2d\u53ef\u4ee5\u770b\u5230\uff0c\u7528\u6237\u6570\u636e\u88ab\u6210\u529f\u5b58\u50a8\u5230 <code>store</code> \u4e2d\u3002</p>"},{"location":"llmapps/langchain/advanced-usage/Long-term%20memory/#_5","title":"\u4e94\u3001\u8fdb\u9636\uff1a\u4f7f\u7528\u6570\u636e\u5e93\u6216\u4e91\u7aef\u5b58\u50a8","text":"<p><code>InMemoryStore</code> \u4ec5\u9002\u5408\u5f00\u53d1\u6d4b\u8bd5\u9636\u6bb5\u3002 \u5728\u751f\u4ea7\u73af\u5883\u4e2d\uff0c\u4f60\u5e94\u4f7f\u7528\u6301\u4e45\u5316\u540e\u7aef\uff0c\u5982\uff1a</p> <ul> <li>SQLite\u3001PostgreSQL\u3001MongoDB</li> <li>\u4e91\u670d\u52a1\uff08\u5982 AWS DynamoDB\u3001Redis\u3001FireStore \u7b49\uff09</li> </ul> <p>LangGraph \u7684\u6301\u4e45\u5316\u63a5\u53e3\u662f\u7edf\u4e00\u7684\uff0c\u8fd9\u610f\u5473\u7740\u4f60\u53ef\u4ee5\u66ff\u6362\u5e95\u5c42\u5b58\u50a8\uff0c\u800c\u4e0d\u5f71\u54cd\u4e0a\u5c42\u903b\u8f91\u3002</p>"},{"location":"llmapps/langchain/advanced-usage/Long-term%20memory/#_6","title":"\u516d\u3001\u603b\u7ed3","text":"<p>\u957f\u671f\u8bb0\u5fc6\u8ba9 LangChain Agent \u62e5\u6709\u66f4\u201c\u4eba\u6027\u5316\u201d\u7684\u4e0a\u4e0b\u6587\u610f\u8bc6\u3002 \u901a\u8fc7\u5b83\uff0cAgent \u80fd\u591f\uff1a</p> <ul> <li>\u8bb0\u4f4f\u7528\u6237\u7684\u5386\u53f2\u4e0e\u504f\u597d</li> <li>\u8de8\u4f1a\u8bdd\u68c0\u7d22\u5e76\u4f7f\u7528\u5148\u524d\u4fe1\u606f</li> <li>\u52a8\u6001\u66f4\u65b0\u77e5\u8bc6\u3001\u4e2a\u6027\u4e0e\u884c\u4e3a\u6a21\u5f0f</li> </ul> <p>\u5728\u6784\u5efa\u4e2a\u6027\u5316\u52a9\u7406\u3001\u5bf9\u8bdd\u673a\u5668\u4eba\u6216\u6301\u7eed\u5b66\u4e60\u578b\u667a\u80fd\u4f53\u65f6\uff0c\u957f\u671f\u8bb0\u5fc6\u662f\u4e0d\u53ef\u6216\u7f3a\u7684\u80fd\u529b\u3002</p>"},{"location":"llmapps/langchain/advanced-usage/MCP/","title":"\ud83e\udded Model Context Protocol (MCP) \u6559\u7a0b","text":""},{"location":"llmapps/langchain/advanced-usage/MCP/#mcp","title":"\u4e00\u3001\u4ec0\u4e48\u662f MCP\uff1f","text":"<p>Model Context Protocol\uff08MCP\uff09 \u662f\u4e00\u79cd\u5f00\u653e\u534f\u8bae\uff0c\u7528\u4e8e\u6807\u51c6\u5316 \u5e94\u7528\u7a0b\u5e8f\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4e4b\u95f4 \u7684\u4e0a\u4e0b\u6587\u4e0e\u5de5\u5177\u4ea4\u4e92\u65b9\u5f0f\u3002 \u7b80\u5355\u6765\u8bf4\uff0c\u5b83\u5b9a\u4e49\u4e86\u4e00\u79cd\u201c\u8bed\u8a00\u6a21\u578b\u8bbf\u95ee\u5916\u90e8\u4e16\u754c\u7684\u7edf\u4e00\u65b9\u5f0f\u201d\u3002</p> <p>\u4f20\u7edf\u4e0a\uff0cLLM \u53ea\u80fd\u5904\u7406\u7eaf\u6587\u672c\u8f93\u5165\uff0c\u4f46\u901a\u8fc7 MCP\uff0c\u4f60\u53ef\u4ee5\u8ba9\u6a21\u578b\u8bbf\u95ee\uff1a</p> <ul> <li>\u672c\u5730\u6216\u8fdc\u7a0b\u5de5\u5177\uff08Tool\uff09</li> <li>\u5916\u90e8 API \u6216\u670d\u52a1\uff08\u4f8b\u5982\u5929\u6c14\u3001\u8ba1\u7b97\u3001\u6570\u636e\u5e93\uff09</li> <li>\u7edf\u4e00\u4e0a\u4e0b\u6587\u7ba1\u7406\uff08Context Management\uff09</li> </ul> <p>MCP \u7684\u76ee\u6807\u662f\u8ba9\u4e0d\u540c\u5e73\u53f0\u7684\u5de5\u5177\u3001\u63d2\u4ef6\u3001\u4e0a\u4e0b\u6587\u6a21\u5757\u4e4b\u95f4\u5b9e\u73b0\u4e92\u64cd\u4f5c\uff0c\u5c31\u50cf HTTP \u8ba9\u4e0d\u540c\u7f51\u7ad9\u4e4b\u95f4\u53ef\u4ee5\u4ea4\u4e92\u4e00\u6837\u3002</p>"},{"location":"llmapps/langchain/advanced-usage/MCP/#mcp-langchain","title":"\u4e8c\u3001MCP \u4e0e LangChain \u7684\u7ed3\u5408","text":"<p>LangChain \u63d0\u4f9b\u4e86 <code>langchain-mcp-adapters</code> \u5e93\uff0c\u4f7f LangChain Agent \u53ef\u4ee5\u76f4\u63a5\u8bbf\u95ee MCP \u5b9a\u4e49\u7684\u5de5\u5177\u3002 \u8fd9\u610f\u5473\u7740\u4f60\u53ef\u4ee5\u50cf\u8c03\u7528\u666e\u901a\u51fd\u6570\u4e00\u6837\uff0c\u8ba9 Agent \u4f7f\u7528\u5916\u90e8 MCP Server \u63d0\u4f9b\u7684\u529f\u80fd\u3002</p>"},{"location":"llmapps/langchain/advanced-usage/MCP/#_1","title":"\u4e09\u3001\u5b89\u88c5","text":""},{"location":"llmapps/langchain/advanced-usage/MCP/#pip","title":"\u4f7f\u7528 <code>pip</code>","text":"<pre><code>pip install langchain-mcp-adapters\n</code></pre>"},{"location":"llmapps/langchain/advanced-usage/MCP/#uv","title":"\u4f7f\u7528 <code>uv</code>","text":"<pre><code>uv add langchain-mcp-adapters\n</code></pre> <p>\u5b89\u88c5\u5b8c\u6210\u540e\uff0c\u4f60\u5c31\u53ef\u4ee5\u5728 LangGraph \u6216 LangChain \u4e2d\u4f7f\u7528 MCP \u5de5\u5177\u4e86\u3002</p>"},{"location":"llmapps/langchain/advanced-usage/MCP/#mcp-transport-types","title":"\u56db\u3001MCP \u7684\u901a\u4fe1\u673a\u5236\uff08Transport Types\uff09","text":"<p>MCP \u652f\u6301\u591a\u79cd\u901a\u4fe1\u673a\u5236\uff08\u4f20\u8f93\u5c42\u534f\u8bae\uff09\u7528\u4e8e\u5ba2\u6237\u7aef\u4e0e\u670d\u52a1\u5668\u4e4b\u95f4\u7684\u6570\u636e\u4ea4\u4e92\uff1a</p> \u7c7b\u578b \u8bf4\u660e \u9002\u7528\u573a\u666f stdio \u4f7f\u7528\u6807\u51c6\u8f93\u5165/\u8f93\u51fa\u8fdb\u884c\u901a\u4fe1\uff0c\u5ba2\u6237\u7aef\u542f\u52a8\u670d\u52a1\u5668\u8fdb\u7a0b\u5e76\u901a\u8fc7\u7ba1\u9053\u901a\u4fe1\u3002 \u672c\u5730\u8fd0\u884c\u3001\u7b80\u5355\u8c03\u8bd5 streamable-http \u4f7f\u7528 HTTP \u901a\u4fe1\uff0c\u652f\u6301\u591a\u5ba2\u6237\u7aef\u5e76\u53d1\u8bbf\u95ee\u3002 \u8fdc\u7a0b\u90e8\u7f72\u3001Web \u670d\u52a1 SSE (Server-Sent Events) HTTP \u7684\u5b9e\u65f6\u6d41\u5f0f\u901a\u4fe1\u53d8\u4f53\u3002 \u5b9e\u65f6\u6570\u636e\u66f4\u65b0\uff0c\u5982\u804a\u5929\u6d41 <p>\u4f8b\u5982\uff1a</p> <ul> <li><code>stdio</code> \u66f4\u9002\u5408\u8fd0\u884c\u5728\u4f60\u672c\u673a\u7684\u8f7b\u91cf\u5de5\u5177\u3002</li> <li><code>streamable_http</code> \u5219\u9002\u5408\u90e8\u7f72\u5728\u4e91\u7aef\u7684\u591a\u7528\u6237\u73af\u5883\u3002</li> </ul>"},{"location":"llmapps/langchain/advanced-usage/MCP/#langchain-mcp","title":"\u4e94\u3001\u5728 LangChain \u4e2d\u4f7f\u7528 MCP \u5de5\u5177","text":"<p><code>MultiServerMCPClient</code> \u5141\u8bb8\u8fde\u63a5\u591a\u4e2a MCP Server\uff0c\u8ba9\u4e00\u4e2a Agent \u540c\u65f6\u4f7f\u7528\u591a\u4e2a\u5916\u90e8\u5de5\u5177\u3002</p>"},{"location":"llmapps/langchain/advanced-usage/MCP/#_2","title":"\u793a\u4f8b\u4ee3\u7801","text":"<pre><code>from langchain_mcp_adapters.client import MultiServerMCPClient\nfrom langchain.agents import create_agent\n\n# \u5b9a\u4e49\u4e24\u4e2a MCP Server\uff1a\u4e00\u4e2a\u6570\u5b66\u8ba1\u7b97\uff0c\u4e00\u4e2a\u5929\u6c14\u670d\u52a1\nclient = MultiServerMCPClient({\n    \"math\": {\n        \"transport\": \"stdio\",\n        \"command\": \"python\",\n        \"args\": [\"/path/to/math_server.py\"],  # \u672c\u5730\u8def\u5f84\n    },\n    \"weather\": {\n        \"transport\": \"streamable_http\",\n        \"url\": \"http://localhost:8000/mcp\",  # \u8fdc\u7a0b\u670d\u52a1\n    }\n})\n\ntools = await client.get_tools()\n\nagent = create_agent(\"anthropic:claude-sonnet-4-5\", tools)\n\n# \u8ba9\u6a21\u578b\u8c03\u7528 math \u5de5\u5177\nmath_response = await agent.ainvoke({\n    \"messages\": [{\"role\": \"user\", \"content\": \"what's (3 + 5) x 12?\"}]\n})\n\n# \u8c03\u7528 weather \u5de5\u5177\nweather_response = await agent.ainvoke({\n    \"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in nyc?\"}]\n})\n</code></pre> <p>\u2699\ufe0f \u6ce8\u610f\uff1a <code>MultiServerMCPClient</code> \u9ed8\u8ba4\u662f\u65e0\u72b6\u6001\u7684\uff08stateless\uff09\uff0c\u6bcf\u6b21\u8c03\u7528\u90fd\u4f1a\u91cd\u65b0\u521b\u5efa\u4e00\u4e2a\u4f1a\u8bdd\u5e76\u5728\u6267\u884c\u540e\u5173\u95ed\u3002</p>"},{"location":"llmapps/langchain/advanced-usage/MCP/#mcp-server","title":"\u516d\u3001\u81ea\u5b9a\u4e49 MCP Server","text":"<p>\u8981\u521b\u5efa\u81ea\u5df1\u7684 MCP Server\uff0c\u53ef\u4ee5\u4f7f\u7528 <code>mcp</code> \u5e93\u3002 \u8fd9\u4e2a\u5e93\u8ba9\u4f60\u5f88\u5bb9\u6613\u5b9a\u4e49\u5de5\u5177\uff08Tool\uff09\u5e76\u5c06\u5176\u66b4\u9732\u4e3a MCP \u670d\u52a1\u3002</p>"},{"location":"llmapps/langchain/advanced-usage/MCP/#_3","title":"\u5b89\u88c5","text":"<pre><code>pip install mcp\n</code></pre>"},{"location":"llmapps/langchain/advanced-usage/MCP/#1-stdio","title":"\u793a\u4f8b 1\uff1a\u6570\u5b66\u670d\u52a1\u5668\uff08\u672c\u5730 stdio \u6a21\u5f0f\uff09","text":"<pre><code>from mcp.server.fastmcp import FastMCP\n\nmcp = FastMCP(\"Math\")\n\n@mcp.tool()\ndef add(a: int, b: int) -&gt; int:\n    \"\"\"\u52a0\u6cd5\"\"\"\n    return a + b\n\n@mcp.tool()\ndef multiply(a: int, b: int) -&gt; int:\n    \"\"\"\u4e58\u6cd5\"\"\"\n    return a * b\n\nif __name__ == \"__main__\":\n    mcp.run(transport=\"stdio\")\n</code></pre> <p>\u8fd0\u884c\u8fd9\u4e2a\u811a\u672c\u540e\uff0c\u5b83\u4f1a\u4f5c\u4e3a\u4e00\u4e2a\u672c\u5730 MCP Server \u8fd0\u884c\uff0c\u5ba2\u6237\u7aef\u53ef\u4ee5\u901a\u8fc7 <code>stdio</code> \u8c03\u7528\u3002</p>"},{"location":"llmapps/langchain/advanced-usage/MCP/#2http","title":"\u793a\u4f8b 2\uff1a\u5929\u6c14\u670d\u52a1\u5668\uff08HTTP \u6a21\u5f0f\uff09","text":"<pre><code>from mcp.server.fastmcp import FastMCP\n\nmcp = FastMCP(\"Weather\")\n\n@mcp.tool()\nasync def get_weather(location: str) -&gt; str:\n    \"\"\"\u83b7\u53d6\u6307\u5b9a\u57ce\u5e02\u7684\u5929\u6c14\"\"\"\n    return \"It's always sunny in New York\"\n\nif __name__ == \"__main__\":\n    mcp.run(transport=\"streamable-http\")\n</code></pre> <p>\u542f\u52a8\u540e\uff0c\u8be5\u670d\u52a1\u4f1a\u76d1\u542c\u4e00\u4e2a HTTP \u7aef\u53e3\uff08\u9ed8\u8ba4 8000\uff09\uff0c\u652f\u6301\u8fdc\u7a0b\u8bbf\u95ee\u3002</p>"},{"location":"llmapps/langchain/advanced-usage/MCP/#stateful-session","title":"\u4e03\u3001\u4fdd\u6301\u6709\u72b6\u6001\u7684\u4f1a\u8bdd\uff08Stateful Session\uff09","text":"<p>\u6709\u65f6\u4f60\u9700\u8981\u8ba9 MCP Server \u8bb0\u4f4f\u4e0a\u4e00\u6b21\u7684\u72b6\u6001\uff0c\u6bd4\u5982\u4e0a\u4e0b\u6587\u3001\u7f13\u5b58\u6216\u7528\u6237\u6570\u636e\u3002 \u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u53ef\u4ee5\u4f7f\u7528 <code>client.session()</code> \u521b\u5efa\u6301\u4e45\u4f1a\u8bdd\u3002</p>"},{"location":"llmapps/langchain/advanced-usage/MCP/#_4","title":"\u793a\u4f8b","text":"<pre><code>from langchain_mcp_adapters.tools import load_mcp_tools\nfrom langchain_mcp_adapters.client import MultiServerMCPClient\n\nclient = MultiServerMCPClient({...})\n\n# \u521b\u5efa\u6301\u4e45\u5316 session\nasync with client.session(\"math\") as session:\n    tools = await load_mcp_tools(session)\n    # \u5728\u540c\u4e00\u4e2a\u4f1a\u8bdd\u4e2d\u591a\u6b21\u8c03\u7528\u5de5\u5177\n</code></pre>"},{"location":"llmapps/langchain/advanced-usage/MCP/#_5","title":"\u516b\u3001\u5ef6\u4f38\u9605\u8bfb","text":"<ul> <li>\u5b98\u65b9 MCP \u6587\u6863</li> <li>MCP Transport \u673a\u5236\u8bf4\u660e</li> <li>langchain-mcp-adapters \u6e90\u7801</li> </ul>"},{"location":"llmapps/langchain/advanced-usage/MCP/#_6","title":"\u4e5d\u3001\u603b\u7ed3","text":"<p>MCP \u4e3a LLM \u5de5\u5177\u8c03\u7528\u5efa\u7acb\u4e86\u4e00\u4e2a\u5f00\u653e\u3001\u901a\u7528\u7684\u534f\u8bae\u5c42\u3002 \u5b83\u5e26\u6765\u7684\u5173\u952e\u4f18\u52bf\u5305\u62ec\uff1a</p> <ol> <li>\u7edf\u4e00\u6807\u51c6\uff1a\u4e0d\u540c\u5de5\u5177\u548c\u670d\u52a1\u4e4b\u95f4\u5b9e\u73b0\u4e00\u81f4\u7684\u63a5\u53e3\u3002</li> <li>\u591a\u8bed\u8a00\u652f\u6301\uff1a\u4efb\u4f55\u5b9e\u73b0 MCP \u534f\u8bae\u7684\u8bed\u8a00\u90fd\u80fd\u4ea4\u4e92\u3002</li> <li>LangChain \u65e0\u7f1d\u96c6\u6210\uff1a\u53ef\u76f4\u63a5\u6269\u5c55 Agent \u7684\u5916\u90e8\u80fd\u529b\u3002</li> </ol> <p>\u5728\u672a\u6765\uff0cMCP \u5f88\u53ef\u80fd\u6210\u4e3a AI Agent \u4e16\u754c\u4e2d\u7684\u201cAPI \u534f\u8bae\u5c42\u201d\uff0c\u8ba9\u6a21\u578b\u80fd\u591f\u50cf\u6d4f\u89c8\u5668\u8bbf\u95ee\u7f51\u9875\u90a3\u6837\u8bbf\u95ee\u5de5\u5177\u4e0e\u4e0a\u4e0b\u6587\u3002</p> <p>\u5982\u679c\u4f60\u60f3\uff0c\u6211\u53ef\u4ee5\u63a5\u7740\u5199\u4e00\u7bc7 \u201c\u624b\u52a8\u4ece\u96f6\u5b9e\u73b0\u4e00\u4e2a\u6700\u5c0f MCP \u5de5\u5177\u94fe\u201d \u6559\u7a0b\uff0c\u5c55\u793a\u4ece\u81ea\u5b9a\u4e49 Server \u5230 LangChain Agent \u5168\u6d41\u7a0b\u8c03\u8bd5\u3002\u662f\u5426\u8981\u7ee7\u7eed\uff1f</p>"},{"location":"llmapps/langchain/advanced-usage/Multi-agent/","title":"\ud83c\udf10 \u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff08Multi-Agent Systems\uff09\u6559\u7a0b","text":"<p>\u5728\u4f20\u7edf\u7684\u667a\u80fd\u4f53\uff08Agent\uff09\u67b6\u6784\u4e2d\uff0c\u5f80\u5f80\u53ea\u6709\u4e00\u4e2a\u201c\u8d85\u7ea7\u667a\u80fd\u4f53\u201d\u6765\u5904\u7406\u6240\u6709\u4efb\u52a1\uff1a\u5b83\u8981\u7406\u89e3\u95ee\u9898\u3001\u89c4\u5212\u6b65\u9aa4\u3001\u8c03\u7528\u5de5\u5177\u3001\u518d\u7efc\u5408\u56de\u7b54\u3002\u4f46\u968f\u7740\u4efb\u52a1\u590d\u6742\u5ea6\u63d0\u5347\u2014\u2014\u5c24\u5176\u662f\u9700\u8981\u8de8\u9886\u57df\u63a8\u7406\u3001\u4e0a\u4e0b\u6587\u7206\u70b8\u6216\u4e13\u4e1a\u5316\u4efb\u52a1\u2014\u2014\u8fd9\u79cd\u201c\u5355\u4f53\u5927\u8111\u201d\u6a21\u578b\u53d8\u5f97\u4f4e\u6548\u4e14\u7b28\u62d9\u3002</p> <p>\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff08Multi-Agent System\uff09 \u7684\u6838\u5fc3\u601d\u60f3\u662f\uff1a</p> <p>\u5c06\u590d\u6742\u95ee\u9898\u62c6\u89e3\u6210\u591a\u4e2a\u4e13\u7cbe\u7684\u5b50\u667a\u80fd\u4f53\uff08Sub-agents\uff09\uff0c\u901a\u8fc7\u534f\u4f5c\u4e0e\u534f\u8c03\u6765\u5171\u540c\u5b8c\u6210\u4efb\u52a1\u3002</p>"},{"location":"llmapps/langchain/advanced-usage/Multi-agent/#_1","title":"\u4e00\u3001\u4e3a\u4ec0\u4e48\u9700\u8981\u591a\u667a\u80fd\u4f53","text":"<p>\u591a\u667a\u80fd\u4f53\u7684\u4f18\u52bf\u5728\u4e8e\u201c\u4e13\u4e1a\u5206\u5de5\u201d\u548c\u201c\u7ed3\u6784\u5316\u534f\u4f5c\u201d\u3002\u5178\u578b\u5e94\u7528\u573a\u666f\u5305\u62ec\uff1a</p> <ul> <li>\u4efb\u52a1\u8fc7\u4e8e\u590d\u6742\uff1a\u5355\u4e00\u667a\u80fd\u4f53\u62e5\u6709\u592a\u591a\u5de5\u5177\uff0c\u5e38\u5e38\u505a\u51fa\u9519\u8bef\u9009\u62e9\u3002</li> <li>\u4e0a\u4e0b\u6587\u8fc7\u957f\uff1a\u5355\u4e2a\u667a\u80fd\u4f53\u65e0\u6cd5\u6709\u6548\u8ffd\u8e2a\u5e9e\u5927\u7684\u5bf9\u8bdd\u6216\u4efb\u52a1\u72b6\u6001\u3002</li> <li>\u9700\u8981\u4e13\u4e1a\u5316\uff1a\u4f8b\u5982\u4e00\u4e2a\u89c4\u5212\u8005\uff08Planner\uff09\u8d1f\u8d23\u4efb\u52a1\u62c6\u89e3\uff0c\u4e00\u4e2a\u7814\u7a76\u8005\uff08Researcher\uff09\u8d1f\u8d23\u4fe1\u606f\u68c0\u7d22\uff0c\u4e00\u4e2a\u5206\u6790\u5e08\uff08Analyst\uff09\u8d1f\u8d23\u8ba1\u7b97\u4e0e\u63a8\u7406\u3002</li> </ul> <p>\u591a\u667a\u80fd\u4f53\u67b6\u6784\u80fd\u8ba9\u6bcf\u4e2a\u5b50\u667a\u80fd\u4f53\u805a\u7126\u81ea\u5df1\u7684\u4e13\u4e1a\u9886\u57df\uff0c\u4e3b\u667a\u80fd\u4f53\uff08Supervisor\uff09\u5219\u8d1f\u8d23\u603b\u4f53\u8c03\u5ea6\u3002</p>"},{"location":"llmapps/langchain/advanced-usage/Multi-agent/#_2","title":"\u4e8c\u3001\u4e24\u79cd\u4e3b\u8981\u6a21\u5f0f","text":"<p>LangChain \u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e3b\u8981\u6709\u4e24\u79cd\u534f\u4f5c\u6a21\u5f0f\uff1a</p> \u6a21\u5f0f \u5de5\u4f5c\u673a\u5236 \u63a7\u5236\u6d41\u7c7b\u578b \u793a\u4f8b\u573a\u666f Tool Calling\uff08\u5de5\u5177\u8c03\u7528\uff09 \u4e3b\u667a\u80fd\u4f53\u8c03\u7528\u5176\u4ed6\u5b50\u667a\u80fd\u4f53\u4f5c\u4e3a\u201c\u5de5\u5177\u201d\u4f7f\u7528\u3002\u5b50\u667a\u80fd\u4f53\u4e0d\u76f4\u63a5\u4e0e\u7528\u6237\u5bf9\u8bdd\uff0c\u53ea\u8fd4\u56de\u7ed3\u679c\u3002 \u96c6\u4e2d\u5f0f\uff08Centralized\uff09 \u81ea\u52a8\u5316\u4efb\u52a1\u7f16\u6392\u3001\u7ed3\u6784\u5316\u6d41\u7a0b Handoffs\uff08\u63a7\u5236\u8f6c\u79fb\uff09 \u5f53\u524d\u667a\u80fd\u4f53\u53ef\u4e3b\u52a8\u201c\u79fb\u4ea4\u63a7\u5236\u6743\u201d\u7ed9\u53e6\u4e00\u667a\u80fd\u4f53\uff0c\u7528\u6237\u63a5\u7740\u4e0e\u65b0\u667a\u80fd\u4f53\u4ea4\u4e92\u3002 \u53bb\u4e2d\u5fc3\u5316\uff08Decentralized\uff09 \u591a\u9886\u57df\u4f1a\u8bdd\u3001\u4e13\u5bb6\u63a5\u7ba1\u5bf9\u8bdd <p>\ud83d\udca1 \u63d0\u793a\uff1a\u4e24\u79cd\u6a21\u5f0f\u5e76\u975e\u4e92\u65a5\uff0c\u4f60\u53ef\u4ee5\u5728\u540c\u4e00\u7cfb\u7edf\u4e2d\u6df7\u5408\u4f7f\u7528\u2014\u2014 \u4f8b\u5982\uff1a\u4f7f\u7528 handoff \u5b9e\u73b0\u667a\u80fd\u4f53\u4e4b\u95f4\u7684\u63a5\u529b\uff0c\u518d\u5728\u6bcf\u4e2a\u667a\u80fd\u4f53\u5185\u90e8\u7528 tool calling \u8c03\u7528\u4e13\u4e1a\u5b50\u4efb\u52a1\u3002</p>"},{"location":"llmapps/langchain/advanced-usage/Multi-agent/#tool-calling","title":"\u4e09\u3001Tool Calling \u6a21\u5f0f\u8be6\u89e3","text":"<p>\u5728 Tool Calling \u6a21\u5f0f\u4e2d\uff0c\u7cfb\u7edf\u7ed3\u6784\u7c7b\u4f3c\u201c\u4e3b\u63a7\u2014\u5de5\u5177\u201d\u6a21\u578b\u3002</p>"},{"location":"llmapps/langchain/advanced-usage/Multi-agent/#_3","title":"\u8fd0\u884c\u6d41\u7a0b","text":"<ol> <li>\u4e3b\u667a\u80fd\u4f53\u63a5\u6536\u7528\u6237\u8f93\u5165\uff0c\u5224\u65ad\u8981\u8c03\u7528\u54ea\u4e2a\u5b50\u667a\u80fd\u4f53\u3002</li> <li>\u88ab\u8c03\u7528\u7684\u5b50\u667a\u80fd\u4f53\u6267\u884c\u4efb\u52a1\u3002</li> <li>\u5b50\u667a\u80fd\u4f53\u8fd4\u56de\u7ed3\u679c\u3002</li> <li>\u4e3b\u667a\u80fd\u4f53\u6c47\u603b\u7ed3\u679c\uff0c\u51b3\u5b9a\u4e0b\u4e00\u6b65\u52a8\u4f5c\u6216\u76f4\u63a5\u56de\u5e94\u7528\u6237\u3002</li> </ol> <pre><code>graph LR\n    A[\u7528\u6237] --&gt; B[\u4e3b\u667a\u80fd\u4f53 Controller]\n    B --&gt; C[\u5b50\u667a\u80fd\u4f53 ToolAgent 1]\n    B --&gt; D[\u5b50\u667a\u80fd\u4f53 ToolAgent 2]\n    C --&gt; B\n    D --&gt; B\n    B --&gt; E[\u7528\u6237\u54cd\u5e94]\n</code></pre> <p>\u5b50\u667a\u80fd\u4f53\u4ec5\u8d1f\u8d23\u6267\u884c\uff0c\u4e0d\u4e0e\u7528\u6237\u4ea4\u4e92\u3002</p>"},{"location":"llmapps/langchain/advanced-usage/Multi-agent/#_4","title":"\u6700\u5c0f\u5b9e\u73b0\u793a\u4f8b","text":"<pre><code>from langchain.tools import tool\nfrom langchain.agents import create_agent\n\n# \u5b9a\u4e49\u5b50\u667a\u80fd\u4f53\nsubagent1 = create_agent(model=\"gpt-4\", tools=[...])\n\n# \u5305\u88c5\u4e3a\u53ef\u88ab\u4e3b\u667a\u80fd\u4f53\u8c03\u7528\u7684\u5de5\u5177\n@tool(\"subagent1_name\", description=\"\u5b50\u667a\u80fd\u4f531\uff1a\u5904\u7406\u6570\u636e\u5206\u6790\u4efb\u52a1\")\ndef call_subagent1(query: str):\n    result = subagent1.invoke({\n        \"messages\": [{\"role\": \"user\", \"content\": query}]\n    })\n    return result[\"messages\"][-1].content\n\n# \u521b\u5efa\u4e3b\u667a\u80fd\u4f53\u5e76\u6ce8\u518c\u5b50\u667a\u80fd\u4f53\u5de5\u5177\nagent = create_agent(model=\"gpt-4\", tools=[call_subagent1])\n</code></pre> <p>\u6267\u884c\u903b\u8f91\uff1a</p> <ul> <li>\u4e3b\u667a\u80fd\u4f53\u6839\u636e\u4efb\u52a1\u63cf\u8ff0\u5224\u65ad\u662f\u5426\u9700\u8981\u8c03\u7528 <code>subagent1</code>\uff1b</li> <li>\u5b50\u667a\u80fd\u4f53\u72ec\u7acb\u8fd0\u884c\uff1b</li> <li>\u8fd4\u56de\u7684\u7ed3\u679c\u4ea4\u7531\u4e3b\u667a\u80fd\u4f53\u8fdb\u4e00\u6b65\u51b3\u7b56\u3002</li> </ul>"},{"location":"llmapps/langchain/advanced-usage/Multi-agent/#_5","title":"\u56db\u4e2a\u53ef\u5b9a\u5236\u70b9","text":"<ol> <li>\u5b50\u667a\u80fd\u4f53\u540d\u79f0\uff1a\u5f71\u54cd\u4e3b\u667a\u80fd\u4f53\u7684\u8c03\u7528\u5224\u65ad\u3002</li> <li>\u63cf\u8ff0\uff08description\uff09\uff1a\u6307\u5bfc\u4e3b\u667a\u80fd\u4f53\u5728\u4f55\u79cd\u60c5\u5883\u4e0b\u8c03\u7528\u8be5\u5b50\u667a\u80fd\u4f53\u3002</li> <li>\u8f93\u5165\uff1a\u5982\u4f55\u5c06\u4e3b\u667a\u80fd\u4f53\u7684\u4e0a\u4e0b\u6587\u8f6c\u5316\u4e3a\u5b50\u667a\u80fd\u4f53\u8f93\u5165\u3002</li> <li>\u8f93\u51fa\uff1a\u8fd4\u56de\u7ed3\u679c\u7684\u7ed3\u6784\u4e0e\u8bed\u4e49\u3002</li> </ol>"},{"location":"llmapps/langchain/advanced-usage/Multi-agent/#_6","title":"\u4f20\u9012\u4e0a\u4e0b\u6587\u7684\u9ad8\u7ea7\u65b9\u5f0f","text":"<p>\u6709\u65f6\u4f60\u9700\u8981\u5c06\u4e3b\u667a\u80fd\u4f53\u7684\u90e8\u5206\u72b6\u6001\uff08\u4f8b\u5982\u5386\u53f2\u5bf9\u8bdd\u3001\u4efb\u52a1\u5143\u6570\u636e\uff09\u6ce8\u5165\u7ed9\u5b50\u667a\u80fd\u4f53\u3002</p> <pre><code>from langchain.agents import AgentState\nfrom langchain.tools import tool, ToolRuntime\n\nclass CustomState(AgentState):\n    example_state_key: str\n\n@tool(\"subagent1_name\", description=\"\u5b50\u667a\u80fd\u4f531\")\ndef call_subagent1(query: str, runtime: ToolRuntime[None, CustomState]):\n    subagent_input = some_logic(query, runtime.state[\"messages\"])\n    result = subagent1.invoke({\n        \"messages\": subagent_input,\n        \"example_state_key\": runtime.state[\"example_state_key\"]\n    })\n    return result[\"messages\"][-1].content\n</code></pre>"},{"location":"llmapps/langchain/advanced-usage/Multi-agent/#_7","title":"\u81ea\u5b9a\u4e49\u8f93\u51fa\u683c\u5f0f","text":"<p>\u82e5\u5e0c\u671b\u8fd4\u56de\u7684\u4e0d\u53ea\u662f\u6587\u672c\uff0c\u8fd8\u5305\u62ec\u4e2d\u95f4\u72b6\u6001\u6216\u9644\u52a0\u6570\u636e\uff0c\u53ef\u4ee5\u4f7f\u7528 <code>Command</code> \u5bf9\u8c61\uff1a</p> <pre><code>from typing import Annotated\nfrom langchain.agents import AgentState\nfrom langchain.tools import InjectedToolCallId\nfrom langgraph.types import Command, ToolMessage\n\n@tool(\"subagent1_name\", description=\"\u5b50\u667a\u80fd\u4f531\")\ndef call_subagent1(query: str, tool_call_id: Annotated[str, InjectedToolCallId]) -&gt; Command:\n    result = subagent1.invoke({\"messages\": [{\"role\": \"user\", \"content\": query}]})\n    return Command(update={\n        \"example_state_key\": result[\"example_state_key\"],\n        \"messages\": [\n            ToolMessage(\n                content=result[\"messages\"][-1].content,\n                tool_call_id=tool_call_id\n            )\n        ]\n    })\n</code></pre> <p>\u8fd9\u6837\u4e3b\u667a\u80fd\u4f53\u5c31\u80fd\u540c\u6b65\u63a5\u6536\u5230\u66f4\u591a\u4e0a\u4e0b\u6587\u72b6\u6001\u3002</p>"},{"location":"llmapps/langchain/advanced-usage/Multi-agent/#handoffs","title":"\u56db\u3001Handoffs \u6a21\u5f0f","text":"<p>\u5728 Handoffs \u6a21\u5f0f\u4e2d\uff0c\u667a\u80fd\u4f53\u4e4b\u95f4\u53ef\u4ee5\u4e92\u76f8\u201c\u63a5\u529b\u201d\uff0c\u7528\u6237\u603b\u662f\u4e0e\u5f53\u524d\u6fc0\u6d3b\u7684\u667a\u80fd\u4f53\u76f4\u63a5\u4ea4\u4e92\u3002</p>"},{"location":"llmapps/langchain/advanced-usage/Multi-agent/#_8","title":"\u6d41\u7a0b\u56fe","text":"<pre><code>graph LR\n    A[\u7528\u6237] --&gt; B[\u667a\u80fd\u4f53 A]\n    B --&gt; C[\u667a\u80fd\u4f53 B]\n    C --&gt; A\n</code></pre> <p>\u6838\u5fc3\u673a\u5236\uff1a</p> <ul> <li>\u5f53\u524d\u667a\u80fd\u4f53\u5728\u6267\u884c\u8fc7\u7a0b\u4e2d\u53ef\u51b3\u5b9a\u201c\u6211\u4e0d\u64c5\u957f\u6b64\u4efb\u52a1\u201d\uff0c\u5e76\u4e3b\u52a8\u8f6c\u4ea4\u63a7\u5236\u6743\uff1b</li> <li>\u4e0b\u4e00\u4e2a\u667a\u80fd\u4f53\u6210\u4e3a\u201c\u6d3b\u8dc3\u667a\u80fd\u4f53\u201d\uff0c\u76f4\u63a5\u4e0e\u7528\u6237\u5bf9\u8bdd\uff1b</li> <li>\u6700\u7ec8\u67d0\u4e2a\u667a\u80fd\u4f53\u51b3\u5b9a\u4efb\u52a1\u7ed3\u675f\u3002</li> </ul> <p>\u6b64\u6a21\u5f0f\u7279\u522b\u9002\u5408\uff1a</p> <ul> <li>\u591a\u9886\u57df\u5bf9\u8bdd\uff08\u5982\u5ba2\u670d\u63a5\u529b\uff09\uff1b</li> <li>\u591a\u9636\u6bb5\u521b\u4f5c\uff08\u5982\u89c4\u5212\u8005\u2192\u7f16\u5199\u8005\u2192\u5ba1\u9605\u8005\uff09\uff1b</li> <li>\u9ad8\u4ea4\u4e92\u6027\u5e94\u7528\uff08\u4f8b\u5982\u6a21\u62df\u4e13\u5bb6\u4f1a\u8bae\uff09\u3002</li> </ul>"},{"location":"llmapps/langchain/advanced-usage/Multi-agent/#context-engineering","title":"\u4e94\u3001\u4e0a\u4e0b\u6587\u5de5\u7a0b\uff08Context Engineering\uff09","text":"<p>\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u6027\u80fd\uff0c\u5f88\u5927\u7a0b\u5ea6\u4e0a\u53d6\u51b3\u4e8e\u4e0a\u4e0b\u6587\u8bbe\u8ba1\u2014\u2014\u5373\u51b3\u5b9a\u6bcf\u4e2a\u667a\u80fd\u4f53\u201c\u80fd\u770b\u5230\u4ec0\u4e48\u201d\u3002</p> <p>\u4f60\u53ef\u4ee5\u63a7\u5236\uff1a</p> <ul> <li>\u5404\u667a\u80fd\u4f53\u80fd\u8bbf\u95ee\u7684\u5bf9\u8bdd\u6216\u72b6\u6001\uff1b</li> <li>\u5404\u81ea\u7684\u63d0\u793a\u6a21\u677f\uff08Prompts\uff09\uff1b</li> <li>\u4e2d\u95f4\u63a8\u7406\u662f\u5426\u66b4\u9732\uff1b</li> <li>\u8f93\u5165\u4e0e\u8f93\u51fa\u7684\u683c\u5f0f\u3002</li> </ul> <p>\u4f18\u8d28\u7684\u4e0a\u4e0b\u6587\u8bbe\u8ba1\u80fd\u786e\u4fdd\u6bcf\u4e2a\u667a\u80fd\u4f53\u53ea\u5904\u7406\u81ea\u5df1\u8be5\u77e5\u9053\u7684\u4fe1\u606f\uff0c\u65e2\u80fd\u9ad8\u6548\u534f\u4f5c\uff0c\u53c8\u907f\u514d\u4fe1\u606f\u5e72\u6270\u3002</p>"},{"location":"llmapps/langchain/advanced-usage/Multi-agent/#_9","title":"\u516d\u3001\u6a21\u5f0f\u9009\u62e9\u6307\u5357","text":"\u95ee\u9898 Tool Calling Handoffs \u9700\u8981\u96c6\u4e2d\u63a7\u5236\u6d41\u7a0b\uff1f \u2705 \u662f \u274c \u5426 \u5e0c\u671b\u5b50\u667a\u80fd\u4f53\u76f4\u63a5\u4e0e\u7528\u6237\u5bf9\u8bdd\uff1f \u274c \u5426 \u2705 \u662f \u60f3\u5b9e\u73b0\u4e13\u5bb6\u95f4\u7684\u4eba\u7c7b\u5f0f\u4ea4\u4e92\uff1f \u274c \u6709\u9650 \u2705 \u5f3a"},{"location":"llmapps/langchain/advanced-usage/Multi-agent/#_10","title":"\u4e03\u3001\u603b\u7ed3","text":"<p>\u591a\u667a\u80fd\u4f53\u67b6\u6784\u7684\u7cbe\u9ad3\u5728\u4e8e\uff1a</p> <p>\u628a\u201c\u667a\u80fd\u201d\u62c6\u5206\u6210\u534f\u4f5c\u7f51\u7edc\uff0c\u800c\u4e0d\u662f\u5806\u53e0\u5728\u4e00\u4e2a\u5355\u4f53\u6a21\u578b\u91cc\u3002</p> <p>\u5728\u5b9e\u9645\u7cfb\u7edf\u4e2d\uff0c\u4f60\u53ef\u4ee5\uff1a</p> <ul> <li>\u4f7f\u7528 Tool Calling \u5b9e\u73b0\u4efb\u52a1\u81ea\u52a8\u5316\uff1b</li> <li>\u4f7f\u7528 Handoffs \u6784\u5efa\u591a\u4e13\u5bb6\u4e92\u52a8\u7cfb\u7edf\uff1b</li> <li>\u6df7\u5408\u4e24\u8005\uff0c\u521b\u9020\u4e00\u4e2a\u771f\u6b63\u7684\u534f\u4f5c\u667a\u80fd\u751f\u6001\u3002</li> </ul> <p>\u4e0b\u4e00\u4e2a\u53ef\u4ee5\u63a2\u7d22\u7684\u65b9\u5411\u662f\uff1a \u5b66\u4e60\u5982\u4f55\u5b9e\u73b0\u4e00\u4e2a Supervisor Agent\uff08\u76d1\u7763\u8005\u667a\u80fd\u4f53\uff09 \u2014\u2014\u5b83\u80fd\u534f\u8c03\u591a\u4e2a\u5b50\u667a\u80fd\u4f53\uff08\u5982\u90ae\u4ef6\u52a9\u624b\u3001\u65e5\u7a0b\u52a9\u624b\uff09\uff0c\u5e76\u5728\u654f\u611f\u64cd\u4f5c\u4e2d\u8bf7\u6c42\u4eba\u5de5\u786e\u8ba4\uff0c\u5b9e\u73b0\u201c\u4eba\u673a\u5171\u7ba1\u201d\u7684\u6df7\u5408\u7cfb\u7edf\u3002</p>"},{"location":"llmapps/langchain/advanced-usage/Retrieval/","title":"\ud83d\udcda LangChain \u68c0\u7d22\u4e0e RAG \u6559\u7a0b","text":"<p>\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u867d\u7136\u5f3a\u5927\uff0c\u4f46\u5b83\u4eec\u5929\u7136\u6709\u4e24\u4e2a\u9650\u5236\uff1a</p> <ol> <li>\u4e0a\u4e0b\u6587\u6709\u9650\uff08Finite context\uff09 \u2014\u2014 \u6a21\u578b\u4e00\u6b21\u80fd\u201c\u770b\u201d\u7684\u6587\u672c\u6709\u9650\uff0c\u65e0\u6cd5\u76f4\u63a5\u8bfb\u53d6\u6574\u4e2a\u77e5\u8bc6\u5e93\u3002</li> <li>\u77e5\u8bc6\u9759\u6001\uff08Static knowledge\uff09 \u2014\u2014 \u6a21\u578b\u7684\u8bad\u7ec3\u6570\u636e\u5728\u67d0\u4e2a\u65f6\u95f4\u70b9\u88ab\u51bb\u7ed3\uff0c\u65e0\u6cd5\u611f\u77e5\u4e4b\u540e\u7684\u65b0\u4fe1\u606f\u3002</li> </ol> <p>\u68c0\u7d22\uff08Retrieval\uff09 \u6280\u672f\u6b63\u662f\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e24\u70b9\uff0c\u5b83\u5141\u8bb8\u6a21\u578b\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u5b9e\u65f6\u67e5\u8be2\u5916\u90e8\u77e5\u8bc6\uff0c\u4ece\u800c\u83b7\u53d6\u66f4\u51c6\u786e\u3001\u66f4\u5b9e\u65f6\u3001\u66f4\u53ef\u63a7\u7684\u7b54\u6848\u3002 \u8fd9\u662f RAG\uff08Retrieval-Augmented Generation\uff09 \u7684\u7406\u8bba\u57fa\u7840\u3002</p>"},{"location":"llmapps/langchain/advanced-usage/Retrieval/#rag","title":"\u4e00\u3001\u4ece\u68c0\u7d22\u5230 RAG\uff1a\u601d\u7ef4\u7684\u8f6c\u53d8","text":"<p>\u4f20\u7edf LLM \u662f\u201c\u95ed\u5377\u8003\u8bd5\u201d\u2014\u2014\u5b83\u53ea\u80fd\u9760\u8bad\u7ec3\u65f6\u5b66\u5230\u7684\u77e5\u8bc6\u56de\u7b54\u95ee\u9898\u3002 RAG \u5219\u8ba9\u5b83\u201c\u5f00\u5377\u8003\u8bd5\u201d\u2014\u2014\u5728\u56de\u7b54\u95ee\u9898\u524d\uff0c\u5148\u53bb\u77e5\u8bc6\u5e93\u91cc\u67e5\u627e\u76f8\u5173\u5185\u5bb9\u3002</p> <p>\u6d41\u7a0b\u5982\u4e0b\uff1a</p> <p></p> <p>RAG \u7684\u6838\u5fc3\u7406\u5ff5\u662f\uff1a</p> <p>\u68c0\u7d22\uff08Retrieve\uff09\u76f8\u5173\u77e5\u8bc6 + \u751f\u6210\uff08Generate\uff09\u6574\u5408\u6027\u7b54\u6848 = \u53ef\u89e3\u91ca\u4e14\u52a8\u6001\u7684\u667a\u80fd\u7cfb\u7edf</p>"},{"location":"llmapps/langchain/advanced-usage/Retrieval/#knowledge-base","title":"\u4e8c\u3001\u6784\u5efa\u77e5\u8bc6\u5e93\uff08Knowledge Base\uff09","text":"<p>\u77e5\u8bc6\u5e93\u662f\u68c0\u7d22\u7cfb\u7edf\u7684\u57fa\u7840\uff0c\u7528\u4e8e\u5b58\u50a8\u4f60\u5e0c\u671b LLM \u80fd\u201c\u67e5\u9605\u201d\u7684\u5185\u5bb9\u3002\u5b83\u53ef\u4ee5\u6765\u6e90\u4e8e\uff1a</p> <ul> <li>\u5185\u90e8\u6587\u6863\u3001Wiki\u3001\u624b\u518c</li> <li>\u6570\u636e\u5e93\uff08SQL/CRM\uff09</li> <li>\u6587\u4ef6\u7cfb\u7edf\uff08PDF\u3001Markdown\u3001HTML\uff09</li> <li>Web \u9875\u9762\u6216 API</li> </ul> <p>\u5982\u679c\u4f60\u5df2\u7ecf\u6709\u77e5\u8bc6\u7cfb\u7edf\uff08\u5982 CRM\u3001\u6570\u636e\u5e93\uff09\uff0c\u53ef\u4ee5\u76f4\u63a5\u5c06\u5176\u4f5c\u4e3a\u68c0\u7d22\u5de5\u5177\u63a5\u5165\uff1b \u5426\u5219\uff0c\u5c31\u53ef\u4ee5\u7528 LangChain \u81ea\u5e26\u7684\u5de5\u5177\u4ece\u96f6\u6784\u5efa\u4e00\u4e2a\u3002</p>"},{"location":"llmapps/langchain/advanced-usage/Retrieval/#_1","title":"\u6838\u5fc3\u7ec4\u4ef6","text":"\u6a21\u5757 \u529f\u80fd \u793a\u4f8b Document Loaders \u52a0\u8f7d\u5916\u90e8\u6570\u636e\u6e90 Google Drive\u3001Notion\u3001Slack Text Splitters \u5c06\u957f\u6587\u6863\u5207\u6210\u5c0f\u5757 \u6309\u6bb5\u843d\u6216\u5b57\u7b26\u6570\u5207\u5206 Embedding Models \u628a\u6587\u672c\u8f6c\u4e3a\u5411\u91cf OpenAI\u3001Cohere\u3001SentenceTransformers Vector Stores \u5b58\u50a8\u548c\u641c\u7d22\u5411\u91cf FAISS\u3001Pinecone\u3001Milvus Retrievers \u6839\u636e\u67e5\u8be2\u5411\u91cf\u8fd4\u56de\u76f8\u4f3c\u5185\u5bb9 \u5411\u91cf\u68c0\u7d22\u3001\u6df7\u5408\u68c0\u7d22"},{"location":"llmapps/langchain/advanced-usage/Retrieval/#rag_1","title":"\u4e09\u3001RAG \u7684\u4e09\u79cd\u5178\u578b\u67b6\u6784","text":"<p>RAG \u4e0d\u662f\u5355\u4e00\u7ed3\u6784\uff0c\u800c\u662f\u4e00\u7cfb\u5217\u53ef\u7ec4\u5408\u7684\u6a21\u5f0f\u3002LangChain \u5c06\u5176\u5206\u4e3a\u4e09\u79cd\u4e3b\u8981\u5f62\u5f0f\uff1a</p> \u67b6\u6784\u7c7b\u578b \u7279\u70b9 \u63a7\u5236\u6743 \u7075\u6d3b\u5ea6 \u5ef6\u8fdf \u9002\u7528\u573a\u666f 2-Step RAG \u56fa\u5b9a\u4e24\u6b65\uff1a\u5148\u68c0\u7d22\u518d\u751f\u6210 \u2705 \u9ad8 \u274c \u4f4e \u26a1 \u5feb FAQ\u3001\u6587\u6863\u95ee\u7b54 Agentic RAG \u667a\u80fd\u4f53\u81ea\u4e3b\u51b3\u5b9a\u4f55\u65f6\u68c0\u7d22 \u274c \u4f4e \u2705 \u9ad8 \u23f3 \u53d8\u5316 \u7814\u7a76\u52a9\u7406\u3001\u591a\u5de5\u5177\u7cfb\u7edf Hybrid RAG \u6df7\u5408\u7ed3\u6784 + \u9a8c\u8bc1\u4e0e\u53cd\u9988\u673a\u5236 \u2696\ufe0f \u4e2d \u2696\ufe0f \u4e2d \u23f3 \u4e2d \u9ad8\u8d28\u91cf\u95ee\u7b54\u3001\u9886\u57df\u77e5\u8bc6\u7cfb\u7edf"},{"location":"llmapps/langchain/advanced-usage/Retrieval/#2-step-rag","title":"\u56db\u30012-Step RAG\uff1a\u56fa\u5b9a\u6d41\u7a0b\u7684\u9ad8\u6548\u65b9\u6848","text":"<p>\u5728 2-Step RAG \u4e2d\uff0c\u7cfb\u7edf\u603b\u662f\u6309\u7167\u56fa\u5b9a\u987a\u5e8f\u8fd0\u884c\uff1a</p> <ol> <li>\u68c0\u7d22\u9636\u6bb5\uff1a\u6839\u636e\u7528\u6237\u95ee\u9898\uff0c\u4ece\u77e5\u8bc6\u5e93\u4e2d\u627e\u51fa\u6700\u76f8\u5173\u7684\u5185\u5bb9\u3002</li> <li>\u751f\u6210\u9636\u6bb5\uff1a\u5c06\u8fd9\u4e9b\u5185\u5bb9\u4f5c\u4e3a\u4e0a\u4e0b\u6587\u8f93\u5165\u7ed9 LLM\uff0c\u8ba9\u5b83\u636e\u6b64\u751f\u6210\u7b54\u6848\u3002</li> </ol> <p></p> <p>\u793a\u4f8b\uff08\u4f2a\u4ee3\u7801\uff09\uff1a</p> <pre><code>from langchain.chains import RetrievalQA\nfrom langchain.vectorstores import FAISS\nfrom langchain.embeddings import OpenAIEmbeddings\nfrom langchain.llms import OpenAI\n\n# 1. \u6784\u5efa\u77e5\u8bc6\u5411\u91cf\u5e93\nvectorstore = FAISS.from_texts(\n    [\"LangChain \u662f\u4e00\u4e2a\u5f00\u53d1\u6846\u67b6...\", \"RAG \u7528\u4e8e\u589e\u5f3a\u6a21\u578b...\"],\n    embedding=OpenAIEmbeddings()\n)\n\n# 2. \u521b\u5efa\u68c0\u7d22\u5668\nretriever = vectorstore.as_retriever()\n\n# 3. \u6784\u5efa RAG QA \u94fe\nqa = RetrievalQA.from_chain_type(\n    llm=OpenAI(),\n    retriever=retriever,\n    return_source_documents=True\n)\n\n# 4. \u8fd0\u884c\u67e5\u8be2\nresult = qa(\"LangChain \u7684\u4f5c\u7528\u662f\u4ec0\u4e48\uff1f\")\nprint(result[\"result\"])\n</code></pre> <p>\u4f18\u70b9\uff1a</p> <ul> <li>\u53ef\u9884\u6d4b\u3001\u7b80\u5355\u3001\u5ef6\u8fdf\u4f4e\uff1b</li> <li>\u53ea\u9700\u4e00\u6b21 LLM \u8c03\u7528\uff1b</li> <li>\u9002\u5408\u95ee\u7b54\u3001\u6587\u6863\u67e5\u8be2\u3001\u804a\u5929\u673a\u5668\u4eba\u3002</li> </ul>"},{"location":"llmapps/langchain/advanced-usage/Retrieval/#agentic-rag","title":"\u4e94\u3001Agentic RAG\uff1a\u8ba9\u667a\u80fd\u4f53\u81ea\u4e3b\u51b3\u5b9a\u201c\u4f55\u65f6\u68c0\u7d22\u201d","text":"<p>Agentic RAG \u662f\u4e00\u4e2a\u5e26\u6709\u51b3\u7b56\u80fd\u529b\u7684\u7cfb\u7edf\u3002 LLM \u4e0d\u518d\u88ab\u52a8\u5730\u63a5\u6536\u68c0\u7d22\u7ed3\u679c\uff0c\u800c\u662f\u80fd\u63a8\u7406\u3001\u5224\u65ad\u662f\u5426\u9700\u8981\u68c0\u7d22\uff0c\u751a\u81f3\u9009\u62e9\u4f7f\u7528\u54ea\u4e2a\u5de5\u5177\u6765\u67e5\u627e\u4fe1\u606f\u3002</p> <p></p> <p>\u4f8b\u5982\uff0c\u4e00\u4e2a\u7814\u7a76\u52a9\u7406\u667a\u80fd\u4f53\u53ef\u4ee5\u5224\u65ad\uff1a</p> <p>\u201c\u8fd9\u4e2a\u95ee\u9898\u6d89\u53ca\u5b9e\u65f6\u6570\u636e\uff0c\u6211\u9700\u8981\u5148\u53bb\u67e5\u4e00\u4e0b\u6700\u65b0\u7f51\u9875\u3002\u201d</p> <p>\u5b9e\u73b0\u793a\u4f8b\uff1a</p> <pre><code>import requests\nfrom langchain.tools import tool\nfrom langchain.chat_models import init_chat_model\nfrom langchain.agents import create_agent\n\n@tool\ndef fetch_url(url: str) -&gt; str:\n    \"\"\"\u4ece\u7f51\u9875\u6293\u53d6\u6587\u672c\u5185\u5bb9\"\"\"\n    response = requests.get(url, timeout=10)\n    response.raise_for_status()\n    return response.text\n\nsystem_prompt = \"\"\"\\\n\u5f53\u9700\u8981\u6700\u65b0\u4fe1\u606f\u65f6\uff0c\u8bf7\u4f7f\u7528 fetch_url \u5de5\u5177\u4ece\u7f51\u9875\u83b7\u53d6\u5185\u5bb9\u3002\n\u5f15\u7528\u76f8\u5173\u7247\u6bb5\u540e\u56de\u7b54\u7528\u6237\u3002\n\"\"\"\n\nagent = create_agent(\n    model=\"gpt-4\",\n    tools=[fetch_url],\n    system_prompt=system_prompt,\n)\n</code></pre> <p>\u8fd9\u79cd\u65b9\u5f0f\u8ba9\u6a21\u578b\u5177\u5907\u81ea\u4e3b\u4fe1\u606f\u641c\u96c6\u80fd\u529b\uff0c\u53ef\u52a8\u6001\u5e94\u5bf9\u4e0d\u786e\u5b9a\u7684\u4efb\u52a1\u573a\u666f\u3002</p>"},{"location":"llmapps/langchain/advanced-usage/Retrieval/#hybrid-rag","title":"\u516d\u3001Hybrid RAG\uff1a\u6df7\u5408\u7ed3\u6784\u4e0e\u81ea\u6821\u6b63\u673a\u5236","text":"<p>Hybrid RAG\uff08\u6df7\u5408\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff09 \u878d\u5408\u4e86\u4e24\u8005\u7684\u4f18\u52bf\uff1a \u65e2\u6709\u56fa\u5b9a\u6d41\u7a0b\u7684\u7a33\u5b9a\u6027\uff0c\u4e5f\u80fd\u5f15\u5165\u667a\u80fd\u4f53\u7684\u7075\u6d3b\u5224\u65ad\u3002</p> <p>\u5b83\u901a\u5e38\u5305\u62ec\uff1a</p> <ul> <li>\u67e5\u8be2\u589e\u5f3a\uff1a\u91cd\u5199\u7528\u6237\u95ee\u9898\uff0c\u63d0\u9ad8\u68c0\u7d22\u76f8\u5173\u5ea6\u3002</li> <li>\u68c0\u7d22\u9a8c\u8bc1\uff1a\u8bc4\u4f30\u68c0\u7d22\u7ed3\u679c\u662f\u5426\u8db3\u591f\u76f8\u5173\u3002</li> <li>\u7b54\u6848\u9a8c\u8bc1\uff1a\u68c0\u67e5\u751f\u6210\u7684\u7b54\u6848\u662f\u5426\u4e0e\u6587\u6863\u4e00\u81f4\u3002</li> <li>\u5faa\u73af\u6539\u8fdb\uff1a\u82e5\u4e0d\u6ee1\u8db3\u6761\u4ef6\uff0c\u81ea\u52a8\u91cd\u8bd5\u6216\u91cd\u65b0\u68c0\u7d22\u3002</li> </ul> <p>\u6d41\u7a0b\u5982\u4e0b\uff1a</p> <p></p> <p>\u5e94\u7528\u793a\u4f8b\uff1a</p> <ul> <li>\u533b\u7597\u3001\u91d1\u878d\u7b49\u9886\u57df\u9700\u8981\u7ed3\u679c\u9a8c\u8bc1\u7684\u95ee\u7b54\u7cfb\u7edf\uff1b</li> <li>\u591a\u6570\u636e\u6e90\u6574\u5408\u7cfb\u7edf\uff1b</li> <li>\u9700\u8981\u591a\u8f6e\u81ea\u4fee\u6b63\u7684\u667a\u80fd\u52a9\u624b\u3002</li> </ul>"},{"location":"llmapps/langchain/advanced-usage/Retrieval/#rag_2","title":"\u4e03\u3001RAG \u7684\u5ef6\u8fdf\u4e0e\u6027\u80fd\u8003\u91cf","text":"<ul> <li>2-Step RAG \u5ef6\u8fdf\u6700\u53ef\u63a7\uff08\u4e00\u6b21 LLM \u8c03\u7528\u5373\u53ef\uff09\u3002</li> <li>Agentic RAG / Hybrid RAG \u5ef6\u8fdf\u4e0d\u56fa\u5b9a\uff08\u53d6\u51b3\u4e8e\u51b3\u7b56\u4e0e\u68c0\u7d22\u6b21\u6570\uff09\u3002</li> <li>\u771f\u5b9e\u7cfb\u7edf\u4e2d\uff0c\u7f51\u7edc\u5ef6\u8fdf\u3001\u6570\u636e\u5e93\u54cd\u5e94\u65f6\u95f4\u7b49\u4e5f\u4f1a\u663e\u8457\u5f71\u54cd\u603b\u8017\u65f6\u3002</li> </ul> <p>\u5728\u90e8\u7f72\u65f6\uff0c\u5e94\u6839\u636e\u4e1a\u52a1\u4f18\u5148\u7ea7\u9009\u62e9\u5e73\u8861\u70b9\uff1a</p> <ul> <li>\u5feb\u901f\u54cd\u5e94 \u2192 \u7528 2-Step\uff1b</li> <li>\u667a\u80fd\u4e0e\u7075\u6d3b \u2192 \u7528 Agentic\uff1b</li> <li>\u8d28\u91cf\u4e0e\u7a33\u5b9a\u5e76\u91cd \u2192 \u7528 Hybrid\u3002</li> </ul>"},{"location":"llmapps/langchain/advanced-usage/Retrieval/#_2","title":"\u516b\u3001\u603b\u7ed3\uff1a\u8ba9\u6a21\u578b\u201c\u77e5\u9053\u81ea\u5df1\u4e0d\u77e5\u9053\u201d","text":"<p>RAG \u4ee3\u8868\u4e86\u4ece\u5c01\u95ed\u8bed\u8a00\u6a21\u578b\u5411\u77e5\u8bc6\u9a71\u52a8\u578b\u667a\u80fd\u7cfb\u7edf\u7684\u8dc3\u8fc1\u3002 \u5b83\u8ba9\u6a21\u578b\u5728\u63a8\u7406\u65f6\u80fd\u4e3b\u52a8\u201c\u67e5\u9605\u8d44\u6599\u201d\uff0c\u5728\u4e8b\u5b9e\u5c42\u9762\u4e0a\u66f4\u52a0\u53ef\u9760\u3002</p> <p>RAG \u67b6\u6784\u4e0d\u662f\u7ec8\u70b9\uff0c\u800c\u662f\u57fa\u7840\uff1a</p> <ul> <li>\u4f60\u53ef\u4ee5\u5728\u5176\u4e0a\u6784\u5efa\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff1b</li> <li>\u7ed3\u5408\u8bb0\u5fc6\u3001\u63a8\u7406\u3001\u89c4\u5212\uff1b</li> <li>\u6700\u7ec8\u6253\u9020\u5177\u5907\u81ea\u6211\u5b66\u4e60\u4e0e\u9a8c\u8bc1\u80fd\u529b\u7684\u667a\u80fd\u4f53\u3002</li> </ul> <p>\u63a5\u4e0b\u6765\u53ef\u4ee5\u5b66\u4e60\u5982\u4f55\u4f7f\u7528 LangChain \u7684 <code>RetrievalQA</code> \u6216 Agentic RAG \u6846\u67b6\u6765\u5b9e\u73b0\u4e00\u4e2a\u57fa\u4e8e\u4f60\u81ea\u5df1\u77e5\u8bc6\u5e93\u7684\u804a\u5929\u673a\u5668\u4eba\uff0c\u5b9e\u73b0\u771f\u6b63\u7684\u201c\u4f1a\u67e5\u8d44\u6599\u7684 AI \u52a9\u7406\u201d\u3002</p>"},{"location":"llmapps/langchain/advanced-usage/Runtime/","title":"LangChain Runtime \u4f7f\u7528\u6559\u7a0b","text":""},{"location":"llmapps/langchain/advanced-usage/Runtime/#_1","title":"\u6982\u8ff0","text":"<p>LangChain \u7684 <code>create_agent</code> \u5728\u5e95\u5c42\u8fd0\u884c\u5728 LangGraph \u7684 Runtime \u4e4b\u4e0a\u3002</p> <p>LangGraph \u66b4\u9732\u4e86\u4e00\u4e2a Runtime \u5bf9\u8c61\uff0c\u5305\u542b\u4ee5\u4e0b\u4fe1\u606f\uff1a</p> <ol> <li>Context\uff1a\u9759\u6001\u4fe1\u606f\uff0c\u5982\u7528\u6237 ID\u3001\u6570\u636e\u5e93\u8fde\u63a5\u6216\u5176\u4ed6\u4ee3\u7406\u8c03\u7528\u4f9d\u8d56\u9879</li> <li>Store\uff1a\u7528\u4e8e[\u957f\u671f\u8bb0\u5fc6]\u7684 BaseStore \u5b9e\u4f8b</li> <li>Stream writer\uff1a\u901a\u8fc7 <code>\"custom\"</code> \u6d41\u6a21\u5f0f\u6d41\u5f0f\u4f20\u8f93\u4fe1\u606f\u7684\u5bf9\u8c61</li> </ol>"},{"location":"llmapps/langchain/advanced-usage/Runtime/#_2","title":"\u57fa\u672c\u7528\u6cd5","text":""},{"location":"llmapps/langchain/advanced-usage/Runtime/#context-schema","title":"\u5b9a\u4e49 Context Schema","text":"<p>\u4f7f\u7528 <code>create_agent</code> \u521b\u5efa\u4ee3\u7406\u65f6\uff0c\u53ef\u4ee5\u6307\u5b9a <code>context_schema</code> \u6765\u5b9a\u4e49\u5b58\u50a8\u5728\u4ee3\u7406 Runtime \u4e2d\u7684 <code>context</code> \u7ed3\u6784\u3002</p> <p>\u8c03\u7528\u4ee3\u7406\u65f6\uff0c\u4f20\u9012\u5e26\u6709\u76f8\u5173\u914d\u7f6e\u7684 <code>context</code> \u53c2\u6570\uff1a</p> <pre><code>from dataclasses import dataclass\nfrom langchain.agents import create_agent\n\n@dataclass\nclass Context:\n    user_name: str\n\nagent = create_agent(\n    model=\"openai:gpt-5-nano\",\n    tools=[...],\n    context_schema=Context  # \u5b9a\u4e49 context \u7ed3\u6784\n)\n\n# \u8c03\u7528\u65f6\u4f20\u9012 context\nagent.invoke(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"What's my name?\"}]},\n    context=Context(user_name=\"John Smith\")  # \u8bbe\u7f6e\u5177\u4f53 context \u503c\n)\n</code></pre>"},{"location":"llmapps/langchain/advanced-usage/Runtime/#runtime","title":"\u5728\u5de5\u5177\u4e2d\u8bbf\u95ee Runtime","text":"<p>\u4f60\u53ef\u4ee5\u5728\u5de5\u5177\u5185\u90e8\u8bbf\u95ee Runtime \u4fe1\u606f\u6765\uff1a</p> <ul> <li>\u8bbf\u95ee context</li> <li>\u8bfb\u53d6\u6216\u5199\u5165\u957f\u671f\u8bb0\u5fc6</li> <li>\u5199\u5165[\u81ea\u5b9a\u4e49\u6d41]\uff08\u4f8b\u5982\u5de5\u5177\u8fdb\u5ea6/\u66f4\u65b0\uff09</li> </ul> <p>\u4f7f\u7528 <code>ToolRuntime</code> \u53c2\u6570\u5728\u5de5\u5177\u5185\u90e8\u8bbf\u95ee Runtime \u5bf9\u8c61\u3002</p>"},{"location":"llmapps/langchain/advanced-usage/Runtime/#_3","title":"\u793a\u4f8b\uff1a\u8bbf\u95ee\u7528\u6237\u4fe1\u606f\u548c\u957f\u671f\u8bb0\u5fc6","text":"<pre><code>from dataclasses import dataclass\nfrom langchain.tools import tool, ToolRuntime\n\n@dataclass\nclass Context:\n    user_id: str\n\n@tool\ndef fetch_user_email_preferences(runtime: ToolRuntime[Context]) -&gt; str:\n    \"\"\"\u4ece\u5b58\u50a8\u4e2d\u83b7\u53d6\u7528\u6237\u7684\u7535\u5b50\u90ae\u4ef6\u504f\u597d\u8bbe\u7f6e\u3002\"\"\"\n    # \u8bbf\u95ee context \u4e2d\u7684\u7528\u6237 ID\n    user_id = runtime.context.user_id\n\n    # \u9ed8\u8ba4\u504f\u597d\u8bbe\u7f6e\n    preferences: str = \"\u7528\u6237\u504f\u597d\u7b80\u6d01\u793c\u8c8c\u7684\u7535\u5b50\u90ae\u4ef6\u3002\"\n\n    # \u5982\u679c\u5b58\u5728\u5b58\u50a8\uff0c\u5c1d\u8bd5\u4ece\u957f\u671f\u8bb0\u5fc6\u4e2d\u83b7\u53d6\u7528\u6237\u504f\u597d\n    if runtime.store:\n        # \u4ece\u5b58\u50a8\u4e2d\u83b7\u53d6\u7528\u6237\u8bb0\u5fc6\n        memory = runtime.store.get((\"users\",), user_id)\n        if memory:\n            preferences = memory.value[\"preferences\"]\n\n    return preferences\n</code></pre>"},{"location":"llmapps/langchain/advanced-usage/Runtime/#_4","title":"\u793a\u4f8b\uff1a\u5199\u5165\u81ea\u5b9a\u4e49\u6d41\u548c\u5b58\u50a8","text":"<pre><code>from langchain.tools import tool, ToolRuntime\n\n@tool\ndef process_user_data(runtime: ToolRuntime[Context]) -&gt; str:\n    \"\"\"\u5904\u7406\u7528\u6237\u6570\u636e\u5e76\u66f4\u65b0\u8fdb\u5ea6\u3002\"\"\"\n    user_id = runtime.context.user_id\n\n    # \u5411\u81ea\u5b9a\u4e49\u6d41\u5199\u5165\u8fdb\u5ea6\u66f4\u65b0\n    if runtime.stream_writer:\n        runtime.stream_writer.send({\n            \"type\": \"progress\",\n            \"message\": \"\u5f00\u59cb\u5904\u7406\u7528\u6237\u6570\u636e...\",\n            \"user_id\": user_id\n        })\n\n    # \u6a21\u62df\u6570\u636e\u5904\u7406\n    processed_data = f\"\u5df2\u5904\u7406\u7528\u6237 {user_id} \u7684\u6570\u636e\"\n\n    # \u5c06\u7ed3\u679c\u4fdd\u5b58\u5230\u957f\u671f\u8bb0\u5fc6\n    if runtime.store:\n        runtime.store.set(\n            (\"processed_data\",), \n            user_id, \n            {\"data\": processed_data, \"timestamp\": \"2024-01-01\"}\n        )\n\n    # \u53d1\u9001\u5b8c\u6210\u901a\u77e5\n    if runtime.stream_writer:\n        runtime.stream_writer.send({\n            \"type\": \"progress\", \n            \"message\": \"\u7528\u6237\u6570\u636e\u5904\u7406\u5b8c\u6210\",\n            \"user_id\": user_id\n        })\n\n    return processed_data\n</code></pre>"},{"location":"llmapps/langchain/advanced-usage/Runtime/#runtime_1","title":"\u5728\u4e2d\u95f4\u4ef6\u4e2d\u8bbf\u95ee Runtime","text":"<p>\u4f60\u53ef\u4ee5\u5728\u4e2d\u95f4\u4ef6\u4e2d\u8bbf\u95ee Runtime \u4fe1\u606f\u6765\u521b\u5efa\u52a8\u6001\u63d0\u793a\u3001\u4fee\u6539\u6d88\u606f\u6216\u57fa\u4e8e\u7528\u6237\u4e0a\u4e0b\u6587\u63a7\u5236\u4ee3\u7406\u884c\u4e3a\u3002</p> <p>\u4f7f\u7528 <code>request.runtime</code> \u5728\u4e2d\u95f4\u4ef6\u88c5\u9970\u5668\u5185\u90e8\u8bbf\u95ee Runtime \u5bf9\u8c61\u3002Runtime \u5bf9\u8c61\u5728\u4f20\u9012\u7ed9\u4e2d\u95f4\u4ef6\u51fd\u6570\u7684 <code>ModelRequest</code> \u53c2\u6570\u4e2d\u53ef\u7528\u3002</p>"},{"location":"llmapps/langchain/advanced-usage/Runtime/#_5","title":"\u52a8\u6001\u63d0\u793a\u793a\u4f8b","text":"<pre><code>from dataclasses import dataclass\nfrom langchain.agents import create_agent\nfrom langchain.agents.middleware import dynamic_prompt, ModelRequest\n\n@dataclass\nclass Context:\n    user_name: str\n    user_role: str\n\n# \u52a8\u6001\u7cfb\u7edf\u63d0\u793a\n@dynamic_prompt\ndef dynamic_system_prompt(request: ModelRequest) -&gt; str:\n    user_name = request.runtime.context.user_name\n    user_role = request.runtime.context.user_role\n\n    # \u57fa\u4e8e\u7528\u6237\u89d2\u8272\u5b9a\u5236\u7cfb\u7edf\u63d0\u793a\n    if user_role == \"admin\":\n        system_prompt = f\"\u4f60\u662f\u7ba1\u7406\u5458 {user_name} \u7684\u52a9\u624b\u3002\u4f60\u53ef\u4ee5\u8bbf\u95ee\u6240\u6709\u7cfb\u7edf\u529f\u80fd\u3002\"\n    elif user_role == \"customer\":\n        system_prompt = f\"\u4f60\u662f\u5ba2\u6237 {user_name} \u7684\u52a9\u624b\u3002\u8bf7\u63d0\u4f9b\u53cb\u597d\u7684\u5ba2\u6237\u670d\u52a1\u3002\"\n    else:\n        system_prompt = f\"\u4f60\u662f {user_name} \u7684\u52a9\u624b\u3002\u8bf7\u63d0\u4f9b\u6709\u5e2e\u52a9\u7684\u56de\u7b54\u3002\"\n\n    return system_prompt\n</code></pre>"},{"location":"llmapps/langchain/advanced-usage/Runtime/#beforeafter-model","title":"Before/After Model \u94a9\u5b50\u793a\u4f8b","text":"<pre><code>from dataclasses import dataclass\nfrom langchain.agents import create_agent, AgentState\nfrom langchain.agents.middleware import before_model, after_model\nfrom langgraph.runtime import Runtime\n\n@dataclass\nclass Context:\n    user_name: str\n    session_id: str\n\n# Before model \u94a9\u5b50 - \u6a21\u578b\u8c03\u7528\u524d\u6267\u884c\n@before_model\ndef log_before_model(state: AgentState, runtime: Runtime[Context]) -&gt; dict | None:\n    user_name = runtime.context.user_name\n    session_id = runtime.context.session_id\n\n    print(f\"\u4e3a\u7528\u6237 {user_name} \u5904\u7406\u8bf7\u6c42 (\u4f1a\u8bdd: {session_id})\")\n\n    # \u53ef\u4ee5\u5728\u6b64\u4fee\u6539\u72b6\u6001\u6216\u6dfb\u52a0\u9a8c\u8bc1\n    return None\n\n# After model \u94a9\u5b50 - \u6a21\u578b\u8c03\u7528\u540e\u6267\u884c\n@after_model\ndef log_after_model(state: AgentState, runtime: Runtime[Context]) -&gt; dict | None:\n    user_name = runtime.context.user_name\n    session_id = runtime.context.session_id\n\n    print(f\"\u5b8c\u6210\u7528\u6237 {user_name} \u7684\u8bf7\u6c42 (\u4f1a\u8bdd: {session_id})\")\n\n    # \u8bb0\u5f55\u5230\u957f\u671f\u8bb0\u5fc6\n    if runtime.store and state[\"messages\"]:\n        last_message = state[\"messages\"][-1]\n        runtime.store.set(\n            (\"conversations\",), \n            session_id, \n            {\n                \"user\": user_name,\n                \"last_interaction\": str(last_message.content)[:100],\n                \"timestamp\": \"2024-01-01\"\n            }\n        )\n\n    return None\n</code></pre>"},{"location":"llmapps/langchain/advanced-usage/Runtime/#_6","title":"\u5b8c\u6574\u7684\u4ee3\u7406\u914d\u7f6e\u793a\u4f8b","text":"<pre><code>from dataclasses import dataclass\nfrom langchain.agents import create_agent, AgentState\nfrom langchain.agents.middleware import dynamic_prompt, before_model, after_model, ModelRequest\nfrom langgraph.runtime import Runtime\n\n@dataclass\nclass Context:\n    user_name: str\n    user_role: str\n    session_id: str\n    api_key: str  # \u53ef\u4ee5\u5305\u542b\u654f\u611f\u4fe1\u606f\uff0c\u5982 API \u5bc6\u94a5\n\n# \u52a8\u6001\u63d0\u793a\n@dynamic_prompt\ndef role_based_prompt(request: ModelRequest) -&gt; str:\n    context = request.runtime.context\n    base_prompt = f\"\u4f60\u6b63\u5728\u4e0e {context.user_name} ({context.user_role}) \u5bf9\u8bdd\u3002\"\n\n    if context.user_role == \"premium\":\n        base_prompt += \" \u8fd9\u662f\u5c0a\u4eab\u7528\u6237\uff0c\u8bf7\u63d0\u4f9b\u4f18\u5148\u670d\u52a1\u3002\"\n    elif context.user_role == \"trial\":\n        base_prompt += \" \u8fd9\u662f\u8bd5\u7528\u7528\u6237\uff0c\u8bf7\u53cb\u597d\u5730\u4ecb\u7ecd\u6211\u4eec\u7684\u670d\u52a1\u3002\"\n\n    return base_prompt\n\n# \u8bf7\u6c42\u9a8c\u8bc1\u4e2d\u95f4\u4ef6\n@before_model\ndef validate_request(state: AgentState, runtime: Runtime[Context]) -&gt; dict | None:\n    # \u68c0\u67e5\u5fc5\u8981\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\n    if not runtime.context.api_key:\n        return {\n            \"messages\": [{\n                \"role\": \"assistant\", \n                \"content\": \"\u8ba4\u8bc1\u4fe1\u606f\u7f3a\u5931\uff0c\u8bf7\u8054\u7cfb\u7ba1\u7406\u5458\u3002\"\n            }]\n        }\n\n    # \u53ef\u4ee5\u6dfb\u52a0\u5176\u4ed6\u9a8c\u8bc1\u903b\u8f91\n    return None\n\n# \u521b\u5efa\u914d\u7f6e\u5b8c\u6574\u7684\u4ee3\u7406\nagent = create_agent(\n    model=\"openai:gpt-5-nano\",\n    tools=[fetch_user_email_preferences, process_user_data],\n    middleware=[role_based_prompt, validate_request, log_before_model, log_after_model],\n    context_schema=Context\n)\n\n# \u4f7f\u7528\u5b8c\u6574\u4e0a\u4e0b\u6587\u8c03\u7528\u4ee3\u7406\nresult = agent.invoke(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"\u5e2e\u6211\u67e5\u770b\u6211\u7684\u8d26\u6237\u4fe1\u606f\"}]},\n    context=Context(\n        user_name=\"\u5f20\u4e09\",\n        user_role=\"premium\", \n        session_id=\"session_123\",\n        api_key=\"sk-xxx\"\n    )\n)\n</code></pre>"},{"location":"llmapps/langchain/advanced-usage/Runtime/#_7","title":"\u6700\u4f73\u5b9e\u8df5","text":""},{"location":"llmapps/langchain/advanced-usage/Runtime/#1-context-schema","title":"1. \u5408\u7406\u8bbe\u8ba1 Context Schema","text":"<pre><code>from dataclasses import dataclass\nfrom typing import Optional\n\n@dataclass\nclass AppContext:\n    user_id: str\n    user_tier: str = \"basic\"  # basic, premium, admin\n    language: str = \"zh-CN\"\n    timezone: str = \"Asia/Shanghai\"\n    permissions: list[str] = None\n\n    def __post_init__(self):\n        if self.permissions is None:\n            self.permissions = []\n</code></pre>"},{"location":"llmapps/langchain/advanced-usage/Runtime/#2","title":"2. \u9519\u8bef\u5904\u7406","text":"<pre><code>from langchain.tools import tool, ToolRuntime\n\n@tool\ndef safe_tool_operation(runtime: ToolRuntime[Context]) -&gt; str:\n    \"\"\"\u5e26\u6709\u9519\u8bef\u5904\u7406\u7684\u5de5\u5177\u793a\u4f8b\u3002\"\"\"\n    try:\n        # \u68c0\u67e5\u5fc5\u8981\u7684\u4e0a\u4e0b\u6587\n        if not hasattr(runtime.context, 'user_id'):\n            return \"\u9519\u8bef\uff1a\u7f3a\u5c11\u7528\u6237ID\"\n\n        # \u4e1a\u52a1\u903b\u8f91\n        user_id = runtime.context.user_id\n        return f\"\u5904\u7406\u7528\u6237 {user_id} \u7684\u8bf7\u6c42\"\n\n    except Exception as e:\n        # \u8bb0\u5f55\u9519\u8bef\u5230\u6d41\n        if runtime.stream_writer:\n            runtime.stream_writer.send({\n                \"type\": \"error\",\n                \"message\": f\"\u5de5\u5177\u6267\u884c\u5931\u8d25: {str(e)}\"\n            })\n        return f\"\u64cd\u4f5c\u5931\u8d25: {str(e)}\"\n</code></pre>"},{"location":"llmapps/langchain/advanced-usage/Runtime/#3","title":"3. \u6027\u80fd\u4f18\u5316","text":"<pre><code>from langchain.agents.middleware import before_model\n\n@before_model\ndef cache_check(state: AgentState, runtime: Runtime[Context]) -&gt; dict | None:\n    \"\"\"\u68c0\u67e5\u7f13\u5b58\u4ee5\u907f\u514d\u91cd\u590d\u5904\u7406\u3002\"\"\"\n    if runtime.store:\n        # \u57fa\u4e8e\u6d88\u606f\u5185\u5bb9\u751f\u6210\u7f13\u5b58\u952e\n        cache_key = hash(str(state[\"messages\"]))\n        cached_result = runtime.store.get((\"cache\",), str(cache_key))\n\n        if cached_result:\n            # \u8fd4\u56de\u7f13\u5b58\u7ed3\u679c\n            return {\n                \"messages\": [{\n                    \"role\": \"assistant\",\n                    \"content\": cached_result.value[\"response\"]\n                }]\n            }\n\n    return None\n</code></pre> <p>\u901a\u8fc7\u5408\u7406\u4f7f\u7528 Runtime \u529f\u80fd\uff0c\u4f60\u53ef\u4ee5\u521b\u5efa\u66f4\u52a0\u667a\u80fd\u3001\u4e2a\u6027\u5316\u548c\u9ad8\u6548\u7684 AI \u4ee3\u7406\u5e94\u7528\u3002</p>"},{"location":"llmapps/langchain/advanced-usage/context-engineering/","title":"\u667a\u80fd\u4f53\u4e0a\u4e0b\u6587\u5de5\u7a0b\u5b8c\u6574\u6559\u7a0b","text":""},{"location":"llmapps/langchain/advanced-usage/context-engineering/#_2","title":"\u6982\u8ff0\uff1a\u4e3a\u4ec0\u4e48\u667a\u80fd\u4f53\u4f1a\u5931\u8d25\uff1f","text":"<p>\u6784\u5efa\u667a\u80fd\u4f53\uff08\u6216\u4efb\u4f55LLM\u5e94\u7528\uff09\u7684\u96be\u70b9\u5728\u4e8e\u4f7f\u5b83\u4eec\u8db3\u591f\u53ef\u9760\u3002\u867d\u7136\u539f\u578b\u53ef\u80fd\u8fd0\u884c\u826f\u597d\uff0c\u4f46\u5728\u5b9e\u9645\u4f7f\u7528\u4e2d\u5e38\u5e38\u5931\u8d25\u3002</p>"},{"location":"llmapps/langchain/advanced-usage/context-engineering/#_3","title":"\u667a\u80fd\u4f53\u5931\u8d25\u7684\u539f\u56e0","text":"<p>\u5f53\u667a\u80fd\u4f53\u5931\u8d25\u65f6\uff0c\u901a\u5e38\u662f\u56e0\u4e3a\u5185\u90e8\u7684LLM\u8c03\u7528\u91c7\u53d6\u4e86\u9519\u8bef\u7684\u884c\u52a8/\u6ca1\u6709\u8fbe\u5230\u6211\u4eec\u7684\u9884\u671f\u3002LLM\u5931\u8d25\u6709\u4e24\u4e2a\u4e3b\u8981\u539f\u56e0\uff1a</p> <ol> <li>\u5e95\u5c42LLM\u80fd\u529b\u4e0d\u8db3</li> <li>\u6ca1\u6709\u5c06\"\u6b63\u786e\u7684\"\u4e0a\u4e0b\u6587\u4f20\u9012\u7ed9LLM</li> </ol> <p>\u66f4\u5e38\u89c1\u7684\u662f\u7b2c\u4e8c\u4e2a\u539f\u56e0\u5bfc\u81f4\u667a\u80fd\u4f53\u4e0d\u53ef\u9760\u3002</p> <p>\u4e0a\u4e0b\u6587\u5de5\u7a0b\u662f\u6307\u4ee5\u6b63\u786e\u7684\u683c\u5f0f\u63d0\u4f9b\u6b63\u786e\u7684\u4fe1\u606f\u548c\u5de5\u5177\uff0c\u4f7fLLM\u80fd\u591f\u5b8c\u6210\u4efb\u52a1\u3002\u8fd9\u662fAI\u5de5\u7a0b\u5e08\u7684\u9996\u8981\u5de5\u4f5c\u3002\u7f3a\u4e4f\"\u6b63\u786e\u7684\"\u4e0a\u4e0b\u6587\u662f\u6784\u5efa\u66f4\u53ef\u9760\u667a\u80fd\u4f53\u7684\u9996\u8981\u969c\u788d\uff0c\u800cLangChain\u7684\u667a\u80fd\u4f53\u62bd\u8c61\u8bbe\u8ba1\u72ec\u7279\uff0c\u65e8\u5728\u4fc3\u8fdb\u4e0a\u4e0b\u6587\u5de5\u7a0b\u3002</p>"},{"location":"llmapps/langchain/advanced-usage/context-engineering/#_4","title":"\u667a\u80fd\u4f53\u5faa\u73af","text":"<p>\u5178\u578b\u7684\u667a\u80fd\u4f53\u5faa\u73af\u5305\u542b\u4e24\u4e2a\u4e3b\u8981\u6b65\u9aa4\uff1a</p> <ol> <li>\u6a21\u578b\u8c03\u7528 - \u4f7f\u7528\u63d0\u793a\u548c\u53ef\u7528\u5de5\u5177\u8c03\u7528LLM\uff0c\u8fd4\u56de\u54cd\u5e94\u6216\u6267\u884c\u5de5\u5177\u7684\u8bf7\u6c42</li> <li>\u5de5\u5177\u6267\u884c - \u6267\u884cLLM\u8bf7\u6c42\u7684\u5de5\u5177\uff0c\u8fd4\u56de\u5de5\u5177\u7ed3\u679c</li> </ol> <p>\u8fd9\u4e2a\u5faa\u73af\u6301\u7eed\u8fdb\u884c\uff0c\u76f4\u5230LLM\u51b3\u5b9a\u7ed3\u675f\u3002</p>"},{"location":"llmapps/langchain/advanced-usage/context-engineering/#_5","title":"\u53ef\u63a7\u56e0\u7d20","text":"<p>\u8981\u6784\u5efa\u53ef\u9760\u7684\u667a\u80fd\u4f53\uff0c\u4f60\u9700\u8981\u63a7\u5236\u667a\u80fd\u4f53\u5faa\u73af\u6bcf\u4e00\u6b65\u53d1\u751f\u7684\u4e8b\u60c5\uff0c\u4ee5\u53ca\u6b65\u9aa4\u4e4b\u95f4\u53d1\u751f\u7684\u4e8b\u60c5\u3002</p> \u4e0a\u4e0b\u6587\u7c7b\u578b \u63a7\u5236\u5185\u5bb9 \u77ac\u6001\u6216\u6301\u4e45\u5316 \u6a21\u578b\u4e0a\u4e0b\u6587 \u6a21\u578b\u8c03\u7528\u7684\u5185\u5bb9\uff08\u6307\u4ee4\u3001\u6d88\u606f\u5386\u53f2\u3001\u5de5\u5177\u3001\u54cd\u5e94\u683c\u5f0f\uff09 \u77ac\u6001 \u5de5\u5177\u4e0a\u4e0b\u6587 \u5de5\u5177\u53ef\u4ee5\u8bbf\u95ee\u548c\u4ea7\u751f\u7684\u5185\u5bb9\uff08\u5bf9\u72b6\u6001\u3001\u5b58\u50a8\u3001\u8fd0\u884c\u65f6\u4e0a\u4e0b\u6587\u7684\u8bfb\u5199\uff09 \u6301\u4e45\u5316 \u751f\u547d\u5468\u671f\u4e0a\u4e0b\u6587 \u6a21\u578b\u548c\u5de5\u5177\u8c03\u7528\u4e4b\u95f4\u53d1\u751f\u7684\u4e8b\u60c5\uff08\u6458\u8981\u3001\u62a4\u680f\u3001\u65e5\u5fd7\u8bb0\u5f55\u7b49\uff09 \u6301\u4e45\u5316"},{"location":"llmapps/langchain/advanced-usage/context-engineering/#_6","title":"\u6570\u636e\u6e90","text":"<p>\u5728\u6574\u4e2a\u8fc7\u7a0b\u4e2d\uff0c\u4f60\u7684\u667a\u80fd\u4f53\u8bbf\u95ee\uff08\u8bfb/\u5199\uff09\u4e0d\u540c\u7684\u6570\u636e\u6e90\uff1a</p> \u6570\u636e\u6e90 \u53c8\u540d \u8303\u56f4 \u793a\u4f8b \u8fd0\u884c\u65f6\u4e0a\u4e0b\u6587 \u9759\u6001\u914d\u7f6e \u4f1a\u8bdd\u8303\u56f4 \u7528\u6237ID\u3001API\u5bc6\u94a5\u3001\u6570\u636e\u5e93\u8fde\u63a5\u3001\u6743\u9650\u3001\u73af\u5883\u8bbe\u7f6e \u72b6\u6001 \u77ed\u671f\u8bb0\u5fc6 \u4f1a\u8bdd\u8303\u56f4 \u5f53\u524d\u6d88\u606f\u3001\u4e0a\u4f20\u7684\u6587\u4ef6\u3001\u8ba4\u8bc1\u72b6\u6001\u3001\u5de5\u5177\u7ed3\u679c \u5b58\u50a8 \u957f\u671f\u8bb0\u5fc6 \u8de8\u4f1a\u8bdd \u7528\u6237\u504f\u597d\u3001\u63d0\u53d6\u7684\u89c1\u89e3\u3001\u8bb0\u5fc6\u3001\u5386\u53f2\u6570\u636e"},{"location":"llmapps/langchain/advanced-usage/context-engineering/#_7","title":"\u6a21\u578b\u4e0a\u4e0b\u6587","text":"<p>\u63a7\u5236\u6bcf\u6b21\u6a21\u578b\u8c03\u7528\u7684\u5185\u5bb9 - \u6307\u4ee4\u3001\u53ef\u7528\u5de5\u5177\u3001\u4f7f\u7528\u54ea\u4e2a\u6a21\u578b\u4ee5\u53ca\u8f93\u51fa\u683c\u5f0f\u3002\u8fd9\u4e9b\u51b3\u7b56\u76f4\u63a5\u5f71\u54cd\u53ef\u9760\u6027\u548c\u6210\u672c\u3002</p>"},{"location":"llmapps/langchain/advanced-usage/context-engineering/#_8","title":"\u7cfb\u7edf\u63d0\u793a","text":"<p>\u7cfb\u7edf\u63d0\u793a\u8bbe\u7f6eLLM\u7684\u884c\u4e3a\u548c\u80fd\u529b\u3002\u4e0d\u540c\u7684\u7528\u6237\u3001\u4e0a\u4e0b\u6587\u6216\u5bf9\u8bdd\u9636\u6bb5\u9700\u8981\u4e0d\u540c\u7684\u6307\u4ee4\u3002</p> <p>\u57fa\u4e8e\u72b6\u6001\u7684\u52a8\u6001\u63d0\u793a</p> <pre><code>from langchain.agents import create_agent\nfrom langchain.agents.middleware import dynamic_prompt, ModelRequest\n\n@dynamic_prompt\ndef state_aware_prompt(request: ModelRequest) -&gt; str:\n    message_count = len(request.messages)\n\n    base = \"\u4f60\u662f\u4e00\u4e2a\u6709\u7528\u7684\u52a9\u624b\u3002\"\n\n    if message_count &gt; 10:\n        base += \"\\n\u8fd9\u662f\u4e00\u4e2a\u957f\u5bf9\u8bdd - \u8bf7\u7279\u522b\u7b80\u6d01\u3002\"\n\n    return base\n\nagent = create_agent(\n    model=\"openai:gpt-4o\",\n    tools=[...],\n    middleware=[state_aware_prompt]\n)\n</code></pre> <p>\u57fa\u4e8e\u5b58\u50a8\u7684\u7528\u6237\u504f\u597d\u63d0\u793a</p> <pre><code>from dataclasses import dataclass\n\n@dataclass\nclass Context:\n    user_id: str\n\n@dynamic_prompt\ndef store_aware_prompt(request: ModelRequest) -&gt; str:\n    user_id = request.runtime.context.user_id\n    store = request.runtime.store\n    user_prefs = store.get((\"preferences\",), user_id)\n\n    base = \"\u4f60\u662f\u4e00\u4e2a\u6709\u7528\u7684\u52a9\u624b\u3002\"\n\n    if user_prefs:\n        style = user_prefs.value.get(\"communication_style\", \"balanced\")\n        base += f\"\\n\u7528\u6237\u504f\u597d{style}\u98ce\u683c\u7684\u56de\u590d\u3002\"\n\n    return base\n</code></pre>"},{"location":"llmapps/langchain/advanced-usage/context-engineering/#_9","title":"\u6d88\u606f\u7ba1\u7406","text":"<p>\u6d88\u606f\u6784\u6210\u53d1\u9001\u7ed9LLM\u7684\u63d0\u793a\u3002\u7ba1\u7406\u6d88\u606f\u5185\u5bb9\u5bf9\u4e8e\u786e\u4fddLLM\u6709\u6b63\u786e\u7684\u4fe1\u606f\u6765\u826f\u597d\u54cd\u5e94\u81f3\u5173\u91cd\u8981\u3002</p> <p>\u6ce8\u5165\u6587\u4ef6\u4e0a\u4e0b\u6587</p> <pre><code>from langchain.agents.middleware import wrap_model_call, ModelRequest, ModelResponse\n\n@wrap_model_call\ndef inject_file_context(request: ModelRequest, handler) -&gt; ModelResponse:\n    uploaded_files = request.state.get(\"uploaded_files\", [])\n\n    if uploaded_files:\n        file_descriptions = []\n        for file in uploaded_files:\n            file_descriptions.append(f\"- {file['name']} ({file['type']}): {file['summary']}\")\n\n        file_context = f\"\"\"\u672c\u6b21\u5bf9\u8bdd\u4e2d\u4f60\u53ef\u4ee5\u8bbf\u95ee\u7684\u6587\u4ef6\uff1a\n{chr(10).join(file_descriptions)}\n\n\u56de\u7b54\u95ee\u9898\u65f6\u8bf7\u53c2\u8003\u8fd9\u4e9b\u6587\u4ef6\u3002\"\"\"\n\n        messages = [\n            *request.messages,\n            {\"role\": \"user\", \"content\": file_context},\n        ]\n        request = request.override(messages=messages)\n\n    return handler(request)\n</code></pre>"},{"location":"llmapps/langchain/advanced-usage/context-engineering/#_10","title":"\u5de5\u5177\u7ba1\u7406","text":"<p>\u5de5\u5177\u8ba9\u6a21\u578b\u80fd\u591f\u4e0e\u6570\u636e\u5e93\u3001API\u548c\u5916\u90e8\u7cfb\u7edf\u4ea4\u4e92\u3002\u4f60\u5b9a\u4e49\u548c\u9009\u62e9\u5de5\u5177\u7684\u65b9\u5f0f\u76f4\u63a5\u5f71\u54cd\u6a21\u578b\u80fd\u5426\u6709\u6548\u5b8c\u6210\u4efb\u52a1\u3002</p> <p>\u5de5\u5177\u5b9a\u4e49\u6700\u4f73\u5b9e\u8df5</p> <pre><code>from langchain.tools import tool\n\n@tool(parse_docstring=True)\ndef search_orders(user_id: str, status: str, limit: int = 10) -&gt; str:\n    \"\"\"\u6309\u72b6\u6001\u641c\u7d22\u7528\u6237\u8ba2\u5355\u3002\n\n    \u5f53\u7528\u6237\u8be2\u95ee\u8ba2\u5355\u5386\u53f2\u6216\u60f3\u8981\u68c0\u67e5\u8ba2\u5355\u72b6\u6001\u65f6\u4f7f\u7528\u6b64\u5de5\u5177\u3002\n    \u59cb\u7ec8\u6309\u63d0\u4f9b\u7684\u72b6\u6001\u8fdb\u884c\u8fc7\u6ee4\u3002\n\n    \u53c2\u6570\uff1a\n        user_id: \u7528\u6237\u7684\u552f\u4e00\u6807\u8bc6\u7b26\n        status: \u8ba2\u5355\u72b6\u6001\uff1a'pending'\u3001'shipped' \u6216 'delivered'\n        limit: \u8fd4\u56de\u7684\u6700\u5927\u7ed3\u679c\u6570\n    \"\"\"\n    # \u5b9e\u73b0\u4ee3\u7801\n    pass\n</code></pre> <p>\u57fa\u4e8e\u72b6\u6001\u52a8\u6001\u9009\u62e9\u5de5\u5177</p> <pre><code>@wrap_model_call\ndef state_based_tools(request: ModelRequest, handler) -&gt; ModelResponse:\n    state = request.state\n    is_authenticated = state.get(\"authenticated\", False)\n    message_count = len(state[\"messages\"])\n\n    if not is_authenticated:\n        tools = [t for t in request.tools if t.name.startswith(\"public_\")]\n        request = request.override(tools=tools)\n    elif message_count &lt; 5:\n        tools = [t for t in request.tools if t.name != \"advanced_search\"]\n        request = request.override(tools=tools)\n\n    return handler(request)\n</code></pre>"},{"location":"llmapps/langchain/advanced-usage/context-engineering/#_11","title":"\u6a21\u578b\u9009\u62e9","text":"<p>\u4e0d\u540c\u7684\u6a21\u578b\u6709\u4e0d\u540c\u7684\u4f18\u52bf\u3001\u6210\u672c\u548c\u4e0a\u4e0b\u6587\u7a97\u53e3\u3002\u6839\u636e\u5f53\u524d\u4efb\u52a1\u9009\u62e9\u5408\u9002\u7684\u6a21\u578b\u3002</p> <p>\u57fa\u4e8e\u5bf9\u8bdd\u957f\u5ea6\u9009\u62e9\u6a21\u578b</p> <pre><code>from langchain.chat_models import init_chat_model\n\nlarge_model = init_chat_model(\"anthropic:claude-sonnet-4-5\")\nstandard_model = init_chat_model(\"openai:gpt-4o\")\nefficient_model = init_chat_model(\"openai:gpt-4o-mini\")\n\n@wrap_model_call\ndef state_based_model(request: ModelRequest, handler) -&gt; ModelResponse:\n    message_count = len(request.messages)\n\n    if message_count &gt; 20:\n        model = large_model\n    elif message_count &gt; 10:\n        model = standard_model\n    else:\n        model = efficient_model\n\n    request = request.override(model=model)\n    return handler(request)\n</code></pre>"},{"location":"llmapps/langchain/advanced-usage/context-engineering/#_12","title":"\u54cd\u5e94\u683c\u5f0f","text":"<p>\u7ed3\u6784\u5316\u8f93\u51fa\u5c06\u975e\u7ed3\u6784\u5316\u6587\u672c\u8f6c\u6362\u4e3a\u7ecf\u8fc7\u9a8c\u8bc1\u7684\u7ed3\u6784\u5316\u6570\u636e\u3002</p> <p>\u5b9a\u4e49\u54cd\u5e94\u683c\u5f0f</p> <pre><code>from pydantic import BaseModel, Field\n\nclass CustomerSupportTicket(BaseModel):\n    \"\"\"\u4ece\u5ba2\u6237\u6d88\u606f\u4e2d\u63d0\u53d6\u7684\u7ed3\u6784\u5316\u7968\u636e\u4fe1\u606f\u3002\"\"\"\n\n    category: str = Field(description=\"\u95ee\u9898\u7c7b\u522b\uff1a'billing'\u3001'technical'\u3001'account' \u6216 'product'\")\n    priority: str = Field(description=\"\u7d27\u6025\u7a0b\u5ea6\uff1a'low'\u3001'medium'\u3001'high' \u6216 'critical'\")\n    summary: str = Field(description=\"\u5ba2\u6237\u95ee\u9898\u7684\u4e00\u53e5\u8bdd\u6458\u8981\")\n    customer_sentiment: str = Field(description=\"\u5ba2\u6237\u60c5\u7eea\uff1a'frustrated'\u3001'neutral' \u6216 'satisfied'\")\n</code></pre> <p>\u57fa\u4e8e\u72b6\u6001\u52a8\u6001\u9009\u62e9\u54cd\u5e94\u683c\u5f0f</p> <pre><code>class SimpleResponse(BaseModel):\n    answer: str = Field(description=\"\u7b80\u77ed\u56de\u7b54\")\n\nclass DetailedResponse(BaseModel):\n    answer: str = Field(description=\"\u8be6\u7ec6\u56de\u7b54\")\n    reasoning: str = Field(description=\"\u63a8\u7406\u8fc7\u7a0b\u8bf4\u660e\")\n    confidence: float = Field(description=\"\u7f6e\u4fe1\u5ea6\u5206\u65700-1\")\n\n@wrap_model_call\ndef state_based_output(request: ModelRequest, handler) -&gt; ModelResponse:\n    message_count = len(request.messages)\n\n    if message_count &lt; 3:\n        request = request.override(response_format=SimpleResponse)\n    else:\n        request = request.override(response_format=DetailedResponse)\n\n    return handler(request)\n</code></pre>"},{"location":"llmapps/langchain/advanced-usage/context-engineering/#_13","title":"\u5de5\u5177\u4e0a\u4e0b\u6587","text":"<p>\u5de5\u5177\u7684\u7279\u6b8a\u4e4b\u5904\u5728\u4e8e\u5b83\u4eec\u65e2\u8bfb\u53d6\u53c8\u5199\u5165\u4e0a\u4e0b\u6587\u3002</p>"},{"location":"llmapps/langchain/advanced-usage/context-engineering/#_14","title":"\u8bfb\u53d6\u4e0a\u4e0b\u6587","text":"<p>\u5927\u591a\u6570\u771f\u5b9e\u4e16\u754c\u7684\u5de5\u5177\u9700\u8981\u7684\u4e0d\u4ec5\u4ec5\u662fLLM\u7684\u53c2\u6570\u3002\u5b83\u4eec\u9700\u8981\u7528\u6237ID\u8fdb\u884c\u6570\u636e\u5e93\u67e5\u8be2\u3001API\u5bc6\u94a5\u8bbf\u95ee\u5916\u90e8\u670d\u52a1\uff0c\u6216\u5f53\u524d\u4f1a\u8bdd\u72b6\u6001\u6765\u505a\u51b3\u7b56\u3002</p> <p>\u4ece\u8fd0\u884c\u65f6\u4e0a\u4e0b\u6587\u8bfb\u53d6\u914d\u7f6e</p> <pre><code>from dataclasses import dataclass\n\n@dataclass\nclass Context:\n    user_id: str\n    api_key: str\n    db_connection: str\n\n@tool\ndef fetch_user_data(query: str, runtime: ToolRuntime[Context]) -&gt; str:\n    \"\"\"\u4f7f\u7528\u8fd0\u884c\u65f6\u4e0a\u4e0b\u6587\u914d\u7f6e\u83b7\u53d6\u6570\u636e\u3002\"\"\"\n    user_id = runtime.context.user_id\n    api_key = runtime.context.api_key\n    db_connection = runtime.context.db_connection\n\n    results = perform_database_query(db_connection, query, api_key)\n    return f\"\u4e3a\u7528\u6237 {user_id} \u627e\u5230 {len(results)} \u6761\u7ed3\u679c\"\n</code></pre>"},{"location":"llmapps/langchain/advanced-usage/context-engineering/#_15","title":"\u5199\u5165\u4e0a\u4e0b\u6587","text":"<p>\u5de5\u5177\u7ed3\u679c\u53ef\u7528\u4e8e\u5e2e\u52a9\u667a\u80fd\u4f53\u5b8c\u6210\u7ed9\u5b9a\u4efb\u52a1\u3002\u5de5\u5177\u65e2\u53ef\u4ee5\u76f4\u63a5\u5411\u6a21\u578b\u8fd4\u56de\u7ed3\u679c\uff0c\u4e5f\u53ef\u4ee5\u66f4\u65b0\u667a\u80fd\u4f53\u7684\u8bb0\u5fc6\uff0c\u4f7f\u91cd\u8981\u7684\u4e0a\u4e0b\u6587\u5728\u540e\u7eed\u6b65\u9aa4\u4e2d\u53ef\u7528\u3002</p> <p>\u5199\u5165\u72b6\u6001\u8ddf\u8e2a\u4f1a\u8bdd\u4fe1\u606f</p> <pre><code>from langgraph.types import Command\n\n@tool\ndef authenticate_user(password: str, runtime: ToolRuntime) -&gt; Command:\n    \"\"\"\u9a8c\u8bc1\u7528\u6237\u5e76\u66f4\u65b0\u72b6\u6001\u3002\"\"\"\n    if password == \"correct\":\n        return Command(update={\"authenticated\": True})\n    else:\n        return Command(update={\"authenticated\": False})\n</code></pre> <p>\u5199\u5165\u5b58\u50a8\u6301\u4e45\u5316\u6570\u636e</p> <pre><code>@tool\ndef save_preference(preference_key: str, preference_value: str, runtime: ToolRuntime[Context]) -&gt; str:\n    \"\"\"\u5c06\u7528\u6237\u504f\u597d\u4fdd\u5b58\u5230\u5b58\u50a8\u3002\"\"\"\n    user_id = runtime.context.user_id\n    store = runtime.store\n\n    existing_prefs = store.get((\"preferences\",), user_id)\n    prefs = existing_prefs.value if existing_prefs else {}\n    prefs[preference_key] = preference_value\n\n    store.put((\"preferences\",), user_id, prefs)\n    return f\"\u4fdd\u5b58\u504f\u597d\uff1a{preference_key} = {preference_value}\"\n</code></pre>"},{"location":"llmapps/langchain/advanced-usage/context-engineering/#_16","title":"\u751f\u547d\u5468\u671f\u4e0a\u4e0b\u6587","text":"<p>\u63a7\u5236\u6838\u5fc3\u667a\u80fd\u4f53\u6b65\u9aa4\u4e4b\u95f4\u53d1\u751f\u7684\u4e8b\u60c5 - \u62e6\u622a\u6570\u636e\u6d41\u4ee5\u5b9e\u73b0\u6a2a\u5207\u5173\u6ce8\u70b9\uff0c\u5982\u6458\u8981\u3001\u62a4\u680f\u548c\u65e5\u5fd7\u8bb0\u5f55\u3002</p>"},{"location":"llmapps/langchain/advanced-usage/context-engineering/#_17","title":"\u81ea\u52a8\u6458\u8981","text":"<p>\u6700\u5e38\u89c1\u7684\u751f\u547d\u5468\u671f\u6a21\u5f0f\u4e4b\u4e00\u662f\u5728\u5bf9\u8bdd\u5386\u53f2\u8fc7\u957f\u65f6\u81ea\u52a8\u538b\u7f29\u3002\u4e0e\u6a21\u578b\u4e0a\u4e0b\u6587\u4e2d\u663e\u793a\u7684\u77ac\u6001\u6d88\u606f\u4fee\u526a\u4e0d\u540c\uff0c\u6458\u8981\u6301\u4e45\u66f4\u65b0\u72b6\u6001 - \u6c38\u4e45\u7528\u6458\u8981\u66ff\u6362\u65e7\u6d88\u606f\uff0c\u8be5\u6458\u8981\u5c06\u4fdd\u5b58\u4f9b\u6240\u6709\u672a\u6765\u8f6e\u6b21\u4f7f\u7528\u3002</p> <p>\u4f7f\u7528\u5185\u7f6e\u6458\u8981\u4e2d\u95f4\u4ef6</p> <pre><code>from langchain.agents.middleware import SummarizationMiddleware\n\nagent = create_agent(\n    model=\"openai:gpt-4o\",\n    tools=[...],\n    middleware=[\n        SummarizationMiddleware(\n            model=\"openai:gpt-4o-mini\",\n            max_tokens_before_summary=4000,  # \u57284000\u4e2atoken\u65f6\u89e6\u53d1\u6458\u8981\n            messages_to_keep=20,  # \u6458\u8981\u540e\u4fdd\u7559\u6700\u540e20\u6761\u6d88\u606f\n        ),\n    ],\n)\n</code></pre>"},{"location":"llmapps/langchain/advanced-usage/context-engineering/#_18","title":"\u81ea\u5b9a\u4e49\u751f\u547d\u5468\u671f\u94a9\u5b50","text":"<p>Before Model\u94a9\u5b50</p> <pre><code>from langchain.agents.middleware import before_model\n\n@before_model\ndef log_before_model(state: AgentState, runtime: Runtime[Context]) -&gt; dict | None:\n    user_name = runtime.context.user_name\n    session_id = runtime.context.session_id\n    print(f\"\u4e3a\u7528\u6237 {user_name} \u5904\u7406\u8bf7\u6c42 (\u4f1a\u8bdd: {session_id})\")\n    return None\n</code></pre> <p>After Model\u94a9\u5b50</p> <pre><code>from langchain.agents.middleware import after_model\n\n@after_model\ndef log_after_model(state: AgentState, runtime: Runtime[Context]) -&gt; dict | None:\n    user_name = runtime.context.user_name\n    session_id = runtime.context.session_id\n\n    if runtime.store and state[\"messages\"]:\n        last_message = state[\"messages\"][-1]\n        runtime.store.set(\n            (\"conversations\",), \n            session_id, \n            {\n                \"user\": user_name,\n                \"last_interaction\": str(last_message.content)[:100],\n                \"timestamp\": \"2024-01-01\"\n            }\n        )\n\n    return None\n</code></pre>"},{"location":"llmapps/langchain/advanced-usage/context-engineering/#_19","title":"\u5b8c\u6574\u793a\u4f8b\uff1a\u6784\u5efa\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u5ba2\u6237\u670d\u52a1\u667a\u80fd\u4f53","text":"<pre><code>from dataclasses import dataclass\nfrom langchain.agents import create_agent\nfrom langchain.agents.middleware import (\n    dynamic_prompt, wrap_model_call, before_model, after_model,\n    SummarizationMiddleware\n)\nfrom langchain.tools import tool, ToolRuntime\nfrom langgraph.types import Command\nfrom pydantic import BaseModel, Field\n\n# \u4e0a\u4e0b\u6587\u5b9a\u4e49\n@dataclass\nclass CustomerContext:\n    user_id: str\n    user_tier: str  # basic, premium, vip\n    language: str = \"zh-CN\"\n    permissions: list[str] = None\n\n    def __post_init__(self):\n        if self.permissions is None:\n            self.permissions = [\"basic_support\"]\n\n# \u54cd\u5e94\u683c\u5f0f\nclass SupportResponse(BaseModel):\n    answer: str = Field(description=\"\u5bf9\u5ba2\u6237\u95ee\u9898\u7684\u56de\u7b54\")\n    next_steps: list[str] = Field(description=\"\u5efa\u8bae\u7684\u540e\u7eed\u6b65\u9aa4\")\n    confidence: float = Field(description=\"\u56de\u7b54\u7684\u7f6e\u4fe1\u5ea6\")\n\n# \u52a8\u6001\u7cfb\u7edf\u63d0\u793a\n@dynamic_prompt\ndef customer_aware_prompt(request: ModelRequest) -&gt; str:\n    context = request.runtime.context\n    base = f\"\u4f60\u662f\u5ba2\u6237\u670d\u52a1\u52a9\u624b\uff0c\u6b63\u5728\u4e3a{context.user_tier}\u7ea7\u522b\u7528\u6237\u670d\u52a1\u3002\"\n\n    if context.user_tier == \"vip\":\n        base += \" \u8fd9\u662fVIP\u7528\u6237\uff0c\u8bf7\u63d0\u4f9b\u4f18\u5148\u548c\u4e2a\u6027\u5316\u670d\u52a1\u3002\"\n    elif context.user_tier == \"premium\":\n        base += \" \u8fd9\u662f\u9ad8\u7ea7\u7528\u6237\uff0c\u8bf7\u63d0\u4f9b\u4f18\u8d28\u670d\u52a1\u3002\"\n\n    if \"zh-CN\" in context.language:\n        base += \" \u8bf7\u4f7f\u7528\u4e2d\u6587\u56de\u590d\u3002\"\n\n    return base\n\n# \u5de5\u5177\uff1a\u83b7\u53d6\u7528\u6237\u5386\u53f2\n@tool\ndef get_user_ticket_history(runtime: ToolRuntime[CustomerContext]) -&gt; str:\n    \"\"\"\u83b7\u53d6\u7528\u6237\u7684\u5de5\u5355\u5386\u53f2\u3002\"\"\"\n    user_id = runtime.context.user_id\n    store = runtime.store\n\n    history = store.get((\"ticket_history\",), user_id)\n    if history:\n        return f\"\u7528\u6237\u6700\u8fd1\u7684\u5de5\u5355\uff1a{history.value}\"\n    return \"\u7528\u6237\u6ca1\u6709\u5386\u53f2\u5de5\u5355\u8bb0\u5f55\"\n\n# \u5de5\u5177\uff1a\u521b\u5efa\u65b0\u5de5\u5355\n@tool\ndef create_support_ticket(issue: str, runtime: ToolRuntime[CustomerContext]) -&gt; Command:\n    \"\"\"\u4e3a\u7528\u6237\u521b\u5efa\u652f\u6301\u5de5\u5355\u3002\"\"\"\n    user_id = runtime.context.user_id\n    store = runtime.store\n\n    # \u83b7\u53d6\u73b0\u6709\u5386\u53f2\n    history = store.get((\"ticket_history\",), user_id)\n    tickets = history.value if history else []\n\n    # \u6dfb\u52a0\u65b0\u5de5\u5355\n    new_ticket = {\n        \"issue\": issue,\n        \"timestamp\": \"2024-01-01\",\n        \"status\": \"open\"\n    }\n    tickets.append(new_ticket)\n\n    # \u66f4\u65b0\u5b58\u50a8\n    store.put((\"ticket_history\",), user_id, tickets)\n\n    return Command(\n        update={\"last_ticket_created\": new_ticket},\n        message=f\"\u5df2\u521b\u5efa\u5de5\u5355\uff1a{issue}\"\n    )\n\n# \u521b\u5efa\u5b8c\u6574\u7684\u667a\u80fd\u4f53\nagent = create_agent(\n    model=\"openai:gpt-4o\",\n    tools=[get_user_ticket_history, create_support_ticket],\n    middleware=[\n        customer_aware_prompt,\n        SummarizationMiddleware(\n            model=\"openai:gpt-4o-mini\",\n            max_tokens_before_summary=3000,\n        ),\n    ],\n    context_schema=CustomerContext,\n    response_format=SupportResponse\n)\n\n# \u4f7f\u7528\u793a\u4f8b\nresult = agent.invoke(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"\u6211\u7684\u8ba2\u5355\u6709\u95ee\u9898\"}]},\n    context=CustomerContext(\n        user_id=\"user_123\",\n        user_tier=\"premium\",\n        language=\"zh-CN\"\n    )\n)\n</code></pre>"},{"location":"llmapps/langchain/advanced-usage/context-engineering/#_20","title":"\u6700\u4f73\u5b9e\u8df5","text":"<ol> <li>\u4ece\u7b80\u5355\u5f00\u59cb - \u4ece\u9759\u6001\u63d0\u793a\u548c\u5de5\u5177\u5f00\u59cb\uff0c\u4ec5\u5728\u9700\u8981\u65f6\u6dfb\u52a0\u52a8\u6001\u529f\u80fd</li> <li>\u589e\u91cf\u6d4b\u8bd5 - \u4e00\u6b21\u6dfb\u52a0\u4e00\u4e2a\u4e0a\u4e0b\u6587\u5de5\u7a0b\u529f\u80fd</li> <li>\u76d1\u63a7\u6027\u80fd - \u8ddf\u8e2a\u6a21\u578b\u8c03\u7528\u3001token\u4f7f\u7528\u548c\u5ef6\u8fdf</li> <li>\u4f7f\u7528\u5185\u7f6e\u4e2d\u95f4\u4ef6 - \u5229\u7528<code>SummarizationMiddleware</code>\u7b49\u73b0\u6709\u7ec4\u4ef6</li> <li>\u8bb0\u5f55\u4e0a\u4e0b\u6587\u7b56\u7565 - \u660e\u786e\u8bf4\u660e\u6b63\u5728\u4f20\u9012\u4ec0\u4e48\u4e0a\u4e0b\u6587\u4ee5\u53ca\u539f\u56e0</li> <li>\u7406\u89e3\u77ac\u6001\u4e0e\u6301\u4e45\u5316\uff1a\u6a21\u578b\u4e0a\u4e0b\u6587\u66f4\u6539\u662f\u77ac\u6001\u7684\uff08\u6bcf\u6b21\u8c03\u7528\uff09\uff0c\u800c\u751f\u547d\u5468\u671f\u4e0a\u4e0b\u6587\u66f4\u6539\u4f1a\u6301\u4e45\u5316\u5230\u72b6\u6001</li> </ol> <p>\u901a\u8fc7\u6709\u6548\u5b9e\u65bd\u4e0a\u4e0b\u6587\u5de5\u7a0b\uff0c\u4f60\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u667a\u80fd\u4f53\u7684\u53ef\u9760\u6027\u548c\u5b9e\u7528\u6027\uff0c\u4f7f\u5176\u80fd\u591f\u5904\u7406\u590d\u6742\u7684\u73b0\u5b9e\u4e16\u754c\u4efb\u52a1\u3002</p>"},{"location":"llmapps/langchain/core-components/agents/","title":"LangChain Agents\uff08\u667a\u80fd\u4f53\uff09","text":""},{"location":"llmapps/langchain/core-components/agents/#_1","title":"\u6982\u8ff0","text":"<p>Agents\uff08\u4ee3\u7406\uff09\u5c06\u8bed\u8a00\u6a21\u578b\u4e0e\u5de5\u5177\u76f8\u7ed3\u5408\uff0c\u521b\u5efa\u80fd\u591f\u63a8\u7406\u4efb\u52a1\u3001\u51b3\u5b9a\u4f7f\u7528\u54ea\u4e9b\u5de5\u5177\u5e76\u8fed\u4ee3\u5de5\u4f5c\u4ee5\u627e\u5230\u89e3\u51b3\u65b9\u6848\u7684\u7cfb\u7edf\u3002</p>"},{"location":"llmapps/langchain/core-components/agents/#_2","title":"\u6838\u5fc3\u6982\u5ff5","text":"<ul> <li>\u63a8\u7406\u5f15\u64ce\uff1a\u8bed\u8a00\u6a21\u578b\u8d1f\u8d23\u601d\u8003\u548c\u51b3\u7b56</li> <li>\u5de5\u5177\u8c03\u7528\uff1a\u4ee3\u7406\u53ef\u4ee5\u8c03\u7528\u5916\u90e8\u5de5\u5177\u6267\u884c\u64cd\u4f5c</li> <li>\u8fed\u4ee3\u8fc7\u7a0b\uff1a\u4ee3\u7406\u5728\u5faa\u73af\u4e2d\u5de5\u4f5c\u76f4\u5230\u8fbe\u5230\u505c\u6b62\u6761\u4ef6</li> <li>\u72b6\u6001\u7ba1\u7406\uff1a\u4ee3\u7406\u7ef4\u62a4\u5bf9\u8bdd\u5386\u53f2\u548c\u81ea\u5b9a\u4e49\u72b6\u6001</li> </ul>"},{"location":"llmapps/langchain/core-components/agents/#agent","title":"\u57fa\u7840 Agent \u521b\u5efa","text":""},{"location":"llmapps/langchain/core-components/agents/#1-agent","title":"1. \u7b80\u5355 Agent","text":"<pre><code>from langchain.agents import create_agent\nfrom langchain.tools import tool\n\n@tool\ndef search_web(query: str) -&gt; str:\n    \"\"\"\u5728\u7f51\u7edc\u4e0a\u641c\u7d22\u4fe1\u606f\u3002\"\"\"\n    return f\"\u5173\u4e8e '{query}' \u7684\u641c\u7d22\u7ed3\u679c\uff1a\u76f8\u5173\u6587\u7ae0\u3001\u65b0\u95fb\u548c\u4fe1\u606f\"\n\n@tool\ndef get_weather(location: str) -&gt; str:\n    \"\"\"\u83b7\u53d6\u6307\u5b9a\u4f4d\u7f6e\u7684\u5929\u6c14\u4fe1\u606f\u3002\"\"\"\n    return f\"{location}\u7684\u5929\u6c14\uff1a\u6674\u6717\uff0c25\u00b0C\"\n\n# \u521b\u5efa\u57fa\u7840 Agent\nagent = create_agent(\n    model=\"openai:gpt-4o\",\n    tools=[search_web, get_weather]\n)\n</code></pre>"},{"location":"llmapps/langchain/core-components/agents/#2-agent","title":"2. \u8c03\u7528 Agent","text":"<pre><code># \u57fa\u7840\u8c03\u7528\nresult = agent.invoke(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"\u5317\u4eac\u4eca\u5929\u5929\u6c14\u600e\u4e48\u6837\uff1f\"}]}\n)\n\nprint(result[\"messages\"][-1].content)\n</code></pre>"},{"location":"llmapps/langchain/core-components/agents/#_3","title":"\u6838\u5fc3\u7ec4\u4ef6\u8be6\u89e3","text":""},{"location":"llmapps/langchain/core-components/agents/#1","title":"1. \u6a21\u578b\u914d\u7f6e","text":""},{"location":"llmapps/langchain/core-components/agents/#_4","title":"\u9759\u6001\u6a21\u578b\u914d\u7f6e","text":"<pre><code>from langchain.agents import create_agent\nfrom langchain_openai import ChatOpenAI\n\n# \u65b9\u6cd51\uff1a\u4f7f\u7528\u6a21\u578b\u6807\u8bc6\u7b26\u5b57\u7b26\u4e32\nagent1 = create_agent(\n    \"openai:gpt-4o\",  # \u81ea\u52a8\u63a8\u65ad\u4e3a OpenAI GPT-4o\n    tools=[search_web, get_weather]\n)\n\n# \u65b9\u6cd52\uff1a\u4f7f\u7528\u6a21\u578b\u5b9e\u4f8b\uff08\u63a8\u8350\u7528\u4e8e\u751f\u4ea7\u73af\u5883\uff09\nmodel = ChatOpenAI(\n    model=\"gpt-4o\",\n    temperature=0.1,      # \u63a7\u5236\u521b\u9020\u6027\n    max_tokens=1000,      # \u6700\u5927\u8f93\u51fa\u957f\u5ea6\n    timeout=30,           # \u8d85\u65f6\u8bbe\u7f6e\n    # \u5176\u4ed6\u53c2\u6570...\n)\n\nagent2 = create_agent(\n    model=model,\n    tools=[search_web, get_weather]\n)\n</code></pre>"},{"location":"llmapps/langchain/core-components/agents/#_5","title":"\u52a8\u6001\u6a21\u578b\u9009\u62e9","text":"<pre><code>from langchain.agents.middleware import wrap_model_call, ModelRequest\nfrom langchain_openai import ChatOpenAI\n\n# \u5b9a\u4e49\u4e0d\u540c\u6a21\u578b\nbasic_model = ChatOpenAI(model=\"gpt-4o-mini\")  # \u7ecf\u6d4e\u578b\u6a21\u578b\nadvanced_model = ChatOpenAI(model=\"gpt-4o\")    # \u9ad8\u7ea7\u6a21\u578b\n\n@wrap_model_call\ndef dynamic_model_selection(request: ModelRequest, handler):\n    \"\"\"\u57fa\u4e8e\u5bf9\u8bdd\u590d\u6742\u5ea6\u9009\u62e9\u6a21\u578b\"\"\"\n    messages = request.state[\"messages\"]\n    message_count = len(messages)\n\n    # \u590d\u6742\u5bf9\u8bdd\u4f7f\u7528\u9ad8\u7ea7\u6a21\u578b\n    if message_count &gt; 5 or any(\"\u590d\u6742\" in msg.content for msg in messages if hasattr(msg, 'content')):\n        request.model = advanced_model\n    else:\n        request.model = basic_model\n\n    return handler(request)\n\n# \u521b\u5efa\u652f\u6301\u52a8\u6001\u6a21\u578b\u9009\u62e9\u7684 Agent\nagent = create_agent(\n    model=basic_model,  # \u9ed8\u8ba4\u6a21\u578b\n    tools=[search_web, get_weather],\n    middleware=[dynamic_model_selection]\n)\n</code></pre>"},{"location":"llmapps/langchain/core-components/agents/#2","title":"2. \u5de5\u5177\u7cfb\u7edf","text":""},{"location":"llmapps/langchain/core-components/agents/#_6","title":"\u57fa\u7840\u5de5\u5177\u5b9a\u4e49","text":"<pre><code>from langchain.tools import tool\nfrom datetime import datetime\n\n@tool\ndef calculator(expression: str) -&gt; str:\n    \"\"\"\u8ba1\u7b97\u6570\u5b66\u8868\u8fbe\u5f0f\u3002\"\"\"\n    try:\n        result = eval(expression)\n        return f\"{expression} = {result}\"\n    except Exception as e:\n        return f\"\u8ba1\u7b97\u9519\u8bef: {str(e)}\"\n\n@tool\ndef get_current_time(timezone: str = \"UTC\") -&gt; str:\n    \"\"\"\u83b7\u53d6\u6307\u5b9a\u65f6\u533a\u7684\u5f53\u524d\u65f6\u95f4\u3002\"\"\"\n    now = datetime.now()\n    return f\"{timezone}\u65f6\u533a\u5f53\u524d\u65f6\u95f4: {now.strftime('%Y-%m-%d %H:%M:%S')}\"\n\n@tool\ndef search_products(query: str, category: str = \"all\") -&gt; str:\n    \"\"\"\u641c\u7d22\u4ea7\u54c1\u4fe1\u606f\u3002\"\"\"\n    return f\"\u5728 '{category}' \u7c7b\u522b\u4e2d\u627e\u5230\u5173\u4e8e '{query}' \u7684\u4ea7\u54c1\"\n\n# \u521b\u5efa\u5305\u542b\u591a\u4e2a\u5de5\u5177\u7684 Agent\nagent = create_agent(\n    model=\"openai:gpt-4o\",\n    tools=[calculator, get_current_time, search_products]\n)\n</code></pre>"},{"location":"llmapps/langchain/core-components/agents/#_7","title":"\u5de5\u5177\u9519\u8bef\u5904\u7406","text":"<pre><code>from langchain.agents.middleware import wrap_tool_call\nfrom langchain_core.messages import ToolMessage\n\n@wrap_tool_call\ndef handle_tool_errors(request, handler):\n    \"\"\"\u81ea\u5b9a\u4e49\u5de5\u5177\u9519\u8bef\u5904\u7406\"\"\"\n    try:\n        return handler(request)\n    except Exception as e:\n        # \u8fd4\u56de\u53cb\u597d\u7684\u9519\u8bef\u4fe1\u606f\n        error_message = f\"\u5de5\u5177\u6267\u884c\u5931\u8d25\uff1a{str(e)}\u3002\u8bf7\u68c0\u67e5\u8f93\u5165\u53c2\u6570\u5e76\u91cd\u8bd5\u3002\"\n\n        return ToolMessage(\n            content=error_message,\n            tool_call_id=request.tool_call[\"id\"]\n        )\n\nagent = create_agent(\n    model=\"openai:gpt-4o\",\n    tools=[calculator, get_current_time],\n    middleware=[handle_tool_errors]\n)\n</code></pre>"},{"location":"llmapps/langchain/core-components/agents/#3","title":"3. \u7cfb\u7edf\u63d0\u793a\u8bcd","text":""},{"location":"llmapps/langchain/core-components/agents/#_8","title":"\u9759\u6001\u7cfb\u7edf\u63d0\u793a\u8bcd","text":"<pre><code>agent = create_agent(\n    model=\"openai:gpt-4o\",\n    tools=[search_web, get_weather],\n    system_prompt=\"\"\"\u4f60\u662f\u4e00\u4e2a\u4e13\u4e1a\u3001\u53cb\u597d\u7684\u52a9\u624b\u3002\u8bf7\u9075\u5faa\u4ee5\u4e0b\u6307\u5bfc\u539f\u5219\uff1a\n    1. \u56de\u7b54\u8981\u51c6\u786e\u3001\u7b80\u6d01\n    2. \u4f7f\u7528\u5de5\u5177\u83b7\u53d6\u6700\u65b0\u4fe1\u606f\n    3. \u5982\u679c\u7528\u6237\u95ee\u9898\u6d89\u53ca\u4e13\u4e1a\u9886\u57df\uff0c\u8bf7\u8bf4\u660e\u4fe1\u606f\u6765\u6e90\n    4. \u5bf9\u4e0d\u786e\u5b9a\u7684\u4fe1\u606f\u8981\u660e\u786e\u8bf4\u660e\n    \"\"\"\n)\n</code></pre>"},{"location":"llmapps/langchain/core-components/agents/#_9","title":"\u52a8\u6001\u7cfb\u7edf\u63d0\u793a\u8bcd","text":"<pre><code>from langchain.agents.middleware import dynamic_prompt, ModelRequest\nfrom typing import TypedDict\n\nclass UserContext(TypedDict):\n    user_level: str  # \"beginner\", \"intermediate\", \"expert\"\n    language: str\n\n@dynamic_prompt\ndef adaptive_system_prompt(request: ModelRequest) -&gt; str:\n    \"\"\"\u57fa\u4e8e\u7528\u6237\u6c34\u5e73\u548c\u8bed\u8a00\u751f\u6210\u52a8\u6001\u7cfb\u7edf\u63d0\u793a\u8bcd\"\"\"\n    context = request.runtime.context\n    user_level = context.get(\"user_level\", \"beginner\")\n    language = context.get(\"language\", \"zh-CN\")\n\n    base_prompt = \"\u4f60\u662f\u4e00\u4e2a\u6709\u5e2e\u52a9\u7684AI\u52a9\u624b\u3002\"\n\n    # \u6839\u636e\u7528\u6237\u6c34\u5e73\u8c03\u6574\u63d0\u793a\u8bcd\n    level_prompts = {\n        \"beginner\": \"\u8bf7\u7528\u7b80\u5355\u6613\u61c2\u7684\u8bed\u8a00\u89e3\u91ca\u6982\u5ff5\uff0c\u907f\u514d\u4e13\u4e1a\u672f\u8bed\u3002\",\n        \"intermediate\": \"\u63d0\u4f9b\u5e73\u8861\u7684\u89e3\u7b54\uff0c\u5305\u542b\u57fa\u672c\u6982\u5ff5\u548c\u4e00\u4e9b\u8fdb\u9636\u4fe1\u606f\u3002\",\n        \"expert\": \"\u63d0\u4f9b\u8be6\u7ec6\u7684\u6280\u672f\u5206\u6790\uff0c\u53ef\u4ee5\u4f7f\u7528\u4e13\u4e1a\u672f\u8bed\u3002\"\n    }\n\n    level_prompt = level_prompts.get(user_level, level_prompts[\"beginner\"])\n\n    # \u8bed\u8a00\u7279\u5b9a\u63d0\u793a\n    if language == \"zh-CN\":\n        language_prompt = \"\u8bf7\u4f7f\u7528\u4e2d\u6587\u56de\u590d\uff0c\u4fdd\u6301\u8bed\u8a00\u7684\u81ea\u7136\u548c\u6d41\u7545\u3002\"\n    else:\n        language_prompt = \"Please respond in natural and fluent language.\"\n\n    return f\"{base_prompt} {level_prompt} {language_prompt}\"\n\n# \u521b\u5efa\u652f\u6301\u52a8\u6001\u63d0\u793a\u8bcd\u7684 Agent\nagent = create_agent(\n    model=\"openai:gpt-4o\",\n    tools=[search_web, get_weather],\n    middleware=[adaptive_system_prompt],\n    context_schema=UserContext\n)\n\n# \u4f7f\u7528\u4e0a\u4e0b\u6587\u8c03\u7528\nresult = agent.invoke(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"\u89e3\u91ca\u673a\u5668\u5b66\u4e60\"}]},\n    context={\"user_level\": \"beginner\", \"language\": \"zh-CN\"}\n)\n</code></pre>"},{"location":"llmapps/langchain/core-components/agents/#_10","title":"\u9ad8\u7ea7\u529f\u80fd","text":""},{"location":"llmapps/langchain/core-components/agents/#1_1","title":"1. \u7ed3\u6784\u5316\u8f93\u51fa","text":"<pre><code>from pydantic import BaseModel, Field\nfrom langchain.agents import create_agent\nfrom langchain.agents.structured_output import ToolStrategy\n\nclass ProductReview(BaseModel):\n    \"\"\"\u4ea7\u54c1\u8bc4\u4ef7\u5206\u6790\"\"\"\n    product_name: str = Field(description=\"\u4ea7\u54c1\u540d\u79f0\")\n    rating: int = Field(description=\"\u8bc4\u5206(1-5)\", ge=1, le=5)\n    positive_points: list[str] = Field(description=\"\u4f18\u70b9\u5217\u8868\")\n    negative_points: list[str] = Field(description=\"\u7f3a\u70b9\u5217\u8868\")\n    summary: str = Field(description=\"\u603b\u4f53\u8bc4\u4ef7\u603b\u7ed3\")\n\nclass CustomerInfo(BaseModel):\n    \"\"\"\u5ba2\u6237\u4fe1\u606f\u63d0\u53d6\"\"\"\n    name: str = Field(description=\"\u5ba2\u6237\u59d3\u540d\")\n    email: str = Field(description=\"\u90ae\u7bb1\u5730\u5740\")\n    phone: str = Field(description=\"\u7535\u8bdd\u53f7\u7801\")\n    interests: list[str] = Field(description=\"\u5174\u8da3\u5217\u8868\")\n\n# \u4f7f\u7528 ToolStrategy \u5b9e\u73b0\u7ed3\u6784\u5316\u8f93\u51fa\nagent = create_agent(\n    model=\"openai:gpt-4o\",\n    tools=[search_web],\n    response_format=ToolStrategy(ProductReview)  # \u6216 CustomerInfo\n)\n\n# \u8c03\u7528\u5e76\u83b7\u53d6\u7ed3\u6784\u5316\u8f93\u51fa\nresult = agent.invoke({\n    \"messages\": [{\n        \"role\": \"user\", \n        \"content\": \"\u5206\u6790\u8fd9\u4e2a\u4ea7\u54c1\u8bc4\u4ef7\uff1a'iPhone 15 Pro \u592a\u68d2\u4e86\uff01\u76f8\u673a\u8d28\u91cf\u4f18\u79c0\uff0c\u7535\u6c60\u7eed\u822a\u4e5f\u5f88\u597d\uff0c\u5c31\u662f\u4ef7\u683c\u6709\u70b9\u8d35\u3002\u8bc4\u52065/5'\"\n    }]\n})\n\nstructured_data = result[\"structured_response\"]\nprint(f\"\u4ea7\u54c1: {structured_data.product_name}\")\nprint(f\"\u8bc4\u5206: {structured_data.rating}\")\nprint(f\"\u4f18\u70b9: {', '.join(structured_data.positive_points)}\")\n</code></pre>"},{"location":"llmapps/langchain/core-components/agents/#2_1","title":"2. \u5185\u5b58\u7ba1\u7406","text":""},{"location":"llmapps/langchain/core-components/agents/#_11","title":"\u81ea\u5b9a\u4e49\u72b6\u6001\u7ba1\u7406","text":"<pre><code>from typing import TypedDict, List, Optional\nfrom langchain.agents import AgentState, create_agent\n\nclass CustomAgentState(AgentState):\n    \"\"\"\u81ea\u5b9a\u4e49 Agent \u72b6\u6001\"\"\"\n    user_preferences: dict\n    conversation_topics: List[str]\n    interaction_count: int = 0\n    last_active: Optional[str] = None\n\n# \u901a\u8fc7 state_schema \u5b9a\u4e49\u72b6\u6001\nagent = create_agent(\n    model=\"openai:gpt-4o\",\n    tools=[search_web, get_weather],\n    state_schema=CustomAgentState\n)\n\n# \u4f7f\u7528\u81ea\u5b9a\u4e49\u72b6\u6001\u8c03\u7528\nresult = agent.invoke({\n    \"messages\": [{\"role\": \"user\", \"content\": \"\u6211\u559c\u6b22\u6280\u672f\u7c7b\u5185\u5bb9\"}],\n    \"user_preferences\": {\"category\": \"technology\", \"detail_level\": \"high\"},\n    \"conversation_topics\": [\"AI\", \"\u7f16\u7a0b\"],\n    \"interaction_count\": 1\n})\n</code></pre>"},{"location":"llmapps/langchain/core-components/agents/#_12","title":"\u901a\u8fc7\u4e2d\u95f4\u4ef6\u7ba1\u7406\u72b6\u6001","text":"<pre><code>from langchain.agents.middleware import AgentMiddleware\nfrom typing import Any\n\nclass UserPreferencesMiddleware(AgentMiddleware):\n    \"\"\"\u7528\u6237\u504f\u597d\u7ba1\u7406\u4e2d\u95f4\u4ef6\"\"\"\n    state_schema = CustomAgentState\n\n    def before_model(self, state: CustomAgentState, runtime) -&gt; dict[str, Any] | None:\n        \"\"\"\u5728\u6a21\u578b\u8c03\u7528\u524d\u5904\u7406\u7528\u6237\u504f\u597d\"\"\"\n        preferences = state.get(\"user_preferences\", {})\n\n        # \u57fa\u4e8e\u7528\u6237\u504f\u597d\u8c03\u6574\u884c\u4e3a\n        if preferences.get(\"detail_level\") == \"high\":\n            # \u53ef\u4ee5\u5728\u8fd9\u91cc\u4fee\u6539\u6d88\u606f\u6216\u6dfb\u52a0\u4e0a\u4e0b\u6587\n            pass\n\n        return None\n\n    def after_model(self, state: CustomAgentState, runtime) -&gt; dict[str, Any] | None:\n        \"\"\"\u5728\u6a21\u578b\u8c03\u7528\u540e\u66f4\u65b0\u4ea4\u4e92\u7edf\u8ba1\"\"\"\n        return {\n            \"interaction_count\": state.get(\"interaction_count\", 0) + 1,\n            \"last_active\": \"2024-01-01T10:00:00\"  # \u5b9e\u9645\u4f7f\u7528\u4e2d\u5e94\u4e3a\u5f53\u524d\u65f6\u95f4\n        }\n\nagent = create_agent(\n    model=\"openai:gpt-4o\",\n    tools=[search_web, get_weather],\n    middleware=[UserPreferencesMiddleware()]\n)\n</code></pre>"},{"location":"llmapps/langchain/core-components/agents/#3_1","title":"3. \u6d41\u5f0f\u4f20\u8f93","text":"<pre><code>def stream_agent_progress():\n    \"\"\"\u6d41\u5f0f\u4f20\u8f93 Agent \u6267\u884c\u8fdb\u5ea6\"\"\"\n    print(\"\u5f00\u59cb\u6d41\u5f0f\u4f20\u8f93 Agent \u6267\u884c...\")\n\n    for chunk in agent.stream(\n        {\"messages\": [{\"role\": \"user\", \"content\": \"\u641c\u7d22AI\u6700\u65b0\u53d1\u5c55\u5e76\u603b\u7ed3\u8981\u70b9\"}]},\n        stream_mode=\"values\"  # \u4e5f\u53ef\u4ee5\u4f7f\u7528 \"updates\" \u6216 \"messages\"\n    ):\n        # \u83b7\u53d6\u6700\u65b0\u6d88\u606f\n        latest_message = chunk[\"messages\"][-1]\n\n        # \u5904\u7406AI\u56de\u590d\n        if hasattr(latest_message, 'content') and latest_message.content:\n            print(f\"\ud83e\udd16 AI: {latest_message.content}\")\n\n        # \u5904\u7406\u5de5\u5177\u8c03\u7528\n        elif hasattr(latest_message, 'tool_calls') and latest_message.tool_calls:\n            for tool_call in latest_message.tool_calls:\n                print(f\"\ud83d\udee0\ufe0f  \u8c03\u7528\u5de5\u5177: {tool_call['name']}\")\n                print(f\"   \u53c2\u6570: {tool_call['args']}\")\n\n# \u8c03\u7528\u6d41\u5f0f\u4f20\u8f93\nstream_agent_progress()\n</code></pre>"},{"location":"llmapps/langchain/core-components/agents/#4","title":"4. \u4e2d\u95f4\u4ef6\u7cfb\u7edf","text":"<pre><code>from langchain.agents.middleware import before_model, after_model, wrap_tool_call\nfrom langchain.messages import RemoveMessage\nfrom langgraph.graph.message import REMOVE_ALL_MESSAGES\n\n@before_model\ndef trim_long_conversations(state, runtime):\n    \"\"\"\u4fee\u526a\u8fc7\u957f\u7684\u5bf9\u8bdd\u5386\u53f2\"\"\"\n    messages = state[\"messages\"]\n\n    if len(messages) &gt; 10:\n        # \u4fdd\u7559\u7cfb\u7edf\u6d88\u606f\u548c\u6700\u8fd15\u6761\u6d88\u606f\n        system_messages = [msg for msg in messages if msg.type == \"system\"]\n        recent_messages = messages[-5:]\n\n        return {\n            \"messages\": [\n                RemoveMessage(id=REMOVE_ALL_MESSAGES),\n                *system_messages,\n                *recent_messages\n            ]\n        }\n\n    return None\n\n@after_model\ndef validate_response_content(state, runtime):\n    \"\"\"\u9a8c\u8bc1\u6a21\u578b\u54cd\u5e94\u5185\u5bb9\"\"\"\n    last_message = state[\"messages\"][-1]\n\n    # \u68c0\u67e5\u662f\u5426\u5305\u542b\u4e0d\u5f53\u5185\u5bb9\n    inappropriate_keywords = [\"\u66b4\u529b\", \"\u4ec7\u6068\", \"\u6b67\u89c6\"]\n    if any(keyword in last_message.content for keyword in inappropriate_keywords):\n        return {\n            \"messages\": [\n                RemoveMessage(id=last_message.id),\n                *state[\"messages\"][:-1]\n            ]\n        }\n\n    return None\n\n@wrap_tool_call\ndef log_tool_execution(request, handler):\n    \"\"\"\u8bb0\u5f55\u5de5\u5177\u6267\u884c\u65e5\u5fd7\"\"\"\n    tool_name = request.tool_call[\"name\"]\n    tool_args = request.tool_call[\"args\"]\n\n    print(f\"\ud83d\udcdd \u5f00\u59cb\u6267\u884c\u5de5\u5177: {tool_name}\")\n    print(f\"   \u53c2\u6570: {tool_args}\")\n\n    start_time = time.time()\n    result = handler(request)\n    execution_time = time.time() - start_time\n\n    print(f\"\u2705 \u5de5\u5177\u6267\u884c\u5b8c\u6210: {tool_name} (\u8017\u65f6: {execution_time:.2f}s)\")\n\n    return result\n\n# \u521b\u5efa\u5305\u542b\u591a\u4e2a\u4e2d\u95f4\u4ef6\u7684 Agent\nagent = create_agent(\n    model=\"openai:gpt-4o\",\n    tools=[search_web, get_weather, calculator],\n    middleware=[\n        trim_long_conversations,\n        validate_response_content,\n        log_tool_execution\n    ]\n)\n</code></pre>"},{"location":"llmapps/langchain/core-components/agents/#_13","title":"\u5b9e\u9645\u5e94\u7528\u573a\u666f","text":""},{"location":"llmapps/langchain/core-components/agents/#1-agent_1","title":"\u573a\u666f1\uff1a\u5ba2\u6237\u670d\u52a1 Agent","text":"<pre><code>from langchain.tools import tool\nfrom datetime import datetime\n\nclass CustomerServiceAgent:\n    \"\"\"\u5ba2\u6237\u670d\u52a1 Agent\"\"\"\n\n    def __init__(self):\n        self.agent = self._create_agent()\n\n    @tool\n    def check_order_status(self, order_id: str) -&gt; str:\n        \"\"\"\u68c0\u67e5\u8ba2\u5355\u72b6\u6001\u3002\"\"\"\n        # \u6a21\u62df\u8ba2\u5355\u6570\u636e\u5e93\n        orders = {\n            \"ORD001\": {\"status\": \"\u5df2\u53d1\u8d27\", \"tracking\": \"SF123456789\"},\n            \"ORD002\": {\"status\": \"\u5904\u7406\u4e2d\", \"tracking\": None},\n            \"ORD003\": {\"status\": \"\u5df2\u9001\u8fbe\", \"tracking\": \"SF987654321\"}\n        }\n\n        if order_id in orders:\n            order = orders[order_id]\n            result = f\"\u8ba2\u5355 {order_id} \u72b6\u6001: {order['status']}\"\n            if order['tracking']:\n                result += f\"\\n\u7269\u6d41\u5355\u53f7: {order['tracking']}\"\n            return result\n        return f\"\u672a\u627e\u5230\u8ba2\u5355 {order_id}\"\n\n    @tool\n    def process_refund(self, order_id: str, reason: str) -&gt; str:\n        \"\"\"\u5904\u7406\u9000\u6b3e\u7533\u8bf7\u3002\"\"\"\n        return f\"\u8ba2\u5355 {order_id} \u7684\u9000\u6b3e\u7533\u8bf7\u5df2\u63d0\u4ea4\u3002\u539f\u56e0: {reason}\\n\u9884\u8ba13-5\u4e2a\u5de5\u4f5c\u65e5\u5904\u7406\u5b8c\u6210\u3002\"\n\n    @tool\n    def get_faq(self, category: str) -&gt; str:\n        \"\"\"\u83b7\u53d6\u5e38\u89c1\u95ee\u9898\u89e3\u7b54\u3002\"\"\"\n        faqs = {\n            \"shipping\": \"\u914d\u9001\u65f6\u95f4\uff1a\u666e\u901a\u5feb\u90123-5\u5929\uff0c\u52a0\u6025\u5feb\u90121-2\u5929\",\n            \"returns\": \"\u9000\u6362\u8d27\u653f\u7b56\uff1a7\u5929\u65e0\u7406\u7531\u9000\u8d27\uff0c30\u5929\u8d28\u91cf\u95ee\u9898\u7684\u6362\u8d27\",\n            \"payment\": \"\u652f\u4ed8\u65b9\u5f0f\uff1a\u652f\u6301\u652f\u4ed8\u5b9d\u3001\u5fae\u4fe1\u652f\u4ed8\u3001\u94f6\u884c\u5361\"\n        }\n        return faqs.get(category, \"\u6682\u65e0\u8be5\u7c7b\u522b\u5e38\u89c1\u95ee\u9898\")\n\n    def _create_agent(self):\n        \"\"\"\u521b\u5efa\u5ba2\u6237\u670d\u52a1 Agent\"\"\"\n        return create_agent(\n            model=\"openai:gpt-4o\",\n            tools=[self.check_order_status, self.process_refund, self.get_faq],\n            system_prompt=\"\"\"\u4f60\u662f\u4e00\u4e2a\u4e13\u4e1a\u7684\u5ba2\u6237\u670d\u52a1\u4ee3\u8868\u3002\u8bf7\u9075\u5faa\u4ee5\u4e0b\u539f\u5219\uff1a\n            1. \u59cb\u7ec8\u4fdd\u6301\u53cb\u597d\u548c\u4e13\u4e1a\u7684\u6001\u5ea6\n            2. \u51c6\u786e\u56de\u7b54\u5ba2\u6237\u95ee\u9898\n            3. \u4f7f\u7528\u5de5\u5177\u83b7\u53d6\u6700\u65b0\u4fe1\u606f\n            4. \u5bf9\u4e8e\u590d\u6742\u95ee\u9898\uff0c\u63d0\u4f9b\u6e05\u6670\u7684\u540e\u7eed\u6b65\u9aa4\n            5. \u5982\u679c\u65e0\u6cd5\u89e3\u51b3\u95ee\u9898\uff0c\u5efa\u8bae\u8054\u7cfb\u4eba\u5de5\u5ba2\u670d\n            \"\"\",\n            state_schema=CustomAgentState\n        )\n\n    def handle_customer_query(self, query: str, user_id: str):\n        \"\"\"\u5904\u7406\u5ba2\u6237\u67e5\u8be2\"\"\"\n        return self.agent.invoke({\n            \"messages\": [{\"role\": \"user\", \"content\": query}],\n            \"user_preferences\": {\"user_id\": user_id}\n        })\n\n# \u4f7f\u7528\u793a\u4f8b\nservice_agent = CustomerServiceAgent()\nresult = service_agent.handle_customer_query(\"\u6211\u7684\u8ba2\u5355ORD001\u72b6\u6001\u5982\u4f55\uff1f\", \"user123\")\n</code></pre>"},{"location":"llmapps/langchain/core-components/agents/#2-agent_1","title":"\u573a\u666f2\uff1a\u6570\u636e\u5206\u6790 Agent","text":"<pre><code>import pandas as pd\nimport numpy as np\nfrom io import StringIO\n\nclass DataAnalysisAgent:\n    \"\"\"\u6570\u636e\u5206\u6790 Agent\"\"\"\n\n    def __init__(self):\n        self.agent = self._create_agent()\n        self.current_dataset = None\n\n    @tool\n    def load_csv_data(self, csv_content: str) -&gt; str:\n        \"\"\"\u52a0\u8f7dCSV\u6570\u636e\u3002\"\"\"\n        try:\n            self.current_dataset = pd.read_csv(StringIO(csv_content))\n            stats = {\n                \"\u884c\u6570\": len(self.current_dataset),\n                \"\u5217\u6570\": len(self.current_dataset.columns),\n                \"\u5217\u540d\": list(self.current_dataset.columns)\n            }\n            return f\"\u6570\u636e\u52a0\u8f7d\u6210\u529f\uff01\u7edf\u8ba1\u4fe1\u606f: {stats}\"\n        except Exception as e:\n            return f\"\u6570\u636e\u52a0\u8f7d\u5931\u8d25: {str(e)}\"\n\n    @tool\n    def describe_dataset(self) -&gt; str:\n        \"\"\"\u63cf\u8ff0\u6570\u636e\u96c6\u57fa\u672c\u4fe1\u606f\u3002\"\"\"\n        if self.current_dataset is None:\n            return \"\u8bf7\u5148\u52a0\u8f7d\u6570\u636e\"\n\n        description = self.current_dataset.describe()\n        return f\"\u6570\u636e\u96c6\u63cf\u8ff0:\\n{description}\"\n\n    @tool\n    def calculate_correlation(self, column1: str, column2: str) -&gt; str:\n        \"\"\"\u8ba1\u7b97\u4e24\u5217\u4e4b\u95f4\u7684\u76f8\u5173\u6027\u3002\"\"\"\n        if self.current_dataset is None:\n            return \"\u8bf7\u5148\u52a0\u8f7d\u6570\u636e\"\n\n        if column1 not in self.current_dataset.columns or column2 not in self.current_dataset.columns:\n            return \"\u6307\u5b9a\u7684\u5217\u4e0d\u5b58\u5728\"\n\n        correlation = self.current_dataset[column1].corr(self.current_dataset[column2])\n        return f\"{column1} \u548c {column2} \u7684\u76f8\u5173\u6027: {correlation:.3f}\"\n\n    @tool\n    def filter_data(self, condition: str) -&gt; str:\n        \"\"\"\u6839\u636e\u6761\u4ef6\u8fc7\u6ee4\u6570\u636e\u3002\"\"\"\n        if self.current_dataset is None:\n            return \"\u8bf7\u5148\u52a0\u8f7d\u6570\u636e\"\n\n        try:\n            filtered_data = self.current_dataset.query(condition)\n            return f\"\u8fc7\u6ee4\u540e\u6570\u636e: {len(filtered_data)} \u884c\"\n        except Exception as e:\n            return f\"\u8fc7\u6ee4\u6761\u4ef6\u9519\u8bef: {str(e)}\"\n\n    def _create_agent(self):\n        \"\"\"\u521b\u5efa\u6570\u636e\u5206\u6790 Agent\"\"\"\n        return create_agent(\n            model=\"openai:gpt-4o\",\n            tools=[\n                self.load_csv_data, \n                self.describe_dataset, \n                self.calculate_correlation,\n                self.filter_data\n            ],\n            system_prompt=\"\"\"\u4f60\u662f\u4e00\u4e2a\u6570\u636e\u5206\u6790\u4e13\u5bb6\u3002\u8bf7\u5e2e\u52a9\u7528\u6237\uff1a\n            1. \u52a0\u8f7d\u548c\u5206\u6790\u6570\u636e\n            2. \u63d0\u4f9b\u6570\u636e\u7edf\u8ba1\u4fe1\u606f\n            3. \u8ba1\u7b97\u6307\u6807\u548c\u76f8\u5173\u6027\n            4. \u89e3\u91ca\u5206\u6790\u7ed3\u679c\u7684\u542b\u4e49\n            5. \u7528\u901a\u4fd7\u6613\u61c2\u7684\u8bed\u8a00\u89e3\u91ca\u6280\u672f\u6982\u5ff5\n            \"\"\"\n        )\n\n# \u4f7f\u7528\u793a\u4f8b\nanalysis_agent = DataAnalysisAgent()\n\n# \u6a21\u62dfCSV\u6570\u636e\nsample_data = \"\"\"name,age,salary,department\n\u5f20\u4e09,25,50000,\u6280\u672f\u90e8\n\u674e\u56db,30,60000,\u9500\u552e\u90e8\n\u738b\u4e94,35,70000,\u6280\u672f\u90e8\n\u8d75\u516d,28,55000,\u5e02\u573a\u90e8\"\"\"\n\nresult = analysis_agent.agent.invoke({\n    \"messages\": [{\"role\": \"user\", \"content\": f\"\u8bf7\u5206\u6790\u4ee5\u4e0b\u6570\u636e:\\n{sample_data}\"}]\n})\n</code></pre>"},{"location":"llmapps/langchain/core-components/agents/#3-agent","title":"\u573a\u666f3\uff1a\u7814\u7a76\u52a9\u624b Agent","text":"<pre><code>class ResearchAssistantAgent:\n    \"\"\"\u7814\u7a76\u52a9\u624b Agent\"\"\"\n\n    def __init__(self):\n        self.agent = self._create_agent()\n        self.research_topics = []\n\n    @tool\n    def search_academic_papers(self, topic: str, max_results: int = 5) -&gt; str:\n        \"\"\"\u641c\u7d22\u5b66\u672f\u8bba\u6587\u3002\"\"\"\n        # \u6a21\u62df\u5b66\u672f\u641c\u7d22\n        papers = [\n            f\"\u300a{topic}\u7684\u6700\u65b0\u7814\u7a76\u8fdb\u5c55\u300b- \u4f5c\u8005A et al.\",\n            f\"\u300a{topic}\u5728\u5b9e\u8df5\u4e2d\u7684\u5e94\u7528\u300b- \u4f5c\u8005B et al.\", \n            f\"\u300a{topic}\u7684\u672a\u6765\u53d1\u5c55\u8d8b\u52bf\u300b- \u4f5c\u8005C et al.\"\n        ]\n        return f\"\u627e\u5230 {len(papers)} \u7bc7\u76f8\u5173\u8bba\u6587:\\n\" + \"\\n\".join(papers[:max_results])\n\n    @tool\n    def summarize_research_topic(self, topic: str) -&gt; str:\n        \"\"\"\u603b\u7ed3\u7814\u7a76\u4e3b\u9898\u3002\"\"\"\n        self.research_topics.append(topic)\n        return f\"\"\"\n        {topic} \u7814\u7a76\u603b\u7ed3\uff1a\n        1. \u6838\u5fc3\u6982\u5ff5\uff1a{topic}\u6d89\u53ca\u591a\u4e2a\u4ea4\u53c9\u5b66\u79d1\u9886\u57df\n        2. \u5f53\u524d\u70ed\u70b9\uff1aAI\u9a71\u52a8\u7684{topic}\u7814\u7a76\u6b63\u5728\u5174\u8d77\n        3. \u4e3b\u8981\u6311\u6218\uff1a\u6570\u636e\u8d28\u91cf\u548c\u7b97\u6cd5\u53ef\u89e3\u91ca\u6027\n        4. \u672a\u6765\u65b9\u5411\uff1a\u81ea\u52a8\u5316\u3001\u667a\u80fd\u5316{topic}\u89e3\u51b3\u65b9\u6848\n        \"\"\"\n\n    @tool\n    def compare_topics(self, topic1: str, topic2: str) -&gt; str:\n        \"\"\"\u6bd4\u8f83\u4e24\u4e2a\u7814\u7a76\u4e3b\u9898\u3002\"\"\"\n        return f\"\"\"\n        {topic1} vs {topic2} \u6bd4\u8f83\uff1a\n\n        \u76f8\u4f3c\u70b9\uff1a\n        - \u90fd\u662f\u524d\u6cbf\u6280\u672f\u9886\u57df\n        - \u90fd\u9700\u8981\u8de8\u5b66\u79d1\u77e5\u8bc6\n        - \u90fd\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u573a\u666f\n\n        \u4e0d\u540c\u70b9\uff1a\n        - {topic1}\u66f4\u6ce8\u91cd\u7406\u8bba\u53d1\u5c55\n        - {topic2}\u66f4\u6ce8\u91cd\u5b9e\u8df5\u5e94\u7528\n        - \u6280\u672f\u6808\u548c\u7814\u7a76\u65b9\u6cd5\u6709\u6240\u4e0d\u540c\n        \"\"\"\n\n    @tool\n    def generate_research_questions(self, topic: str) -&gt; str:\n        \"\"\"\u751f\u6210\u7814\u7a76\u95ee\u9898\u3002\"\"\"\n        questions = [\n            f\"{topic}\u5982\u4f55\u5f71\u54cd\u76f8\u5173\u884c\u4e1a\uff1f\",\n            f\"{topic}\u9762\u4e34\u7684\u4e3b\u8981\u6280\u672f\u6311\u6218\u662f\u4ec0\u4e48\uff1f\",\n            f\"{topic}\u7684\u672a\u6765\u53d1\u5c55\u65b9\u5411\u6709\u54ea\u4e9b\uff1f\",\n            f\"\u5982\u4f55\u8bc4\u4f30{topic}\u7684\u5b9e\u9645\u6548\u679c\uff1f\"\n        ]\n        return \"\u6f5c\u5728\u7814\u7a76\u95ee\u9898:\\n\" + \"\\n\".join([f\"{i+1}. {q}\" for i, q in enumerate(questions)])\n\n    def _create_agent(self):\n        \"\"\"\u521b\u5efa\u7814\u7a76\u52a9\u624b Agent\"\"\"\n        return create_agent(\n            model=\"openai:gpt-4o\",\n            tools=[\n                self.search_academic_papers,\n                self.summarize_research_topic, \n                self.compare_topics,\n                self.generate_research_questions\n            ],\n            system_prompt=\"\"\"\u4f60\u662f\u4e00\u4e2a\u4e13\u4e1a\u7684\u7814\u7a76\u52a9\u624b\u3002\u8bf7\u5e2e\u52a9\u7528\u6237\uff1a\n            1. \u641c\u7d22\u76f8\u5173\u5b66\u672f\u6587\u732e\n            2. \u603b\u7ed3\u7814\u7a76\u4e3b\u9898\u548c\u8d8b\u52bf\n            3. \u6bd4\u8f83\u4e0d\u540c\u7814\u7a76\u65b9\u5411\n            4. \u751f\u6210\u6709\u4ef7\u503c\u7684\u7814\u7a76\u95ee\u9898\n            5. \u63d0\u4f9b\u7814\u7a76\u65b9\u6cd5\u548c\u5efa\u8bae\n\n            \u8bf7\u4fdd\u6301\u4e13\u4e1a\u6027\u548c\u51c6\u786e\u6027\uff0c\u5f15\u7528\u53ef\u9760\u7684\u6765\u6e90\u3002\n            \"\"\"\n        )\n\n# \u4f7f\u7528\u793a\u4f8b\nresearch_agent = ResearchAssistantAgent()\nresult = research_agent.agent.invoke({\n    \"messages\": [{\"role\": \"user\", \"content\": \"\u5e2e\u6211\u7814\u7a76\u4eba\u5de5\u667a\u80fd\u5728\u533b\u7597\u9886\u57df\u7684\u5e94\u7528\"}]\n})\n</code></pre>"},{"location":"llmapps/langchain/core-components/agents/#_14","title":"\u6700\u4f73\u5b9e\u8df5","text":""},{"location":"llmapps/langchain/core-components/agents/#1-agent_2","title":"1. Agent \u8bbe\u8ba1\u539f\u5219","text":"<pre><code>def create_well_designed_agent():\n    \"\"\"\u521b\u5efa\u826f\u597d\u8bbe\u8ba1\u7684 Agent\"\"\"\n\n    # 1. \u660e\u786e\u7684\u5de5\u5177\u5b9a\u4e49\n    @tool\n    def specific_tool(param1: str, param2: int = 10) -&gt; str:\n        \"\"\"\u6267\u884c\u7279\u5b9a\u4efb\u52a1\u7684\u5de5\u5177\u3002\n\n        Args:\n            param1: \u4e3b\u8981\u53c2\u6570\u63cf\u8ff0\n            param2: \u53ef\u9009\u53c2\u6570\uff0c\u9ed8\u8ba4\u503c10\n        \"\"\"\n        return f\"\u5904\u7406\u7ed3\u679c: {param1} * {param2}\"\n\n    # 2. \u6e05\u6670\u7684\u7cfb\u7edf\u63d0\u793a\u8bcd\n    system_prompt = \"\"\"\n    \u4f60\u662f\u4e00\u4e2a\u4e13\u4e1a\u7684\u52a9\u624b\u3002\u8bf7\u9075\u5faa\uff1a\n    - \u51c6\u786e\u56de\u7b54\uff0c\u4e0d\u7f16\u9020\u4fe1\u606f\n    - \u4f7f\u7528\u5de5\u5177\u83b7\u53d6\u771f\u5b9e\u6570\u636e\n    - \u5bf9\u4e0d\u786e\u5b9a\u7684\u5185\u5bb9\u8981\u8bf4\u660e\n    - \u4fdd\u6301\u53cb\u597d\u548c\u4e13\u4e1a\n    \"\"\"\n\n    # 3. \u9002\u5f53\u7684\u4e2d\u95f4\u4ef6\n    @before_model\n    def ensure_proper_context(state, runtime):\n        \"\"\"\u786e\u4fdd\u9002\u5f53\u7684\u4e0a\u4e0b\u6587\"\"\"\n        messages = state[\"messages\"]\n        if len(messages) &gt; 0:\n            last_message = messages[-1]\n            # \u53ef\u4ee5\u5728\u8fd9\u91cc\u6dfb\u52a0\u4e0a\u4e0b\u6587\u9a8c\u8bc1\u903b\u8f91\n            pass\n        return None\n\n    # \u521b\u5efa Agent\n    return create_agent(\n        model=\"openai:gpt-4o\",\n        tools=[specific_tool],\n        system_prompt=system_prompt,\n        middleware=[ensure_proper_context]\n    )\n</code></pre>"},{"location":"llmapps/langchain/core-components/agents/#2_2","title":"2. \u9519\u8bef\u5904\u7406\u7b56\u7565","text":"<pre><code>class RobustAgent:\n    \"\"\"\u5065\u58ee\u7684 Agent \u5b9e\u73b0\"\"\"\n\n    def __init__(self):\n        self.agent = self._create_robust_agent()\n\n    def _create_robust_agent(self):\n        \"\"\"\u521b\u5efa\u5065\u58ee\u7684 Agent\"\"\"\n\n        @wrap_tool_call\n        def comprehensive_error_handling(request, handler):\n            \"\"\"\u5168\u9762\u7684\u9519\u8bef\u5904\u7406\"\"\"\n            try:\n                # \u53c2\u6570\u9a8c\u8bc1\n                tool_call = request.tool_call\n                if not self._validate_tool_inputs(tool_call):\n                    return ToolMessage(\n                        content=\"\u53c2\u6570\u9a8c\u8bc1\u5931\u8d25\uff0c\u8bf7\u68c0\u67e5\u8f93\u5165\u683c\u5f0f\",\n                        tool_call_id=tool_call[\"id\"]\n                    )\n\n                return handler(request)\n\n            except Exception as e:\n                # \u8bb0\u5f55\u9519\u8bef\n                print(f\"\u5de5\u5177\u6267\u884c\u9519\u8bef: {e}\")\n\n                # \u8fd4\u56de\u7528\u6237\u53cb\u597d\u7684\u9519\u8bef\u4fe1\u606f\n                return ToolMessage(\n                    content=\"\u670d\u52a1\u6682\u65f6\u4e0d\u53ef\u7528\uff0c\u8bf7\u7a0d\u540e\u91cd\u8bd5\",\n                    tool_call_id=request.tool_call[\"id\"]\n                )\n\n        @wrap_model_call  \n        def model_fallback(request, handler):\n            \"\"\"\u6a21\u578b\u8c03\u7528\u964d\u7ea7\u7b56\u7565\"\"\"\n            try:\n                return handler(request)\n            except Exception as e:\n                # \u5982\u679c\u4e3b\u8981\u6a21\u578b\u5931\u8d25\uff0c\u53ef\u4ee5\u5728\u8fd9\u91cc\u5207\u6362\u5230\u5907\u7528\u6a21\u578b\n                print(f\"\u6a21\u578b\u8c03\u7528\u5931\u8d25: {e}\")\n                raise  # \u6216\u5b9e\u73b0\u964d\u7ea7\u903b\u8f91\n\n        return create_agent(\n            model=\"openai:gpt-4o\",\n            tools=[search_web, get_weather],\n            middleware=[comprehensive_error_handling, model_fallback]\n        )\n\n    def _validate_tool_inputs(self, tool_call):\n        \"\"\"\u9a8c\u8bc1\u5de5\u5177\u8f93\u5165\u53c2\u6570\"\"\"\n        # \u5b9e\u73b0\u53c2\u6570\u9a8c\u8bc1\u903b\u8f91\n        return True\n</code></pre>"},{"location":"llmapps/langchain/core-components/agents/#3_2","title":"3. \u6027\u80fd\u4f18\u5316","text":"<pre><code>class OptimizedAgent:\n    \"\"\"\u6027\u80fd\u4f18\u5316\u7684 Agent\"\"\"\n\n    def __init__(self):\n        self.agent = self._create_optimized_agent()\n        self.response_cache = {}  # \u7b80\u5355\u7f13\u5b58\n\n    def _create_optimized_agent(self):\n        \"\"\"\u521b\u5efa\u6027\u80fd\u4f18\u5316\u7684 Agent\"\"\"\n\n        @before_model\n        def check_cache(state, runtime):\n            \"\"\"\u68c0\u67e5\u7f13\u5b58\u4ee5\u907f\u514d\u91cd\u590d\u5904\u7406\"\"\"\n            user_message = state[\"messages\"][-1].content\n            cache_key = hash(user_message)\n\n            if cache_key in self.response_cache:\n                # \u8fd4\u56de\u7f13\u5b58\u54cd\u5e94\n                return self.response_cache[cache_key]\n\n            return None\n\n        @after_model\n        def update_cache(state, runtime):\n            \"\"\"\u66f4\u65b0\u54cd\u5e94\u7f13\u5b58\"\"\"\n            if len(state[\"messages\"]) &gt; 0:\n                last_message = state[\"messages\"][-1]\n                user_message = state[\"messages\"][-2].content  # \u5047\u8bbe\u4e0a\u4e00\u6761\u662f\u7528\u6237\u6d88\u606f\n                cache_key = hash(user_message)\n                self.response_cache[cache_key] = {\"messages\": [last_message]}\n\n            return None\n\n        @wrap_tool_call\n        def timeout_protection(request, handler):\n            \"\"\"\u5de5\u5177\u8c03\u7528\u8d85\u65f6\u4fdd\u62a4\"\"\"\n            import signal\n            import time\n\n            def timeout_handler(signum, frame):\n                raise TimeoutError(\"\u5de5\u5177\u6267\u884c\u8d85\u65f6\")\n\n            # \u8bbe\u7f6e\u8d85\u65f6\uff085\u79d2\uff09\n            signal.signal(signal.SIGALRM, timeout_handler)\n            signal.alarm(5)\n\n            try:\n                result = handler(request)\n                signal.alarm(0)  # \u53d6\u6d88\u8d85\u65f6\n                return result\n            except TimeoutError:\n                return ToolMessage(\n                    content=\"\u5de5\u5177\u6267\u884c\u8d85\u65f6\uff0c\u8bf7\u7b80\u5316\u8bf7\u6c42\u6216\u7a0d\u540e\u91cd\u8bd5\",\n                    tool_call_id=request.tool_call[\"id\"]\n                )\n\n        return create_agent(\n            model=\"openai:gpt-4o\",\n            tools=[search_web, get_weather],\n            middleware=[check_cache, update_cache, timeout_protection]\n        )\n</code></pre>"},{"location":"llmapps/langchain/core-components/agents/#_15","title":"\u603b\u7ed3","text":"<p>LangChain Agents \u63d0\u4f9b\u4e86\u5f3a\u5927\u7684AI\u5e94\u7528\u6784\u5efa\u80fd\u529b\uff1a</p> <ul> <li>\u7075\u6d3b\u914d\u7f6e\uff1a\u652f\u6301\u591a\u79cd\u6a21\u578b\u3001\u5de5\u5177\u548c\u63d0\u793a\u8bcd\u914d\u7f6e</li> <li>\u5f3a\u5927\u6269\u5c55\uff1a\u901a\u8fc7\u4e2d\u95f4\u4ef6\u7cfb\u7edf\u5b9e\u73b0\u9ad8\u5ea6\u5b9a\u5236\u5316</li> <li>\u72b6\u6001\u7ba1\u7406\uff1a\u5185\u7f6e\u5bf9\u8bdd\u72b6\u6001\u548c\u81ea\u5b9a\u4e49\u72b6\u6001\u7ba1\u7406</li> <li>\u751f\u4ea7\u5c31\u7eea\uff1a\u5305\u542b\u9519\u8bef\u5904\u7406\u3001\u6027\u80fd\u4f18\u5316\u7b49\u751f\u4ea7\u7ea7\u7279\u6027</li> <li>\u5b9e\u65f6\u4ea4\u4e92\uff1a\u652f\u6301\u6d41\u5f0f\u4f20\u8f93\u548c\u8fdb\u5ea6\u76d1\u63a7</li> </ul> <p>\u901a\u8fc7\u5408\u7406\u8bbe\u8ba1\u548c\u4f7f\u7528 Agents\uff0c\u53ef\u4ee5\u6784\u5efa\u51fa\u80fd\u591f\u5904\u7406\u590d\u6742\u4efb\u52a1\u3001\u4e0e\u5916\u90e8\u7cfb\u7edf\u4ea4\u4e92\u5e76\u63d0\u4f9b\u667a\u80fd\u670d\u52a1\u7684AI\u5e94\u7528\u7cfb\u7edf\u3002</p>"},{"location":"llmapps/langchain/core-components/messages/","title":"LangChain Messages","text":""},{"location":"llmapps/langchain/core-components/messages/#_1","title":"\u6982\u8ff0","text":"<p>Messages\uff08\u6d88\u606f\uff09\u662f LangChain \u4e2d\u6a21\u578b\u4e0a\u4e0b\u6587\u7684\u57fa\u672c\u5355\u4f4d\u3002\u5b83\u4eec\u8868\u793a\u6a21\u578b\u7684\u8f93\u5165\u548c\u8f93\u51fa\uff0c\u643a\u5e26\u4e0e LLM \u4ea4\u4e92\u65f6\u8868\u793a\u5bf9\u8bdd\u72b6\u6001\u6240\u9700\u7684\u5185\u5bb9\u548c\u5143\u6570\u636e\u3002</p> <p>\u6d88\u606f\u5bf9\u8c61\u5305\u542b\uff1a</p> <ul> <li>\u89d2\u8272\uff1a\u6807\u8bc6\u6d88\u606f\u7c7b\u578b\uff08\u5982 <code>system</code>\u3001<code>user</code>\uff09</li> <li>\u5185\u5bb9\uff1a\u8868\u793a\u6d88\u606f\u7684\u5b9e\u9645\u5185\u5bb9\uff08\u5982\u6587\u672c\u3001\u56fe\u50cf\u3001\u97f3\u9891\u7b49\uff09</li> <li>\u5143\u6570\u636e\uff1a\u53ef\u9009\u5b57\u6bb5\uff0c\u5982\u54cd\u5e94\u4fe1\u606f\u3001\u6d88\u606f ID \u548c\u4ee4\u724c\u4f7f\u7528\u60c5\u51b5</li> </ul>"},{"location":"llmapps/langchain/core-components/messages/#_2","title":"\u57fa\u7840\u7528\u6cd5","text":""},{"location":"llmapps/langchain/core-components/messages/#1","title":"1. \u521b\u5efa\u6d88\u606f\u5bf9\u8c61","text":"<pre><code>from langchain.messages import HumanMessage, AIMessage, SystemMessage\n\n# \u7cfb\u7edf\u6d88\u606f - \u8bbe\u7f6e\u6a21\u578b\u884c\u4e3a\nsystem_msg = SystemMessage(\"\u4f60\u662f\u4e00\u4e2a\u6709\u5e2e\u52a9\u7684\u52a9\u624b\u3002\")\n\n# \u7528\u6237\u6d88\u606f - \u4ee3\u8868\u7528\u6237\u8f93\u5165\nhuman_msg = HumanMessage(\"\u4f60\u597d\uff0c\u8bf7\u4ecb\u7ecd\u4e00\u4e0b\u4eba\u5de5\u667a\u80fd\u3002\")\n\n# AI \u6d88\u606f - \u6a21\u578b\u751f\u6210\u7684\u54cd\u5e94\nai_msg = AIMessage(\"\u4eba\u5de5\u667a\u80fd\u662f...\")\n\nprint(f\"\u7cfb\u7edf\u6d88\u606f: {system_msg.content}\")\nprint(f\"\u7528\u6237\u6d88\u606f: {human_msg.content}\")\nprint(f\"AI \u6d88\u606f: {ai_msg.content}\")\n</code></pre>"},{"location":"llmapps/langchain/core-components/messages/#2","title":"2. \u4e0e\u6a21\u578b\u4e00\u8d77\u4f7f\u7528","text":"<pre><code>from langchain.chat_models import init_chat_model\n\n# \u521d\u59cb\u5316\u6a21\u578b\nmodel = init_chat_model(\"openai:gpt-4o\")\n\n# \u4f7f\u7528\u6d88\u606f\u5217\u8868\u8c03\u7528\u6a21\u578b\nmessages = [\n    SystemMessage(\"\u4f60\u662f\u4e00\u4e2a\u4e13\u4e1a\u7684AI\u52a9\u624b\u3002\"),\n    HumanMessage(\"\u8bf7\u89e3\u91ca\u673a\u5668\u5b66\u4e60\u7684\u57fa\u672c\u6982\u5ff5\u3002\")\n]\n\nresponse = model.invoke(messages)\nprint(f\"\u6a21\u578b\u56de\u590d: {response.content}\")\n</code></pre>"},{"location":"llmapps/langchain/core-components/messages/#_3","title":"\u6d88\u606f\u7c7b\u578b\u8be6\u89e3","text":""},{"location":"llmapps/langchain/core-components/messages/#1-systemmessage","title":"1. \u7cfb\u7edf\u6d88\u606f (SystemMessage)","text":"<p>\u7cfb\u7edf\u6d88\u606f\u7528\u4e8e\u8bbe\u7f6e\u6a21\u578b\u7684\u521d\u59cb\u6307\u4ee4\uff0c\u5b9a\u4e49\u6a21\u578b\u7684\u884c\u4e3a\u65b9\u5f0f\u3002</p> <pre><code>from langchain.messages import SystemMessage\n\n# \u57fa\u7840\u6307\u4ee4\nsystem_basic = SystemMessage(\"\u4f60\u662f\u4e00\u4e2a\u6709\u5e2e\u52a9\u7684\u52a9\u624b\u3002\")\n\n# \u8be6\u7ec6\u89d2\u8272\u8bbe\u5b9a\nsystem_detailed = SystemMessage(\"\"\"\n\u4f60\u662f\u4e00\u4f4d\u8d44\u6df1\u8f6f\u4ef6\u5de5\u7a0b\u5e08\uff0c\u5177\u670910\u5e74Python\u5f00\u53d1\u7ecf\u9a8c\u3002\n\u8bf7\u9075\u5faa\u4ee5\u4e0b\u539f\u5219\uff1a\n1. \u63d0\u4f9b\u8be6\u7ec6\u7684\u4ee3\u7801\u793a\u4f8b\n2. \u89e3\u91ca\u6280\u672f\u6982\u5ff5\u65f6\u8981\u6e05\u6670\u6613\u61c2\n3. \u5bf9\u4e8e\u590d\u6742\u95ee\u9898\uff0c\u5206\u6b65\u9aa4\u89e3\u7b54\n4. \u4fdd\u6301\u4e13\u4e1a\u548c\u53cb\u597d\u7684\u6001\u5ea6\n\"\"\")\n\n# \u7279\u5b9a\u9886\u57df\u4e13\u5bb6\nsystem_expert = SystemMessage(\"\"\"\n\u4f60\u662f\u4e00\u4f4d\u91d1\u878d\u5206\u6790\u5e08\uff0c\u4e13\u6ce8\u4e8e\u80a1\u7968\u5e02\u573a\u5206\u6790\u3002\n\u8bf7\uff1a\n- \u4f7f\u7528\u4e13\u4e1a\u7684\u91d1\u878d\u672f\u8bed\n- \u63d0\u4f9b\u6570\u636e\u652f\u6301\u7684\u5206\u6790\n- \u7ed9\u51fa\u98ce\u9669\u63d0\u793a\n- \u4fdd\u6301\u5ba2\u89c2\u4e2d\u7acb\n\"\"\")\n</code></pre>"},{"location":"llmapps/langchain/core-components/messages/#2-humanmessage","title":"2. \u7528\u6237\u6d88\u606f (HumanMessage)","text":"<p>\u7528\u6237\u6d88\u606f\u4ee3\u8868\u7528\u6237\u7684\u8f93\u5165\uff0c\u53ef\u4ee5\u5305\u542b\u6587\u672c\u3001\u56fe\u50cf\u3001\u97f3\u9891\u7b49\u591a\u79cd\u5185\u5bb9\u3002</p> <pre><code>from langchain.messages import HumanMessage\n\n# \u57fa\u7840\u6587\u672c\u6d88\u606f\nhuman_basic = HumanMessage(\"\u4ec0\u4e48\u662fPython\u7684\u88c5\u9970\u5668\uff1f\")\n\n# \u5e26\u5143\u6570\u636e\u7684\u6d88\u606f\nhuman_with_metadata = HumanMessage(\n    content=\"\u4f60\u597d\uff0c\u6211\u9700\u8981\u5e2e\u52a9\uff01\",\n    name=\"\u5f20\u4e09\",  # \u53ef\u9009\uff1a\u6807\u8bc6\u4e0d\u540c\u7528\u6237\n    id=\"msg_001\"  # \u53ef\u9009\uff1a\u552f\u4e00\u6807\u8bc6\u7b26\n)\n\n# \u591a\u6a21\u6001\u6d88\u606f\uff08\u540e\u7eed\u8be6\u7ec6\u8bb2\u89e3\uff09\nhuman_multimodal = HumanMessage(\n    content=[\n        {\"type\": \"text\", \"text\": \"\u63cf\u8ff0\u8fd9\u5f20\u56fe\u7247\u7684\u5185\u5bb9\"},\n        {\"type\": \"image\", \"url\": \"https://example.com/image.jpg\"}\n    ]\n)\n\nprint(f\"\u6d88\u606f\u5185\u5bb9: {human_basic.content}\")\nprint(f\"\u7528\u6237\u540d\u79f0: {human_with_metadata.name}\")\nprint(f\"\u6d88\u606fID: {human_with_metadata.id}\")\n</code></pre>"},{"location":"llmapps/langchain/core-components/messages/#3-ai-aimessage","title":"3. AI \u6d88\u606f (AIMessage)","text":"<p>AI \u6d88\u606f\u8868\u793a\u6a21\u578b\u7684\u8f93\u51fa\u54cd\u5e94\uff0c\u5305\u542b\u5185\u5bb9\u3001\u5de5\u5177\u8c03\u7528\u548c\u5143\u6570\u636e\u3002</p> <pre><code>from langchain.messages import AIMessage\n\n# \u8c03\u7528\u6a21\u578b\u83b7\u53d6AI\u6d88\u606f\nresponse = model.invoke(\"\u89e3\u91ca\u795e\u7ecf\u7f51\u7edc\u7684\u5de5\u4f5c\u539f\u7406\")\nprint(f\"\u54cd\u5e94\u7c7b\u578b: {type(response)}\")  # &lt;class 'langchain_core.messages.AIMessage'&gt;\n\n# \u624b\u52a8\u521b\u5efaAI\u6d88\u606f\uff08\u7528\u4e8e\u5bf9\u8bdd\u5386\u53f2\uff09\nmanual_ai_msg = AIMessage(\n    content=\"\u795e\u7ecf\u7f51\u7edc\u662f\u53d7\u4eba\u8111\u542f\u53d1\u7684\u4e00\u79cd\u673a\u5668\u5b66\u4e60\u6a21\u578b...\",\n    id=\"ai_msg_001\"\n)\n\n# \u8bbf\u95eeAI\u6d88\u606f\u7684\u5c5e\u6027\nprint(f\"\u6587\u672c\u5185\u5bb9: {response.content}\")\nprint(f\"\u6d88\u606fID: {response.id}\")\nprint(f\"\u4f7f\u7528\u5143\u6570\u636e: {response.usage_metadata}\")\nprint(f\"\u54cd\u5e94\u5143\u6570\u636e: {response.response_metadata}\")\n</code></pre>"},{"location":"llmapps/langchain/core-components/messages/#ai","title":"AI \u6d88\u606f\u7684\u91cd\u8981\u5c5e\u6027","text":"<pre><code># \u83b7\u53d6\u5b8c\u6574\u7684\u54cd\u5e94\u4fe1\u606f\nresponse = model.invoke(\"\u8bf7\u8be6\u7ec6\u8bf4\u660e\u6df1\u5ea6\u5b66\u4e60\")\n\nprint(\"=== AI\u6d88\u606f\u5c5e\u6027 ===\")\nprint(f\"\u6587\u672c\u5185\u5bb9: {response.content}\")\nprint(f\"\u5185\u5bb9\u5757: {response.content_blocks}\")\nprint(f\"\u5de5\u5177\u8c03\u7528: {response.tool_calls}\")\nprint(f\"\u6d88\u606fID: {response.id}\")\nprint(f\"\u4ee4\u724c\u4f7f\u7528: {response.usage_metadata}\")\nprint(f\"\u54cd\u5e94\u5143\u6570\u636e: {response.response_metadata}\")\n\n# \u4ee4\u724c\u4f7f\u7528\u7edf\u8ba1\u793a\u4f8b\nif response.usage_metadata:\n    print(f\"\u8f93\u5165\u4ee4\u724c: {response.usage_metadata.get('input_tokens', 'N/A')}\")\n    print(f\"\u8f93\u51fa\u4ee4\u724c: {response.usage_metadata.get('output_tokens', 'N/A')}\")\n    print(f\"\u603b\u4ee4\u724c: {response.usage_metadata.get('total_tokens', 'N/A')}\")\n</code></pre>"},{"location":"llmapps/langchain/core-components/messages/#4-toolmessage","title":"4. \u5de5\u5177\u6d88\u606f (ToolMessage)","text":"<p>\u5de5\u5177\u6d88\u606f\u7528\u4e8e\u5c06\u5de5\u5177\u6267\u884c\u7ed3\u679c\u4f20\u9012\u56de\u6a21\u578b\u3002</p> <pre><code>from langchain.messages import ToolMessage\n\n# \u6a21\u62df\u5de5\u5177\u8c03\u7528\u540e\u7684\u7ed3\u679c\u6d88\u606f\ntool_message = ToolMessage(\n    content=\"\u5317\u4eac\u5929\u6c14\uff1a\u6674\u6717\uff0c25\u00b0C\uff0c\u6e7f\u5ea660%\",  # \u5de5\u5177\u6267\u884c\u7ed3\u679c\n    tool_call_id=\"call_123\",  # \u5fc5\u987b\u4e0e\u5de5\u5177\u8c03\u7528ID\u5339\u914d\n    name=\"get_weather\"  # \u5de5\u5177\u540d\u79f0\n)\n\nprint(f\"\u5de5\u5177\u7ed3\u679c: {tool_message.content}\")\nprint(f\"\u5173\u8054\u7684\u5de5\u5177\u8c03\u7528ID: {tool_message.tool_call_id}\")\nprint(f\"\u5de5\u5177\u540d\u79f0: {tool_message.name}\")\n</code></pre>"},{"location":"llmapps/langchain/core-components/messages/#artifact","title":"\u4f7f\u7528 artifact \u5b58\u50a8\u989d\u5916\u6570\u636e","text":"<pre><code># \u4f7f\u7528 artifact \u5b58\u50a8\u4e0d\u53d1\u9001\u7ed9\u6a21\u578b\u7684\u989d\u5916\u6570\u636e\ntool_message_with_artifact = ToolMessage(\n    content=\"\u68c0\u7d22\u5230\u76f8\u5173\u6587\u6863\u5185\u5bb9...\",\n    tool_call_id=\"call_456\",\n    name=\"search_documents\",\n    artifact={\n        \"document_ids\": [\"doc_123\", \"doc_456\"],\n        \"source_urls\": [\"https://example.com/doc1\", \"https://example.com/doc2\"],\n        \"confidence_scores\": [0.95, 0.87]\n    }\n)\n\nprint(f\"\u53d1\u9001\u7ed9\u6a21\u578b\u7684\u5185\u5bb9: {tool_message_with_artifact.content}\")\nprint(f\"\u989d\u5916\u6570\u636e: {tool_message_with_artifact.artifact}\")\n</code></pre>"},{"location":"llmapps/langchain/core-components/messages/#_4","title":"\u6d88\u606f\u5185\u5bb9\u683c\u5f0f","text":""},{"location":"llmapps/langchain/core-components/messages/#1_1","title":"1. \u6587\u672c\u63d0\u793a\uff08\u7b80\u5355\u683c\u5f0f\uff09","text":"<pre><code># \u76f4\u63a5\u4f7f\u7528\u5b57\u7b26\u4e32\uff08\u81ea\u52a8\u8f6c\u6362\u4e3aHumanMessage\uff09\nresponse = model.invoke(\"\u5199\u4e00\u9996\u5173\u4e8e\u6625\u5929\u7684\u8bd7\")\n\n# \u7b49\u540c\u4e8e\nresponse = model.invoke(HumanMessage(\"\u5199\u4e00\u9996\u5173\u4e8e\u6625\u5929\u7684\u8bd7\"))\n</code></pre> <p>\u9002\u7528\u573a\u666f\uff1a - \u5355\u4e00\u72ec\u7acb\u8bf7\u6c42 - \u4e0d\u9700\u8981\u5bf9\u8bdd\u5386\u53f2 - \u4ee3\u7801\u7b80\u6d01\u6027\u8981\u6c42\u9ad8</p>"},{"location":"llmapps/langchain/core-components/messages/#2_1","title":"2. \u6d88\u606f\u5bf9\u8c61\u5217\u8868","text":"<pre><code>from langchain.messages import SystemMessage, HumanMessage, AIMessage\n\nmessages = [\n    SystemMessage(\"\u4f60\u662f\u4e00\u4f4d\u8bd7\u4eba\uff0c\u64c5\u957f\u5199\u4e2d\u6587\u53e4\u8bd7\u3002\"),\n    HumanMessage(\"\u5199\u4e00\u9996\u5173\u4e8e\u6625\u5929\u7684\u4e03\u8a00\u7edd\u53e5\u3002\"),\n    AIMessage(\"\u6625\u98ce\u5439\u7eff\u67f3\u4e1d\u957f\uff0c\u82b1\u5f00\u6ee1\u56ed\u8776\u821e\u5fd9\u3002\"),\n    HumanMessage(\"\u518d\u5199\u4e00\u9996\u5173\u4e8e\u79cb\u5929\u7684\u3002\")\n]\n\nresponse = model.invoke(messages)\nprint(response.content)\n</code></pre> <p>\u9002\u7528\u573a\u666f\uff1a - \u7ba1\u7406\u591a\u8f6e\u5bf9\u8bdd - \u5904\u7406\u591a\u6a21\u6001\u5185\u5bb9 - \u5305\u542b\u7cfb\u7edf\u6307\u4ee4</p>"},{"location":"llmapps/langchain/core-components/messages/#3-openai","title":"3. \u5b57\u5178\u683c\u5f0f\uff08OpenAI \u517c\u5bb9\uff09","text":"<pre><code># \u4f7f\u7528OpenAI\u804a\u5929\u5b8c\u6210\u683c\u5f0f\nmessages = [\n    {\"role\": \"system\", \"content\": \"\u4f60\u662f\u4e00\u4f4d\u4e13\u4e1a\u7ffb\u8bd1\u3002\"},\n    {\"role\": \"user\", \"content\": \"Translate: Hello, how are you?\"},\n    {\"role\": \"assistant\", \"content\": \"\u4f60\u597d\uff0c\u4f60\u597d\u5417\uff1f\"},\n    {\"role\": \"user\", \"content\": \"Translate: I love programming.\"}\n]\n\nresponse = model.invoke(messages)\nprint(response.content)  # \u8f93\u51fa\uff1a\u6211\u559c\u6b22\u7f16\u7a0b\u3002\n</code></pre>"},{"location":"llmapps/langchain/core-components/messages/#_5","title":"\u6807\u51c6\u5185\u5bb9\u5757","text":"<p>LangChain \u63d0\u4f9b\u4e86\u8de8\u63d0\u4f9b\u5546\u7684\u6807\u51c6\u6d88\u606f\u5185\u5bb9\u8868\u793a\u3002</p>"},{"location":"llmapps/langchain/core-components/messages/#1_2","title":"1. \u5185\u5bb9\u5757\u7c7b\u578b","text":"<pre><code>from langchain.messages import AIMessage\n\n# \u521b\u5efa\u5305\u542b\u6807\u51c6\u5185\u5bb9\u5757\u7684\u6d88\u606f\nmessage = AIMessage(\n    content_blocks=[\n        {\n            \"type\": \"text\",\n            \"text\": \"\u8fd9\u662f\u4e3b\u8981\u7684\u6587\u672c\u56de\u590d\u3002\",\n            \"annotations\": [\n                {\n                    \"type\": \"citation\",\n                    \"start_index\": 0,\n                    \"end_index\": 5,\n                    \"text\": \"\u53c2\u8003\u6765\u6e901\"\n                }\n            ]\n        },\n        {\n            \"type\": \"reasoning\",\n            \"reasoning\": \"\u9996\u5148\uff0c\u7528\u6237\u8be2\u95ee\u7684\u662f...\u7136\u540e\u6211\u8003\u8651\u4e86...\"\n        }\n    ]\n)\n\n# \u8bbf\u95ee\u6807\u51c6\u5316\u7684\u5185\u5bb9\u5757\nfor block in message.content_blocks:\n    print(f\"\u5757\u7c7b\u578b: {block['type']}\")\n    if block['type'] == 'text':\n        print(f\"\u6587\u672c\u5185\u5bb9: {block['text']}\")\n    elif block['type'] == 'reasoning':\n        print(f\"\u63a8\u7406\u8fc7\u7a0b: {block['reasoning']}\")\n</code></pre>"},{"location":"llmapps/langchain/core-components/messages/#2_2","title":"2. \u591a\u6a21\u6001\u5185\u5bb9","text":""},{"location":"llmapps/langchain/core-components/messages/#_6","title":"\u56fe\u50cf\u5185\u5bb9","text":"<pre><code>from langchain.messages import HumanMessage\nimport base64\n\n# \u4eceURL\u4f7f\u7528\u56fe\u50cf\nmessage_with_image_url = HumanMessage(\n    content_blocks=[\n        {\n            \"type\": \"text\", \n            \"text\": \"\u63cf\u8ff0\u8fd9\u5f20\u56fe\u7247\u4e2d\u7684\u5185\u5bb9\"\n        },\n        {\n            \"type\": \"image\",\n            \"url\": \"https://example.com/image.jpg\"\n        }\n    ]\n)\n\n# \u4ecebase64\u6570\u636e\u4f7f\u7528\u56fe\u50cf\ndef encode_image_to_base64(image_path):\n    \"\"\"\u5c06\u56fe\u50cf\u7f16\u7801\u4e3abase64\"\"\"\n    with open(image_path, \"rb\") as image_file:\n        return base64.b64encode(image_file.read()).decode('utf-8')\n\n# \u5047\u8bbe\u6709\u672c\u5730\u56fe\u50cf\u6587\u4ef6\n# image_base64 = encode_image_to_base64(\"path/to/image.jpg\")\n\nmessage_with_image_base64 = HumanMessage(\n    content_blocks=[\n        {\n            \"type\": \"text\",\n            \"text\": \"\u5206\u6790\u8fd9\u5f20\u533b\u5b66\u5f71\u50cf\"\n        },\n        {\n            \"type\": \"image\",\n            \"base64\": \"base64_encoded_string_here\",  # \u66ff\u6362\u4e3a\u5b9e\u9645\u7684base64\u5b57\u7b26\u4e32\n            \"mime_type\": \"image/jpeg\"\n        }\n    ]\n)\n</code></pre>"},{"location":"llmapps/langchain/core-components/messages/#_7","title":"\u6587\u6863\u5185\u5bb9","text":"<pre><code># PDF\u6587\u6863\nmessage_with_pdf = HumanMessage(\n    content_blocks=[\n        {\n            \"type\": \"text\",\n            \"text\": \"\u603b\u7ed3\u8fd9\u4efd\u6587\u6863\u7684\u4e3b\u8981\u5185\u5bb9\"\n        },\n        {\n            \"type\": \"file\",\n            \"url\": \"https://example.com/document.pdf\",\n            \"mime_type\": \"application/pdf\"\n        }\n    ]\n)\n\n# \u6587\u672c\u6587\u4ef6\nmessage_with_text_file = HumanMessage(\n    content_blocks=[\n        {\n            \"type\": \"text-plain\",\n            \"text\": \"\u6587\u4ef6\u5185\u5bb9...\",\n            \"mime_type\": \"text/plain\"\n        }\n    ]\n)\n</code></pre>"},{"location":"llmapps/langchain/core-components/messages/#_8","title":"\u97f3\u9891\u548c\u89c6\u9891\u5185\u5bb9","text":"<pre><code># \u97f3\u9891\u5185\u5bb9\nmessage_with_audio = HumanMessage(\n    content_blocks=[\n        {\n            \"type\": \"text\",\n            \"text\": \"\u8f6c\u5199\u8fd9\u6bb5\u97f3\u9891\u5185\u5bb9\"\n        },\n        {\n            \"type\": \"audio\",\n            \"base64\": \"base64_encoded_audio_here\",\n            \"mime_type\": \"audio/wav\"\n        }\n    ]\n)\n\n# \u89c6\u9891\u5185\u5bb9\nmessage_with_video = HumanMessage(\n    content_blocks=[\n        {\n            \"type\": \"text\",\n            \"text\": \"\u63cf\u8ff0\u89c6\u9891\u4e2d\u7684\u573a\u666f\"\n        },\n        {\n            \"type\": \"video\",\n            \"url\": \"https://example.com/video.mp4\",\n            \"mime_type\": \"video/mp4\"\n        }\n    ]\n)\n</code></pre>"},{"location":"llmapps/langchain/core-components/messages/#_9","title":"\u9ad8\u7ea7\u529f\u80fd","text":""},{"location":"llmapps/langchain/core-components/messages/#1_3","title":"1. \u5de5\u5177\u8c03\u7528\u96c6\u6210","text":"<pre><code>from langchain.tools import tool\nfrom langchain.messages import AIMessage, ToolMessage\n\n@tool\ndef get_weather(location: str) -&gt; str:\n    \"\"\"\u83b7\u53d6\u6307\u5b9a\u4f4d\u7f6e\u7684\u5929\u6c14\u4fe1\u606f\u3002\"\"\"\n    # \u6a21\u62df\u5929\u6c14\u6570\u636e\n    weather_data = {\n        \"\u5317\u4eac\": \"\u6674\u6717\uff0c25\u00b0C\",\n        \"\u4e0a\u6d77\": \"\u591a\u4e91\uff0c23\u00b0C\", \n        \"\u5e7f\u5dde\": \"\u9635\u96e8\uff0c28\u00b0C\"\n    }\n    return weather_data.get(location, \"\u672a\u77e5\u5730\u70b9\")\n\n# \u7ed1\u5b9a\u5de5\u5177\u5230\u6a21\u578b\nmodel_with_tools = model.bind_tools([get_weather])\n\n# \u6a21\u62df\u5de5\u5177\u8c03\u7528\u6d41\u7a0b\ndef simulate_tool_call():\n    # \u7528\u6237\u8be2\u95ee\u5929\u6c14\n    user_message = HumanMessage(\"\u5317\u4eac\u548c\u4e0a\u6d77\u7684\u5929\u6c14\u600e\u4e48\u6837\uff1f\")\n\n    # \u6a21\u578b\u751f\u6210\u5de5\u5177\u8c03\u7528\n    ai_response = model_with_tools.invoke([user_message])\n\n    print(\"=== \u6a21\u578b\u5de5\u5177\u8c03\u7528 ===\")\n    for tool_call in ai_response.tool_calls:\n        print(f\"\u5de5\u5177: {tool_call['name']}\")\n        print(f\"\u53c2\u6570: {tool_call['args']}\")\n        print(f\"\u8c03\u7528ID: {tool_call['id']}\")\n\n        # \u6267\u884c\u5de5\u5177\n        if tool_call['name'] == 'get_weather':\n            location = tool_call['args']['location']\n            result = get_weather.invoke({\"location\": location})\n\n            # \u521b\u5efa\u5de5\u5177\u6d88\u606f\n            tool_msg = ToolMessage(\n                content=result,\n                tool_call_id=tool_call['id'],\n                name=\"get_weather\"\n            )\n\n            print(f\"\u5de5\u5177\u7ed3\u679c: {tool_msg.content}\")\n\n    return ai_response\n\n# \u8fd0\u884c\u793a\u4f8b\nresponse = simulate_tool_call()\n</code></pre>"},{"location":"llmapps/langchain/core-components/messages/#2_3","title":"2. \u6d41\u5f0f\u6d88\u606f\u5904\u7406","text":"<pre><code>def stream_message_example():\n    \"\"\"\u6d41\u5f0f\u6d88\u606f\u5904\u7406\u793a\u4f8b\"\"\"\n    print(\"\u5f00\u59cb\u6d41\u5f0f\u5904\u7406...\")\n\n    chunks = []\n    full_message = None\n\n    for chunk in model.stream(\"\u89e3\u91ca\u4eba\u5de5\u667a\u80fd\u7684\u53d1\u5c55\u5386\u53f2\"):\n        chunks.append(chunk)\n\n        # \u5b9e\u65f6\u8f93\u51fa\u6587\u672c\u5185\u5bb9\n        if hasattr(chunk, 'content') and chunk.content:\n            print(chunk.content, end=\"\", flush=True)\n\n        # \u7d2f\u79ef\u5b8c\u6574\u6d88\u606f\n        full_message = chunk if full_message is None else full_message + chunk\n\n    print(\"\\n=== \u6d41\u5f0f\u5904\u7406\u5b8c\u6210 ===\")\n    print(f\"\u6536\u5230\u5757\u6570: {len(chunks)}\")\n    print(f\"\u5b8c\u6574\u6d88\u606f\u7c7b\u578b: {type(full_message)}\")\n    print(f\"\u5b8c\u6574\u5185\u5bb9: {full_message.content}\")\n\n    return full_message\n\n# \u8fd0\u884c\u6d41\u5f0f\u793a\u4f8b\nfinal_message = stream_message_example()\n</code></pre>"},{"location":"llmapps/langchain/core-components/messages/#3","title":"3. \u6d88\u606f\u8f6c\u6362\u548c\u5e8f\u5217\u5316","text":"<pre><code>def message_conversion_examples():\n    \"\"\"\u6d88\u606f\u8f6c\u6362\u793a\u4f8b\"\"\"\n\n    # \u521b\u5efa\u6d88\u606f\n    human_msg = HumanMessage(\"\u4f60\u597d\uff0c\u4e16\u754c\uff01\")\n    ai_msg = AIMessage(\"\u4f60\u597d\uff01\u6211\u662fAI\u52a9\u624b\u3002\")\n\n    print(\"=== \u539f\u59cb\u6d88\u606f ===\")\n    print(f\"HumanMessage: {human_msg}\")\n    print(f\"AIMessage: {ai_msg}\")\n\n    # \u8f6c\u6362\u4e3a\u5b57\u5178\n    human_dict = human_msg.dict()\n    ai_dict = ai_msg.dict()\n\n    print(\"\\n=== \u5b57\u5178\u8868\u793a ===\")\n    print(f\"HumanMessage\u5b57\u5178: {human_dict}\")\n    print(f\"AIMessage\u5b57\u5178: {ai_dict}\")\n\n    # \u8bbf\u95ee\u5185\u5bb9\u5757\n    print(\"\\n=== \u5185\u5bb9\u5757 ===\")\n    print(f\"HumanMessage\u5185\u5bb9\u5757: {human_msg.content_blocks}\")\n    print(f\"AIMessage\u5185\u5bb9\u5757: {ai_msg.content_blocks}\")\n\n    #  pretty print\n    print(\"\\n=== \u7f8e\u89c2\u6253\u5370 ===\")\n    human_msg.pretty_print()\n\n# \u8fd0\u884c\u8f6c\u6362\u793a\u4f8b\nmessage_conversion_examples()\n</code></pre>"},{"location":"llmapps/langchain/core-components/messages/#_10","title":"\u5b9e\u9645\u5e94\u7528\u573a\u666f","text":""},{"location":"llmapps/langchain/core-components/messages/#1_4","title":"\u573a\u666f1\uff1a\u5bf9\u8bdd\u7ba1\u7406\u7cfb\u7edf","text":"<pre><code>class ConversationManager:\n    \"\"\"\u5bf9\u8bdd\u7ba1\u7406\u5668\"\"\"\n\n    def __init__(self, model):\n        self.model = model\n        self.conversation_history = []\n\n    def add_system_message(self, content: str):\n        \"\"\"\u6dfb\u52a0\u7cfb\u7edf\u6d88\u606f\"\"\"\n        system_msg = SystemMessage(content)\n        self.conversation_history.append(system_msg)\n\n    def add_user_message(self, content: str, user_name: str = None):\n        \"\"\"\u6dfb\u52a0\u7528\u6237\u6d88\u606f\"\"\"\n        human_msg = HumanMessage(content, name=user_name)\n        self.conversation_history.append(human_msg)\n\n    def add_ai_message(self, content: str):\n        \"\"\"\u6dfb\u52a0AI\u6d88\u606f\"\"\"\n        ai_msg = AIMessage(content)\n        self.conversation_history.append(ai_msg)\n\n    def get_ai_response(self, user_input: str, user_name: str = None) -&gt; str:\n        \"\"\"\u83b7\u53d6AI\u54cd\u5e94\"\"\"\n        # \u6dfb\u52a0\u7528\u6237\u6d88\u606f\n        self.add_user_message(user_input, user_name)\n\n        # \u8c03\u7528\u6a21\u578b\uff08\u53ea\u4f7f\u7528\u6700\u8fd110\u6761\u6d88\u606f\u4ee5\u907f\u514d\u4e0a\u4e0b\u6587\u8fc7\u957f\uff09\n        recent_messages = self.conversation_history[-10:] if len(self.conversation_history) &gt; 10 else self.conversation_history\n\n        # \u83b7\u53d6AI\u54cd\u5e94\n        response = self.model.invoke(recent_messages)\n\n        # \u6dfb\u52a0AI\u6d88\u606f\u5230\u5386\u53f2\n        self.add_ai_message(response.content)\n\n        return response.content\n\n    def get_conversation_summary(self) -&gt; dict:\n        \"\"\"\u83b7\u53d6\u5bf9\u8bdd\u6458\u8981\"\"\"\n        user_msgs = [msg for msg in self.conversation_history if isinstance(msg, HumanMessage)]\n        ai_msgs = [msg for msg in self.conversation_history if isinstance(msg, AIMessage)]\n\n        return {\n            \"total_messages\": len(self.conversation_history),\n            \"user_messages\": len(user_msgs),\n            \"ai_messages\": len(ai_msgs),\n            \"last_user_message\": user_msgs[-1].content if user_msgs else None,\n            \"last_ai_message\": ai_msgs[-1].content if ai_msgs else None\n        }\n\n# \u4f7f\u7528\u793a\u4f8b\nmanager = ConversationManager(model)\nmanager.add_system_message(\"\u4f60\u662f\u4e00\u4e2a\u53cb\u597d\u7684\u5ba2\u670d\u52a9\u624b\u3002\")\n\n# \u8fdb\u884c\u5bf9\u8bdd\nresponse1 = manager.get_ai_response(\"\u4f60\u597d\uff0c\u6211\u60f3\u67e5\u8be2\u8ba2\u5355\u72b6\u6001\")\nprint(f\"AI\u56de\u590d1: {response1}\")\n\nresponse2 = manager.get_ai_response(\"\u6211\u7684\u8ba2\u5355\u53f7\u662f12345\")\nprint(f\"AI\u56de\u590d2: {response2}\")\n\n# \u83b7\u53d6\u5bf9\u8bdd\u7edf\u8ba1\nsummary = manager.get_conversation_summary()\nprint(f\"\u5bf9\u8bdd\u7edf\u8ba1: {summary}\")\n</code></pre>"},{"location":"llmapps/langchain/core-components/messages/#2_4","title":"\u573a\u666f2\uff1a\u591a\u6a21\u6001\u5185\u5bb9\u5904\u7406","text":"<pre><code>class MultimodalProcessor:\n    \"\"\"\u591a\u6a21\u6001\u5185\u5bb9\u5904\u7406\u5668\"\"\"\n\n    def __init__(self, model):\n        self.model = model\n\n    def analyze_image_with_text(self, image_url: str, question: str) -&gt; str:\n        \"\"\"\u5206\u6790\u56fe\u50cf\u5e76\u56de\u7b54\u95ee\u9898\"\"\"\n        message = HumanMessage(\n            content_blocks=[\n                {\n                    \"type\": \"text\",\n                    \"text\": question\n                },\n                {\n                    \"type\": \"image\",\n                    \"url\": image_url\n                }\n            ]\n        )\n\n        response = self.model.invoke([message])\n        return response.content\n\n    def process_document_qa(self, document_url: str, questions: list) -&gt; dict:\n        \"\"\"\u5904\u7406\u6587\u6863\u95ee\u7b54\"\"\"\n        results = {}\n\n        for question in questions:\n            message = HumanMessage(\n                content_blocks=[\n                    {\n                        \"type\": \"text\",\n                        \"text\": question\n                    },\n                    {\n                        \"type\": \"file\",\n                        \"url\": document_url,\n                        \"mime_type\": \"application/pdf\"\n                    }\n                ]\n            )\n\n            response = self.model.invoke([message])\n            results[question] = response.content\n\n        return results\n\n    def create_content_with_citations(self, topic: str, sources: list) -&gt; AIMessage:\n        \"\"\"\u521b\u5efa\u5e26\u5f15\u7528\u7684\u5185\u5bb9\"\"\"\n        # \u6a21\u62df\u5e26\u5f15\u7528\u7684\u54cd\u5e94\n        citations = [{\"type\": \"citation\", \"text\": source, \"url\": f\"https://example.com/{i}\"} \n                    for i, source in enumerate(sources)]\n\n        response = AIMessage(\n            content_blocks=[\n                {\n                    \"type\": \"text\",\n                    \"text\": f\"\u5173\u4e8e{topic}\u7684\u8be6\u7ec6\u8bf4\u660e...\",\n                    \"annotations\": citations\n                }\n            ]\n        )\n\n        return response\n\n# \u4f7f\u7528\u793a\u4f8b\nprocessor = MultimodalProcessor(model)\n\n# \u56fe\u50cf\u5206\u6790\uff08\u5047\u8bbe\u6709\u56fe\u50cfURL\uff09\n# image_analysis = processor.analyze_image_with_text(\n#     \"https://example.com/medical-image.jpg\",\n#     \"\u63cf\u8ff0\u8fd9\u5f20\u533b\u5b66\u5f71\u50cf\u4e2d\u7684\u5f02\u5e38\u60c5\u51b5\"\n# )\n\n# \u6587\u6863\u95ee\u7b54\uff08\u5047\u8bbe\u6709\u6587\u6863URL\uff09\n# doc_qa = processor.process_document_qa(\n#     \"https://example.com/research-paper.pdf\",\n#     [\"\u7814\u7a76\u7684\u4e3b\u8981\u53d1\u73b0\u662f\u4ec0\u4e48\uff1f\", \"\u7814\u7a76\u65b9\u6cd5\u662f\u4ec0\u4e48\uff1f\"]\n# )\n\n# \u521b\u5efa\u5e26\u5f15\u7528\u7684\u5185\u5bb9\ncited_content = processor.create_content_with_citations(\n    \"\u4eba\u5de5\u667a\u80fd\u4f26\u7406\",\n    [\"AI\u4f26\u7406\u6307\u53572023\", \"\u673a\u5668\u5b66\u4e60\u9053\u5fb7\u6807\u51c6\", \"AI\u6cbb\u7406\u767d\u76ae\u4e66\"]\n)\n\nprint(\"\u5e26\u5f15\u7528\u7684\u5185\u5bb9:\")\ncited_content.pretty_print()\n</code></pre>"},{"location":"llmapps/langchain/core-components/messages/#3_1","title":"\u573a\u666f3\uff1a\u5de5\u5177\u8c03\u7528\u5de5\u4f5c\u6d41","text":"<pre><code>class ToolWorkflowManager:\n    \"\"\"\u5de5\u5177\u8c03\u7528\u5de5\u4f5c\u6d41\u7ba1\u7406\u5668\"\"\"\n\n    def __init__(self, model):\n        self.model = model\n        self.available_tools = {}\n\n    def register_tool(self, tool):\n        \"\"\"\u6ce8\u518c\u5de5\u5177\"\"\"\n        self.available_tools[tool.name] = tool\n\n    def execute_workflow(self, user_query: str) -&gt; str:\n        \"\"\"\u6267\u884c\u5de5\u5177\u8c03\u7528\u5de5\u4f5c\u6d41\"\"\"\n        # \u7ed1\u5b9a\u6240\u6709\u53ef\u7528\u5de5\u5177\n        tool_list = list(self.available_tools.values())\n        model_with_tools = self.model.bind_tools(tool_list)\n\n        messages = [HumanMessage(user_query)]\n        max_iterations = 5  # \u9632\u6b62\u65e0\u9650\u5faa\u73af\n\n        for iteration in range(max_iterations):\n            # \u83b7\u53d6\u6a21\u578b\u54cd\u5e94\n            ai_response = model_with_tools.invoke(messages)\n            messages.append(ai_response)\n\n            # \u5982\u679c\u6ca1\u6709\u5de5\u5177\u8c03\u7528\uff0c\u8fd4\u56de\u6700\u7ec8\u54cd\u5e94\n            if not ai_response.tool_calls:\n                return ai_response.content\n\n            # \u6267\u884c\u6240\u6709\u5de5\u5177\u8c03\u7528\n            for tool_call in ai_response.tool_calls:\n                tool_name = tool_call[\"name\"]\n                if tool_name in self.available_tools:\n                    # \u6267\u884c\u5de5\u5177\n                    result = self.available_tools[tool_name].invoke(tool_call[\"args\"])\n\n                    # \u521b\u5efa\u5de5\u5177\u6d88\u606f\n                    tool_msg = ToolMessage(\n                        content=str(result),\n                        tool_call_id=tool_call[\"id\"],\n                        name=tool_name\n                    )\n                    messages.append(tool_msg)\n                else:\n                    # \u5de5\u5177\u672a\u627e\u5230\n                    error_msg = ToolMessage(\n                        content=f\"\u9519\u8bef\uff1a\u5de5\u5177 '{tool_name}' \u672a\u627e\u5230\",\n                        tool_call_id=tool_call[\"id\"],\n                        name=tool_name\n                    )\n                    messages.append(error_msg)\n\n        return \"\u8fbe\u5230\u6700\u5927\u8fed\u4ee3\u6b21\u6570\uff0c\u5de5\u4f5c\u6d41\u7ec8\u6b62\"\n\n# \u5b9a\u4e49\u4e00\u4e9b\u5de5\u5177\n@tool\ndef calculate_bmi(weight: float, height: float) -&gt; str:\n    \"\"\"\u8ba1\u7b97BMI\u6307\u6570\"\"\"\n    bmi = weight / (height ** 2)\n    category = \"\u504f\u7626\" if bmi &lt; 18.5 else \"\u6b63\u5e38\" if bmi &lt; 24 else \"\u8d85\u91cd\" if bmi &lt; 28 else \"\u80a5\u80d6\"\n    return f\"BMI: {bmi:.1f} ({category})\"\n\n@tool\ndef get_time(timezone: str = \"UTC\") -&gt; str:\n    \"\"\"\u83b7\u53d6\u6307\u5b9a\u65f6\u533a\u7684\u5f53\u524d\u65f6\u95f4\"\"\"\n    from datetime import datetime\n    now = datetime.now()\n    return f\"{timezone}\u65f6\u95f4: {now.strftime('%Y-%m-%d %H:%M:%S')}\"\n\n# \u4f7f\u7528\u793a\u4f8b\nworkflow_manager = ToolWorkflowManager(model)\nworkflow_manager.register_tool(calculate_bmi)\nworkflow_manager.register_tool(get_time)\n\n# \u6267\u884c\u590d\u6742\u67e5\u8be2\nresult = workflow_manager.execute_workflow(\n    \"\u8bf7\u8ba1\u7b97\u6211\u7684BMI\uff0c\u6211\u4f53\u91cd70\u516c\u65a4\uff0c\u8eab\u9ad81.75\u7c73\uff0c\u7136\u540e\u544a\u8bc9\u6211\u73b0\u5728\u5317\u4eac\u65f6\u95f4\"\n)\n\nprint(\"\u5de5\u4f5c\u6d41\u7ed3\u679c:\", result)\n</code></pre>"},{"location":"llmapps/langchain/core-components/messages/#_11","title":"\u6700\u4f73\u5b9e\u8df5","text":""},{"location":"llmapps/langchain/core-components/messages/#1_5","title":"1. \u6d88\u606f\u7ba1\u7406","text":"<pre><code>class MessageBestPractices:\n    \"\"\"\u6d88\u606f\u7ba1\u7406\u6700\u4f73\u5b9e\u8df5\"\"\"\n\n    @staticmethod\n    def create_effective_system_prompt(role: str, guidelines: list) -&gt; SystemMessage:\n        \"\"\"\u521b\u5efa\u6709\u6548\u7684\u7cfb\u7edf\u63d0\u793a\"\"\"\n        guidelines_text = \"\\n\".join([f\"{i+1}. {guideline}\" for i, guideline in enumerate(guidelines)])\n\n        prompt = f\"\"\"\n        \u89d2\u8272: {role}\n\n        \u6307\u5bfc\u539f\u5219:\n        {guidelines_text}\n\n        \u8bf7\u59cb\u7ec8\u9075\u5faa\u4ee5\u4e0a\u539f\u5219\u8fdb\u884c\u56de\u590d\u3002\n        \"\"\"\n\n        return SystemMessage(prompt.strip())\n\n    @staticmethod\n    def manage_conversation_length(messages: list, max_messages: int = 20) -&gt; list:\n        \"\"\"\u7ba1\u7406\u5bf9\u8bdd\u957f\u5ea6\"\"\"\n        if len(messages) &lt;= max_messages:\n            return messages\n\n        # \u4fdd\u7559\u7cfb\u7edf\u6d88\u606f\u548c\u6700\u8fd1\u7684\u6d88\u606f\n        system_messages = [msg for msg in messages if isinstance(msg, SystemMessage)]\n        recent_messages = messages[-(max_messages - len(system_messages)):]\n\n        return system_messages + recent_messages\n\n    @staticmethod\n    def extract_usage_statistics(messages: list) -&gt; dict:\n        \"\"\"\u63d0\u53d6\u4f7f\u7528\u7edf\u8ba1\"\"\"\n        ai_messages = [msg for msg in messages if isinstance(msg, AIMessage)]\n\n        total_input_tokens = 0\n        total_output_tokens = 0\n\n        for msg in ai_messages:\n            if hasattr(msg, 'usage_metadata') and msg.usage_metadata:\n                total_input_tokens += msg.usage_metadata.get('input_tokens', 0)\n                total_output_tokens += msg.usage_metadata.get('output_tokens', 0)\n\n        return {\n            \"total_ai_messages\": len(ai_messages),\n            \"total_input_tokens\": total_input_tokens,\n            \"total_output_tokens\": total_output_tokens,\n            \"total_tokens\": total_input_tokens + total_output_tokens\n        }\n\n# \u4f7f\u7528\u6700\u4f73\u5b9e\u8df5\nsystem_prompt = MessageBestPractices.create_effective_system_prompt(\n    \"\u4e13\u4e1a\u6280\u672f\u987e\u95ee\",\n    [\n        \"\u63d0\u4f9b\u51c6\u786e\u7684\u6280\u672f\u4fe1\u606f\",\n        \"\u4f7f\u7528\u4ee3\u7801\u793a\u4f8b\u8bf4\u660e\u6982\u5ff5\", \n        \"\u89e3\u91ca\u590d\u6742\u6982\u5ff5\u65f6\u8981\u6e05\u6670\",\n        \"\u4fdd\u6301\u4e13\u4e1a\u548c\u53cb\u597d\u7684\u6001\u5ea6\"\n    ]\n)\n\nprint(\"\u7cfb\u7edf\u63d0\u793a:\", system_prompt.content)\n</code></pre>"},{"location":"llmapps/langchain/core-components/messages/#2_5","title":"2. \u9519\u8bef\u5904\u7406","text":"<pre><code>class MessageErrorHandler:\n    \"\"\"\u6d88\u606f\u9519\u8bef\u5904\u7406\"\"\"\n\n    @staticmethod\n    def safe_message_creation(content, message_type=\"human\", **kwargs):\n        \"\"\"\u5b89\u5168\u521b\u5efa\u6d88\u606f\"\"\"\n        try:\n            if message_type == \"human\":\n                return HumanMessage(content, **kwargs)\n            elif message_type == \"ai\":\n                return AIMessage(content, **kwargs)\n            elif message_type == \"system\":\n                return SystemMessage(content, **kwargs)\n            elif message_type == \"tool\":\n                return ToolMessage(content, **kwargs)\n            else:\n                raise ValueError(f\"\u672a\u77e5\u7684\u6d88\u606f\u7c7b\u578b: {message_type}\")\n        except Exception as e:\n            print(f\"\u521b\u5efa\u6d88\u606f\u65f6\u51fa\u9519: {e}\")\n            return None\n\n    @staticmethod\n    def validate_tool_message(tool_call_id: str, content: str) -&gt; bool:\n        \"\"\"\u9a8c\u8bc1\u5de5\u5177\u6d88\u606f\"\"\"\n        if not tool_call_id:\n            print(\"\u9519\u8bef: \u5de5\u5177\u6d88\u606f\u7f3a\u5c11 tool_call_id\")\n            return False\n\n        if not content:\n            print(\"\u8b66\u544a: \u5de5\u5177\u6d88\u606f\u5185\u5bb9\u4e3a\u7a7a\")\n\n        return True\n\n    @staticmethod\n    def handle_streaming_errors(stream_generator):\n        \"\"\"\u5904\u7406\u6d41\u5f0f\u9519\u8bef\"\"\"\n        try:\n            for chunk in stream_generator:\n                yield chunk\n        except Exception as e:\n            print(f\"\u6d41\u5f0f\u5904\u7406\u9519\u8bef: {e}\")\n            # \u8fd4\u56de\u9519\u8bef\u6d88\u606f\n            yield AIMessage(f\"\u62b1\u6b49\uff0c\u5904\u7406\u8fc7\u7a0b\u4e2d\u51fa\u73b0\u9519\u8bef: {str(e)}\")\n\n# \u4f7f\u7528\u9519\u8bef\u5904\u7406\nsafe_msg = MessageErrorHandler.safe_message_creation(\n    \"\u6b63\u5e38\u5185\u5bb9\",\n    \"human\",\n    name=\"test_user\"\n)\n\nprint(\"\u5b89\u5168\u521b\u5efa\u7684\u6d88\u606f:\", safe_msg.content if safe_msg else \"\u521b\u5efa\u5931\u8d25\")\n</code></pre>"},{"location":"llmapps/langchain/core-components/messages/#_12","title":"\u603b\u7ed3","text":"<p>LangChain Messages \u63d0\u4f9b\u4e86\u5f3a\u5927\u800c\u7075\u6d3b\u7684\u65b9\u5f0f\u6765\u7ba1\u7406AI\u5bf9\u8bdd\uff1a</p> <ul> <li>\u591a\u79cd\u6d88\u606f\u7c7b\u578b\uff1aSystemMessage\u3001HumanMessage\u3001AIMessage\u3001ToolMessage</li> <li>\u4e30\u5bcc\u7684\u5185\u5bb9\u652f\u6301\uff1a\u6587\u672c\u3001\u56fe\u50cf\u3001\u97f3\u9891\u3001\u89c6\u9891\u3001\u6587\u6863\u7b49\u591a\u6a21\u6001\u5185\u5bb9</li> <li>\u6807\u51c6\u5316\u5185\u5bb9\u5757\uff1a\u8de8\u63d0\u4f9b\u5546\u7684\u4e00\u81f4\u5185\u5bb9\u8868\u793a</li> <li>\u5de5\u5177\u8c03\u7528\u96c6\u6210\uff1a\u5b8c\u6574\u7684\u5de5\u5177\u8c03\u7528\u548c\u5de5\u4f5c\u6d41\u652f\u6301</li> <li>\u751f\u4ea7\u7ea7\u7279\u6027\uff1a\u9519\u8bef\u5904\u7406\u3001\u6027\u80fd\u4f18\u5316\u3001\u4f7f\u7528\u7edf\u8ba1</li> </ul> <p>\u901a\u8fc7\u5408\u7406\u4f7f\u7528Messages\uff0c\u53ef\u4ee5\u6784\u5efa\u51fa\u80fd\u591f\u5904\u7406\u590d\u6742\u5bf9\u8bdd\u3001\u591a\u6a21\u6001\u5185\u5bb9\u548c\u5de5\u5177\u8c03\u7528\u7684\u667a\u80fdAI\u5e94\u7528\u7cfb\u7edf\u3002</p>"},{"location":"llmapps/langchain/core-components/middleware/","title":"LangChain Middleware","text":""},{"location":"llmapps/langchain/core-components/middleware/#_1","title":"\u6982\u8ff0","text":"<p>Middleware\uff08\u4e2d\u95f4\u4ef6\uff09\u5728 LangChain \u4e2d\u63d0\u4f9b\u4e86\u5bf9 Agent \u6267\u884c\u8fc7\u7a0b\u7684\u7cbe\u7ec6\u63a7\u5236\u80fd\u529b\u3002\u5b83\u5141\u8bb8\u4f60\u5728 Agent \u6267\u884c\u7684\u5404\u4e2a\u5173\u952e\u8282\u70b9\u63d2\u5165\u81ea\u5b9a\u4e49\u903b\u8f91\uff0c\u5b9e\u73b0\u76d1\u63a7\u3001\u4fee\u6539\u3001\u63a7\u5236\u548c\u5f3a\u5236\u6267\u884c\u7b49\u529f\u80fd\u3002</p> <p></p>"},{"location":"llmapps/langchain/core-components/middleware/#_2","title":"\u6838\u5fc3\u6982\u5ff5","text":""},{"location":"llmapps/langchain/core-components/middleware/#agent","title":"Agent \u6267\u884c\u6d41\u7a0b","text":"<p>\u6807\u51c6\u7684 Agent \u6267\u884c\u5faa\u73af\u5305\u542b\u4e09\u4e2a\u4e3b\u8981\u6b65\u9aa4\uff1a</p> <ol> <li>\u8c03\u7528\u6a21\u578b</li> <li>\u9009\u62e9\u8981\u6267\u884c\u7684\u5de5\u5177</li> <li>\u5f53\u4e0d\u518d\u8c03\u7528\u5de5\u5177\u65f6\u7ed3\u675f</li> </ol> <pre><code># \u57fa\u7840 Agent \u521b\u5efa\nfrom langchain.agents import create_agent\n\nagent = create_agent(\n    model=\"openai:gpt-4o\",\n    tools=[...]\n)\n</code></pre>"},{"location":"llmapps/langchain/core-components/middleware/#middleware","title":"Middleware \u6267\u884c\u94a9\u5b50","text":"<p>Middleware \u5728\u4ee5\u4e0b\u5173\u952e\u8282\u70b9\u66b4\u9732\u94a9\u5b50\uff1a</p> <ul> <li>before_model: \u5728\u6a21\u578b\u8c03\u7528\u4e4b\u524d</li> <li>after_model: \u5728\u6a21\u578b\u54cd\u5e94\u4e4b\u540e</li> <li>wrap_model_call: \u56f4\u7ed5\u6a21\u578b\u8c03\u7528\uff08\u5b8c\u5168\u63a7\u5236\uff09</li> <li>wrap_tool_call: \u56f4\u7ed5\u5de5\u5177\u8c03\u7528</li> </ul>"},{"location":"llmapps/langchain/core-components/middleware/#middleware_1","title":"\u5185\u7f6e Middleware \u4f7f\u7528\u6307\u5357","text":""},{"location":"llmapps/langchain/core-components/middleware/#1-summarizationmiddleware-","title":"1. SummarizationMiddleware - \u5bf9\u8bdd\u603b\u7ed3","text":"<p>\u81ea\u52a8\u603b\u7ed3\u5bf9\u8bdd\u5386\u53f2\u4ee5\u907f\u514d\u8d85\u51fa token \u9650\u5236\u3002</p> <pre><code>from langchain.agents import create_agent\nfrom langchain.agents.middleware import SummarizationMiddleware\n\nagent = create_agent(\n    model=\"openai:gpt-4o\",\n    tools=[weather_tool, calculator_tool],\n    middleware=[\n        SummarizationMiddleware(\n            model=\"openai:gpt-4o-mini\",\n            max_tokens_before_summary=4000,  # \u5728 4000 tokens \u65f6\u89e6\u53d1\u603b\u7ed3\n            messages_to_keep=20,  # \u603b\u7ed3\u540e\u4fdd\u7559\u6700\u8fd1 20 \u6761\u6d88\u606f\n        ),\n    ],\n)\n</code></pre> <p>\u9002\u7528\u573a\u666f\uff1a</p> <ul> <li>\u957f\u65f6\u95f4\u8fd0\u884c\u7684\u5bf9\u8bdd</li> <li>\u591a\u8f6e\u5bf9\u8bdd\u4e14\u6709\u5927\u91cf\u5386\u53f2\u8bb0\u5f55</li> <li>\u9700\u8981\u4fdd\u7559\u5b8c\u6574\u5bf9\u8bdd\u4e0a\u4e0b\u6587\u7684\u5e94\u7528</li> </ul>"},{"location":"llmapps/langchain/core-components/middleware/#2-humanintheloopmiddleware-","title":"2. HumanInTheLoopMiddleware - \u4eba\u5de5\u5ba1\u6838","text":"<p>\u5728\u6267\u884c\u5de5\u5177\u8c03\u7528\u524d\u6682\u505c\uff0c\u7b49\u5f85\u4eba\u5de5\u6279\u51c6\u3001\u7f16\u8f91\u6216\u62d2\u7edd\u3002</p> <pre><code>from langchain.agents import create_agent\nfrom langchain.agents.middleware import HumanInTheLoopMiddleware\nfrom langgraph.checkpoint.memory import InMemorySaver\n\nagent = create_agent(\n    model=\"openai:gpt-4o\",\n    tools=[read_email_tool, send_email_tool],\n    checkpointer=InMemorySaver(),  # \u5fc5\u987b\u4f7f\u7528 checkpointer\n    middleware=[\n        HumanInTheLoopMiddleware(\n            interrupt_on={\n                \"send_email_tool\": {  # \u53d1\u9001\u90ae\u4ef6\u9700\u8981\u4eba\u5de5\u5ba1\u6838\n                    \"allowed_decisions\": [\"approve\", \"edit\", \"reject\"],\n                },\n                \"read_email_tool\": False,  # \u81ea\u52a8\u6279\u51c6\u8bfb\u53d6\u90ae\u4ef6\n            }\n        ),\n    ],\n)\n</code></pre> <p>\u91cd\u8981\u63d0\u793a\uff1a\u5fc5\u987b\u914d\u7f6e checkpointer \u6765\u7ef4\u6301\u4e2d\u65ad\u95f4\u7684\u72b6\u6001\u3002</p>"},{"location":"llmapps/langchain/core-components/middleware/#3-modelcalllimitmiddleware-","title":"3. ModelCallLimitMiddleware - \u6a21\u578b\u8c03\u7528\u9650\u5236","text":"<p>\u9650\u5236\u6a21\u578b\u8c03\u7528\u6b21\u6570\uff0c\u9632\u6b62\u65e0\u9650\u5faa\u73af\u6216\u8fc7\u9ad8\u6210\u672c\u3002</p> <pre><code>from langchain.agents import create_agent\nfrom langchain.agents.middleware import ModelCallLimitMiddleware\n\nagent = create_agent(\n    model=\"openai:gpt-4o\",\n    tools=[...],\n    middleware=[\n        ModelCallLimitMiddleware(\n            thread_limit=10,  # \u6bcf\u4e2a\u7ebf\u7a0b\u6700\u591a 10 \u6b21\u8c03\u7528\n            run_limit=5,     # \u6bcf\u6b21\u8fd0\u884c\u6700\u591a 5 \u6b21\u8c03\u7528\n            exit_behavior=\"end\",  # \u8fbe\u5230\u9650\u5236\u65f6\u4f18\u96c5\u7ed3\u675f\n        ),\n    ],\n)\n</code></pre>"},{"location":"llmapps/langchain/core-components/middleware/#4-toolcalllimitmiddleware-","title":"4. ToolCallLimitMiddleware - \u5de5\u5177\u8c03\u7528\u9650\u5236","text":"<p>\u9650\u5236\u7279\u5b9a\u5de5\u5177\u6216\u6240\u6709\u5de5\u5177\u7684\u8c03\u7528\u6b21\u6570\u3002</p> <pre><code>from langchain.agents import create_agent\nfrom langchain.agents.middleware import ToolCallLimitMiddleware\n\n# \u9650\u5236\u6240\u6709\u5de5\u5177\u8c03\u7528\nglobal_limiter = ToolCallLimitMiddleware(thread_limit=20, run_limit=10)\n\n# \u9650\u5236\u7279\u5b9a\u5de5\u5177\nsearch_limiter = ToolCallLimitMiddleware(\n    tool_name=\"search\",\n    thread_limit=5,\n    run_limit=3,\n)\n\nagent = create_agent(\n    model=\"openai:gpt-4o\",\n    tools=[...],\n    middleware=[global_limiter, search_limiter],\n)\n</code></pre>"},{"location":"llmapps/langchain/core-components/middleware/#5-modelfallbackmiddleware-","title":"5. ModelFallbackMiddleware - \u6a21\u578b\u6545\u969c\u8f6c\u79fb","text":"<p>\u5f53\u4e3b\u6a21\u578b\u5931\u8d25\u65f6\u81ea\u52a8\u5207\u6362\u5230\u5907\u7528\u6a21\u578b\u3002</p> <pre><code>from langchain.agents import create_agent\nfrom langchain.agents.middleware import ModelFallbackMiddleware\n\nagent = create_agent(\n    model=\"openai:gpt-4o\",  # \u4e3b\u6a21\u578b\n    tools=[...],\n    middleware=[\n        ModelFallbackMiddleware(\n            \"openai:gpt-4o-mini\",  # \u7b2c\u4e00\u5907\u7528\u6a21\u578b\n            \"anthropic:claude-3-5-sonnet-20241022\",  # \u7b2c\u4e8c\u5907\u7528\u6a21\u578b\n        ),\n    ],\n)\n</code></pre>"},{"location":"llmapps/langchain/core-components/middleware/#6-piimiddleware-","title":"6. PIIMiddleware - \u4e2a\u4eba\u4fe1\u606f\u68c0\u6d4b","text":"<p>\u68c0\u6d4b\u548c\u5904\u7406\u5bf9\u8bdd\u4e2d\u7684\u4e2a\u4eba\u8eab\u4efd\u4fe1\u606f\u3002</p> <pre><code>from langchain.agents import create_agent\nfrom langchain.agents.middleware import PIIMiddleware\n\nagent = create_agent(\n    model=\"openai:gpt-4o\",\n    tools=[...],\n    middleware=[\n        # \u5728\u7528\u6237\u8f93\u5165\u4e2d\u5c4f\u853d\u90ae\u7bb1\n        PIIMiddleware(\"email\", strategy=\"redact\", apply_to_input=True),\n        # \u63a9\u7801\u4fe1\u7528\u5361\u53f7\uff08\u663e\u793a\u6700\u540e4\u4f4d\uff09\n        PIIMiddleware(\"credit_card\", strategy=\"mask\", apply_to_input=True),\n        # \u81ea\u5b9a\u4e49 API \u5bc6\u94a5\u68c0\u6d4b\n        PIIMiddleware(\n            \"api_key\",\n            detector=r\"sk-[a-zA-Z0-9]{32}\",\n            strategy=\"block\",  # \u68c0\u6d4b\u5230\u65f6\u62a5\u9519\n        ),\n    ],\n)\n</code></pre> <p>\u5904\u7406\u7b56\u7565\uff1a</p> <ul> <li><code>block</code>: \u68c0\u6d4b\u5230\u65f6\u629b\u51fa\u5f02\u5e38</li> <li><code>redact</code>: \u66ff\u6362\u4e3a <code>[REDACTED_TYPE]</code></li> <li><code>mask</code>: \u90e8\u5206\u63a9\u7801</li> <li><code>hash</code>: \u66ff\u6362\u4e3a\u786e\u5b9a\u6027\u54c8\u5e0c\u503c</li> </ul>"},{"location":"llmapps/langchain/core-components/middleware/#7-toolretrymiddleware-","title":"7. ToolRetryMiddleware - \u5de5\u5177\u91cd\u8bd5","text":"<p>\u5bf9\u5931\u8d25\u7684\u5de5\u5177\u8c03\u7528\u8fdb\u884c\u6307\u6570\u9000\u907f\u91cd\u8bd5\u3002</p> <pre><code>from langchain.agents import create_agent\nfrom langchain.agents.middleware import ToolRetryMiddleware\n\nagent = create_agent(\n    model=\"openai:gpt-4o\",\n    tools=[search_tool, database_tool],\n    middleware=[\n        ToolRetryMiddleware(\n            max_retries=3,      # \u6700\u591a\u91cd\u8bd5 3 \u6b21\n            backoff_factor=2.0, # \u6307\u6570\u9000\u907f\u4e58\u6570\n            initial_delay=1.0,  # \u521d\u59cb\u5ef6\u8fdf 1 \u79d2\n            max_delay=60.0,     # \u6700\u5927\u5ef6\u8fdf 60 \u79d2\n            jitter=True,        # \u6dfb\u52a0\u968f\u673a\u6296\u52a8\n        ),\n    ],\n)\n</code></pre>"},{"location":"llmapps/langchain/core-components/middleware/#middleware_2","title":"\u81ea\u5b9a\u4e49 Middleware \u5f00\u53d1","text":""},{"location":"llmapps/langchain/core-components/middleware/#_3","title":"\u88c5\u9970\u5668\u65b9\u5f0f\uff08\u7b80\u5355\u573a\u666f\uff09","text":"<p>\u9002\u7528\u4e8e\u53ea\u9700\u8981\u5355\u4e2a\u94a9\u5b50\u7684\u7b80\u5355\u4e2d\u95f4\u4ef6\u3002</p> <pre><code>from langchain.agents.middleware import before_model, after_model, wrap_model_call\nfrom langchain.agents.middleware import AgentState\nfrom langchain.messages import AIMessage\n\n# \u6a21\u578b\u8c03\u7528\u524d\u65e5\u5fd7\u8bb0\u5f55\n@before_model\ndef log_before_model(state: AgentState, runtime) -&gt; dict | None:\n    print(f\"\u51c6\u5907\u8c03\u7528\u6a21\u578b\uff0c\u6d88\u606f\u6570\u91cf: {len(state['messages'])}\")\n    return None\n\n# \u6a21\u578b\u8c03\u7528\u540e\u9a8c\u8bc1\n@after_model\ndef validate_output(state: AgentState, runtime) -&gt; dict | None:\n    last_message = state[\"messages\"][-1]\n    if \"BLOCKED\" in last_message.content:\n        return {\n            \"messages\": [AIMessage(\"\u6211\u65e0\u6cd5\u54cd\u5e94\u8fd9\u4e2a\u8bf7\u6c42\u3002\")],\n            \"jump_to\": \"end\"\n        }\n    return None\n\n# \u6a21\u578b\u8c03\u7528\u91cd\u8bd5\u5305\u88c5\n@wrap_model_call\ndef retry_model(request, handler):\n    for attempt in range(3):\n        try:\n            return handler(request)\n        except Exception as e:\n            if attempt == 2:\n                raise\n            print(f\"\u91cd\u8bd5 {attempt + 1}/3\uff0c\u9519\u8bef: {e}\")\n</code></pre>"},{"location":"llmapps/langchain/core-components/middleware/#_4","title":"\u7c7b\u65b9\u5f0f\uff08\u590d\u6742\u573a\u666f\uff09","text":"<p>\u9002\u7528\u4e8e\u9700\u8981\u591a\u4e2a\u94a9\u5b50\u6216\u590d\u6742\u914d\u7f6e\u7684\u4e2d\u95f4\u4ef6\u3002</p> <pre><code>from langchain.agents.middleware import AgentMiddleware, AgentState\nfrom langchain.agents.middleware import ModelRequest, ModelResponse\nfrom typing import Callable, Any\n\nclass ComprehensiveLoggingMiddleware(AgentMiddleware):\n    def __init__(self, log_level: str = \"INFO\"):\n        super().__init__()\n        self.log_level = log_level\n\n    def before_model(self, state: AgentState, runtime) -&gt; dict[str, Any] | None:\n        print(f\"[{self.log_level}] \u6a21\u578b\u8c03\u7528\u524d - \u6d88\u606f\u6570: {len(state['messages'])}\")\n        return None\n\n    def after_model(self, state: AgentState, runtime) -&gt; dict[str, Any] | None:\n        last_msg = state[\"messages\"][-1]\n        print(f\"[{self.log_level}] \u6a21\u578b\u54cd\u5e94: {last_msg.content[:100]}...\")\n        return None\n\n    def wrap_model_call(\n        self,\n        request: ModelRequest,\n        handler: Callable[[ModelRequest], ModelResponse],\n    ) -&gt; ModelResponse:\n        print(f\"[{self.log_level}] \u5f00\u59cb\u6a21\u578b\u8c03\u7528\")\n        start_time = time.time()\n\n        try:\n            response = handler(request)\n            duration = time.time() - start_time\n            print(f\"[{self.log_level}] \u6a21\u578b\u8c03\u7528\u6210\u529f\uff0c\u8017\u65f6: {duration:.2f}s\")\n            return response\n        except Exception as e:\n            duration = time.time() - start_time\n            print(f\"[{self.log_level}] \u6a21\u578b\u8c03\u7528\u5931\u8d25\uff0c\u8017\u65f6: {duration:.2f}s\uff0c\u9519\u8bef: {e}\")\n            raise\n</code></pre>"},{"location":"llmapps/langchain/core-components/middleware/#_5","title":"\u81ea\u5b9a\u4e49\u72b6\u6001\u7ba1\u7406","text":"<p>Middleware \u53ef\u4ee5\u6269\u5c55 Agent \u7684\u72b6\u6001\u7ed3\u6784\uff1a</p> <pre><code>from typing_extensions import NotRequired\nfrom typing import Any\n\nclass CustomState(AgentState):\n    model_call_count: NotRequired[int]\n    user_preferences: NotRequired[dict]\n\nclass StateAwareMiddleware(AgentMiddleware[CustomState]):\n    state_schema = CustomState\n\n    def before_model(self, state: CustomState, runtime) -&gt; dict[str, Any] | None:\n        # \u8bbf\u95ee\u81ea\u5b9a\u4e49\u72b6\u6001\n        call_count = state.get(\"model_call_count\", 0)\n        preferences = state.get(\"user_preferences\", {})\n\n        if call_count &gt; 50:\n            return {\"jump_to\": \"end\"}\n\n        return None\n\n    def after_model(self, state: CustomState, runtime) -&gt; dict[str, Any] | None:\n        # \u66f4\u65b0\u81ea\u5b9a\u4e49\u72b6\u6001\n        return {\n            \"model_call_count\": state.get(\"model_call_count\", 0) + 1\n        }\n</code></pre>"},{"location":"llmapps/langchain/core-components/middleware/#_6","title":"\u9ad8\u7ea7\u7528\u4f8b","text":""},{"location":"llmapps/langchain/core-components/middleware/#_7","title":"\u52a8\u6001\u5de5\u5177\u9009\u62e9","text":"<p>\u6839\u636e\u4e0a\u4e0b\u6587\u667a\u80fd\u9009\u62e9\u76f8\u5173\u5de5\u5177\uff1a</p> <pre><code>class SmartToolSelectorMiddleware(AgentMiddleware):\n    def wrap_model_call(\n        self,\n        request: ModelRequest,\n        handler: Callable[[ModelRequest], ModelResponse],\n    ) -&gt; ModelResponse:\n        # \u57fa\u4e8e\u5bf9\u8bdd\u5185\u5bb9\u9009\u62e9\u76f8\u5173\u5de5\u5177\n        user_message = request.state[\"messages\"][-1].content.lower()\n\n        if \"weather\" in user_message:\n            relevant_tools = [t for t in request.tools if \"weather\" in t.name]\n        elif \"calculate\" in user_message:\n            relevant_tools = [t for t in request.tools if \"calc\" in t.name or \"math\" in t.name]\n        else:\n            relevant_tools = request.tools[:5]  # \u9650\u5236\u5de5\u5177\u6570\u91cf\n\n        request.tools = relevant_tools\n        return handler(request)\n</code></pre>"},{"location":"llmapps/langchain/core-components/middleware/#_8","title":"\u6743\u9650\u63a7\u5236\u4e2d\u95f4\u4ef6","text":"<pre><code>class PermissionMiddleware(AgentMiddleware):\n    def __init__(self, user_roles: dict):\n        super().__init__()\n        self.user_roles = user_roles\n\n    def before_model(self, state: AgentState, runtime) -&gt; dict[str, Any] | None:\n        user_id = runtime.context.get(\"user_id\")\n        user_role = self.user_roles.get(user_id, \"guest\")\n\n        # \u57fa\u4e8e\u89d2\u8272\u9650\u5236\u5de5\u5177\u8bbf\u95ee\n        if user_role == \"guest\":\n            restricted_tools = [\"delete\", \"admin\", \"config\"]\n            for tool in state.get(\"tools\", []):\n                if any(restricted in tool.name for restricted in restricted_tools):\n                    return {\n                        \"messages\": [AIMessage(\"\u6743\u9650\u4e0d\u8db3\uff0c\u65e0\u6cd5\u4f7f\u7528\u8be5\u529f\u80fd\")],\n                        \"jump_to\": \"end\"\n                    }\n        return None\n</code></pre>"},{"location":"llmapps/langchain/core-components/middleware/#_9","title":"\u6700\u4f73\u5b9e\u8df5","text":""},{"location":"llmapps/langchain/core-components/middleware/#1","title":"1. \u6267\u884c\u987a\u5e8f\u7ba1\u7406","text":"<pre><code># Middleware \u6267\u884c\u987a\u5e8f\u5f88\u91cd\u8981\nagent = create_agent(\n    model=\"openai:gpt-4o\",\n    middleware=[\n        LoggingMiddleware(),      # \u6700\u5148\u6267\u884c - \u57fa\u7840\u65e5\u5fd7\n        ValidationMiddleware(),   # \u5176\u6b21 - \u8f93\u5165\u9a8c\u8bc1\n        SecurityMiddleware(),     # \u5b89\u5168\u68c0\u67e5\n        BusinessLogicMiddleware(), # \u4e1a\u52a1\u903b\u8f91\n        FallbackMiddleware()      # \u6700\u540e - \u6545\u969c\u5904\u7406\n    ],\n    tools=[...]\n)\n</code></pre>"},{"location":"llmapps/langchain/core-components/middleware/#2","title":"2. \u9519\u8bef\u5904\u7406","text":"<pre><code>class RobustMiddleware(AgentMiddleware):\n    def wrap_model_call(self, request, handler):\n        try:\n            return handler(request)\n        except Exception as e:\n            # \u8bb0\u5f55\u9519\u8bef\u4f46\u4e0d\u4e2d\u65ad\u6267\u884c\n            logger.error(f\"Middleware error: {e}\")\n            # \u8fd4\u56de\u964d\u7ea7\u54cd\u5e94\n            return ModelResponse(\n                messages=[AIMessage(\"\u7cfb\u7edf\u6682\u65f6\u4e0d\u53ef\u7528\uff0c\u8bf7\u7a0d\u540e\u91cd\u8bd5\u3002\")]\n            )\n</code></pre>"},{"location":"llmapps/langchain/core-components/middleware/#3","title":"3. \u6027\u80fd\u4f18\u5316","text":"<pre><code>class CachingMiddleware(AgentMiddleware):\n    def __init__(self):\n        super().__init__()\n        self.cache = {}\n\n    def wrap_model_call(self, request, handler):\n        cache_key = self._generate_cache_key(request)\n\n        if cache_key in self.cache:\n            return self.cache[cache_key]\n\n        response = handler(request)\n        self.cache[cache_key] = response\n        return response\n\n    def _generate_cache_key(self, request):\n        # \u57fa\u4e8e\u8bf7\u6c42\u5185\u5bb9\u751f\u6210\u7f13\u5b58\u952e\n        return hash(str(request.messages))\n</code></pre>"},{"location":"llmapps/langchain/core-components/middleware/#_10","title":"\u5b8c\u6574\u793a\u4f8b","text":"<p>\u4e0b\u9762\u662f\u4e00\u4e2a\u7efc\u5408\u4f7f\u7528\u591a\u4e2a Middleware \u7684\u751f\u4ea7\u7ea7\u793a\u4f8b\uff1a</p> <pre><code>from langchain.agents import create_agent\nfrom langchain.agents.middleware import (\n    SummarizationMiddleware,\n    ModelCallLimitMiddleware,\n    ToolRetryMiddleware,\n    PIIMiddleware\n)\n\n# \u521b\u5efa\u5177\u5907\u5b8c\u6574\u4e2d\u95f4\u4ef6\u6808\u7684 Agent\nproduction_agent = create_agent(\n    model=\"openai:gpt-4o\",\n    tools=[search_tool, calculator_tool, database_tool, email_tool],\n    middleware=[\n        # \u5b89\u5168\u548c\u5408\u89c4\n        PIIMiddleware(\"email\", strategy=\"redact\", apply_to_input=True),\n        PIIMiddleware(\"credit_card\", strategy=\"mask\", apply_to_input=True),\n\n        # \u6027\u80fd\u548c\u7a33\u5b9a\u6027\n        SummarizationMiddleware(\n            model=\"openai:gpt-4o-mini\",\n            max_tokens_before_summary=3000,\n        ),\n        ToolRetryMiddleware(\n            max_retries=2,\n            backoff_factor=1.5,\n        ),\n\n        # \u8d44\u6e90\u63a7\u5236\n        ModelCallLimitMiddleware(thread_limit=20, run_limit=10),\n\n        # \u81ea\u5b9a\u4e49\u4e1a\u52a1\u903b\u8f91\n        CustomLoggingMiddleware(),\n        PermissionMiddleware(user_roles=USER_ROLES),\n    ],\n    checkpointer=InMemorySaver(),  # \u7528\u4e8e\u7ef4\u6301\u72b6\u6001\n)\n</code></pre>"},{"location":"llmapps/langchain/core-components/middleware/#_11","title":"\u603b\u7ed3","text":"<p>LangChain Middleware \u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u6269\u5c55\u80fd\u529b\uff0c\u8ba9\u4f60\u80fd\u591f\uff1a</p> <ul> <li>\u76d1\u63a7\uff1a\u8ddf\u8e2a Agent \u884c\u4e3a\uff0c\u8bb0\u5f55\u65e5\u5fd7\u548c\u5206\u6790</li> <li>\u4fee\u6539\uff1a\u8f6c\u6362\u63d0\u793a\u3001\u5de5\u5177\u9009\u62e9\u548c\u8f93\u51fa\u683c\u5f0f</li> <li>\u63a7\u5236\uff1a\u6dfb\u52a0\u91cd\u8bd5\u3001\u6545\u969c\u8f6c\u79fb\u548c\u63d0\u524d\u7ec8\u6b62\u903b\u8f91</li> <li>\u5f3a\u5236\u6267\u884c\uff1a\u5e94\u7528\u901f\u7387\u9650\u5236\u3001\u9632\u62a4\u680f\u548c PII \u68c0\u6d4b</li> </ul> <p>\u901a\u8fc7\u5408\u7406\u4f7f\u7528\u5185\u7f6e Middleware \u548c\u5f00\u53d1\u81ea\u5b9a\u4e49 Middleware\uff0c\u4f60\u53ef\u4ee5\u6784\u5efa\u51fa\u66f4\u52a0\u5065\u58ee\u3001\u5b89\u5168\u548c\u9ad8\u6548\u7684 AI Agent \u5e94\u7528\u3002</p>"},{"location":"llmapps/langchain/core-components/models/","title":"LangChain Models","text":""},{"location":"llmapps/langchain/core-components/models/#_1","title":"\u6982\u8ff0","text":"<p>\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u662f\u80fd\u591f\u50cf\u4eba\u7c7b\u4e00\u6837\u89e3\u91ca\u548c\u751f\u6210\u6587\u672c\u7684\u5f3a\u5927AI\u5de5\u5177\u3002\u5b83\u4eec\u8db3\u591f\u901a\u7528\uff0c\u53ef\u4ee5\u7f16\u5199\u5185\u5bb9\u3001\u7ffb\u8bd1\u8bed\u8a00\u3001\u603b\u7ed3\u548c\u56de\u7b54\u95ee\u9898\uff0c\u800c\u65e0\u9700\u4e3a\u6bcf\u4e2a\u4efb\u52a1\u8fdb\u884c\u4e13\u95e8\u8bad\u7ec3\u3002</p> <p>\u9664\u4e86\u6587\u672c\u751f\u6210\uff0c\u8bb8\u591a\u6a21\u578b\u8fd8\u652f\u6301\uff1a</p> <ul> <li>\u5de5\u5177\u8c03\u7528 - \u8c03\u7528\u5916\u90e8\u5de5\u5177\u5e76\u5728\u54cd\u5e94\u4e2d\u4f7f\u7528\u7ed3\u679c</li> <li>\u7ed3\u6784\u5316\u8f93\u51fa - \u6a21\u578b\u7684\u54cd\u5e94\u88ab\u7ea6\u675f\u4e3a\u9075\u5faa\u5b9a\u4e49\u7684\u683c\u5f0f</li> <li>\u591a\u6a21\u6001 - \u5904\u7406\u548c\u8fd4\u56de\u6587\u672c\u4ee5\u5916\u7684\u6570\u636e\uff0c\u5982\u56fe\u50cf\u3001\u97f3\u9891\u548c\u89c6\u9891</li> <li>\u63a8\u7406 - \u6a21\u578b\u6267\u884c\u591a\u6b65\u63a8\u7406\u4ee5\u5f97\u51fa\u7ed3\u8bba</li> </ul> <p>\u6a21\u578b\u662fAgent\u7684\u63a8\u7406\u5f15\u64ce\uff0c\u9a71\u52a8Agent\u7684\u51b3\u7b56\u8fc7\u7a0b\u3002\u60a8\u9009\u62e9\u7684\u6a21\u578b\u7684\u8d28\u91cf\u548c\u80fd\u529b\u76f4\u63a5\u5f71\u54cdAgent\u7684\u53ef\u9760\u6027\u548c\u6027\u80fd\u3002</p>"},{"location":"llmapps/langchain/core-components/models/#_2","title":"\u57fa\u7840\u7528\u6cd5","text":""},{"location":"llmapps/langchain/core-components/models/#1","title":"1. \u521d\u59cb\u5316\u6a21\u578b","text":""},{"location":"llmapps/langchain/core-components/models/#init_chat_model","title":"\u4f7f\u7528 <code>init_chat_model</code>\uff08\u63a8\u8350\uff09","text":"<pre><code>import os\nfrom langchain.chat_models import init_chat_model\n\n# \u8bbe\u7f6eAPI\u5bc6\u94a5\nos.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\n\n# \u521d\u59cb\u5316\u6a21\u578b\nmodel = init_chat_model(\"openai:gpt-4o\")\n\n# \u57fa\u672c\u8c03\u7528\nresponse = model.invoke(\"\u4e3a\u4ec0\u4e48\u9e66\u9e49\u4f1a\u8bf4\u8bdd\uff1f\")\nprint(response.content)\n</code></pre>"},{"location":"llmapps/langchain/core-components/models/#_3","title":"\u4f7f\u7528\u6a21\u578b\u7c7b","text":"<pre><code>from langchain_openai import ChatOpenAI\n\n# \u76f4\u63a5\u4f7f\u7528\u6a21\u578b\u7c7b\nmodel = ChatOpenAI(\n    model=\"gpt-4o\",\n    temperature=0.7,\n    max_tokens=1000,\n    timeout=30\n)\n\nresponse = model.invoke(\"\u89e3\u91ca\u91cf\u5b50\u8ba1\u7b97\")\nprint(response.content)\n</code></pre>"},{"location":"llmapps/langchain/core-components/models/#2","title":"2. \u652f\u6301\u7684\u63d0\u4f9b\u5546","text":"<pre><code># Anthropic\nfrom langchain_anthropic import ChatAnthropic\nmodel = ChatAnthropic(model=\"claude-3-5-sonnet-20241022\")\n\n# Google Gemini\nfrom langchain_google_genai import ChatGoogleGenerativeAI\nmodel = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-exp\")\n\n# Azure OpenAI\nfrom langchain_openai import AzureChatOpenAI\nmodel = AzureChatOpenAI(\n    azure_deployment=\"your-deployment-name\",\n    openai_api_version=\"2023-05-15\"\n)\n</code></pre>"},{"location":"llmapps/langchain/core-components/models/#_4","title":"\u53c2\u6570\u914d\u7f6e","text":""},{"location":"llmapps/langchain/core-components/models/#_5","title":"\u5e38\u7528\u53c2\u6570","text":"<pre><code>model = init_chat_model(\n    \"openai:gpt-4o\",\n    # \u6838\u5fc3\u53c2\u6570\n    temperature=0.7,      # \u63a7\u5236\u968f\u673a\u6027 (0-1)\n    max_tokens=1000,      # \u6700\u5927\u8f93\u51fa\u957f\u5ea6\n    timeout=30,           # \u8d85\u65f6\u65f6\u95f4\uff08\u79d2\uff09\n    max_retries=3,        # \u6700\u5927\u91cd\u8bd5\u6b21\u6570\n\n    # \u9ad8\u7ea7\u53c2\u6570\n    top_p=0.9,           # \u6838\u91c7\u6837\u53c2\u6570\n    frequency_penalty=0.1, # \u9891\u7387\u60e9\u7f5a\n    presence_penalty=0.1,  # \u5b58\u5728\u60e9\u7f5a\n)\n\nresponse = model.invoke(\"\u5199\u4e00\u4e2a\u5173\u4e8eAI\u7684\u77ed\u6545\u4e8b\")\n</code></pre>"},{"location":"llmapps/langchain/core-components/models/#_6","title":"\u8c03\u7528\u65b9\u5f0f","text":""},{"location":"llmapps/langchain/core-components/models/#1-invoke","title":"1. \u5355\u6b21\u8c03\u7528\uff08Invoke\uff09","text":"<pre><code># \u5355\u6761\u6d88\u606f\nresponse = model.invoke(\"Python\u7684\u4e3b\u8981\u7279\u70b9\u662f\u4ec0\u4e48\uff1f\")\nprint(response.content)\n\n# \u5bf9\u8bdd\u5386\u53f2\nmessages = [\n    {\"role\": \"system\", \"content\": \"\u4f60\u662f\u4e00\u4e2a\u6709\u5e2e\u52a9\u7684\u52a9\u624b\u3002\"},\n    {\"role\": \"user\", \"content\": \"\u6559\u6211Python\"},\n    {\"role\": \"assistant\", \"content\": \"Python\u662f\u4e00\u79cd\u9ad8\u7ea7\u7f16\u7a0b\u8bed\u8a00...\"},\n    {\"role\": \"user\", \"content\": \"\u5b83\u7684\u4e3b\u8981\u5e94\u7528\u9886\u57df\u662f\u4ec0\u4e48\uff1f\"}\n]\n\nresponse = model.invoke(messages)\nprint(response.content)\n</code></pre>"},{"location":"llmapps/langchain/core-components/models/#2-stream","title":"2. \u6d41\u5f0f\u8c03\u7528\uff08Stream\uff09","text":"<pre><code>print(\"AI\u56de\u590d: \", end=\"\", flush=True)\n\nfor chunk in model.stream(\"\u89e3\u91ca\u673a\u5668\u5b66\u4e60\u7684\u57fa\u672c\u6982\u5ff5\"):\n    if hasattr(chunk, 'content'):\n        print(chunk.content, end=\"\", flush=True)\nprint()  # \u6362\u884c\n\n# \u6216\u8005\u7d2f\u79ef\u5b8c\u6574\u7684\u6d88\u606f\nfull_response = None\nfor chunk in model.stream(\"\u5929\u6c14\u5982\u4f55\u5f71\u54cd\u5fc3\u60c5\uff1f\"):\n    full_response = chunk if full_response is None else full_response + chunk\n\nprint(f\"\\n\u5b8c\u6574\u56de\u590d: {full_response.content}\")\n</code></pre>"},{"location":"llmapps/langchain/core-components/models/#3-batch","title":"3. \u6279\u91cf\u8c03\u7528\uff08Batch\uff09","text":"<pre><code># \u57fa\u672c\u6279\u91cf\u5904\u7406\nquestions = [\n    \"\u4ec0\u4e48\u662f\u4eba\u5de5\u667a\u80fd\uff1f\",\n    \"\u89e3\u91ca\u6df1\u5ea6\u5b66\u4e60\",\n    \"\u673a\u5668\u5b66\u4e60\u7684\u5e94\u7528\u573a\u666f\",\n    \"\u795e\u7ecf\u7f51\u7edc\u5982\u4f55\u5de5\u4f5c\"\n]\n\nresponses = model.batch(questions)\nfor i, response in enumerate(responses):\n    print(f\"\u95ee\u9898 {i+1}: {response.content[:100]}...\")\n\n# \u5f02\u6b65\u5b8c\u6210\u6279\u91cf\u5904\u7406\nprint(\"\u6309\u5b8c\u6210\u987a\u5e8f\u8f93\u51fa:\")\nfor response in model.batch_as_completed(questions):\n    print(f\"\u6536\u5230\u56de\u590d: {response.content[:50]}...\")\n\n# \u63a7\u5236\u5e76\u53d1\u6570\nresponses = model.batch(\n    questions,\n    config={'max_concurrency': 2}  # \u9650\u5236\u540c\u65f62\u4e2a\u8bf7\u6c42\n)\n</code></pre>"},{"location":"llmapps/langchain/core-components/models/#_7","title":"\u5de5\u5177\u8c03\u7528","text":""},{"location":"llmapps/langchain/core-components/models/#1_1","title":"1. \u7ed1\u5b9a\u5de5\u5177","text":"<pre><code>from langchain.tools import tool\n\n@tool\ndef get_weather(location: str) -&gt; str:\n    \"\"\"\u83b7\u53d6\u6307\u5b9a\u4f4d\u7f6e\u7684\u5929\u6c14\u4fe1\u606f\u3002\"\"\"\n    return f\"{location}\u7684\u5929\u6c14\uff1a\u6674\u6717\uff0c25\u00b0C\"\n\n@tool\ndef calculator(expression: str) -&gt; str:\n    \"\"\"\u8ba1\u7b97\u6570\u5b66\u8868\u8fbe\u5f0f\u3002\"\"\"\n    try:\n        result = eval(expression)\n        return f\"{expression} = {result}\"\n    except:\n        return \"\u8ba1\u7b97\u9519\u8bef\"\n\n# \u7ed1\u5b9a\u5de5\u5177\u5230\u6a21\u578b\nmodel_with_tools = model.bind_tools([get_weather, calculator])\n\n# \u8c03\u7528\u5e26\u5de5\u5177\u7684\u6a21\u578b\nresponse = model_with_tools.invoke(\"\u5317\u4eac\u4eca\u5929\u5929\u6c14\u600e\u4e48\u6837\uff1f\u7136\u540e\u8ba1\u7b97 25 * 4\")\nprint(\"\u5de5\u5177\u8c03\u7528:\", response.tool_calls)\n</code></pre>"},{"location":"llmapps/langchain/core-components/models/#2_1","title":"2. \u5de5\u5177\u6267\u884c\u5faa\u73af","text":"<pre><code>def execute_tool_calls(model, messages, tools):\n    \"\"\"\u6267\u884c\u5de5\u5177\u8c03\u7528\u5faa\u73af\"\"\"\n    # \u6a21\u578b\u751f\u6210\u5de5\u5177\u8c03\u7528\n    ai_msg = model.invoke(messages)\n    messages.append(ai_msg)\n\n    # \u6267\u884c\u6240\u6709\u5de5\u5177\u8c03\u7528\n    for tool_call in ai_msg.tool_calls:\n        tool_name = tool_call[\"name\"]\n        tool_args = tool_call[\"args\"]\n\n        # \u627e\u5230\u5bf9\u5e94\u7684\u5de5\u5177\u5e76\u6267\u884c\n        for tool in tools:\n            if tool.name == tool_name:\n                result = tool.invoke(tool_args)\n                messages.append({\n                    \"role\": \"tool\",\n                    \"content\": result,\n                    \"tool_call_id\": tool_call[\"id\"]\n                })\n                break\n\n    # \u83b7\u53d6\u6700\u7ec8\u56de\u590d\n    final_response = model.invoke(messages)\n    return final_response\n\n# \u4f7f\u7528\u793a\u4f8b\ntools = [get_weather, calculator]\nmessages = [{\"role\": \"user\", \"content\": \"\u5317\u4eac\u5929\u6c14\u5982\u4f55\uff1f\u7136\u540e\u8ba1\u7b97 15 + 27\"}]\nresult = execute_tool_calls(model_with_tools, messages, tools)\nprint(\"\u6700\u7ec8\u56de\u590d:\", result.content)\n</code></pre>"},{"location":"llmapps/langchain/core-components/models/#3","title":"3. \u9ad8\u7ea7\u5de5\u5177\u529f\u80fd","text":"<pre><code># \u5f3a\u5236\u4f7f\u7528\u7279\u5b9a\u5de5\u5177\nforced_model = model.bind_tools(\n    [get_weather], \n    tool_choice=\"get_weather\"  # \u5f3a\u5236\u4f7f\u7528\u5929\u6c14\u5de5\u5177\n)\n\n# \u7981\u7528\u5e76\u884c\u5de5\u5177\u8c03\u7528\nsequential_model = model.bind_tools(\n    [get_weather, calculator],\n    parallel_tool_calls=False  # \u987a\u5e8f\u6267\u884c\u5de5\u5177\n)\n\n# \u6d41\u5f0f\u5de5\u5177\u8c03\u7528\nprint(\"\u6d41\u5f0f\u5de5\u5177\u8c03\u7528:\")\nfor chunk in model_with_tools.stream(\"\u67e5\u8be2\u5317\u4eac\u548c\u4e0a\u6d77\u7684\u5929\u6c14\"):\n    if hasattr(chunk, 'tool_call_chunks') and chunk.tool_call_chunks:\n        for tool_chunk in chunk.tool_call_chunks:\n            if tool_chunk.get('name'):\n                print(f\"\u5de5\u5177: {tool_chunk['name']}\")\n            if tool_chunk.get('args'):\n                print(f\"\u53c2\u6570: {tool_chunk['args']}\")\n</code></pre>"},{"location":"llmapps/langchain/core-components/models/#_8","title":"\u7ed3\u6784\u5316\u8f93\u51fa","text":""},{"location":"llmapps/langchain/core-components/models/#1-pydantic","title":"1. Pydantic \u6a21\u578b","text":"<pre><code>from pydantic import BaseModel, Field\nfrom typing import List\n\nclass Movie(BaseModel):\n    \"\"\"\u7535\u5f71\u4fe1\u606f\"\"\"\n    title: str = Field(description=\"\u7535\u5f71\u6807\u9898\")\n    year: int = Field(description=\"\u4e0a\u6620\u5e74\u4efd\")\n    director: str = Field(description=\"\u5bfc\u6f14\")\n    rating: float = Field(description=\"\u8bc4\u5206(0-10)\")\n    genres: List[str] = Field(description=\"\u7c7b\u578b\u5217\u8868\")\n\nclass ProductReview(BaseModel):\n    \"\"\"\u4ea7\u54c1\u8bc4\u4ef7\"\"\"\n    product_name: str = Field(description=\"\u4ea7\u54c1\u540d\u79f0\")\n    rating: int = Field(description=\"\u8bc4\u5206(1-5)\")\n    pros: List[str] = Field(description=\"\u4f18\u70b9\")\n    cons: List[str] = Field(description=\"\u7f3a\u70b9\")\n    summary: str = Field(description=\"\u603b\u7ed3\")\n\n# \u4f7f\u7528\u7ed3\u6784\u5316\u8f93\u51fa\nstructured_model = model.with_structured_output(Movie)\nresponse = structured_model.invoke(\"\u63d0\u4f9b\u7535\u5f71\u300a\u76d7\u68a6\u7a7a\u95f4\u300b\u7684\u8be6\u7ec6\u4fe1\u606f\")\n\nprint(f\"\u6807\u9898: {response.title}\")\nprint(f\"\u5e74\u4efd: {response.year}\")\nprint(f\"\u5bfc\u6f14: {response.director}\")\nprint(f\"\u8bc4\u5206: {response.rating}\")\n</code></pre>"},{"location":"llmapps/langchain/core-components/models/#2_2","title":"2. \u5305\u542b\u539f\u59cb\u54cd\u5e94","text":"<pre><code># \u540c\u65f6\u83b7\u53d6\u89e3\u6790\u7ed3\u679c\u548c\u539f\u59cb\u6d88\u606f\nstructured_model_with_raw = model.with_structured_output(\n    Movie, \n    include_raw=True\n)\n\nresult = structured_model_with_raw.invoke(\"\u63cf\u8ff0\u7535\u5f71\u300a\u963f\u51e1\u8fbe\u300b\")\n\nprint(\"\u89e3\u6790\u7ed3\u679c:\", result.parsed)\nprint(\"\u539f\u59cb\u6d88\u606f:\", result.raw)\nprint(\"\u89e3\u6790\u9519\u8bef:\", result.parsing_error)\n</code></pre>"},{"location":"llmapps/langchain/core-components/models/#3_1","title":"3. \u590d\u6742\u5d4c\u5957\u7ed3\u6784","text":"<pre><code>from typing import Optional\n\nclass Actor(BaseModel):\n    \"\"\"\u6f14\u5458\u4fe1\u606f\"\"\"\n    name: str = Field(description=\"\u6f14\u5458\u59d3\u540d\")\n    character: str = Field(description=\"\u626e\u6f14\u89d2\u8272\")\n\nclass MovieDetails(BaseModel):\n    \"\"\"\u8be6\u7ec6\u7535\u5f71\u4fe1\u606f\"\"\"\n    title: str = Field(description=\"\u7535\u5f71\u6807\u9898\")\n    year: int = Field(description=\"\u4e0a\u6620\u5e74\u4efd\")\n    director: str = Field(description=\"\u5bfc\u6f14\")\n    cast: List[Actor] = Field(description=\"\u6f14\u5458\u8868\")\n    budget: Optional[float] = Field(description=\"\u9884\u7b97\uff08\u767e\u4e07\u7f8e\u5143\uff09\")\n    box_office: Optional[float] = Field(description=\"\u7968\u623f\uff08\u767e\u4e07\u7f8e\u5143\uff09\")\n\n# \u4f7f\u7528\u5d4c\u5957\u7ed3\u6784\ndetailed_model = model.with_structured_output(MovieDetails)\nresponse = detailed_model.invoke(\"\u63d0\u4f9b\u300a\u6cf0\u5766\u5c3c\u514b\u53f7\u300b\u7684\u5b8c\u6574\u4fe1\u606f\")\n\nprint(f\"\u7535\u5f71: {response.title} ({response.year})\")\nprint(f\"\u5bfc\u6f14: {response.director}\")\nprint(\"\u4e3b\u6f14:\")\nfor actor in response.cast:\n    print(f\"  - {actor.name} \u9970\u6f14 {actor.character}\")\n</code></pre>"},{"location":"llmapps/langchain/core-components/models/#_9","title":"\u9ad8\u7ea7\u529f\u80fd","text":""},{"location":"llmapps/langchain/core-components/models/#1_2","title":"1. \u591a\u6a21\u6001\u5904\u7406","text":"<pre><code>from langchain_core.messages import HumanMessage\nimport base64\n\n# \u5904\u7406\u56fe\u50cf\uff08\u6a21\u62df\uff09\ndef encode_image(image_path):\n    \"\"\"\u7f16\u7801\u56fe\u50cf\u4e3abase64\"\"\"\n    with open(image_path, \"rb\") as image_file:\n        return base64.b64encode(image_file.read()).decode('utf-8')\n\n# \u521b\u5efa\u591a\u6a21\u6001\u6d88\u606f\nmultimodal_message = [\n    {\n        \"type\": \"text\",\n        \"text\": \"\u63cf\u8ff0\u8fd9\u5f20\u56fe\u7247\u4e2d\u7684\u5185\u5bb9\"\n    },\n    {\n        \"type\": \"image_url\",\n        \"image_url\": {\n            \"url\": \"data:image/jpeg;base64,...\"  # \u5b9e\u9645\u4f7f\u7528\u4e2d\u66ff\u6362\u4e3a\u771f\u5b9ebase64\u6570\u636e\n        }\n    }\n]\n\n# \u652f\u6301\u591a\u6a21\u6001\u7684\u6a21\u578b\u8c03\u7528\nresponse = model.invoke(multimodal_message)\nprint(\"\u56fe\u50cf\u63cf\u8ff0:\", response.content)\n</code></pre>"},{"location":"llmapps/langchain/core-components/models/#2_3","title":"2. \u63a8\u7406\u8fc7\u7a0b","text":"<pre><code># \u6d41\u5f0f\u63a8\u7406\u8fc7\u7a0b\nprint(\"\u63a8\u7406\u8fc7\u7a0b:\")\nfor chunk in model.stream(\"\u4e3a\u4ec0\u4e48\u5929\u7a7a\u662f\u84dd\u8272\u7684\uff1f\"):\n    # \u68c0\u67e5\u63a8\u7406\u5757\n    if hasattr(chunk, 'content_blocks'):\n        for block in chunk.content_blocks:\n            if block.get(\"type\") == \"reasoning\" and block.get(\"reasoning\"):\n                print(f\"\u63a8\u7406: {block['reasoning']}\")\n            elif block.get(\"type\") == \"text\" and block.get(\"text\"):\n                print(f\"\u56de\u7b54: {block['text']}\")\n\n# \u83b7\u53d6\u5b8c\u6574\u63a8\u7406\nresponse = model.invoke(\"\u89e3\u91ca\u5168\u7403\u53d8\u6696\u7684\u539f\u56e0\", reasoning_effort=\"high\")\nreasoning_blocks = [b for b in response.content_blocks if b.get(\"type\") == \"reasoning\"]\nif reasoning_blocks:\n    print(\"\u5b8c\u6574\u63a8\u7406\u8fc7\u7a0b:\")\n    for block in reasoning_blocks:\n        print(block.get(\"reasoning\", \"\"))\n</code></pre>"},{"location":"llmapps/langchain/core-components/models/#3_2","title":"3. \u672c\u5730\u6a21\u578b","text":"<pre><code># \u4f7f\u7528 Ollama \u8fd0\u884c\u672c\u5730\u6a21\u578b\nfrom langchain_ollama import ChatOllama\n\nmodel = ChatOllama(\n    model=\"qwen3:1.7b\",\n    temperature=0.8\n)\n\nresponse = model.invoke(\"\u7528\u4e2d\u6587\u89e3\u91ca\u673a\u5668\u5b66\u4e60\")\nprint(\"\u672c\u5730\u6a21\u578b\u56de\u590d:\", response.content)\n</code></pre>"},{"location":"llmapps/langchain/core-components/models/#4","title":"4. \u901f\u7387\u9650\u5236","text":"<pre><code>from langchain_core.rate_limiters import InMemoryRateLimiter\n\n# \u521b\u5efa\u901f\u7387\u9650\u5236\u5668\nrate_limiter = InMemoryRateLimiter(\n    requests_per_second=1,      # \u6bcf\u79d21\u4e2a\u8bf7\u6c42\n    check_every_n_seconds=0.1,  # \u6bcf100ms\u68c0\u67e5\u4e00\u6b21\n    max_bucket_size=5          # \u6700\u5927\u7a81\u53d1\u8bf7\u6c42\u6570\n)\n\nmodel_with_limiter = init_chat_model(\n    \"openai:gpt-4o\",\n    rate_limiter=rate_limiter\n)\n\n# \u53d7\u901f\u7387\u9650\u5236\u7684\u8c03\u7528\nfor i in range(3):\n    response = model_with_limiter.invoke(f\"\u95ee\u9898 {i+1}: \u4ec0\u4e48\u662fAI\uff1f\")\n    print(f\"\u56de\u590d {i+1}: {response.content[:50]}...\")\n</code></pre>"},{"location":"llmapps/langchain/core-components/models/#5","title":"5. \u4ee4\u724c\u4f7f\u7528\u7edf\u8ba1","text":"<pre><code>from langchain_core.callbacks import get_usage_metadata_callback\n\n# \u4f7f\u7528\u4e0a\u4e0b\u6587\u7ba1\u7406\u5668\u8ddf\u8e2a\u4ee4\u724c\u4f7f\u7528\nwith get_usage_metadata_callback() as callback:\n    response1 = model.invoke(\"\u89e3\u91ca\u795e\u7ecf\u7f51\u7edc\")\n    response2 = model.invoke(\"\u4ec0\u4e48\u662f\u6df1\u5ea6\u5b66\u4e60\")\n\n    print(\"\u4ee4\u724c\u4f7f\u7528\u7edf\u8ba1:\")\n    print(callback.usage_metadata)\n\n# \u76f4\u63a5\u4ece\u54cd\u5e94\u83b7\u53d6\u4ee4\u724c\u4fe1\u606f\nresponse = model.invoke(\"\u5199\u4e00\u4e2aPython\u51fd\u6570\u8ba1\u7b97\u6590\u6ce2\u90a3\u5951\u6570\u5217\")\nif hasattr(response, 'response_metadata'):\n    usage = response.response_metadata.get('token_usage', {})\n    print(f\"\u8f93\u5165\u4ee4\u724c: {usage.get('prompt_tokens', 'N/A')}\")\n    print(f\"\u8f93\u51fa\u4ee4\u724c: {usage.get('completion_tokens', 'N/A')}\")\n    print(f\"\u603b\u4ee4\u724c: {usage.get('total_tokens', 'N/A')}\")\n</code></pre>"},{"location":"llmapps/langchain/core-components/models/#6","title":"6. \u53ef\u914d\u7f6e\u6a21\u578b","text":"<pre><code># \u521b\u5efa\u8fd0\u884c\u65f6\u53ef\u914d\u7f6e\u7684\u6a21\u578b\nconfigurable_model = init_chat_model(\n    temperature=0,\n    configurable_fields=(\"model\", \"temperature\", \"max_tokens\")\n)\n\n# \u4f7f\u7528\u4e0d\u540c\u914d\u7f6e\u8c03\u7528\nresponse1 = configurable_model.invoke(\n    \"\u89e3\u91ca\u673a\u5668\u5b66\u4e60\",\n    config={\"configurable\": {\"model\": \"gpt-4o\", \"temperature\": 0.7}}\n)\n\nresponse2 = configurable_model.invoke(\n    \"\u5199\u4e00\u9996\u8bd7\", \n    config={\"configurable\": {\"model\": \"gpt-4o\", \"temperature\": 0.9}}\n)\n\nprint(\"\u6280\u672f\u89e3\u91ca:\", response1.content[:100])\nprint(\"\u8bd7\u6b4c\u521b\u4f5c:\", response2.content[:100])\n</code></pre>"},{"location":"llmapps/langchain/core-components/models/#_10","title":"\u5b9e\u9645\u5e94\u7528\u573a\u666f","text":""},{"location":"llmapps/langchain/core-components/models/#1_3","title":"\u573a\u666f1\uff1a\u5185\u5bb9\u751f\u6210","text":"<pre><code>class ContentGenerator:\n    \"\"\"\u5185\u5bb9\u751f\u6210\u5668\"\"\"\n\n    def __init__(self, model):\n        self.model = model\n\n    def generate_blog_post(self, topic: str, style: str = \"informative\") -&gt; str:\n        \"\"\"\u751f\u6210\u535a\u5ba2\u6587\u7ae0\"\"\"\n        prompt = f\"\"\"\n        \u4ee5{style}\u7684\u98ce\u683c\u5199\u4e00\u7bc7\u5173\u4e8e{topic}\u7684\u535a\u5ba2\u6587\u7ae0\u3002\n        \u8981\u6c42\uff1a\n        1. \u6807\u9898\u5438\u5f15\u4eba\n        2. \u7ed3\u6784\u6e05\u6670\uff08\u5f15\u8a00\u3001\u6b63\u6587\u3001\u7ed3\u8bba\uff09\n        3. \u5305\u542b\u5177\u4f53\u4f8b\u5b50\n        4. \u5b57\u6570800-1000\u5b57\n        \"\"\"\n\n        response = self.model.invoke(prompt)\n        return response.content\n\n    def generate_social_media_post(self, topic: str, platform: str) -&gt; str:\n        \"\"\"\u751f\u6210\u793e\u4ea4\u5a92\u4f53\u5e16\u5b50\"\"\"\n        platform_formats = {\n            \"twitter\": \"280\u5b57\u7b26\u4ee5\u5185\uff0c\u4f7f\u7528\u8bdd\u9898\u6807\u7b7e\",\n            \"linkedin\": \"\u4e13\u4e1a\u98ce\u683c\uff0c\u805a\u7126\u884c\u4e1a\u89c1\u89e3\",\n            \"instagram\": \"\u8f7b\u677e\u6709\u8da3\uff0c\u4f7f\u7528\u8868\u60c5\u7b26\u53f7\"\n        }\n\n        format_guide = platform_formats.get(platform, \"\u7b80\u6d01\u6709\u529b\")\n        prompt = f\"\u4e3a{platform}\u521b\u5efa\u5173\u4e8e{topic}\u7684\u5e16\u5b50\u3002\u8981\u6c42\uff1a{format_guide}\"\n\n        response = self.model.invoke(prompt)\n        return response.content\n\n# \u4f7f\u7528\u793a\u4f8b\ngenerator = ContentGenerator(model)\nblog_post = generator.generate_blog_post(\"\u4eba\u5de5\u667a\u80fd\u7684\u672a\u6765\", \"\u4e13\u4e1a\")\ntwitter_post = generator.generate_social_media_post(\"\u673a\u5668\u5b66\u4e60\", \"twitter\")\n\nprint(\"\u535a\u5ba2\u6587\u7ae0:\", blog_post[:200])\nprint(\"\u63a8\u7279\u5e16\u5b50:\", twitter_post)\n</code></pre>"},{"location":"llmapps/langchain/core-components/models/#2_4","title":"\u573a\u666f2\uff1a\u6570\u636e\u5206\u6790\u52a9\u624b","text":"<pre><code>import json\nfrom typing import Dict, Any\n\nclass DataAnalysisAssistant:\n    \"\"\"\u6570\u636e\u5206\u6790\u52a9\u624b\"\"\"\n\n    def __init__(self, model):\n        self.model = model\n        # \u914d\u7f6e\u7ed3\u6784\u5316\u8f93\u51fa\u7528\u4e8e\u6570\u636e\u5206\u6790\n        self.analysis_model = model.with_structured_output(DataAnalysisResult)\n\n    def analyze_dataset(self, data_description: str, questions: List[str]) -&gt; Dict[str, Any]:\n        \"\"\"\u5206\u6790\u6570\u636e\u96c6\"\"\"\n        prompt = f\"\"\"\n        \u6570\u636e\u96c6\u63cf\u8ff0: {data_description}\n\n        \u8bf7\u5206\u6790\u8fd9\u4e2a\u6570\u636e\u96c6\u5e76\u56de\u7b54\u4ee5\u4e0b\u95ee\u9898:\n        {chr(10).join(f'{i+1}. {q}' for i, q in enumerate(questions))}\n\n        \u63d0\u4f9b:\n        - \u5173\u952e\u6d1e\u5bdf\n        - \u6f5c\u5728\u6a21\u5f0f\n        - \u5efa\u8bae\u7684\u8fdb\u4e00\u6b65\u5206\u6790\n        \"\"\"\n\n        response = self.analysis_model.invoke(prompt)\n        return response.dict()\n\n    def generate_sql_query(self, requirement: str, schema: str) -&gt; str:\n        \"\"\"\u751f\u6210SQL\u67e5\u8be2\"\"\"\n        prompt = f\"\"\"\n        \u6570\u636e\u5e93\u6a21\u5f0f: {schema}\n\n        \u9700\u6c42: {requirement}\n\n        \u8bf7\u751f\u6210\u4e00\u4e2a\u4f18\u5316\u7684SQL\u67e5\u8be2\u6765\u6ee1\u8db3\u8fd9\u4e2a\u9700\u6c42\u3002\n        \u540c\u65f6\u89e3\u91ca\u67e5\u8be2\u7684\u903b\u8f91\u3002\n        \"\"\"\n\n        response = self.model.invoke(prompt)\n        return response.content\n\n# \u6570\u636e\u7ed3\u6784\u5b9a\u4e49\nclass DataAnalysisResult(BaseModel):\n    key_insights: List[str]\n    patterns: List[str]\n    recommendations: List[str]\n    summary: str\n\n# \u4f7f\u7528\u793a\u4f8b\nassistant = DataAnalysisAssistant(model)\n\nschema = \"\"\"\n\u7528\u6237\u8868(users): id, name, age, city, signup_date\n\u8ba2\u5355\u8868(orders): id, user_id, amount, order_date, status\n\"\"\"\n\nanalysis = assistant.analyze_dataset(\n    \"\u7535\u5546\u5e73\u53f0\u7684\u7528\u6237\u548c\u8ba2\u5355\u6570\u636e\",\n    [\"\u7528\u6237\u5e74\u9f84\u5206\u5e03\u5982\u4f55\uff1f\", \"\u54ea\u4e2a\u57ce\u5e02\u7684\u7528\u6237\u6700\u6d3b\u8dc3\uff1f\", \"\u8ba2\u5355\u8d8b\u52bf\u5982\u4f55\uff1f\"]\n)\n\nsql_query = assistant.generate_sql_query(\n    \"\u67e5\u8be2\u6700\u8fd130\u5929\u6bcf\u4e2a\u57ce\u5e02\u7684\u8ba2\u5355\u603b\u91cf\",\n    schema\n)\n\nprint(\"\u5206\u6790\u7ed3\u679c:\", analysis)\nprint(\"SQL\u67e5\u8be2:\", sql_query)\n</code></pre>"},{"location":"llmapps/langchain/core-components/models/#3_3","title":"\u573a\u666f3\uff1a\u4ee3\u7801\u52a9\u624b","text":"<pre><code>class CodeAssistant:\n    \"\"\"\u4ee3\u7801\u52a9\u624b\"\"\"\n\n    def __init__(self, model):\n        self.model = model\n\n    def explain_code(self, code: str, language: str = \"python\") -&gt; str:\n        \"\"\"\u89e3\u91ca\u4ee3\u7801\"\"\"\n        prompt = f\"\"\"\n        \u8bf7\u89e3\u91ca\u4ee5\u4e0b{language}\u4ee3\u7801:\n\n        ```{language}\n        {code}\n        ```\n\n        \u89e3\u91ca\u5e94\u8be5\u5305\u62ec:\n        1. \u4ee3\u7801\u7684\u529f\u80fd\n        2. \u5173\u952e\u903b\u8f91\u6b65\u9aa4\n        3. \u53ef\u80fd\u7684\u6539\u8fdb\u5efa\u8bae\n        \"\"\"\n\n        response = self.model.invoke(prompt)\n        return response.content\n\n    def debug_code(self, code: str, error: str, language: str = \"python\") -&gt; str:\n        \"\"\"\u8c03\u8bd5\u4ee3\u7801\"\"\"\n        prompt = f\"\"\"\n        \u8bf7\u5e2e\u52a9\u8c03\u8bd5\u4ee5\u4e0b{language}\u4ee3\u7801:\n\n        ```{language}\n        {code}\n        ```\n\n        \u9519\u8bef\u4fe1\u606f: {error}\n\n        \u8bf7\u63d0\u4f9b:\n        1. \u9519\u8bef\u539f\u56e0\u5206\u6790\n        2. \u4fee\u590d\u5efa\u8bae\n        3. \u4fee\u590d\u540e\u7684\u4ee3\u7801\n        \"\"\"\n\n        response = self.model.invoke(prompt)\n        return response.content\n\n    def generate_test_cases(self, code: str, language: str = \"python\") -&gt; str:\n        \"\"\"\u751f\u6210\u6d4b\u8bd5\u7528\u4f8b\"\"\"\n        prompt = f\"\"\"\n        \u4e3a\u4ee5\u4e0b{language}\u4ee3\u7801\u751f\u6210\u6d4b\u8bd5\u7528\u4f8b:\n\n        ```{language}\n        {code}\n        ```\n\n        \u5305\u62ec:\n        1. \u6b63\u5e38\u60c5\u51b5\u6d4b\u8bd5\n        2. \u8fb9\u754c\u60c5\u51b5\u6d4b\u8bd5  \n        3. \u9519\u8bef\u60c5\u51b5\u6d4b\u8bd5\n        \"\"\"\n\n        response = self.model.invoke(prompt)\n        return response.content\n\n# \u4f7f\u7528\u793a\u4f8b\ncode_assistant = CodeAssistant(model)\n\nsample_code = \"\"\"\ndef fibonacci(n):\n    if n &lt;= 1:\n        return n\n    else:\n        return fibonacci(n-1) + fibonacci(n-2)\n\"\"\"\n\nexplanation = code_assistant.explain_code(sample_code)\ntest_cases = code_assistant.generate_test_cases(sample_code)\n\nprint(\"\u4ee3\u7801\u89e3\u91ca:\", explanation)\nprint(\"\u6d4b\u8bd5\u7528\u4f8b:\", test_cases)\n</code></pre>"},{"location":"llmapps/langchain/core-components/models/#_11","title":"\u6700\u4f73\u5b9e\u8df5","text":""},{"location":"llmapps/langchain/core-components/models/#1_4","title":"1. \u9519\u8bef\u5904\u7406","text":"<pre><code>from tenacity import retry, stop_after_attempt, wait_exponential\nimport asyncio\n\nclass RobustModelClient:\n    \"\"\"\u5065\u58ee\u7684\u6a21\u578b\u5ba2\u6237\u7aef\"\"\"\n\n    def __init__(self, model):\n        self.model = model\n\n    @retry(\n        stop=stop_after_attempt(3),\n        wait=wait_exponential(multiplier=1, min=4, max=10)\n    )\n    def invoke_with_retry(self, prompt: str, **kwargs):\n        \"\"\"\u5e26\u91cd\u8bd5\u7684\u8c03\u7528\"\"\"\n        try:\n            return self.model.invoke(prompt, **kwargs)\n        except Exception as e:\n            print(f\"\u8c03\u7528\u5931\u8d25: {e}, \u8fdb\u884c\u91cd\u8bd5...\")\n            raise\n\n    def safe_batch_process(self, prompts: List[str], batch_size: int = 5):\n        \"\"\"\u5b89\u5168\u7684\u6279\u91cf\u5904\u7406\"\"\"\n        results = []\n\n        for i in range(0, len(prompts), batch_size):\n            batch = prompts[i:i + batch_size]\n            try:\n                batch_results = self.model.batch(\n                    batch, \n                    config={'max_concurrency': 2}\n                )\n                results.extend(batch_results)\n                print(f\"\u5b8c\u6210\u6279\u6b21 {i//batch_size + 1}\")\n            except Exception as e:\n                print(f\"\u6279\u6b21 {i//batch_size + 1} \u5931\u8d25: {e}\")\n                # \u53ef\u4ee5\u5728\u8fd9\u91cc\u6dfb\u52a0\u91cd\u8bd5\u903b\u8f91\n\n        return results\n\n# \u4f7f\u7528\u793a\u4f8b\nrobust_client = RobustModelClient(model)\n\ntry:\n    response = robust_client.invoke_with_retry(\n        \"\u89e3\u91ca\u91cf\u5b50\u529b\u5b66\", \n        temperature=0.7\n    )\n    print(\"\u6210\u529f\u83b7\u53d6\u54cd\u5e94\")\nexcept Exception as e:\n    print(f\"\u6240\u6709\u91cd\u8bd5\u90fd\u5931\u8d25\u4e86: {e}\")\n</code></pre>"},{"location":"llmapps/langchain/core-components/models/#2_5","title":"2. \u6027\u80fd\u4f18\u5316","text":"<pre><code>import time\nfrom functools import lru_cache\n\nclass OptimizedModelHandler:\n    \"\"\"\u4f18\u5316\u7684\u6a21\u578b\u5904\u7406\u5668\"\"\"\n\n    def __init__(self, model):\n        self.model = model\n        self.response_cache = {}\n\n    @lru_cache(maxsize=100)\n    def cached_invoke(self, prompt: str, temperature: float = 0.7) -&gt; str:\n        \"\"\"\u5e26\u7f13\u5b58\u7684\u8c03\u7528\"\"\"\n        cache_key = hash(prompt + str(temperature))\n\n        if cache_key in self.response_cache:\n            return self.response_cache[cache_key]\n\n        start_time = time.time()\n        response = self.model.invoke(prompt, temperature=temperature)\n        execution_time = time.time() - start_time\n\n        self.response_cache[cache_key] = response.content\n        print(f\"\u65b0\u8bf7\u6c42 - \u8017\u65f6: {execution_time:.2f}s\")\n\n        return response.content\n\n    def batch_optimized(self, prompts: List[str], **kwargs):\n        \"\"\"\u4f18\u5316\u7684\u6279\u91cf\u5904\u7406\"\"\"\n        # \u53bb\u91cd\n        unique_prompts = list(set(prompts))\n\n        # \u6279\u91cf\u5904\u7406\u552f\u4e00\u63d0\u793a\n        unique_responses = self.model.batch(unique_prompts, **kwargs)\n\n        # \u6784\u5efa\u54cd\u5e94\u6620\u5c04\n        response_map = {prompt: resp.content for prompt, resp in zip(unique_prompts, unique_responses)}\n\n        # \u6309\u539f\u59cb\u987a\u5e8f\u8fd4\u56de\n        return [response_map[prompt] for prompt in prompts]\n\n# \u4f7f\u7528\u793a\u4f8b\noptimized_handler = OptimizedModelHandler(model)\n\n# \u91cd\u590d\u8bf7\u6c42\u4f1a\u4f7f\u7528\u7f13\u5b58\nfor i in range(3):\n    result = optimized_handler.cached_invoke(\"\u4ec0\u4e48\u662fPython\uff1f\")\n    print(f\"\u8bf7\u6c42 {i+1}: {result[:50]}...\")\n</code></pre>"},{"location":"llmapps/langchain/core-components/models/#3_4","title":"3. \u6210\u672c\u63a7\u5236","text":"<pre><code>class CostAwareModelClient:\n    \"\"\"\u6210\u672c\u611f\u77e5\u7684\u6a21\u578b\u5ba2\u6237\u7aef\"\"\"\n\n    def __init__(self, model, budget_limit: int = 1000000):  # 100\u4e07token\u9650\u5236\n        self.model = model\n        self.budget_limit = budget_limit\n        self.tokens_used = 0\n        self.requests_count = 0\n\n    def track_usage(self, response):\n        \"\"\"\u8ddf\u8e2a\u4ee4\u724c\u4f7f\u7528\"\"\"\n        if hasattr(response, 'response_metadata'):\n            usage = response.response_metadata.get('token_usage', {})\n            tokens = usage.get('total_tokens', 0)\n            self.tokens_used += tokens\n            self.requests_count += 1\n\n            print(f\"\u672c\u6b21\u4f7f\u7528: {tokens} tokens\")\n            print(f\"\u7d2f\u8ba1\u4f7f\u7528: {self.tokens_used}/{self.budget_limit} tokens\")\n\n            if self.tokens_used &gt;= self.budget_limit:\n                print(\"\u8b66\u544a: \u63a5\u8fd1\u9884\u7b97\u9650\u5236\uff01\")\n\n    def invoke_with_budget(self, prompt: str, **kwargs):\n        \"\"\"\u5e26\u9884\u7b97\u63a7\u5236\u7684\u8c03\u7528\"\"\"\n        if self.tokens_used &gt;= self.budget_limit:\n            raise Exception(\"\u5df2\u8d85\u8fc7\u9884\u7b97\u9650\u5236\")\n\n        response = self.model.invoke(prompt, **kwargs)\n        self.track_usage(response)\n        return response\n\n    def get_usage_stats(self):\n        \"\"\"\u83b7\u53d6\u4f7f\u7528\u7edf\u8ba1\"\"\"\n        return {\n            'tokens_used': self.tokens_used,\n            'requests_count': self.requests_count,\n            'budget_remaining': self.budget_limit - self.tokens_used,\n            'utilization_percentage': (self.tokens_used / self.budget_limit) * 100\n        }\n\n# \u4f7f\u7528\u793a\u4f8b\ncost_aware_client = CostAwareModelClient(model, budget_limit=5000)  # 5000token\u6d4b\u8bd5\u9650\u5236\n\ntry:\n    response1 = cost_aware_client.invoke_with_budget(\"\u89e3\u91ca\u673a\u5668\u5b66\u4e60\")\n    response2 = cost_aware_client.invoke_with_budget(\"\u4ec0\u4e48\u662f\u6df1\u5ea6\u5b66\u4e60\")\n\n    stats = cost_aware_client.get_usage_stats()\n    print(\"\u4f7f\u7528\u7edf\u8ba1:\", stats)\n\nexcept Exception as e:\n    print(f\"\u8c03\u7528\u5931\u8d25: {e}\")\n</code></pre>"},{"location":"llmapps/langchain/core-components/models/#_12","title":"\u603b\u7ed3","text":"<p>LangChain Models \u63d0\u4f9b\u4e86\u5f3a\u5927\u800c\u7075\u6d3b\u7684\u65b9\u5f0f\u6765\u4f7f\u7528\u5404\u79cd\u5927\u8bed\u8a00\u6a21\u578b\uff1a</p> <ul> <li>\u591a\u63d0\u4f9b\u5546\u652f\u6301\uff1aOpenAI\u3001Anthropic\u3001Google\u3001Azure\u7b49</li> <li>\u591a\u79cd\u8c03\u7528\u65b9\u5f0f\uff1a\u5355\u6b21\u8c03\u7528\u3001\u6d41\u5f0f\u8c03\u7528\u3001\u6279\u91cf\u8c03\u7528</li> <li>\u5de5\u5177\u96c6\u6210\uff1a\u7ed1\u5b9a\u548c\u6267\u884c\u5916\u90e8\u5de5\u5177</li> <li>\u7ed3\u6784\u5316\u8f93\u51fa\uff1a\u786e\u4fdd\u54cd\u5e94\u683c\u5f0f\u7b26\u5408\u9884\u671f</li> <li>\u9ad8\u7ea7\u529f\u80fd\uff1a\u591a\u6a21\u6001\u3001\u63a8\u7406\u3001\u672c\u5730\u90e8\u7f72\u7b49</li> <li>\u751f\u4ea7\u5c31\u7eea\uff1a\u9519\u8bef\u5904\u7406\u3001\u6027\u80fd\u4f18\u5316\u3001\u6210\u672c\u63a7\u5236</li> </ul> <p>\u901a\u8fc7\u5408\u7406\u4f7f\u7528\u8fd9\u4e9b\u529f\u80fd\uff0c\u60a8\u53ef\u4ee5\u6784\u5efa\u51fa\u5f3a\u5927\u3001\u53ef\u9760\u4e14\u6210\u672c\u6548\u76ca\u9ad8\u7684AI\u5e94\u7528\u7cfb\u7edf\u3002</p>"},{"location":"llmapps/langchain/core-components/short-term%20memory/","title":"LangChain \u77ed\u671f\u8bb0\u5fc6","text":""},{"location":"llmapps/langchain/core-components/short-term%20memory/#_1","title":"\u6982\u8ff0","text":"<p>\u77ed\u671f\u8bb0\u5fc6\u7cfb\u7edf\u8ba9 AI Agent \u80fd\u591f\u8bb0\u4f4f\u5355\u6b21\u5bf9\u8bdd\u6216\u7ebf\u7a0b\u4e2d\u7684\u5148\u524d\u4ea4\u4e92\u4fe1\u606f\u3002\u8fd9\u5bf9\u4e8e\u6784\u5efa\u80fd\u591f\u7406\u89e3\u4e0a\u4e0b\u6587\u3001\u5b66\u4e60\u7528\u6237\u504f\u597d\u5e76\u4fdd\u6301\u8fde\u8d2f\u5bf9\u8bdd\u7684\u667a\u80fd\u5e94\u7528\u81f3\u5173\u91cd\u8981\u3002</p>"},{"location":"llmapps/langchain/core-components/short-term%20memory/#_2","title":"\u6838\u5fc3\u6982\u5ff5","text":"<ul> <li>\u7ebf\u7a0b\uff08Thread\uff09\uff1a\u7ec4\u7ec7\u591a\u6b21\u4ea4\u4e92\u7684\u4f1a\u8bdd\uff0c\u7c7b\u4f3c\u7535\u5b50\u90ae\u4ef6\u5bf9\u8bdd</li> <li>\u68c0\u67e5\u70b9\uff08Checkpointer\uff09\uff1a\u8d1f\u8d23\u72b6\u6001\u7684\u6301\u4e45\u5316\u5b58\u50a8</li> <li>\u72b6\u6001\u7ba1\u7406\uff1aAgent \u901a\u8fc7\u72b6\u6001\u6765\u7ef4\u62a4\u5bf9\u8bdd\u5386\u53f2\u548c\u81ea\u5b9a\u4e49\u4fe1\u606f</li> </ul>"},{"location":"llmapps/langchain/core-components/short-term%20memory/#_3","title":"\u57fa\u7840\u8bbe\u7f6e","text":""},{"location":"llmapps/langchain/core-components/short-term%20memory/#1","title":"1. \u542f\u7528\u77ed\u671f\u8bb0\u5fc6","text":"<pre><code>from langchain.agents import create_agent\nfrom langgraph.checkpoint.memory import InMemorySaver\n\n# \u521b\u5efa\u5e26\u6709\u77ed\u671f\u8bb0\u5fc6\u7684 Agent\nagent = create_agent(\n    model=\"openai:gpt-4o\",\n    tools=[get_user_info],\n    checkpointer=InMemorySaver(),  # \u542f\u7528\u5185\u5b58\u68c0\u67e5\u70b9\n)\n\n# \u4f7f\u7528\u7ebf\u7a0bID\u6765\u533a\u5206\u4e0d\u540c\u5bf9\u8bdd\nresult = agent.invoke(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"Hi! My name is Bob.\"}]},\n    {\"configurable\": {\"thread_id\": \"1\"}},  # \u6307\u5b9a\u7ebf\u7a0bID\n)\n</code></pre>"},{"location":"llmapps/langchain/core-components/short-term%20memory/#2","title":"2. \u751f\u4ea7\u73af\u5883\u914d\u7f6e","text":"<pre><code>from langchain.agents import create_agent\nfrom langgraph.checkpoint.postgres import PostgresSaver\n\n# \u5b89\u88c5\u4f9d\u8d56\uff1apip install langgraph-checkpoint-postgres\nDB_URI = \"postgresql://postgres:postgres@localhost:5442/postgres?sslmode=disable\"\n\nwith PostgresSaver.from_conn_string(DB_URI) as checkpointer:\n    checkpointer.setup()  # \u81ea\u52a8\u521b\u5efa\u6570\u636e\u5e93\u8868\n\n    agent = create_agent(\n        model=\"openai:gpt-4o\",\n        tools=[get_user_info],\n        checkpointer=checkpointer,  # \u4f7f\u7528 PostgreSQL \u68c0\u67e5\u70b9\n    )\n</code></pre>"},{"location":"llmapps/langchain/core-components/short-term%20memory/#agent","title":"\u81ea\u5b9a\u4e49 Agent \u72b6\u6001","text":""},{"location":"llmapps/langchain/core-components/short-term%20memory/#_4","title":"\u6269\u5c55\u9ed8\u8ba4\u72b6\u6001","text":"<pre><code>from langchain.agents import create_agent, AgentState\nfrom langgraph.checkpoint.memory import InMemorySaver\nfrom typing import Optional, Dict, List\n\nclass CustomAgentState(AgentState):\n    \"\"\"\u81ea\u5b9a\u4e49 Agent \u72b6\u6001\"\"\"\n    user_id: str\n    preferences: Dict[str, str]\n    conversation_topics: List[str]\n    last_active: Optional[str] = None\n\n# \u521b\u5efa\u4f7f\u7528\u81ea\u5b9a\u4e49\u72b6\u6001\u7684 Agent\nagent = create_agent(\n    model=\"openai:gpt-4o\",\n    tools=[get_user_info],\n    state_schema=CustomAgentState,  # \u4f7f\u7528\u81ea\u5b9a\u4e49\u72b6\u6001\u6a21\u5f0f\n    checkpointer=InMemorySaver(),\n)\n\n# \u8c03\u7528\u65f6\u4f20\u5165\u81ea\u5b9a\u4e49\u72b6\u6001\nresult = agent.invoke(\n    {\n        \"messages\": [{\"role\": \"user\", \"content\": \"Hello\"}],\n        \"user_id\": \"user_123\",\n        \"preferences\": {\"theme\": \"dark\", \"language\": \"zh-CN\"},\n        \"conversation_topics\": [\"technology\", \"programming\"]\n    },\n    {\"configurable\": {\"thread_id\": \"1\"}}\n)\n</code></pre>"},{"location":"llmapps/langchain/core-components/short-term%20memory/#_5","title":"\u5185\u5b58\u7ba1\u7406\u7b56\u7565","text":""},{"location":"llmapps/langchain/core-components/short-term%20memory/#1-trim-messages","title":"1. \u6d88\u606f\u4fee\u526a\uff08Trim Messages\uff09","text":"<p>\u5f53\u5bf9\u8bdd\u5386\u53f2\u8fc7\u957f\u65f6\uff0c\u4fee\u526a\u6d88\u606f\u4ee5\u9002\u914d\u4e0a\u4e0b\u6587\u7a97\u53e3\u3002</p> <pre><code>from langchain.messages import RemoveMessage\nfrom langgraph.graph.message import REMOVE_ALL_MESSAGES\nfrom langchain.agents.middleware import before_model\nfrom langgraph.runtime import Runtime\nfrom typing import Any\n\n@before_model\ndef trim_messages(state: AgentState, runtime: Runtime) -&gt; dict[str, Any] | None:\n    \"\"\"\u4fdd\u7559\u6700\u8fd1\u51e0\u6761\u6d88\u606f\u4ee5\u9002\u914d\u4e0a\u4e0b\u6587\u7a97\u53e3\"\"\"\n    messages = state[\"messages\"]\n\n    # \u5982\u679c\u6d88\u606f\u6570\u91cf\u4e0d\u591a\uff0c\u4e0d\u9700\u8981\u4fee\u526a\n    if len(messages) &lt;= 4:\n        return None\n\n    # \u4fdd\u7559\u7cfb\u7edf\u6d88\u606f\u548c\u6700\u8fd1\u76843\u6761\u6d88\u606f\n    system_messages = [msg for msg in messages if msg.type == \"system\"]\n    recent_messages = messages[-3:]\n\n    new_messages = system_messages + recent_messages\n\n    return {\n        \"messages\": [\n            RemoveMessage(id=REMOVE_ALL_MESSAGES),  # \u79fb\u9664\u6240\u6709\u73b0\u6709\u6d88\u606f\n            *new_messages  # \u6dfb\u52a0\u4fee\u526a\u540e\u7684\u6d88\u606f\n        ]\n    }\n\n# \u4f7f\u7528\u4fee\u526a\u4e2d\u95f4\u4ef6\u7684 Agent\nagent = create_agent(\n    model=\"openai:gpt-4o\",\n    tools=[],\n    middleware=[trim_messages],\n    checkpointer=InMemorySaver(),\n)\n</code></pre>"},{"location":"llmapps/langchain/core-components/short-term%20memory/#2-delete-messages","title":"2. \u6d88\u606f\u5220\u9664\uff08Delete Messages\uff09","text":"<p>\u6c38\u4e45\u5220\u9664\u7279\u5b9a\u6d88\u606f\u4ee5\u7ba1\u7406\u5bf9\u8bdd\u5386\u53f2\u3002</p> <pre><code>from langchain.agents.middleware import after_model\nfrom langchain.messages import RemoveMessage\n\n@after_model\ndef delete_old_messages(state: AgentState, runtime: Runtime) -&gt; dict | None:\n    \"\"\"\u5220\u9664\u65e7\u6d88\u606f\u4ee5\u4fdd\u6301\u5bf9\u8bdd\u53ef\u7ba1\u7406\"\"\"\n    messages = state[\"messages\"]\n\n    # \u5982\u679c\u6d88\u606f\u8d85\u8fc75\u6761\uff0c\u5220\u9664\u6700\u65e9\u7684\u4e24\u6761\n    if len(messages) &gt; 5:\n        messages_to_remove = messages[:2]\n        return {\n            \"messages\": [RemoveMessage(id=msg.id) for msg in messages_to_remove]\n        }\n\n    return None\n\n# \u4f7f\u7528\u5220\u9664\u4e2d\u95f4\u4ef6\u7684 Agent\nagent = create_agent(\n    model=\"openai:gpt-4o\",\n    tools=[],\n    middleware=[delete_old_messages],\n    checkpointer=InMemorySaver(),\n)\n</code></pre>"},{"location":"llmapps/langchain/core-components/short-term%20memory/#3-summarize-messages","title":"3. \u6d88\u606f\u603b\u7ed3\uff08Summarize Messages\uff09","text":"<p>\u4f7f\u7528\u603b\u7ed3\u4e2d\u95f4\u4ef6\u81ea\u52a8\u603b\u7ed3\u957f\u5bf9\u8bdd\u5386\u53f2\u3002</p> <pre><code>from langchain.agents import create_agent\nfrom langchain.agents.middleware import SummarizationMiddleware\nfrom langgraph.checkpoint.memory import InMemorySaver\n\ncheckpointer = InMemorySaver()\n\nagent = create_agent(\n    model=\"openai:gpt-4o\",\n    tools=[],\n    middleware=[\n        SummarizationMiddleware(\n            model=\"openai:gpt-4o-mini\",  # \u4f7f\u7528\u66f4\u4fbf\u5b9c\u7684\u6a21\u578b\u8fdb\u884c\u603b\u7ed3\n            max_tokens_before_summary=2000,  # \u57282000\u4e2atoken\u65f6\u89e6\u53d1\u603b\u7ed3\n            messages_to_keep=10,  # \u603b\u7ed3\u540e\u4fdd\u7559\u6700\u8fd110\u6761\u6d88\u606f\n            summary_prompt=\"\u8bf7\u603b\u7ed3\u4e4b\u524d\u7684\u5bf9\u8bdd\uff0c\u4fdd\u7559\u5173\u952e\u4fe1\u606f\uff1a\",\n        )\n    ],\n    checkpointer=checkpointer,\n)\n\n# \u6d4b\u8bd5\u957f\u5bf9\u8bdd\nconfig = {\"configurable\": {\"thread_id\": \"1\"}}\n\nagent.invoke({\"messages\": \"Hi, my name is Bob\"}, config)\nagent.invoke({\"messages\": \"I'm a software engineer from Beijing\"}, config)\nagent.invoke({\"messages\": \"I enjoy hiking and reading books\"}, config)\nagent.invoke({\"messages\": \"My favorite programming language is Python\"}, config)\n\n# \u5373\u4f7f\u7ecf\u8fc7\u591a\u6b21\u5bf9\u8bdd\uff0cAgent \u4ecd\u7136\u8bb0\u5f97\u7528\u6237\u4fe1\u606f\nfinal_response = agent.invoke({\"messages\": \"Can you remind me what I told you about myself?\"}, config)\nprint(final_response[\"messages\"][-1].content)\n</code></pre>"},{"location":"llmapps/langchain/core-components/short-term%20memory/#_6","title":"\u8bbf\u95ee\u548c\u64cd\u4f5c\u5185\u5b58","text":""},{"location":"llmapps/langchain/core-components/short-term%20memory/#1_1","title":"1. \u5728\u5de5\u5177\u4e2d\u8bbf\u95ee\u5185\u5b58","text":"<pre><code>from langchain.tools import tool, ToolRuntime\nfrom langchain.agents import create_agent, AgentState\n\nclass UserState(AgentState):\n    user_profile: dict\n    conversation_count: int\n\n@tool\ndef get_user_profile(runtime: ToolRuntime) -&gt; str:\n    \"\"\"\u83b7\u53d6\u7528\u6237\u6863\u6848\u4fe1\u606f\"\"\"\n    state = runtime.state\n    user_profile = state.get(\"user_profile\", {})\n    conversation_count = state.get(\"conversation_count\", 0)\n\n    return f\"\u7528\u6237\u6863\u6848: {user_profile}, \u5bf9\u8bdd\u6b21\u6570: {conversation_count}\"\n\n@tool  \ndef update_user_preference(runtime: ToolRuntime, preference: str, value: str) -&gt; str:\n    \"\"\"\u66f4\u65b0\u7528\u6237\u504f\u597d\"\"\"\n    from langgraph.types import Command\n\n    # \u66f4\u65b0\u72b6\u6001\n    return Command(update={\n        \"user_profile\": {\n            **runtime.state.get(\"user_profile\", {}),\n            preference: value\n        },\n        \"conversation_count\": runtime.state.get(\"conversation_count\", 0) + 1\n    })\n\nagent = create_agent(\n    model=\"openai:gpt-4o\",\n    tools=[get_user_profile, update_user_preference],\n    state_schema=UserState,\n    checkpointer=InMemorySaver(),\n)\n</code></pre>"},{"location":"llmapps/langchain/core-components/short-term%20memory/#2_1","title":"2. \u4f7f\u7528\u52a8\u6001\u63d0\u793a","text":"<pre><code>from langchain.agents.middleware import dynamic_prompt, ModelRequest\nfrom typing import TypedDict\n\nclass ConversationContext(TypedDict):\n    user_name: str\n    user_role: str\n\n@dynamic_prompt\ndef personalized_system_prompt(request: ModelRequest) -&gt; str:\n    \"\"\"\u57fa\u4e8e\u7528\u6237\u4e0a\u4e0b\u6587\u7684\u52a8\u6001\u7cfb\u7edf\u63d0\u793a\"\"\"\n    context = request.runtime.context\n    user_name = context.get(\"user_name\", \"\u7528\u6237\")\n    user_role = context.get(\"user_role\", \"\u8bbf\u5ba2\")\n\n    return f\"\"\"\n    \u4f60\u662f\u4e00\u4e2a\u6709\u5e2e\u52a9\u7684\u52a9\u624b\uff0c\u6b63\u5728\u4e0e{user_name}\u5bf9\u8bdd\u3002\n    {user_name}\u7684\u8eab\u4efd\u662f\uff1a{user_role}\n\n    \u8bf7\u6839\u636e\u5bf9\u8bdd\u5386\u53f2\u63d0\u4f9b\u4e2a\u6027\u5316\u7684\u56de\u5e94\u3002\n    \u4fdd\u6301\u53cb\u597d\u548c\u4e13\u4e1a\u7684\u6001\u5ea6\u3002\n    \"\"\"\n\ndef get_weather(city: str) -&gt; str:\n    \"\"\"\u83b7\u53d6\u5929\u6c14\u4fe1\u606f\"\"\"\n    return f\"{city}\u7684\u5929\u6c14\u662f\u6674\u6717\u7684\uff0c25\u00b0C\"\n\nagent = create_agent(\n    model=\"openai:gpt-4o\",\n    tools=[get_weather],\n    middleware=[personalized_system_prompt],\n    context_schema=ConversationContext,\n)\n\n# \u4f7f\u7528\u4e0a\u4e0b\u6587\u8c03\u7528\nresult = agent.invoke(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"\u4eca\u5929\u5929\u6c14\u600e\u4e48\u6837\uff1f\"}]},\n    context=ConversationContext(user_name=\"\u5f20\u4e09\", user_role=\"\u8f6f\u4ef6\u5de5\u7a0b\u5e08\")\n)\n</code></pre>"},{"location":"llmapps/langchain/core-components/short-term%20memory/#3-before-model","title":"3. Before Model \u4e2d\u95f4\u4ef6","text":"<p>\u5728\u6a21\u578b\u8c03\u7528\u524d\u8bbf\u95ee\u548c\u4fee\u6539\u72b6\u6001\u3002</p> <pre><code>from langchain.agents.middleware import before_model\nfrom langchain.messages import SystemMessage\n\n@before_model\ndef enhance_with_context(state: AgentState, runtime: Runtime) -&gt; dict[str, Any] | None:\n    \"\"\"\u5728\u6a21\u578b\u8c03\u7528\u524d\u589e\u5f3a\u4e0a\u4e0b\u6587\"\"\"\n    messages = state[\"messages\"]\n\n    # \u83b7\u53d6\u7528\u6237\u4fe1\u606f\n    user_id = state.get(\"user_id\", \"unknown\")\n    preferences = state.get(\"preferences\", {})\n\n    # \u6dfb\u52a0\u7cfb\u7edf\u6d88\u606f\u63d0\u4f9b\u4e0a\u4e0b\u6587\n    context_message = SystemMessage(content=f\"\"\"\n    \u5f53\u524d\u7528\u6237ID: {user_id}\n    \u7528\u6237\u504f\u597d: {preferences}\n    \u8bf7\u6839\u636e\u4ee5\u4e0a\u4fe1\u606f\u63d0\u4f9b\u4e2a\u6027\u5316\u670d\u52a1\u3002\n    \"\"\")\n\n    # \u5c06\u4e0a\u4e0b\u6587\u6d88\u606f\u6dfb\u52a0\u5230\u5bf9\u8bdd\u5f00\u59cb\n    enhanced_messages = [context_message] + messages\n\n    return {\"messages\": enhanced_messages}\n\nagent = create_agent(\n    model=\"openai:gpt-4o\",\n    tools=[],\n    middleware=[enhance_with_context],\n    state_schema=CustomAgentState,\n    checkpointer=InMemorySaver(),\n)\n</code></pre>"},{"location":"llmapps/langchain/core-components/short-term%20memory/#4-after-model","title":"4. After Model \u4e2d\u95f4\u4ef6","text":"<p>\u5728\u6a21\u578b\u8c03\u7528\u540e\u5904\u7406\u54cd\u5e94\u548c\u72b6\u6001\u3002</p> <pre><code>from langchain.agents.middleware import after_model\nfrom langchain.messages import RemoveMessage\n\n@after_model\ndef track_conversation_metrics(state: AgentState, runtime: Runtime) -&gt; dict | None:\n    \"\"\"\u8ddf\u8e2a\u5bf9\u8bdd\u6307\u6807\u5e76\u6e05\u7406\u654f\u611f\u4fe1\u606f\"\"\"\n    messages = state[\"messages\"]\n\n    # \u66f4\u65b0\u5bf9\u8bdd\u7edf\u8ba1\n    conversation_count = state.get(\"conversation_count\", 0) + 1\n    last_active = datetime.now().isoformat()\n\n    # \u68c0\u67e5\u5e76\u79fb\u9664\u5305\u542b\u654f\u611f\u4fe1\u606f\u7684\u6d88\u606f\n    sensitive_keywords = [\"\u5bc6\u7801\", \"secret\", \"password\", \"token\"]\n    messages_to_remove = []\n\n    for msg in messages:\n        if any(keyword in msg.content.lower() for keyword in sensitive_keywords):\n            messages_to_remove.append(msg)\n\n    updates = {\n        \"conversation_count\": conversation_count,\n        \"last_active\": last_active\n    }\n\n    if messages_to_remove:\n        updates[\"messages\"] = [RemoveMessage(id=msg.id) for msg in messages_to_remove]\n\n    return updates\n\nagent = create_agent(\n    model=\"openai:gpt-4o\",\n    tools=[],\n    middleware=[track_conversation_metrics],\n    state_schema=CustomAgentState,\n    checkpointer=InMemorySaver(),\n)\n</code></pre>"},{"location":"llmapps/langchain/core-components/short-term%20memory/#_7","title":"\u5b9e\u9645\u5e94\u7528\u573a\u666f","text":""},{"location":"llmapps/langchain/core-components/short-term%20memory/#1_2","title":"\u573a\u666f1\uff1a\u4e2a\u6027\u5316\u5ba2\u6237\u670d\u52a1","text":"<pre><code>from datetime import datetime\nfrom typing import Dict, List, Optional\n\nclass CustomerServiceState(AgentState):\n    customer_id: str\n    ticket_history: List[Dict]\n    customer_tier: str  # \"standard\", \"premium\", \"vip\"\n    last_issue: Optional[str] = None\n    satisfaction_score: Optional[int] = None\n\ndef create_customer_service_agent():\n    \"\"\"\u521b\u5efa\u5ba2\u6237\u670d\u52a1 Agent\"\"\"\n\n    @tool\n    def create_support_ticket(runtime: ToolRuntime, issue: str, priority: str) -&gt; str:\n        \"\"\"\u521b\u5efa\u652f\u6301\u5de5\u5355\"\"\"\n        from langgraph.types import Command\n\n        ticket = {\n            \"id\": f\"TICKET_{datetime.now().strftime('%Y%m%d_%H%M%S')}\",\n            \"issue\": issue,\n            \"priority\": priority,\n            \"created_at\": datetime.now().isoformat(),\n            \"status\": \"open\"\n        }\n\n        return Command(update={\n            \"ticket_history\": runtime.state.get(\"ticket_history\", []) + [ticket],\n            \"last_issue\": issue\n        })\n\n    @tool\n    def get_customer_history(runtime: ToolRuntime) -&gt; str:\n        \"\"\"\u83b7\u53d6\u5ba2\u6237\u5386\u53f2\u8bb0\u5f55\"\"\"\n        state = runtime.state\n        ticket_history = state.get(\"ticket_history\", [])\n        customer_tier = state.get(\"customer_tier\", \"standard\")\n\n        if not ticket_history:\n            return \"\u8fd9\u662f\u8be5\u5ba2\u6237\u7684\u7b2c\u4e00\u6b21\u8054\u7cfb\"\n\n        last_ticket = ticket_history[-1]\n        return f\"\"\"\n        \u5ba2\u6237\u7b49\u7ea7: {customer_tier}\n        \u603b\u5de5\u5355\u6570: {len(ticket_history)}\n        \u6700\u8fd1\u95ee\u9898: {last_ticket['issue']}\n        \u6700\u8fd1\u5de5\u5355\u72b6\u6001: {last_ticket['status']}\n        \"\"\"\n\n    @before_model\n    def add_customer_context(state: CustomerServiceState, runtime: Runtime) -&gt; dict | None:\n        \"\"\"\u6dfb\u52a0\u5ba2\u6237\u4e0a\u4e0b\u6587\"\"\"\n        customer_tier = state.get(\"customer_tier\", \"standard\")\n        ticket_count = len(state.get(\"ticket_history\", []))\n\n        tier_benefits = {\n            \"standard\": \"\u6807\u51c6\u652f\u6301\uff0824\u5c0f\u65f6\u5185\u54cd\u5e94\uff09\",\n            \"premium\": \"\u4f18\u5148\u652f\u6301\uff084\u5c0f\u65f6\u5185\u54cd\u5e94\uff09\", \n            \"vip\": \"\u4e13\u5c5e\u652f\u6301\uff081\u5c0f\u65f6\u5185\u54cd\u5e94\uff09\"\n        }\n\n        context_msg = f\"\"\"\n        \u5f53\u524d\u5ba2\u6237\u7b49\u7ea7: {customer_tier}\n        \u652f\u6301\u7ea7\u522b: {tier_benefits.get(customer_tier, '\u6807\u51c6\u652f\u6301')}\n        \u5386\u53f2\u5de5\u5355\u6570\u91cf: {ticket_count}\n        \"\"\"\n\n        if state.get(\"last_issue\"):\n            context_msg += f\"\\n\u6700\u8fd1\u62a5\u544a\u7684\u95ee\u9898: {state['last_issue']}\"\n\n        return {\n            \"messages\": [SystemMessage(content=context_msg)] + state[\"messages\"]\n        }\n\n    return create_agent(\n        model=\"openai:gpt-4o\",\n        tools=[create_support_ticket, get_customer_history],\n        middleware=[add_customer_context],\n        state_schema=CustomerServiceState,\n        checkpointer=InMemorySaver(),\n    )\n\n# \u4f7f\u7528\u793a\u4f8b\nservice_agent = create_customer_service_agent()\n\n# \u7b2c\u4e00\u6b21\u4ea4\u4e92\nresult1 = service_agent.invoke(\n    {\n        \"messages\": [{\"role\": \"user\", \"content\": \"\u6211\u7684\u8d26\u6237\u65e0\u6cd5\u767b\u5f55\"}],\n        \"customer_id\": \"cust_123\",\n        \"customer_tier\": \"premium\",\n        \"ticket_history\": []\n    },\n    {\"configurable\": {\"thread_id\": \"cust_123\"}}\n)\n\n# \u540e\u7eed\u4ea4\u4e92 - Agent \u4f1a\u8bb0\u4f4f\u5ba2\u6237\u5386\u53f2\nresult2 = service_agent.invoke(\n    {\n        \"messages\": [{\"role\": \"user\", \"content\": \"\u67e5\u770b\u6211\u7684\u652f\u6301\u5386\u53f2\"}]\n    },\n    {\"configurable\": {\"thread_id\": \"cust_123\"}}\n)\n</code></pre>"},{"location":"llmapps/langchain/core-components/short-term%20memory/#2_2","title":"\u573a\u666f2\uff1a\u667a\u80fd\u5b66\u4e60\u52a9\u624b","text":"<pre><code>class LearningAssistantState(AgentState):\n    student_level: str  # \"beginner\", \"intermediate\", \"advanced\"\n    learning_topics: List[str]\n    completed_lessons: List[Dict]\n    weak_areas: List[str]\n    learning_style: str  # \"visual\", \"auditory\", \"kinesthetic\"\n\ndef create_learning_assistant():\n    \"\"\"\u521b\u5efa\u5b66\u4e60\u52a9\u624b Agent\"\"\"\n\n    @tool\n    def track_progress(runtime: ToolRuntime, topic: str, score: int) -&gt; str:\n        \"\"\"\u8ddf\u8e2a\u5b66\u4e60\u8fdb\u5ea6\"\"\"\n        from langgraph.types import Command\n\n        lesson = {\n            \"topic\": topic,\n            \"score\": score,\n            \"completed_at\": datetime.now().isoformat()\n        }\n\n        completed_lessons = runtime.state.get(\"completed_lessons\", []) + [lesson]\n\n        # \u81ea\u52a8\u8bc6\u522b\u8584\u5f31\u9886\u57df\n        weak_areas = []\n        if score &lt; 70:\n            weak_areas = list(set(runtime.state.get(\"weak_areas\", []) + [topic]))\n\n        return Command(update={\n            \"completed_lessons\": completed_lessons,\n            \"weak_areas\": weak_areas\n        })\n\n    @tool\n    def get_study_recommendations(runtime: ToolRuntime) -&gt; str:\n        \"\"\"\u83b7\u53d6\u5b66\u4e60\u5efa\u8bae\"\"\"\n        state = runtime.state\n        weak_areas = state.get(\"weak_areas\", [])\n        learning_style = state.get(\"learning_style\", \"visual\")\n        student_level = state.get(\"student_level\", \"beginner\")\n\n        recommendations = []\n\n        if weak_areas:\n            recommendations.append(f\"\u9700\u8981\u52a0\u5f3a\u7684\u9886\u57df: {', '.join(weak_areas)}\")\n\n        style_suggestions = {\n            \"visual\": \"\u5efa\u8bae\u4f7f\u7528\u56fe\u8868\u548c\u89c6\u9891\u5b66\u4e60\",\n            \"auditory\": \"\u5efa\u8bae\u6536\u542c\u8bb2\u89e3\u548c\u53c2\u4e0e\u8ba8\u8bba\", \n            \"kinesthetic\": \"\u5efa\u8bae\u901a\u8fc7\u5b9e\u8df5\u7ec3\u4e60\u5b66\u4e60\"\n        }\n\n        recommendations.append(style_suggestions.get(learning_style, \"\u591a\u79cd\u65b9\u5f0f\u7ed3\u5408\u5b66\u4e60\"))\n        recommendations.append(f\"\u9002\u5408{student_level}\u6c34\u5e73\u7684\u5b66\u4e60\u6750\u6599\")\n\n        return \"\\n\".join(recommendations)\n\n    @dynamic_prompt\n    def personalized_learning_prompt(request: ModelRequest) -&gt; str:\n        \"\"\"\u4e2a\u6027\u5316\u5b66\u4e60\u63d0\u793a\"\"\"\n        state = request.state\n        context = request.runtime.context\n\n        student_name = context.get(\"student_name\", \"\u540c\u5b66\")\n        learning_style = state.get(\"learning_style\", \"visual\")\n        student_level = state.get(\"student_level\", \"beginner\")\n\n        return f\"\"\"\n        \u4f60\u662f\u4e00\u4e2a\u8010\u5fc3\u7684\u5b66\u4e60\u52a9\u624b\uff0c\u6b63\u5728\u5e2e\u52a9{student_name}\u5b66\u4e60\u3002\n\n        \u5b66\u751f\u4fe1\u606f\uff1a\n        - \u5b66\u4e60\u98ce\u683c: {learning_style}\n        - \u5f53\u524d\u6c34\u5e73: {student_level}\n        - \u5df2\u5b8c\u6210\u8bfe\u7a0b: {len(state.get('completed_lessons', []))}\u4e2a\n\n        \u8bf7\u6839\u636e\u5b66\u751f\u7684\u5b66\u4e60\u98ce\u683c\u548c\u6c34\u5e73\u63d0\u4f9b\u4e2a\u6027\u5316\u7684\u6307\u5bfc\u3002\n        \u5bf9\u4e8e{learning_style}\u578b\u5b66\u4e60\u8005\uff0c\u4f7f\u7528\u9002\u5408\u7684\u6559\u5b66\u65b9\u6cd5\u3002\n        \"\"\"\n\n    return create_agent(\n        model=\"openai:gpt-4o\",\n        tools=[track_progress, get_study_recommendations],\n        middleware=[personalized_learning_prompt],\n        state_schema=LearningAssistantState,\n        checkpointer=InMemorySaver(),\n    )\n\n# \u4f7f\u7528\u793a\u4f8b\nlearning_agent = create_learning_assistant()\n\n# \u521d\u59cb\u5316\u5b66\u4e60\u72b6\u6001\nlearning_agent.invoke(\n    {\n        \"messages\": [{\"role\": \"user\", \"content\": \"\u6211\u60f3\u5b66\u4e60Python\u7f16\u7a0b\"}],\n        \"student_level\": \"beginner\",\n        \"learning_style\": \"visual\",\n        \"learning_topics\": [\"Python\", \"\u7f16\u7a0b\u57fa\u7840\"],\n        \"completed_lessons\": [],\n        \"weak_areas\": []\n    },\n    {\"configurable\": {\"thread_id\": \"student_123\"}},\n    context={\"student_name\": \"\u5c0f\u660e\"}\n)\n</code></pre>"},{"location":"llmapps/langchain/core-components/short-term%20memory/#3","title":"\u573a\u666f3\uff1a\u7535\u5546\u63a8\u8350\u7cfb\u7edf","text":"<pre><code>class EcommerceState(AgentState):\n    user_id: str\n    browse_history: List[Dict]\n    purchase_history: List[Dict]\n    interests: List[str]\n    budget_range: str\n    preferred_categories: List[str]\n\ndef create_ecommerce_agent():\n    \"\"\"\u521b\u5efa\u7535\u5546\u63a8\u8350 Agent\"\"\"\n\n    @tool\n    def track_browse_behavior(runtime: ToolRuntime, product: str, category: str) -&gt; str:\n        \"\"\"\u8ddf\u8e2a\u6d4f\u89c8\u884c\u4e3a\"\"\"\n        from langgraph.types import Command\n\n        browse_record = {\n            \"product\": product,\n            \"category\": category,\n            \"timestamp\": datetime.now().isoformat()\n        }\n\n        # \u66f4\u65b0\u6d4f\u89c8\u5386\u53f2\u548c\u5174\u8da3\n        browse_history = runtime.state.get(\"browse_history\", []) + [browse_record]\n        interests = list(set(runtime.state.get(\"interests\", []) + [category]))\n\n        return Command(update={\n            \"browse_history\": browse_history,\n            \"interests\": interests\n        })\n\n    @tool\n    def get_personalized_recommendations(runtime: ToolRuntime) -&gt; str:\n        \"\"\"\u83b7\u53d6\u4e2a\u6027\u5316\u63a8\u8350\"\"\"\n        state = runtime.state\n        interests = state.get(\"interests\", [])\n        budget_range = state.get(\"budget_range\", \"medium\")\n        preferred_categories = state.get(\"preferred_categories\", [])\n\n        # \u57fa\u4e8e\u7528\u6237\u884c\u4e3a\u751f\u6210\u63a8\u8350\u903b\u8f91\n        recommendations = []\n\n        if interests:\n            recommendations.append(f\"\u57fa\u4e8e\u60a8\u7684\u5174\u8da3\u63a8\u8350: {', '.join(interests[:3])} \u76f8\u5173\u5546\u54c1\")\n\n        budget_map = {\n            \"low\": \"\u7ecf\u6d4e\u5b9e\u60e0\u578b\",\n            \"medium\": \"\u6027\u4ef7\u6bd4\u578b\", \n            \"high\": \"\u9ad8\u7aef\u54c1\u8d28\u578b\"\n        }\n\n        recommendations.append(f\"\u7b26\u5408\u60a8{budget_map.get(budget_range, '\u4e2d\u7b49')}\u9884\u7b97\u7684\u5546\u54c1\")\n\n        return \"\\n\".join(recommendations)\n\n    @before_model\n    def enhance_with_shopping_context(state: EcommerceState, runtime: Runtime) -&gt; dict | None:\n        \"\"\"\u589e\u5f3a\u8d2d\u7269\u4e0a\u4e0b\u6587\"\"\"\n        interests = state.get(\"interests\", [])\n        purchase_count = len(state.get(\"purchase_history\", []))\n        browse_count = len(state.get(\"browse_history\", []))\n\n        context_msg = f\"\"\"\n        \u8d2d\u7269\u52a9\u624b\u4e0a\u4e0b\u6587\uff1a\n        - \u7528\u6237\u5174\u8da3: {', '.join(interests) if interests else '\u5c1a\u672a\u786e\u5b9a'}\n        - \u6d4f\u89c8\u5386\u53f2: {browse_count} \u6b21\n        - \u8d2d\u4e70\u8bb0\u5f55: {purchase_count} \u6b21\n        - \u9884\u7b97\u8303\u56f4: {state.get('budget_range', '\u672a\u8bbe\u7f6e')}\n        \"\"\"\n\n        return {\n            \"messages\": [SystemMessage(content=context_msg)] + state[\"messages\"]\n        }\n\n    return create_agent(\n        model=\"openai:gpt-4o\",\n        tools=[track_browse_behavior, get_personalized_recommendations],\n        middleware=[enhance_with_shopping_context],\n        state_schema=EcommerceState,\n        checkpointer=InMemorySaver(),\n    )\n</code></pre>"},{"location":"llmapps/langchain/core-components/short-term%20memory/#_8","title":"\u6700\u4f73\u5b9e\u8df5","text":""},{"location":"llmapps/langchain/core-components/short-term%20memory/#1_3","title":"1. \u72b6\u6001\u8bbe\u8ba1\u539f\u5219","text":"<pre><code>class WellDesignedState(AgentState):\n    \"\"\"\u826f\u597d\u8bbe\u8ba1\u7684\u72b6\u6001\u7c7b\u793a\u4f8b\"\"\"\n\n    # \u5fc5\u9700\u7684\u6838\u5fc3\u5b57\u6bb5\n    user_id: str\n\n    # \u4f1a\u8bdd\u76f8\u5173\u5b57\u6bb5\n    session_start: str\n    interaction_count: int = 0\n\n    # \u4e1a\u52a1\u76f8\u5173\u5b57\u6bb5\n    user_preferences: Dict[str, Any] = {}\n    recent_actions: List[str] = []\n\n    # \u6027\u80fd\u4f18\u5316\u5b57\u6bb5\n    last_summary: Optional[str] = None\n    tokens_used: int = 0\n\n    def should_summarize(self) -&gt; bool:\n        \"\"\"\u5224\u65ad\u662f\u5426\u9700\u8981\u603b\u7ed3\"\"\"\n        return self.interaction_count &gt; 10 or self.tokens_used &gt; 3000\n</code></pre>"},{"location":"llmapps/langchain/core-components/short-term%20memory/#2_3","title":"2. \u5185\u5b58\u7ba1\u7406\u7b56\u7565","text":"<pre><code>def create_memory_optimized_agent():\n    \"\"\"\u521b\u5efa\u5185\u5b58\u4f18\u5316\u7684 Agent\"\"\"\n\n    @before_model\n    def smart_memory_management(state: AgentState, runtime: Runtime) -&gt; dict | None:\n        \"\"\"\u667a\u80fd\u5185\u5b58\u7ba1\u7406\"\"\"\n        messages = state[\"messages\"]\n\n        # \u57fa\u4e8e\u4e0d\u540c\u6761\u4ef6\u91c7\u53d6\u4e0d\u540c\u7b56\u7565\n        if len(messages) &gt; 20:\n            # \u6d88\u606f\u8fc7\u591a\u65f6\u8fdb\u884c\u603b\u7ed3\n            return {\"messages\": messages[-10:]}  # \u4fdd\u7559\u6700\u8fd110\u6761\n\n        elif state.get(\"tokens_used\", 0) &gt; 4000:\n            # Token \u4f7f\u7528\u8fc7\u591a\u65f6\u4fee\u526a\n            return {\"messages\": messages[-8:]}\n\n        return None\n\n    @after_model\n    def update_usage_metrics(state: AgentState, runtime: Runtime) -&gt; dict | None:\n        \"\"\"\u66f4\u65b0\u4f7f\u7528\u6307\u6807\"\"\"\n        # \u4f30\u7b97 token \u4f7f\u7528\u91cf\uff08\u7b80\u5316\u7248\uff09\n        message_content = \" \".join([msg.content for msg in state[\"messages\"]])\n        estimated_tokens = len(message_content) // 4\n\n        return {\n            \"interaction_count\": state.get(\"interaction_count\", 0) + 1,\n            \"tokens_used\": state.get(\"tokens_used\", 0) + estimated_tokens\n        }\n\n    return create_agent(\n        model=\"openai:gpt-4o\",\n        tools=[],\n        middleware=[smart_memory_management, update_usage_metrics],\n        state_schema=WellDesignedState,\n        checkpointer=InMemorySaver(),\n    )\n</code></pre>"},{"location":"llmapps/langchain/core-components/short-term%20memory/#3_1","title":"3. \u9519\u8bef\u5904\u7406\u548c\u6062\u590d","text":"<pre><code>def create_robust_agent():\n    \"\"\"\u521b\u5efa\u5065\u58ee\u7684 Agent\"\"\"\n\n    @after_model\n    def handle_memory_errors(state: AgentState, runtime: Runtime) -&gt; dict | None:\n        \"\"\"\u5904\u7406\u5185\u5b58\u76f8\u5173\u9519\u8bef\"\"\"\n        try:\n            # \u68c0\u67e5\u72b6\u6001\u5065\u5eb7\u5ea6\n            messages = state[\"messages\"]\n\n            if len(messages) &gt; 100:\n                # \u6d88\u606f\u8fc7\u591a\uff0c\u81ea\u52a8\u6e05\u7406\n                return {\"messages\": messages[-20:]}\n\n            return None\n\n        except Exception as e:\n            # \u53d1\u751f\u9519\u8bef\u65f6\u6062\u590d\u5230\u6700\u540e\u5df2\u77e5\u826f\u597d\u72b6\u6001\n            print(f\"\u5185\u5b58\u5904\u7406\u9519\u8bef: {e}\")\n            return None  # \u4fdd\u6301\u5f53\u524d\u72b6\u6001\n\n    return create_agent(\n        model=\"openai:gpt-4o\",\n        tools=[],\n        middleware=[handle_memory_errors],\n        checkpointer=InMemorySaver(),\n    )\n</code></pre>"},{"location":"llmapps/langchain/core-components/short-term%20memory/#_9","title":"\u603b\u7ed3","text":"<p>LangChain \u7684\u77ed\u671f\u8bb0\u5fc6\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u5bf9\u8bdd\u72b6\u6001\u7ba1\u7406\u80fd\u529b\uff1a</p> <ul> <li>\u7075\u6d3b\u7684\u72b6\u6001\u8bbe\u8ba1\uff1a\u652f\u6301\u81ea\u5b9a\u4e49\u72b6\u6001\u5b57\u6bb5</li> <li>\u591a\u79cd\u5b58\u50a8\u540e\u7aef\uff1a\u5185\u5b58\u3001PostgreSQL \u7b49</li> <li>\u667a\u80fd\u5185\u5b58\u7ba1\u7406\uff1a\u4fee\u526a\u3001\u5220\u9664\u3001\u603b\u7ed3\u7b49\u7b56\u7565</li> <li>\u5168\u65b9\u4f4d\u8bbf\u95ee\uff1a\u901a\u8fc7\u5de5\u5177\u3001\u4e2d\u95f4\u4ef6\u7b49\u8bbf\u95ee\u548c\u4fee\u6539\u72b6\u6001</li> <li>\u751f\u4ea7\u7ea7\u53ef\u9760\u6027\uff1a\u9519\u8bef\u5904\u7406\u548c\u6027\u80fd\u4f18\u5316</li> </ul> <p>\u901a\u8fc7\u5408\u7406\u4f7f\u7528\u77ed\u671f\u8bb0\u5fc6\uff0c\u53ef\u4ee5\u6784\u5efa\u51fa\u771f\u6b63\u7406\u89e3\u7528\u6237\u4e0a\u4e0b\u6587\u3001\u63d0\u4f9b\u4e2a\u6027\u5316\u4f53\u9a8c\u7684\u667a\u80fd\u5e94\u7528\u3002</p>"},{"location":"llmapps/langchain/core-components/streaming/","title":"LangChain \u6d41\u5f0f\u4f20\u8f93","text":""},{"location":"llmapps/langchain/core-components/streaming/#_1","title":"\u6982\u8ff0","text":"<p>LangChain \u7684\u6d41\u5f0f\u4f20\u8f93\u7cfb\u7edf\u53ef\u4ee5\u5b9e\u65f6\u5c55\u793a\u66f4\u65b0\uff0c\u8fd9\u5bf9\u4e8e\u6784\u5efa\u54cd\u5e94\u8fc5\u901f\u7684 LLM \u5e94\u7528\u81f3\u5173\u91cd\u8981\u3002\u901a\u8fc7\u9010\u6b65\u663e\u793a\u8f93\u51fa\uff08\u5373\u4f7f\u5728\u5b8c\u6574\u54cd\u5e94\u51c6\u5907\u597d\u4e4b\u524d\uff09\uff0c\u6d41\u5f0f\u4f20\u8f93\u663e\u8457\u6539\u5584\u4e86\u7528\u6237\u4f53\u9a8c\uff0c\u7279\u522b\u662f\u5728\u5904\u7406 LLM \u7684\u5ef6\u8fdf\u65f6\u3002</p>"},{"location":"llmapps/langchain/core-components/streaming/#_2","title":"\u6d41\u5f0f\u4f20\u8f93\u7684\u4f18\u52bf","text":"<ul> <li>\u5b9e\u65f6\u53cd\u9988\uff1a\u7528\u6237\u53ef\u4ee5\u770b\u5230\u5904\u7406\u8fdb\u5ea6</li> <li>\u964d\u4f4e\u611f\u77e5\u5ef6\u8fdf\uff1a\u5373\u4f7f\u603b\u65f6\u95f4\u76f8\u540c\uff0c\u7528\u6237\u4f53\u9a8c\u66f4\u597d</li> <li>\u8c03\u8bd5\u53cb\u597d\uff1a\u53ef\u4ee5\u89c2\u5bdf\u6bcf\u4e2a\u6b65\u9aa4\u7684\u6267\u884c\u60c5\u51b5</li> <li>\u7075\u6d3b\u63a7\u5236\uff1a\u652f\u6301\u591a\u79cd\u6d41\u5f0f\u4f20\u8f93\u6a21\u5f0f</li> </ul>"},{"location":"llmapps/langchain/core-components/streaming/#_3","title":"\u57fa\u7840\u8bbe\u7f6e","text":""},{"location":"llmapps/langchain/core-components/streaming/#agent","title":"\u521b\u5efa\u57fa\u7840 Agent","text":"<pre><code>from langchain.agents import create_agent\n\n# \u521b\u5efa\u4e00\u4e2a\u7b80\u5355\u7684\u5de5\u5177\u51fd\u6570\ndef get_weather(city: str) -&gt; str:\n    \"\"\"\u83b7\u53d6\u6307\u5b9a\u57ce\u5e02\u7684\u5929\u6c14\"\"\"\n    return f\"{city}\u7684\u5929\u6c14\u662f\u6674\u6717\u7684\uff0c25\u00b0C\"\n\n# \u521b\u5efa Agent\nagent = create_agent(\n    model=\"openai:gpt-4o\",\n    tools=[get_weather],\n)\n</code></pre>"},{"location":"llmapps/langchain/core-components/streaming/#_4","title":"\u6d41\u5f0f\u4f20\u8f93\u6a21\u5f0f","text":""},{"location":"llmapps/langchain/core-components/streaming/#1-agent-progress","title":"1. \u4ee3\u7406\u8fdb\u5ea6\u6d41 (Agent Progress)","text":"<p>\u4f7f\u7528 <code>stream_mode=\"updates\"</code> \u6765\u6d41\u5f0f\u4f20\u8f93\u4ee3\u7406\u7684\u6bcf\u4e2a\u6b65\u9aa4\u8fdb\u5ea6\u3002</p> <pre><code>def stream_agent_progress():\n    \"\"\"\u6d41\u5f0f\u4f20\u8f93\u4ee3\u7406\u6267\u884c\u8fdb\u5ea6\"\"\"\n    print(\"=== \u4ee3\u7406\u8fdb\u5ea6\u6d41\u5f0f\u4f20\u8f93 ===\")\n\n    for chunk in agent.stream(\n        {\"messages\": [{\"role\": \"user\", \"content\": \"\u5317\u4eac\u548c\u4e0a\u6d77\u7684\u5929\u6c14\u600e\u4e48\u6837\uff1f\"}]},\n        stream_mode=\"updates\",  # \u5173\u952e\u53c2\u6570\n    ):\n        for step, data in chunk.items():\n            print(f\"\u6b65\u9aa4: {step}\")\n            if 'messages' in data and data['messages']:\n                last_message = data['messages'][-1]\n                print(f\"\u5185\u5bb9: {last_message.content}\")\n                if hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n                    print(f\"\u5de5\u5177\u8c03\u7528: {last_message.tool_calls}\")\n            print(\"-\" * 50)\n\n# \u8c03\u7528\u793a\u4f8b\nstream_agent_progress()\n</code></pre> <p>\u8f93\u51fa\u793a\u4f8b\uff1a</p> <pre><code>\u6b65\u9aa4: model\n\u5185\u5bb9: \n\u5de5\u5177\u8c03\u7528: [{'name': 'get_weather', 'args': {'city': '\u5317\u4eac'}, 'id': 'call_123'}]\n--------------------------------------------------\n\u6b65\u9aa4: tools\n\u5185\u5bb9: \u5317\u4eac\u7684\u5929\u6c14\u662f\u6674\u6717\u7684\uff0c25\u00b0C\n--------------------------------------------------\n\u6b65\u9aa4: model\n\u5185\u5bb9: \u5317\u4eac\u5929\u6c14\u6674\u6717\uff0c25\u00b0C\u3002\u63a5\u4e0b\u6765\u67e5\u8be2\u4e0a\u6d77\u5929\u6c14...\n\u5de5\u5177\u8c03\u7528: [{'name': 'get_weather', 'args': {'city': '\u4e0a\u6d77'}, 'id': 'call_456'}]\n--------------------------------------------------\n\u6b65\u9aa4: tools\n\u5185\u5bb9: \u4e0a\u6d77\u7684\u5929\u6c14\u662f\u6674\u6717\u7684\uff0c25\u00b0C\n--------------------------------------------------\n\u6b65\u9aa4: model\n\u5185\u5bb9: \u5317\u4eac\u548c\u4e0a\u6d77\u90fd\u662f\u6674\u6717\u5929\u6c14\uff0c25\u00b0C\u3002\n--------------------------------------------------\n</code></pre>"},{"location":"llmapps/langchain/core-components/streaming/#2-llm-token-llm-tokens","title":"2. LLM Token \u6d41 (LLM Tokens)","text":"<p>\u4f7f\u7528 <code>stream_mode=\"messages\"</code> \u6765\u6d41\u5f0f\u4f20\u8f93 LLM \u751f\u6210\u7684\u6bcf\u4e2a token\u3002</p> <pre><code>def stream_llm_tokens():\n    \"\"\"\u6d41\u5f0f\u4f20\u8f93 LLM \u751f\u6210\u7684 tokens\"\"\"\n    print(\"=== LLM Token \u6d41\u5f0f\u4f20\u8f93 ===\")\n\n    for token, metadata in agent.stream(\n        {\"messages\": [{\"role\": \"user\", \"content\": \"\u4e0a\u6d77\u7684\u5929\u6c14\u5982\u4f55\uff1f\"}]},\n        stream_mode=\"messages\",  # \u5173\u952e\u53c2\u6570\n    ):\n        node_name = metadata.get('langgraph_node', 'unknown')\n\n        if hasattr(token, 'content_blocks') and token.content_blocks:\n            for block in token.content_blocks:\n                if block.get('type') == 'text' and block.get('text'):\n                    print(f\"[{node_name}] {block['text']}\", end='', flush=True)\n                elif block.get('type') == 'tool_call_chunk':\n                    print(f\"\\n[\u5de5\u5177\u8c03\u7528] {block.get('name', '')} {block.get('args', '')}\")\n\n    print()  # \u6700\u7ec8\u6362\u884c\n\n# \u8c03\u7528\u793a\u4f8b\nstream_llm_tokens()\n</code></pre> <p>\u8f93\u51fa\u793a\u4f8b\uff1a</p> <pre><code>[model] \u8ba9\u6211\n[model] \u6765\u67e5\u8be2\n[model] \u4e00\u4e0b\n[model] \u4e0a\u6d77\n[model] \u7684\u5929\u6c14\n[model] ...\n[\u5de5\u5177\u8c03\u7528] get_weather {\"city\":\"\u4e0a\u6d77\"}\n[tools] \u4e0a\u6d77\u7684\u5929\u6c14\u662f\u6674\u6717\u7684\uff0c25\u00b0C\n[model] \u4e0a\u6d77\n[model] \u7684\u5929\u6c14\n[model] \u662f\u6674\u6717\u7684\n[model] \uff0c25\u00b0C\n[model] \u3002\n</code></pre>"},{"location":"llmapps/langchain/core-components/streaming/#3-custom-updates","title":"3. \u81ea\u5b9a\u4e49\u66f4\u65b0\u6d41 (Custom Updates)","text":"<p>\u5728\u5de5\u5177\u4e2d\u4f7f\u7528 <code>get_stream_writer()</code> \u6765\u53d1\u9001\u81ea\u5b9a\u4e49\u7684\u6d41\u5f0f\u66f4\u65b0\u3002</p> <pre><code>from langgraph.config import get_stream_writer\n\ndef create_custom_streaming_tool():\n    \"\"\"\u521b\u5efa\u652f\u6301\u81ea\u5b9a\u4e49\u6d41\u5f0f\u4f20\u8f93\u7684\u5de5\u5177\"\"\"\n\n    def search_products(query: str, max_results: int = 5) -&gt; str:\n        \"\"\"\u641c\u7d22\u4ea7\u54c1\u4fe1\u606f\"\"\"\n        writer = get_stream_writer()\n\n        # \u53d1\u9001\u81ea\u5b9a\u4e49\u8fdb\u5ea6\u66f4\u65b0\n        writer(f\"\ud83d\udd0d \u5f00\u59cb\u641c\u7d22: {query}\")\n        writer(f\"\ud83d\udcca \u6700\u5927\u7ed3\u679c\u6570: {max_results}\")\n\n        # \u6a21\u62df\u641c\u7d22\u8fc7\u7a0b\n        writer(\"\u23f3 \u8fde\u63a5\u6570\u636e\u5e93...\")\n        # \u6a21\u62df\u6570\u636e\u5e93\u67e5\u8be2\n        writer(\"\u2705 \u6570\u636e\u5e93\u8fde\u63a5\u6210\u529f\")\n\n        writer(\"\ud83d\udd0e \u6267\u884c\u641c\u7d22\u67e5\u8be2...\")\n        # \u6a21\u62df\u641c\u7d22\u903b\u8f91\n        import time\n        time.sleep(0.5)\n\n        writer(f\"\ud83d\udce6 \u627e\u5230 3 \u4e2a\u76f8\u5173\u4ea7\u54c1\")\n\n        # \u8fd4\u56de\u6700\u7ec8\u7ed3\u679c\n        return f\"\u641c\u7d22 '{query}' \u627e\u5230 3 \u4e2a\u4ea7\u54c1: \u4ea7\u54c1A, \u4ea7\u54c1B, \u4ea7\u54c1C\"\n\n    return search_products\n\ndef stream_custom_updates():\n    \"\"\"\u6d41\u5f0f\u4f20\u8f93\u81ea\u5b9a\u4e49\u66f4\u65b0\"\"\"\n    print(\"=== \u81ea\u5b9a\u4e49\u66f4\u65b0\u6d41\u5f0f\u4f20\u8f93 ===\")\n\n    search_tool = create_custom_streaming_tool()\n    custom_agent = create_agent(\n        model=\"openai:gpt-4o\",\n        tools=[search_tool],\n    )\n\n    for chunk in custom_agent.stream(\n        {\"messages\": [{\"role\": \"user\", \"content\": \"\u641c\u7d22\u7b14\u8bb0\u672c\u7535\u8111\"}]},\n        stream_mode=\"custom\"  # \u5173\u952e\u53c2\u6570\n    ):\n        print(f\"\u81ea\u5b9a\u4e49\u66f4\u65b0: {chunk}\")\n\n# \u8c03\u7528\u793a\u4f8b\nstream_custom_updates()\n</code></pre> <p>\u8f93\u51fa\u793a\u4f8b\uff1a</p> <pre><code>\u81ea\u5b9a\u4e49\u66f4\u65b0: \ud83d\udd0d \u5f00\u59cb\u641c\u7d22: \u7b14\u8bb0\u672c\u7535\u8111\n\u81ea\u5b9a\u4e49\u66f4\u65b0: \ud83d\udcca \u6700\u5927\u7ed3\u679c\u6570: 5\n\u81ea\u5b9a\u4e49\u66f4\u65b0: \u23f3 \u8fde\u63a5\u6570\u636e\u5e93...\n\u81ea\u5b9a\u4e49\u66f4\u65b0: \u2705 \u6570\u636e\u5e93\u8fde\u63a5\u6210\u529f\n\u81ea\u5b9a\u4e49\u66f4\u65b0: \ud83d\udd0e \u6267\u884c\u641c\u7d22\u67e5\u8be2...\n\u81ea\u5b9a\u4e49\u66f4\u65b0: \ud83d\udce6 \u627e\u5230 3 \u4e2a\u76f8\u5173\u4ea7\u54c1\n</code></pre>"},{"location":"llmapps/langchain/core-components/streaming/#4","title":"4. \u591a\u6a21\u5f0f\u6d41\u5f0f\u4f20\u8f93","text":"<p>\u53ef\u4ee5\u540c\u65f6\u4f7f\u7528\u591a\u79cd\u6d41\u5f0f\u4f20\u8f93\u6a21\u5f0f\u3002</p> <pre><code>def stream_multiple_modes():\n    \"\"\"\u540c\u65f6\u4f7f\u7528\u591a\u79cd\u6d41\u5f0f\u4f20\u8f93\u6a21\u5f0f\"\"\"\n    print(\"=== \u591a\u6a21\u5f0f\u6d41\u5f0f\u4f20\u8f93 ===\")\n\n    # \u521b\u5efa\u652f\u6301\u81ea\u5b9a\u4e49\u6d41\u7684\u5de5\u5177\n    def advanced_weather_tool(city: str) -&gt; str:\n        \"\"\"\u9ad8\u7ea7\u5929\u6c14\u67e5\u8be2\u5de5\u5177\"\"\"\n        writer = get_stream_writer()\n        writer(f\"\ud83c\udf24\ufe0f  \u5f00\u59cb\u67e5\u8be2 {city} \u7684\u5929\u6c14\")\n        writer(\"\ud83d\udce1 \u8fde\u63a5\u6c14\u8c61API...\")\n        writer(\"\ud83d\udd0d \u83b7\u53d6\u5b9e\u65f6\u6570\u636e...\")\n        return f\"{city}\u7684\u5929\u6c14\uff1a\u6674\u6717\uff0c25\u00b0C\uff0c\u6e7f\u5ea660%\"\n\n    multi_agent = create_agent(\n        model=\"openai:gpt-4o\",\n        tools=[advanced_weather_tool],\n    )\n\n    for stream_mode, chunk in multi_agent.stream(\n        {\"messages\": [{\"role\": \"user\", \"content\": \"\u67e5\u8be2\u676d\u5dde\u7684\u5929\u6c14\"}]},\n        stream_mode=[\"updates\", \"custom\", \"messages\"]  # \u591a\u79cd\u6a21\u5f0f\n    ):\n        print(f\"\u6a21\u5f0f: {stream_mode}\")\n        print(f\"\u5185\u5bb9: {chunk}\")\n        print(\"-\" * 30)\n\n# \u8c03\u7528\u793a\u4f8b\nstream_multiple_modes()\n</code></pre>"},{"location":"llmapps/langchain/core-components/streaming/#_5","title":"\u5b9e\u9645\u5e94\u7528\u573a\u666f","text":""},{"location":"llmapps/langchain/core-components/streaming/#1","title":"\u573a\u666f1\uff1a\u5b9e\u65f6\u804a\u5929\u5e94\u7528","text":"<pre><code>import asyncio\nfrom langchain.agents import create_agent\n\nclass StreamingChatApp:\n    \"\"\"\u652f\u6301\u6d41\u5f0f\u4f20\u8f93\u7684\u804a\u5929\u5e94\u7528\"\"\"\n\n    def __init__(self):\n        self.agent = create_agent(\n            model=\"openai:gpt-4o\",\n            tools=[self.get_weather, self.search_web],\n        )\n\n    def get_weather(self, city: str) -&gt; str:\n        \"\"\"\u83b7\u53d6\u5929\u6c14\u4fe1\u606f\"\"\"\n        writer = get_stream_writer()\n        writer(f\"\u67e5\u8be2{city}\u7684\u5929\u6c14...\")\n        # \u6a21\u62dfAPI\u8c03\u7528\n        return f\"{city}: 25\u00b0C, \u6674\u6717\"\n\n    def search_web(self, query: str) -&gt; str:\n        \"\"\"\u7f51\u9875\u641c\u7d22\"\"\"\n        writer = get_stream_writer()\n        writer(f\"\u641c\u7d22: {query}\")\n        writer(\"\u6b63\u5728\u83b7\u53d6\u6700\u65b0\u4fe1\u606f...\")\n        return f\"\u5173\u4e8e'{query}'\u7684\u641c\u7d22\u7ed3\u679c...\"\n\n    async def chat_stream(self, message: str):\n        \"\"\"\u6d41\u5f0f\u804a\u5929\"\"\"\n        print(f\"\u7528\u6237: {message}\")\n        print(\"\u52a9\u624b: \", end=\"\", flush=True)\n\n        full_response = \"\"\n        for token, metadata in self.agent.stream(\n            {\"messages\": [{\"role\": \"user\", \"content\": message}]},\n            stream_mode=\"messages\",\n        ):\n            if hasattr(token, 'content_blocks'):\n                for block in token.content_blocks:\n                    if block.get('type') == 'text' and block.get('text'):\n                        text = block['text']\n                        print(text, end='', flush=True)\n                        full_response += text\n\n        print()  # \u6362\u884c\n        return full_response\n\n# \u4f7f\u7528\u793a\u4f8b\nasync def demo_chat():\n    app = StreamingChatApp()\n    await app.chat_stream(\"\u4eca\u5929\u676d\u5dde\u5929\u6c14\u600e\u4e48\u6837\uff1f\u7136\u540e\u641c\u7d22AI\u6700\u65b0\u53d1\u5c55\")\n</code></pre>"},{"location":"llmapps/langchain/core-components/streaming/#2","title":"\u573a\u666f2\uff1a\u8fdb\u5ea6\u76d1\u63a7\u4eea\u8868\u677f","text":"<pre><code>from typing import Dict, Any\nimport json\n\nclass ProgressMonitor:\n    \"\"\"\u8fdb\u5ea6\u76d1\u63a7\u5668\"\"\"\n\n    def __init__(self):\n        self.progress_data = {\n            'total_steps': 0,\n            'completed_steps': 0,\n            'current_step': '',\n            'details': []\n        }\n\n    def update_progress(self, step: str, details: str = \"\"):\n        \"\"\"\u66f4\u65b0\u8fdb\u5ea6\"\"\"\n        self.progress_data['current_step'] = step\n        self.progress_data['details'].append({\n            'step': step,\n            'details': details,\n            'timestamp': str(datetime.now())\n        })\n        self.progress_data['completed_steps'] += 1\n\n        # \u53d1\u9001\u5230\u524d\u7aef\uff08\u6a21\u62df\uff09\n        print(f\"\u8fdb\u5ea6\u66f4\u65b0: {json.dumps(self.progress_data, ensure_ascii=False)}\")\n\ndef create_monitored_tools(monitor: ProgressMonitor):\n    \"\"\"\u521b\u5efa\u88ab\u76d1\u63a7\u7684\u5de5\u5177\"\"\"\n\n    def research_topic(topic: str) -&gt; str:\n        \"\"\"\u7814\u7a76\u4e3b\u9898\"\"\"\n        writer = get_stream_writer()\n\n        monitor.update_progress('research', f\"\u5f00\u59cb\u7814\u7a76: {topic}\")\n        writer(f\"\ud83d\udd2c \u7814\u7a76\u4e3b\u9898: {topic}\")\n\n        # \u6a21\u62df\u7814\u7a76\u6b65\u9aa4\n        steps = [\n            \"\u6536\u96c6\u76f8\u5173\u8d44\u6599\",\n            \"\u5206\u6790\u5173\u952e\u4fe1\u606f\", \n            \"\u6574\u7406\u7814\u7a76\u7ed3\u679c\",\n            \"\u751f\u6210\u603b\u7ed3\u62a5\u544a\"\n        ]\n\n        for step in steps:\n            monitor.update_progress('research', step)\n            writer(f\"\u2705 {step}\")\n            import time\n            time.sleep(0.3)\n\n        return f\"\u5173\u4e8e{topic}\u7684\u7814\u7a76\u5b8c\u6210\"\n\n    return research_topic\n\ndef monitored_agent_demo():\n    \"\"\"\u88ab\u76d1\u63a7\u7684Agent\u6f14\u793a\"\"\"\n    monitor = ProgressMonitor()\n    research_tool = create_monitored_tools(monitor)\n\n    agent = create_agent(\n        model=\"openai:gpt-4o\",\n        tools=[research_tool],\n    )\n\n    print(\"\u5f00\u59cb\u76d1\u63a7Agent\u6267\u884c...\")\n    for stream_mode, chunk in agent.stream(\n        {\"messages\": [{\"role\": \"user\", \"content\": \"\u7814\u7a76\u4eba\u5de5\u667a\u80fd\u5728\u533b\u7597\u9886\u57df\u7684\u5e94\u7528\"}]},\n        stream_mode=[\"updates\", \"custom\"]\n    ):\n        if stream_mode == \"custom\":\n            print(f\"\u81ea\u5b9a\u4e49\u4e8b\u4ef6: {chunk}\")\n\n# \u8c03\u7528\u793a\u4f8b\nmonitored_agent_demo()\n</code></pre>"},{"location":"llmapps/langchain/core-components/streaming/#3","title":"\u573a\u666f3\uff1a\u5b9e\u65f6\u6570\u636e\u6d41\u5904\u7406","text":"<pre><code>import time\nfrom datetime import datetime\n\nclass RealTimeDataProcessor:\n    \"\"\"\u5b9e\u65f6\u6570\u636e\u5904\u7406\u5668\"\"\"\n\n    def __init__(self):\n        self.agent = create_agent(\n            model=\"openai:gpt-4o\",\n            tools=[self.process_data_stream],\n        )\n        self.data_buffer = []\n\n    def process_data_stream(self, data_type: str, count: int = 10) -&gt; str:\n        \"\"\"\u5904\u7406\u6570\u636e\u6d41\"\"\"\n        writer = get_stream_writer()\n\n        writer(f\"\u5f00\u59cb\u5904\u7406 {data_type} \u6570\u636e\u6d41...\")\n        writer(f\"\u9884\u8ba1\u5904\u7406 {count} \u6761\u6570\u636e\")\n\n        # \u6a21\u62df\u6570\u636e\u6d41\u5904\u7406\n        for i in range(count):\n            # \u6a21\u62df\u6570\u636e\u5904\u7406\n            processed_item = f\"{data_type}_item_{i+1}\"\n            self.data_buffer.append(processed_item)\n\n            # \u53d1\u9001\u8fdb\u5ea6\u66f4\u65b0\n            progress = (i + 1) / count * 100\n            writer(f\"\ud83d\udcca \u8fdb\u5ea6: {progress:.1f}% - \u5df2\u5904\u7406: {processed_item}\")\n\n            # \u6a21\u62df\u5904\u7406\u65f6\u95f4\n            time.sleep(0.1)\n\n        writer(\"\u2705 \u6570\u636e\u6d41\u5904\u7406\u5b8c\u6210\")\n        return f\"\u6210\u529f\u5904\u7406 {count} \u6761{data_type}\u6570\u636e\"\n\n    def start_processing(self, data_type: str):\n        \"\"\"\u5f00\u59cb\u5904\u7406\"\"\"\n        print(f\"\u5f00\u59cb\u5b9e\u65f6\u5904\u7406 {data_type} \u6570\u636e...\")\n\n        for stream_mode, chunk in self.agent.stream(\n            {\"messages\": [{\"role\": \"user\", \"content\": f\"\u5904\u7406{data_type}\u6570\u636e\u6d41\"}]},\n            stream_mode=[\"custom\", \"updates\"]\n        ):\n            if stream_mode == \"custom\":\n                print(f\"{datetime.now().strftime('%H:%M:%S')} - {chunk}\")\n\n# \u4f7f\u7528\u793a\u4f8b\nprocessor = RealTimeDataProcessor()\nprocessor.start_processing(\"\u4f20\u611f\u5668\")\n</code></pre>"},{"location":"llmapps/langchain/core-components/streaming/#_6","title":"\u9ad8\u7ea7\u529f\u80fd","text":""},{"location":"llmapps/langchain/core-components/streaming/#1_1","title":"1. \u9519\u8bef\u5904\u7406\u548c\u91cd\u8bd5","text":"<pre><code>def create_robust_streaming_tool():\n    \"\"\"\u521b\u5efa\u5065\u58ee\u7684\u6d41\u5f0f\u4f20\u8f93\u5de5\u5177\"\"\"\n\n    def robust_operation(operation: str) -&gt; str:\n        \"\"\"\u5065\u58ee\u7684\u64cd\u4f5c\"\"\"\n        writer = get_stream_writer()\n\n        try:\n            writer(f\"\ud83d\udfe1 \u5f00\u59cb\u6267\u884c: {operation}\")\n\n            # \u6a21\u62df\u53ef\u80fd\u5931\u8d25\u7684\u64cd\u4f5c\n            if \"fail\" in operation:\n                raise Exception(\"\u6a21\u62df\u64cd\u4f5c\u5931\u8d25\")\n\n            writer(\"\ud83d\udfe2 \u64cd\u4f5c\u6267\u884c\u4e2d...\")\n            time.sleep(1)\n            writer(\"\u2705 \u64cd\u4f5c\u5b8c\u6210\")\n\n            return f\"\u64cd\u4f5c '{operation}' \u6210\u529f\u5b8c\u6210\"\n\n        except Exception as e:\n            writer(f\"\ud83d\udd34 \u64cd\u4f5c\u5931\u8d25: {str(e)}\")\n            writer(\"\ud83d\udd04 \u5c1d\u8bd5\u91cd\u8bd5...\")\n            # \u8fd9\u91cc\u53ef\u4ee5\u6dfb\u52a0\u91cd\u8bd5\u903b\u8f91\n            return f\"\u64cd\u4f5c '{operation}' \u5931\u8d25: {str(e)}\"\n\n    return robust_operation\n\ndef error_handling_demo():\n    \"\"\"\u9519\u8bef\u5904\u7406\u6f14\u793a\"\"\"\n    robust_tool = create_robust_streaming_tool()\n    agent = create_agent(\n        model=\"openai:gpt-4o\",\n        tools=[robust_tool],\n    )\n\n    print(\"\u6d4b\u8bd5\u6b63\u5e38\u64cd\u4f5c:\")\n    for chunk in agent.stream(\n        {\"messages\": [{\"role\": \"user\", \"content\": \"\u6267\u884c\u6b63\u5e38\u64cd\u4f5c\"}]},\n        stream_mode=\"custom\"\n    ):\n        print(chunk)\n\n    print(\"\\n\u6d4b\u8bd5\u5931\u8d25\u64cd\u4f5c:\")\n    for chunk in agent.stream(\n        {\"messages\": [{\"role\": \"user\", \"content\": \"\u6267\u884c\u5931\u8d25\u64cd\u4f5c\"}]},\n        stream_mode=\"custom\"\n    ):\n        print(chunk)\n</code></pre>"},{"location":"llmapps/langchain/core-components/streaming/#2_1","title":"2. \u6027\u80fd\u4f18\u5316","text":"<pre><code>class OptimizedStreaming:\n    \"\"\"\u4f18\u5316\u6d41\u5f0f\u4f20\u8f93\u6027\u80fd\"\"\"\n\n    def __init__(self):\n        self.batch_size = 5\n        self.message_buffer = []\n\n    def batch_process_tool(self, items: list) -&gt; str:\n        \"\"\"\u6279\u91cf\u5904\u7406\u5de5\u5177\"\"\"\n        writer = get_stream_writer()\n\n        writer(f\"\ud83d\udd04 \u5f00\u59cb\u6279\u91cf\u5904\u7406 {len(items)} \u4e2a\u9879\u76ee\")\n\n        for i, item in enumerate(items):\n            # \u5904\u7406\u6bcf\u4e2a\u9879\u76ee\n            writer(f\"\u5904\u7406\u9879\u76ee {i+1}/{len(items)}: {item}\")\n\n            # \u6a21\u62df\u5904\u7406\n            time.sleep(0.1)\n\n            # \u6bcf\u5904\u7406\u5b8c\u4e00\u6279\u53d1\u9001\u66f4\u65b0\n            if (i + 1) % self.batch_size == 0:\n                writer(f\"\ud83d\udce6 \u5df2\u5b8c\u6210 {i+1} \u4e2a\u9879\u76ee\")\n\n        writer(\"\u2705 \u6279\u91cf\u5904\u7406\u5b8c\u6210\")\n        return f\"\u6210\u529f\u5904\u7406 {len(items)} \u4e2a\u9879\u76ee\"\n\n    def optimized_stream_demo(self):\n        \"\"\"\u4f18\u5316\u6d41\u5f0f\u4f20\u8f93\u6f14\u793a\"\"\"\n        agent = create_agent(\n            model=\"openai:gpt-4o\",\n            tools=[self.batch_process_tool],\n        )\n\n        items = [f\"item_{i}\" for i in range(1, 16)]\n\n        for chunk in agent.stream(\n            {\"messages\": [{\"role\": \"user\", \"content\": f\"\u6279\u91cf\u5904\u7406\u8fd9\u4e9b\u9879\u76ee: {items}\"}]},\n            stream_mode=\"custom\"\n        ):\n            print(chunk)\n</code></pre>"},{"location":"llmapps/langchain/core-components/streaming/#_7","title":"\u6700\u4f73\u5b9e\u8df5","text":""},{"location":"llmapps/langchain/core-components/streaming/#1_2","title":"1. \u9009\u62e9\u5408\u9002\u7684\u6d41\u5f0f\u4f20\u8f93\u6a21\u5f0f","text":"<pre><code>def choose_stream_mode(use_case: str):\n    \"\"\"\u6839\u636e\u4f7f\u7528\u573a\u666f\u9009\u62e9\u5408\u9002\u7684\u6d41\u5f0f\u4f20\u8f93\u6a21\u5f0f\"\"\"\n    mode_recommendations = {\n        \"chat_application\": \"messages\",  # \u804a\u5929\u5e94\u7528\uff1a\u9700\u8981\u5b9e\u65f6\u663e\u793a\u6587\u5b57\n        \"progress_tracking\": [\"updates\", \"custom\"],  # \u8fdb\u5ea6\u8ddf\u8e2a\uff1a\u9700\u8981\u6b65\u9aa4\u548c\u81ea\u5b9a\u4e49\u66f4\u65b0\n        \"debugging\": \"updates\",  # \u8c03\u8bd5\uff1a\u9700\u8981\u770b\u5230\u6bcf\u4e2a\u6b65\u9aa4\n        \"data_processing\": [\"custom\", \"messages\"],  # \u6570\u636e\u5904\u7406\uff1a\u9700\u8981\u8fdb\u5ea6\u548c\u7ed3\u679c\n        \"real_time_monitoring\": [\"updates\", \"custom\", \"messages\"]  # \u5b9e\u65f6\u76d1\u63a7\uff1a\u5168\u90e8\u4fe1\u606f\n    }\n\n    return mode_recommendations.get(use_case, \"updates\")\n\n# \u4f7f\u7528\u793a\u4f8b\nchat_mode = choose_stream_mode(\"chat_application\")\ndebug_mode = choose_stream_mode(\"debugging\")\n</code></pre>"},{"location":"llmapps/langchain/core-components/streaming/#2_2","title":"2. \u5904\u7406\u6d41\u5f0f\u4f20\u8f93\u9519\u8bef","text":"<pre><code>def safe_stream_invoke(agent, input_data, stream_mode=\"updates\", max_retries=3):\n    \"\"\"\u5b89\u5168\u7684\u6d41\u5f0f\u8c03\u7528\"\"\"\n    for attempt in range(max_retries):\n        try:\n            for chunk in agent.stream(input_data, stream_mode=stream_mode):\n                yield chunk\n            break  # \u6210\u529f\u5b8c\u6210\uff0c\u9000\u51fa\u91cd\u8bd5\u5faa\u73af\n        except Exception as e:\n            print(f\"\u6d41\u5f0f\u4f20\u8f93\u9519\u8bef (\u5c1d\u8bd5 {attempt + 1}/{max_retries}): {e}\")\n            if attempt == max_retries - 1:\n                raise  # \u6700\u540e\u4e00\u6b21\u5c1d\u8bd5\u4ecd\u7136\u5931\u8d25\uff0c\u629b\u51fa\u5f02\u5e38\n            time.sleep(1)  # \u7b49\u5f85\u540e\u91cd\u8bd5\n\n# \u4f7f\u7528\u793a\u4f8b\nfor chunk in safe_stream_invoke(\n    agent,\n    {\"messages\": [{\"role\": \"user\", \"content\": \"\u67e5\u8be2\u5929\u6c14\"}]},\n    stream_mode=\"messages\"\n):\n    print(chunk)\n</code></pre>"},{"location":"llmapps/langchain/core-components/streaming/#_8","title":"\u6545\u969c\u6392\u9664","text":""},{"location":"llmapps/langchain/core-components/streaming/#_9","title":"\u5e38\u89c1\u95ee\u9898\u53ca\u89e3\u51b3\u65b9\u6848","text":"<ol> <li>\u6d41\u5f0f\u4f20\u8f93\u4e0d\u5de5\u4f5c</li> <li>\u68c0\u67e5\u6a21\u578b\u662f\u5426\u652f\u6301\u6d41\u5f0f\u4f20\u8f93</li> <li>\u786e\u8ba4 <code>stream_mode</code> \u53c2\u6570\u8bbe\u7f6e\u6b63\u786e</li> <li> <p>\u9a8c\u8bc1\u7f51\u7edc\u8fde\u63a5</p> </li> <li> <p>\u81ea\u5b9a\u4e49\u66f4\u65b0\u4e0d\u663e\u793a</p> </li> <li>\u786e\u4fdd\u5728\u5de5\u5177\u4e2d\u6b63\u786e\u4f7f\u7528 <code>get_stream_writer()</code></li> <li>\u68c0\u67e5 <code>stream_mode</code> \u5305\u542b \"custom\"</li> <li> <p>\u786e\u8ba4\u5728 LangGraph \u6267\u884c\u4e0a\u4e0b\u6587\u4e2d\u8c03\u7528</p> </li> <li> <p>\u6027\u80fd\u95ee\u9898</p> </li> <li>\u51cf\u5c11\u4e0d\u5fc5\u8981\u7684\u6d41\u5f0f\u66f4\u65b0</li> <li>\u4f7f\u7528\u5408\u9002\u7684\u6279\u5904\u7406\u5927\u5c0f</li> <li>\u8003\u8651\u7981\u7528\u67d0\u4e9b\u6d41\u5f0f\u6a21\u5f0f</li> </ol>"},{"location":"llmapps/langchain/core-components/streaming/#_10","title":"\u603b\u7ed3","text":"<p>LangChain \u7684\u6d41\u5f0f\u4f20\u8f93\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u5b9e\u65f6\u66f4\u65b0\u80fd\u529b\uff1a</p> <ul> <li>\u591a\u79cd\u6a21\u5f0f\uff1a\u4ee3\u7406\u8fdb\u5ea6\u3001LLM tokens\u3001\u81ea\u5b9a\u4e49\u66f4\u65b0</li> <li>\u7075\u6d3b\u7ec4\u5408\uff1a\u53ef\u4ee5\u540c\u65f6\u4f7f\u7528\u591a\u79cd\u6d41\u5f0f\u6a21\u5f0f</li> <li>\u5b9e\u9645\u5e94\u7528\uff1a\u9002\u7528\u4e8e\u804a\u5929\u3001\u76d1\u63a7\u3001\u6570\u636e\u5904\u7406\u7b49\u573a\u666f</li> <li>\u5065\u58ee\u6027\uff1a\u5305\u542b\u9519\u8bef\u5904\u7406\u548c\u6027\u80fd\u4f18\u5316</li> </ul> <p>\u901a\u8fc7\u5408\u7406\u4f7f\u7528\u6d41\u5f0f\u4f20\u8f93\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u5e94\u7528\u7684\u54cd\u5e94\u6027\u548c\u7528\u6237\u4f53\u9a8c\u3002</p>"},{"location":"llmapps/langchain/core-components/structured-output/","title":"LangChain \u7ed3\u6784\u5316\u8f93\u51fa","text":""},{"location":"llmapps/langchain/core-components/structured-output/#_1","title":"\u6982\u8ff0","text":"<p>\u7ed3\u6784\u5316\u8f93\u51fa\u5141\u8bb8 Agent \u4ee5\u7279\u5b9a\u3001\u53ef\u9884\u6d4b\u7684\u683c\u5f0f\u8fd4\u56de\u6570\u636e\u3002\u4e0e\u89e3\u6790\u81ea\u7136\u8bed\u8a00\u54cd\u5e94\u4e0d\u540c\uff0c\u4f60\u53ef\u4ee5\u83b7\u5f97 JSON \u5bf9\u8c61\u3001Pydantic \u6a21\u578b\u6216\u6570\u636e\u7c7b\u5f62\u5f0f\u7684\u7ed3\u6784\u5316\u6570\u636e\uff0c\u8fd9\u4e9b\u6570\u636e\u53ef\u4ee5\u76f4\u63a5\u5728\u4f60\u7684\u5e94\u7528\u7a0b\u5e8f\u4e2d\u4f7f\u7528\u3002</p>"},{"location":"llmapps/langchain/core-components/structured-output/#_2","title":"\u6838\u5fc3\u4f18\u52bf","text":"<ul> <li>\u53ef\u9884\u6d4b\u6027\uff1a\u6570\u636e\u683c\u5f0f\u56fa\u5b9a\uff0c\u4fbf\u4e8e\u540e\u7eed\u5904\u7406</li> <li>\u7c7b\u578b\u5b89\u5168\uff1a\u81ea\u52a8\u9a8c\u8bc1\u548c\u7c7b\u578b\u68c0\u67e5</li> <li>\u76f4\u63a5\u96c6\u6210\uff1a\u65e0\u9700\u624b\u52a8\u89e3\u6790\uff0c\u53ef\u76f4\u63a5\u5728\u4ee3\u7801\u4e2d\u4f7f\u7528</li> <li>\u9519\u8bef\u5904\u7406\uff1a\u5185\u7f6e\u9a8c\u8bc1\u548c\u91cd\u8bd5\u673a\u5236</li> </ul>"},{"location":"llmapps/langchain/core-components/structured-output/#_3","title":"\u57fa\u7840\u7528\u6cd5","text":"<p>LangChain \u7684 <code>create_agent</code> \u81ea\u52a8\u5904\u7406\u7ed3\u6784\u5316\u8f93\u51fa\u3002\u7528\u6237\u8bbe\u7f6e\u6240\u9700\u7684\u7ed3\u6784\u5316\u8f93\u51fa\u6a21\u5f0f\uff0c\u5f53\u6a21\u578b\u751f\u6210\u7ed3\u6784\u5316\u6570\u636e\u65f6\uff0c\u5b83\u4f1a\u88ab\u6355\u83b7\u3001\u9a8c\u8bc1\u5e76\u8fd4\u56de\u5230 Agent \u72b6\u6001\u7684 <code>'structured_response'</code> \u952e\u4e2d\u3002</p> <pre><code>from langchain.agents import create_agent\n\n# \u57fa\u672c\u8bed\u6cd5\nagent = create_agent(\n    model=\"openai:gpt-4o\",\n    tools=[...],\n    response_format=YourSchema  # \u7ed3\u6784\u5316\u8f93\u51fa\u6a21\u5f0f\n)\n</code></pre>"},{"location":"llmapps/langchain/core-components/structured-output/#_4","title":"\u54cd\u5e94\u683c\u5f0f\u7b56\u7565","text":""},{"location":"llmapps/langchain/core-components/structured-output/#1-providerstrategy","title":"1. ProviderStrategy\uff08\u63d0\u4f9b\u8005\u7b56\u7565\uff09","text":"<p>\u5f53\u6a21\u578b\u63d0\u4f9b\u5546\u539f\u751f\u652f\u6301\u7ed3\u6784\u5316\u8f93\u51fa\u65f6\u4f7f\u7528\uff08\u76ee\u524d\u652f\u6301 OpenAI \u548c Grok\uff09\uff0c\u8fd9\u662f\u6700\u53ef\u9760\u7684\u65b9\u6cd5\u3002</p> <pre><code># LangChain \u4f1a\u81ea\u52a8\u9009\u62e9 ProviderStrategy\nagent = create_agent(\n    model=\"openai:gpt-4o\",\n    tools=tools,\n    response_format=ContactInfo  # \u81ea\u52a8\u9009\u62e9\u6700\u4f73\u7b56\u7565\n)\n</code></pre>"},{"location":"llmapps/langchain/core-components/structured-output/#2-toolstrategy","title":"2. ToolStrategy\uff08\u5de5\u5177\u8c03\u7528\u7b56\u7565\uff09","text":"<p>\u5bf9\u4e8e\u4e0d\u652f\u6301\u539f\u751f\u7ed3\u6784\u5316\u8f93\u51fa\u7684\u6a21\u578b\uff0c\u4f7f\u7528\u5de5\u5177\u8c03\u7528\u6765\u5b9e\u73b0\u76f8\u540c\u6548\u679c\u3002</p> <pre><code>from langchain.agents.structured_output import ToolStrategy\n\nagent = create_agent(\n    model=\"anthropic:claude-3-5-sonnet\",\n    tools=tools,\n    response_format=ToolStrategy(ContactInfo)\n)\n</code></pre>"},{"location":"llmapps/langchain/core-components/structured-output/#3","title":"3. \u81ea\u52a8\u9009\u62e9\u7b56\u7565","text":"<p>\u76f4\u63a5\u4f20\u9012\u6a21\u5f0f\u7c7b\u578b\uff0cLangChain \u4f1a\u81ea\u52a8\u9009\u62e9\u6700\u4f73\u7b56\u7565\uff1a</p> <pre><code># LangChain \u6839\u636e\u6a21\u578b\u80fd\u529b\u81ea\u52a8\u9009\u62e9\nagent = create_agent(\n    model=\"openai:gpt-4o\",  # \u652f\u6301\u539f\u751f\u7ed3\u6784\u5316\u8f93\u51fa \u2192 ProviderStrategy\n    tools=tools,\n    response_format=ContactInfo  # \u81ea\u52a8\u9009\u62e9\n)\n</code></pre>"},{"location":"llmapps/langchain/core-components/structured-output/#_5","title":"\u6a21\u5f0f\u5b9a\u4e49\u65b9\u5f0f","text":""},{"location":"llmapps/langchain/core-components/structured-output/#1-pydantic","title":"1. Pydantic \u6a21\u578b\uff08\u63a8\u8350\uff09","text":"<pre><code>from pydantic import BaseModel, Field\nfrom typing import Optional, List\nfrom langchain.agents import create_agent\n\nclass ContactInfo(BaseModel):\n    \"\"\"\u8054\u7cfb\u4eba\u4fe1\u606f\"\"\"\n    name: str = Field(description=\"\u59d3\u540d\")\n    email: str = Field(description=\"\u90ae\u7bb1\u5730\u5740\")\n    phone: Optional[str] = Field(description=\"\u7535\u8bdd\u53f7\u7801\")\n    tags: List[str] = Field(description=\"\u6807\u7b7e\u5217\u8868\")\n\nclass ProductReview(BaseModel):\n    \"\"\"\u4ea7\u54c1\u8bc4\u4ef7\u5206\u6790\"\"\"\n    rating: int = Field(description=\"\u8bc4\u5206(1-5)\", ge=1, le=5)\n    sentiment: str = Field(description=\"\u60c5\u611f\u503e\u5411\")\n    key_points: List[str] = Field(description=\"\u5173\u952e\u70b9\")\n    summary: str = Field(description=\"\u603b\u7ed3\")\n\n# \u4f7f\u7528\u793a\u4f8b\nagent = create_agent(\n    model=\"openai:gpt-4o\",\n    tools=[],\n    response_format=ContactInfo\n)\n\nresult = agent.invoke({\n    \"messages\": [{\n        \"role\": \"user\", \n        \"content\": \"\u63d0\u53d6\u8054\u7cfb\u4eba\uff1a\u5f20\u4e09\uff0c\u90ae\u7bb1zhangsan@example.com\uff0c\u7535\u8bdd13800138000\uff0c\u6807\u7b7e\uff1aVIP\u5ba2\u6237\u3001\u6280\u672f\u90e8\"\n    }]\n})\n\nprint(result[\"structured_response\"])\n# ContactInfo(name='\u5f20\u4e09', email='zhangsan@example.com', phone='13800138000', tags=['VIP\u5ba2\u6237', '\u6280\u672f\u90e8'])\n</code></pre>"},{"location":"llmapps/langchain/core-components/structured-output/#2-dataclass","title":"2. Dataclass","text":"<pre><code>from dataclasses import dataclass\nfrom typing import List, Optional\n\n@dataclass\nclass MeetingNotes:\n    \"\"\"\u4f1a\u8bae\u8bb0\u5f55\"\"\"\n    topic: str                    # \u4f1a\u8bae\u4e3b\u9898\n    participants: List[str]       # \u53c2\u4f1a\u4eba\u5458\n    decisions: List[str]          # \u51b3\u7b56\u4e8b\u9879\n    action_items: List[str]       # \u884c\u52a8\u9879\n    next_meeting: Optional[str]   # \u4e0b\u6b21\u4f1a\u8bae\u65f6\u95f4\n\nagent = create_agent(\n    model=\"openai:gpt-4o\",\n    tools=[],\n    response_format=MeetingNotes\n)\n</code></pre>"},{"location":"llmapps/langchain/core-components/structured-output/#3-typeddict","title":"3. TypedDict","text":"<pre><code>from typing_extensions import TypedDict, List, Optional\n\nclass CustomerOrder(TypedDict):\n    \"\"\"\u5ba2\u6237\u8ba2\u5355\"\"\"\n    order_id: str\n    customer_name: str\n    items: List[str]\n    total_amount: float\n    status: str\n\nagent = create_agent(\n    model=\"openai:gpt-4o\",\n    tools=[],\n    response_format=CustomerOrder\n)\n</code></pre>"},{"location":"llmapps/langchain/core-components/structured-output/#4-json-schema","title":"4. JSON Schema","text":"<pre><code>order_schema = {\n    \"type\": \"object\",\n    \"description\": \"\u5ba2\u6237\u8ba2\u5355\u4fe1\u606f\",\n    \"properties\": {\n        \"order_id\": {\"type\": \"string\", \"description\": \"\u8ba2\u5355ID\"},\n        \"customer_name\": {\"type\": \"string\", \"description\": \"\u5ba2\u6237\u59d3\u540d\"},\n        \"items\": {\n            \"type\": \"array\",\n            \"items\": {\"type\": \"string\"},\n            \"description\": \"\u5546\u54c1\u5217\u8868\"\n        },\n        \"total_amount\": {\"type\": \"number\", \"description\": \"\u603b\u91d1\u989d\"},\n        \"status\": {\"type\": \"string\", \"description\": \"\u8ba2\u5355\u72b6\u6001\"}\n    },\n    \"required\": [\"order_id\", \"customer_name\", \"items\", \"total_amount\"]\n}\n\nagent = create_agent(\n    model=\"openai:gpt-4o\",\n    tools=[],\n    response_format=order_schema\n)\n</code></pre>"},{"location":"llmapps/langchain/core-components/structured-output/#_6","title":"\u9ad8\u7ea7\u529f\u80fd","text":""},{"location":"llmapps/langchain/core-components/structured-output/#1","title":"1. \u8054\u5408\u7c7b\u578b\uff08\u591a\u6a21\u5f0f\u9009\u62e9\uff09","text":"<pre><code>from typing import Union\nfrom pydantic import BaseModel, Field\n\nclass ProductQuery(BaseModel):\n    \"\"\"\u4ea7\u54c1\u67e5\u8be2\"\"\"\n    product_name: str = Field(description=\"\u4ea7\u54c1\u540d\u79f0\")\n    features: List[str] = Field(description=\"\u4ea7\u54c1\u7279\u6027\")\n\nclass TechnicalSupport(BaseModel):\n    \"\"\"\u6280\u672f\u652f\u6301\u8bf7\u6c42\"\"\"\n    issue_type: str = Field(description=\"\u95ee\u9898\u7c7b\u578b\")\n    severity: str = Field(description=\"\u4e25\u91cd\u7a0b\u5ea6\")\n    description: str = Field(description=\"\u95ee\u9898\u63cf\u8ff0\")\n\nclass SalesInquiry(BaseModel):\n    \"\"\"\u9500\u552e\u54a8\u8be2\"\"\"\n    interest_level: str = Field(description=\"\u5174\u8da3\u7b49\u7ea7\")\n    budget_range: str = Field(description=\"\u9884\u7b97\u8303\u56f4\")\n    timeline: str = Field(description=\"\u65f6\u95f4\u7ebf\")\n\n# \u6a21\u578b\u6839\u636e\u4e0a\u4e0b\u6587\u9009\u62e9\u6700\u5408\u9002\u7684\u6a21\u5f0f\nagent = create_agent(\n    model=\"openai:gpt-4o\",\n    tools=[],\n    response_format=ToolStrategy(\n        Union[ProductQuery, TechnicalSupport, SalesInquiry]\n    )\n)\n\n# \u6a21\u578b\u4f1a\u81ea\u52a8\u9009\u62e9 TechnicalSupport\nresult = agent.invoke({\n    \"messages\": [{\n        \"role\": \"user\", \n        \"content\": \"\u6211\u7684\u5e94\u7528\u7a0b\u5e8f\u65e0\u6cd5\u542f\u52a8\uff0c\u663e\u793a\u9519\u8bef\u4ee3\u7801500\uff0c\u9700\u8981\u7d27\u6025\u5e2e\u52a9\"\n    }]\n})\n</code></pre>"},{"location":"llmapps/langchain/core-components/structured-output/#2","title":"2. \u81ea\u5b9a\u4e49\u5de5\u5177\u6d88\u606f\u5185\u5bb9","text":"<pre><code>from langchain.agents.structured_output import ToolStrategy\n\nclass BugReport(BaseModel):\n    \"\"\"Bug\u62a5\u544a\"\"\"\n    title: str = Field(description=\"\u95ee\u9898\u6807\u9898\")\n    severity: str = Field(description=\"\u4e25\u91cd\u7a0b\u5ea6\")\n    steps_to_reproduce: List[str] = Field(description=\"\u91cd\u73b0\u6b65\u9aa4\")\n    expected_behavior: str = Field(description=\"\u9884\u671f\u884c\u4e3a\")\n    actual_behavior: str = Field(description=\"\u5b9e\u9645\u884c\u4e3a\")\n\nagent = create_agent(\n    model=\"openai:gpt-4o\",\n    tools=[],\n    response_format=ToolStrategy(\n        schema=BugReport,\n        tool_message_content=\"\u2705 Bug\u62a5\u544a\u5df2\u6210\u529f\u8bb0\u5f55\u5230\u7cfb\u7edf\uff01\"\n    )\n)\n</code></pre>"},{"location":"llmapps/langchain/core-components/structured-output/#3_1","title":"3. \u590d\u6742\u5d4c\u5957\u7ed3\u6784","text":"<pre><code>from typing import List, Optional\nfrom pydantic import BaseModel, Field\n\nclass Address(BaseModel):\n    \"\"\"\u5730\u5740\u4fe1\u606f\"\"\"\n    street: str = Field(description=\"\u8857\u9053\")\n    city: str = Field(description=\"\u57ce\u5e02\")\n    country: str = Field(description=\"\u56fd\u5bb6\")\n    postal_code: str = Field(description=\"\u90ae\u7f16\")\n\nclass OrderItem(BaseModel):\n    \"\"\"\u8ba2\u5355\u9879\"\"\"\n    product_name: str = Field(description=\"\u5546\u54c1\u540d\u79f0\")\n    quantity: int = Field(description=\"\u6570\u91cf\")\n    price: float = Field(description=\"\u5355\u4ef7\")\n\nclass CustomerOrder(BaseModel):\n    \"\"\"\u5b8c\u6574\u5ba2\u6237\u8ba2\u5355\"\"\"\n    order_id: str = Field(description=\"\u8ba2\u5355ID\")\n    customer_name: str = Field(description=\"\u5ba2\u6237\u59d3\u540d\")\n    shipping_address: Address = Field(description=\"\u914d\u9001\u5730\u5740\")\n    items: List[OrderItem] = Field(description=\"\u8ba2\u5355\u9879\u5217\u8868\")\n    total_amount: float = Field(description=\"\u603b\u91d1\u989d\")\n\nagent = create_agent(\n    model=\"openai:gpt-4o\",\n    tools=[],\n    response_format=CustomerOrder\n)\n</code></pre>"},{"location":"llmapps/langchain/core-components/structured-output/#_7","title":"\u9519\u8bef\u5904\u7406","text":""},{"location":"llmapps/langchain/core-components/structured-output/#1_1","title":"1. \u57fa\u672c\u9519\u8bef\u5904\u7406","text":"<pre><code>from langchain.agents.structured_output import ToolStrategy\n\nclass ProductRating(BaseModel):\n    rating: int = Field(description=\"\u8bc4\u5206(1-5)\", ge=1, le=5)\n    comment: str = Field(description=\"\u8bc4\u4ef7\u5185\u5bb9\")\n\n# \u9ed8\u8ba4\u9519\u8bef\u5904\u7406\uff08\u81ea\u52a8\u91cd\u8bd5\uff09\nagent = create_agent(\n    model=\"openai:gpt-4o\",\n    tools=[],\n    response_format=ToolStrategy(ProductRating)  # handle_errors=True\n)\n</code></pre>"},{"location":"llmapps/langchain/core-components/structured-output/#2_1","title":"2. \u81ea\u5b9a\u4e49\u9519\u8bef\u6d88\u606f","text":"<pre><code>agent = create_agent(\n    model=\"openai:gpt-4o\",\n    tools=[],\n    response_format=ToolStrategy(\n        schema=ProductRating,\n        handle_errors=\"\u8bf7\u63d0\u4f9b1-5\u5206\u7684\u8bc4\u5206\u548c\u6709\u6548\u7684\u8bc4\u4ef7\u5185\u5bb9\u3002\"\n    )\n)\n</code></pre>"},{"location":"llmapps/langchain/core-components/structured-output/#3_2","title":"3. \u7279\u5b9a\u5f02\u5e38\u5904\u7406","text":"<pre><code># \u53ea\u5904\u7406\u7279\u5b9a\u7c7b\u578b\u7684\u5f02\u5e38\nagent = create_agent(\n    model=\"openai:gpt-4o\",\n    tools=[],\n    response_format=ToolStrategy(\n        schema=ProductRating,\n        handle_errors=ValueError  # \u53ea\u5bf9 ValueError \u91cd\u8bd5\n    )\n)\n\n# \u5904\u7406\u591a\u79cd\u5f02\u5e38\u7c7b\u578b\nagent = create_agent(\n    model=\"openai:gpt-4o\",\n    tools=[],\n    response_format=ToolStrategy(\n        schema=ProductRating,\n        handle_errors=(ValueError, TypeError)  # \u5bf9\u4e24\u79cd\u5f02\u5e38\u91cd\u8bd5\n    )\n)\n</code></pre>"},{"location":"llmapps/langchain/core-components/structured-output/#4","title":"4. \u81ea\u5b9a\u4e49\u9519\u8bef\u5904\u7406\u51fd\u6570","text":"<pre><code>def custom_error_handler(error: Exception) -&gt; str:\n    if \"rating\" in str(error):\n        return \"\u8bc4\u5206\u5fc5\u987b\u57281-5\u4e4b\u95f4\uff0c\u8bf7\u4fee\u6b63\u3002\"\n    elif \"comment\" in str(error):\n        return \"\u8bc4\u4ef7\u5185\u5bb9\u4e0d\u80fd\u4e3a\u7a7a\uff0c\u8bf7\u8865\u5145\u3002\"\n    else:\n        return f\"\u683c\u5f0f\u9519\u8bef\uff1a{str(error)}\"\n\nagent = create_agent(\n    model=\"openai:gpt-4o\",\n    tools=[],\n    response_format=ToolStrategy(\n        schema=ProductRating,\n        handle_errors=custom_error_handler\n    )\n)\n</code></pre>"},{"location":"llmapps/langchain/core-components/structured-output/#5","title":"5. \u7981\u7528\u9519\u8bef\u5904\u7406","text":"<pre><code># \u6240\u6709\u9519\u8bef\u90fd\u4f1a\u76f4\u63a5\u629b\u51fa\nagent = create_agent(\n    model=\"openai:gpt-4o\",\n    tools=[],\n    response_format=ToolStrategy(\n        schema=ProductRating,\n        handle_errors=False  # \u4e0d\u8fdb\u884c\u9519\u8bef\u5904\u7406\n    )\n)\n</code></pre>"},{"location":"llmapps/langchain/core-components/structured-output/#_8","title":"\u5b9e\u9645\u5e94\u7528\u573a\u666f","text":""},{"location":"llmapps/langchain/core-components/structured-output/#1_2","title":"\u573a\u666f1\uff1a\u5ba2\u6237\u670d\u52a1\u81ea\u52a8\u5316","text":"<pre><code>from typing import Literal\nfrom pydantic import BaseModel, Field\n\nclass CustomerServiceTicket(BaseModel):\n    \"\"\"\u5ba2\u6237\u670d\u52a1\u5de5\u5355\"\"\"\n    ticket_type: Literal[\"technical\", \"billing\", \"general\", \"complaint\"] = Field(description=\"\u5de5\u5355\u7c7b\u578b\")\n    priority: Literal[\"low\", \"medium\", \"high\", \"urgent\"] = Field(description\u4f18\u5148\u7ea7\")\n    customer_issue: str = Field(description=\"\u5ba2\u6237\u95ee\u9898\u63cf\u8ff0\")\n    suggested_solution: str = Field(description=\"\u5efa\u8bae\u89e3\u51b3\u65b9\u6848\")\n    follow_up_required: bool = Field(description=\"\u662f\u5426\u9700\u8981\u8ddf\u8fdb\")\n\nclass CustomerServiceAgent:\n    def __init__(self):\n        self.agent = create_agent(\n            model=\"openai:gpt-4o\",\n            tools=[],  # \u53ef\u4ee5\u96c6\u6210\u77e5\u8bc6\u5e93\u641c\u7d22\u7b49\u5de5\u5177\n            response_format=CustomerServiceTicket\n        )\n\n    def process_customer_message(self, message: str):\n        result = self.agent.invoke({\n            \"messages\": [{\"role\": \"user\", \"content\": message}]\n        })\n\n        ticket = result[\"structured_response\"]\n        self._route_ticket(ticket)\n        return ticket\n\n    def _route_ticket(self, ticket: CustomerServiceTicket):\n        # \u6839\u636e\u5de5\u5355\u7c7b\u578b\u548c\u4f18\u5148\u7ea7\u8def\u7531\u5230\u4e0d\u540c\u56e2\u961f\n        if ticket.ticket_type == \"technical\" and ticket.priority in [\"high\", \"urgent\"]:\n            print(\"\ud83d\udea8 \u7d27\u6025\u6280\u672f\u95ee\u9898 - \u8def\u7531\u5230\u6280\u672f\u56e2\u961f\")\n        elif ticket.ticket_type == \"billing\":\n            print(\"\ud83d\udcb0 \u8d26\u5355\u95ee\u9898 - \u8def\u7531\u5230\u8d22\u52a1\u56e2\u961f\")\n        # ... \u5176\u4ed6\u8def\u7531\u903b\u8f91\n</code></pre>"},{"location":"llmapps/langchain/core-components/structured-output/#2_2","title":"\u573a\u666f2\uff1a\u5185\u5bb9\u5206\u6790\u548c\u63d0\u53d6","text":"<pre><code>from datetime import datetime\nfrom typing import List, Optional\n\nclass NewsArticle(BaseModel):\n    \"\"\"\u65b0\u95fb\u6587\u7ae0\u5206\u6790\"\"\"\n    headline: str = Field(description=\"\u6807\u9898\")\n    summary: str = Field(description=\"\u6458\u8981\")\n    key_entities: List[str] = Field(description=\"\u5173\u952e\u5b9e\u4f53\")\n    sentiment: str = Field(description=\"\u60c5\u611f\u503e\u5411\")\n    categories: List[str] = Field(description=\"\u5206\u7c7b\")\n    publish_date: Optional[str] = Field(description=\"\u53d1\u5e03\u65e5\u671f\")\n\nclass ContentAnalyzer:\n    def __init__(self):\n        self.agent = create_agent(\n            model=\"openai:gpt-4o\",\n            tools=[],\n            response_format=NewsArticle\n        )\n\n    def analyze_article(self, content: str):\n        result = self.agent.invoke({\n            \"messages\": [{\n                \"role\": \"user\", \n                \"content\": f\"\u5206\u6790\u4ee5\u4e0b\u65b0\u95fb\u5185\u5bb9\uff1a\\n\\n{content}\"\n            }]\n        })\n        return result[\"structured_response\"]\n\n# \u4f7f\u7528\u793a\u4f8b\nanalyzer = ContentAnalyzer()\narticle_content = \"\"\"\n\u4eca\u65e5\uff0c\u67d0\u79d1\u6280\u516c\u53f8\u53d1\u5e03\u4e86\u65b0\u4e00\u4ee3AI\u82af\u7247\uff0c\u6027\u80fd\u63d0\u5347200%\u3002\n\u8be5\u82af\u7247\u91c7\u75285nm\u5de5\u827a\uff0c\u529f\u8017\u964d\u4f4e30%\u3002CEO\u5f20\u4e09\u8868\u793a\uff0c\n\u8fd9\u5c06\u63a8\u52a8\u4eba\u5de5\u667a\u80fd\u5e94\u7528\u7684\u5feb\u901f\u53d1\u5c55\u3002\n\"\"\"\n\nanalysis = analyzer.analyze_article(article_content)\nprint(f\"\u6807\u9898: {analysis.headline}\")\nprint(f\"\u60c5\u611f: {analysis.sentiment}\")\nprint(f\"\u5173\u952e\u5b9e\u4f53: {analysis.key_entities}\")\n</code></pre>"},{"location":"llmapps/langchain/core-components/structured-output/#3_3","title":"\u573a\u666f3\uff1a\u7535\u5b50\u5546\u52a1\u4ea7\u54c1\u4fe1\u606f\u63d0\u53d6","text":"<pre><code>from typing import List, Optional\nfrom decimal import Decimal\n\nclass ProductInfo(BaseModel):\n    \"\"\"\u4ea7\u54c1\u4fe1\u606f\u63d0\u53d6\"\"\"\n    name: str = Field(description=\"\u4ea7\u54c1\u540d\u79f0\")\n    brand: Optional[str] = Field(description=\"\u54c1\u724c\")\n    price: Optional[Decimal] = Field(description=\"\u4ef7\u683c\")\n    features: List[str] = Field(description=\"\u4ea7\u54c1\u7279\u6027\")\n    specifications: dict = Field(description=\"\u89c4\u683c\u53c2\u6570\")\n    availability: bool = Field(description=\"\u662f\u5426\u6709\u8d27\")\n\nclass EcommerceParser:\n    def __init__(self):\n        self.agent = create_agent(\n            model=\"openai:gpt-4o\",\n            tools=[],\n            response_format=ProductInfo\n        )\n\n    def parse_product_description(self, description: str):\n        result = self.agent.invoke({\n            \"messages\": [{\n                \"role\": \"user\",\n                \"content\": f\"\u4ece\u4ee5\u4e0b\u63cf\u8ff0\u4e2d\u63d0\u53d6\u4ea7\u54c1\u4fe1\u606f\uff1a\\n\\n{description}\"\n            }]\n        })\n        return result[\"structured_response\"]\n\n# \u4f7f\u7528\u793a\u4f8b\nparser = EcommerceParser()\nproduct_desc = \"\"\"\n\u82f9\u679c iPhone 15 Pro Max\uff0c256GB\uff0c\u949b\u91d1\u5c5e\u6750\u8d28\n\u4ef7\u683c\uff1a\u00a59,999\n\u7279\u6027\uff1aA17 Pro\u82af\u7247\u30014800\u4e07\u50cf\u7d20\u4e3b\u6444\u30015\u500d\u5149\u5b66\u53d8\u7126\n\u89c4\u683c\uff1a\u91cd\u91cf221g\uff0c6.7\u82f1\u5bf8\u8d85\u89c6\u7f51\u819cXDR\u663e\u793a\u5c4f\n\u5e93\u5b58\u5145\u8db3\uff0c\u6b21\u65e5\u8fbe\n\"\"\"\n\nproduct_info = parser.parse_product_description(product_desc)\n</code></pre>"},{"location":"llmapps/langchain/core-components/structured-output/#_9","title":"\u6700\u4f73\u5b9e\u8df5","text":""},{"location":"llmapps/langchain/core-components/structured-output/#1_3","title":"1. \u8bbe\u8ba1\u6709\u6548\u7684\u6a21\u5f0f","text":"<pre><code># \u2705 \u597d\u7684\u6a21\u5f0f\u8bbe\u8ba1\nclass EffectiveSchema(BaseModel):\n    # \u660e\u786e\u7684\u5b57\u6bb5\u63cf\u8ff0\n    name: str = Field(description=\"\u7528\u6237\u59d3\u540d\")\n    # \u9002\u5f53\u7684\u7ea6\u675f\n    age: int = Field(description=\"\u5e74\u9f84\", ge=0, le=150)\n    # \u5408\u7406\u7684\u53ef\u9009\u5b57\u6bb5\n    email: Optional[str] = Field(description=\"\u90ae\u7bb1\u5730\u5740\")\n    # \u6e05\u6670\u7684\u679a\u4e3e\u503c\n    status: Literal[\"active\", \"inactive\", \"pending\"] = Field(description=\"\u72b6\u6001\")\n\n# \u274c \u907f\u514d\u7684\u6a21\u5f0f\u8bbe\u8ba1\nclass PoorSchema(BaseModel):\n    # \u63cf\u8ff0\u4e0d\u6e05\u6670\n    field1: str\n    # \u7ea6\u675f\u4e0d\u660e\u786e\n    field2: int\n    # \u8fc7\u4e8e\u590d\u6742\u7684\u5d4c\u5957\n    data: Dict[str, Any]\n</code></pre>"},{"location":"llmapps/langchain/core-components/structured-output/#2_3","title":"2. \u9519\u8bef\u5904\u7406\u7b56\u7565","text":"<pre><code># \u6839\u636e\u4f7f\u7528\u573a\u666f\u9009\u62e9\u5408\u9002\u7684\u9519\u8bef\u5904\u7406\ndef create_robust_agent(schema):\n    return create_agent(\n        model=\"openai:gpt-4o\",\n        tools=[],\n        response_format=ToolStrategy(\n            schema=schema,\n            handle_errors=lambda e: f\"\u683c\u5f0f\u9519\u8bef\uff0c\u8bf7\u91cd\u65b0\u8f93\u5165\uff1a{str(e)}\"\n        ),\n        system_prompt=\"\u8bf7\u4e25\u683c\u6309\u7167\u8981\u6c42\u7684\u683c\u5f0f\u8f93\u51fa\u6570\u636e\u3002\"\n    )\n</code></pre>"},{"location":"llmapps/langchain/core-components/structured-output/#3_4","title":"3. \u6027\u80fd\u4f18\u5316","text":"<pre><code># \u91cd\u7528 Agent \u5b9e\u4f8b\nclass StructuredOutputService:\n    def __init__(self):\n        self._agents = {}\n\n    def get_agent(self, schema):\n        schema_key = str(schema)\n        if schema_key not in self._agents:\n            self._agents[schema_key] = create_agent(\n                model=\"openai:gpt-4o\",\n                tools=[],\n                response_format=schema\n            )\n        return self._agents[schema_key]\n</code></pre>"},{"location":"llmapps/langchain/core-components/structured-output/#_10","title":"\u6545\u969c\u6392\u9664","text":""},{"location":"llmapps/langchain/core-components/structured-output/#_11","title":"\u5e38\u89c1\u95ee\u9898\u53ca\u89e3\u51b3\u65b9\u6848","text":"<ol> <li> <p>\u6a21\u578b\u4e0d\u8fd4\u56de\u7ed3\u6784\u5316\u6570\u636e</p> <ul> <li>\u68c0\u67e5\u6a21\u578b\u662f\u5426\u652f\u6301\u5de5\u5177\u8c03\u7528</li> <li>\u9a8c\u8bc1\u6a21\u5f0f\u5b9a\u4e49\u662f\u5426\u6e05\u6670</li> <li>\u6dfb\u52a0\u66f4\u8be6\u7ec6\u7684\u5b57\u6bb5\u63cf\u8ff0</li> </ul> </li> <li> <p>\u9a8c\u8bc1\u9519\u8bef\u9891\u7e41</p> <ul> <li>\u7b80\u5316\u6a21\u5f0f\u7ed3\u6784</li> <li>\u653e\u5bbd\u5b57\u6bb5\u7ea6\u675f</li> <li>\u63d0\u4f9b\u66f4\u660e\u786e\u7684\u7cfb\u7edf\u63d0\u793a</li> </ul> </li> <li> <p>\u6027\u80fd\u95ee\u9898</p> <ul> <li>\u91cd\u7528 Agent \u5b9e\u4f8b</li> <li>\u4f7f\u7528\u66f4\u7b80\u5355\u7684\u6a21\u5f0f</li> <li>\u8003\u8651\u4f7f\u7528 ProviderStrategy\uff08\u5982\u679c\u53ef\u7528\uff09</li> </ul> </li> </ol>"},{"location":"llmapps/langchain/core-components/structured-output/#_12","title":"\u603b\u7ed3","text":"<p>LangChain \u7684\u7ed3\u6784\u5316\u8f93\u51fa\u529f\u80fd\u4e3a\u6784\u5efa\u53ef\u9760\u7684 AI \u5e94\u7528\u63d0\u4f9b\u4e86\u5f3a\u5927\u57fa\u7840\uff1a</p> <ul> <li>\u7075\u6d3b\u7684\u6a21\u5f0f\u5b9a\u4e49\uff1a\u652f\u6301\u591a\u79cd\u6a21\u5f0f\u7c7b\u578b</li> <li>\u667a\u80fd\u7684\u7b56\u7565\u9009\u62e9\uff1a\u81ea\u52a8\u9009\u62e9\u6700\u4f73\u5b9e\u73b0\u65b9\u5f0f</li> <li>\u5f3a\u5927\u7684\u9519\u8bef\u5904\u7406\uff1a\u5185\u7f6e\u9a8c\u8bc1\u548c\u91cd\u8bd5\u673a\u5236</li> <li>\u751f\u4ea7\u7ea7\u53ef\u9760\u6027\uff1a\u9002\u5408\u4f01\u4e1a\u7ea7\u5e94\u7528</li> </ul> <p>\u901a\u8fc7\u5408\u7406\u4f7f\u7528\u7ed3\u6784\u5316\u8f93\u51fa\uff0c\u4f60\u53ef\u4ee5\u6784\u5efa\u51fa\u66f4\u52a0\u7a33\u5b9a\u3001\u53ef\u7ef4\u62a4\u7684 AI \u5e94\u7528\u7cfb\u7edf\u3002</p>"},{"location":"llmapps/langchain/core-components/tools/","title":"LangChain Tools","text":""},{"location":"llmapps/langchain/core-components/tools/#_1","title":"\u6982\u8ff0","text":"<p>Tools\uff08\u5de5\u5177\uff09\u662f AI Agent \u8c03\u7528\u4ee5\u6267\u884c\u64cd\u4f5c\u7684\u7ec4\u4ef6\u3002\u5b83\u4eec\u901a\u8fc7\u5b9a\u4e49\u826f\u597d\u7684\u8f93\u5165\u548c\u8f93\u51fa\u6765\u6269\u5c55\u6a21\u578b\u80fd\u529b\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u4e0e\u5916\u90e8\u7cfb\u7edf\uff08\u5982 API\u3001\u6570\u636e\u5e93\u3001\u6587\u4ef6\u7cfb\u7edf\uff09\u8fdb\u884c\u4ea4\u4e92\u3002</p>"},{"location":"llmapps/langchain/core-components/tools/#_2","title":"\u6838\u5fc3\u6982\u5ff5","text":"<ul> <li>\u7ed3\u6784\u5316\u4ea4\u4e92\uff1aTools \u63d0\u4f9b\u6a21\u578b\u4e0e\u5916\u90e8\u7cfb\u7edf\u7684\u7ed3\u6784\u5316\u63a5\u53e3</li> <li>\u5c01\u88c5\u6027\uff1a\u5c01\u88c5\u53ef\u8c03\u7528\u51fd\u6570\u53ca\u5176\u8f93\u5165\u6a21\u5f0f</li> <li>\u667a\u80fd\u8c03\u7528\uff1a\u6a21\u578b\u51b3\u5b9a\u662f\u5426\u8c03\u7528\u5de5\u5177\u4ee5\u53ca\u4f7f\u7528\u4ec0\u4e48\u53c2\u6570</li> </ul>"},{"location":"llmapps/langchain/core-components/tools/#_3","title":"\u521b\u5efa\u5de5\u5177","text":""},{"location":"llmapps/langchain/core-components/tools/#1","title":"1. \u57fa\u7840\u5de5\u5177\u5b9a\u4e49","text":"<p>\u4f7f\u7528 <code>@tool</code> \u88c5\u9970\u5668\u521b\u5efa\u5de5\u5177\uff0c\u51fd\u6570\u6587\u6863\u5b57\u7b26\u4e32\u4f1a\u81ea\u52a8\u6210\u4e3a\u5de5\u5177\u63cf\u8ff0\uff1a</p> <pre><code>from langchain.tools import tool\n\n@tool\ndef search_database(query: str, limit: int = 10) -&gt; str:\n    \"\"\"\u5728\u5ba2\u6237\u6570\u636e\u5e93\u4e2d\u641c\u7d22\u5339\u914d\u67e5\u8be2\u7684\u8bb0\u5f55\u3002\n\n    Args:\n        query: \u8981\u67e5\u627e\u7684\u641c\u7d22\u8bcd\n        limit: \u8fd4\u56de\u7684\u6700\u5927\u7ed3\u679c\u6570\n    \"\"\"\n    # \u6a21\u62df\u6570\u636e\u5e93\u641c\u7d22\n    return f\"\u627e\u5230 {limit} \u6761\u5173\u4e8e '{query}' \u7684\u7ed3\u679c\"\n\n# \u4f7f\u7528\u5de5\u5177\nresult = search_database.invoke({\"query\": \"\u5ba2\u6237\u6295\u8bc9\", \"limit\": 5})\nprint(result)\n</code></pre>"},{"location":"llmapps/langchain/core-components/tools/#2","title":"2. \u81ea\u5b9a\u4e49\u5de5\u5177\u5c5e\u6027","text":""},{"location":"llmapps/langchain/core-components/tools/#_4","title":"\u81ea\u5b9a\u4e49\u5de5\u5177\u540d\u79f0","text":"<pre><code>@tool(\"web_search\")  # \u81ea\u5b9a\u4e49\u540d\u79f0\ndef search_web(query: str) -&gt; str:\n    \"\"\"\u5728\u7f51\u7edc\u4e0a\u641c\u7d22\u4fe1\u606f\u3002\"\"\"\n    return f\"\u641c\u7d22 '{query}' \u7684\u7ed3\u679c\"\n\nprint(search_web.name)  # \u8f93\u51fa: web_search\n</code></pre>"},{"location":"llmapps/langchain/core-components/tools/#_5","title":"\u81ea\u5b9a\u4e49\u5de5\u5177\u63cf\u8ff0","text":"<pre><code>@tool(\"calculator\", description=\"\u6267\u884c\u7b97\u672f\u8ba1\u7b97\u3002\u7528\u4e8e\u4efb\u4f55\u6570\u5b66\u95ee\u9898\u3002\")\ndef calculate(expression: str) -&gt; str:\n    \"\"\"\u8bc4\u4f30\u6570\u5b66\u8868\u8fbe\u5f0f\u3002\"\"\"\n    return str(eval(expression))\n</code></pre>"},{"location":"llmapps/langchain/core-components/tools/#3","title":"3. \u9ad8\u7ea7\u6a21\u5f0f\u5b9a\u4e49","text":""},{"location":"llmapps/langchain/core-components/tools/#pydantic","title":"\u4f7f\u7528 Pydantic \u6a21\u578b\u5b9a\u4e49\u590d\u6742\u8f93\u5165","text":"<pre><code>from pydantic import BaseModel, Field\nfrom typing import Literal, List\n\nclass WeatherInput(BaseModel):\n    \"\"\"\u5929\u6c14\u67e5\u8be2\u7684\u8f93\u5165\u53c2\u6570\u3002\"\"\"\n    location: str = Field(description=\"\u57ce\u5e02\u540d\u79f0\u6216\u5750\u6807\")\n    units: Literal[\"celsius\", \"fahrenheit\"] = Field(\n        default=\"celsius\",\n        description=\"\u6e29\u5ea6\u5355\u4f4d\u504f\u597d\"\n    )\n    include_forecast: bool = Field(\n        default=False,\n        description=\"\u5305\u542b5\u5929\u9884\u62a5\"\n    )\n    forecast_days: int = Field(\n        default=5,\n        ge=1,\n        le=10,\n        description=\"\u9884\u62a5\u5929\u6570\uff081-10\uff09\"\n    )\n\n@tool(args_schema=WeatherInput)\ndef get_weather(\n    location: str, \n    units: str = \"celsius\", \n    include_forecast: bool = False,\n    forecast_days: int = 5\n) -&gt; str:\n    \"\"\"\u83b7\u53d6\u5f53\u524d\u5929\u6c14\u548c\u53ef\u9009\u9884\u62a5\u3002\"\"\"\n    temp = 22 if units == \"celsius\" else 72\n    result = f\"{location}\u5f53\u524d\u5929\u6c14: {temp}\u5ea6 {units}\"\n\n    if include_forecast:\n        result += f\"\\n\u672a\u6765{forecast_days}\u5929\u9884\u62a5: \u6674\u6717\"\n\n    return result\n</code></pre>"},{"location":"llmapps/langchain/core-components/tools/#json-schema","title":"\u4f7f\u7528 JSON Schema \u5b9a\u4e49","text":"<pre><code>weather_schema = {\n    \"type\": \"object\",\n    \"properties\": {\n        \"location\": {\"type\": \"string\"},\n        \"units\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n        \"include_forecast\": {\"type\": \"boolean\"},\n        \"forecast_days\": {\"type\": \"integer\", \"minimum\": 1, \"maximum\": 10}\n    },\n    \"required\": [\"location\"]\n}\n\n@tool(args_schema=weather_schema)\ndef get_weather_json(\n    location: str, \n    units: str = \"celsius\", \n    include_forecast: bool = False,\n    forecast_days: int = 5\n) -&gt; str:\n    \"\"\"\u4f7f\u7528 JSON Schema \u5b9a\u4e49\u83b7\u53d6\u5929\u6c14\u4fe1\u606f\u3002\"\"\"\n    temp = 22 if units == \"celsius\" else 72\n    result = f\"{location}\u5f53\u524d\u5929\u6c14: {temp}\u5ea6 {units}\"\n\n    if include_forecast:\n        result += f\"\\n\u672a\u6765{forecast_days}\u5929\u9884\u62a5: \u6674\u6717\"\n\n    return result\n</code></pre>"},{"location":"llmapps/langchain/core-components/tools/#_6","title":"\u8bbf\u95ee\u4e0a\u4e0b\u6587","text":"<p>Tools \u6700\u5f3a\u5927\u7684\u529f\u80fd\u662f\u80fd\u591f\u8bbf\u95ee Agent \u72b6\u6001\u3001\u8fd0\u884c\u65f6\u4e0a\u4e0b\u6587\u548c\u957f\u671f\u8bb0\u5fc6\uff0c\u4ece\u800c\u5b9e\u73b0\u4e0a\u4e0b\u6587\u611f\u77e5\u51b3\u7b56\u548c\u4e2a\u6027\u5316\u54cd\u5e94\u3002</p>"},{"location":"llmapps/langchain/core-components/tools/#toolruntime","title":"ToolRuntime \u6982\u8ff0","text":"<p><code>ToolRuntime</code> \u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u53c2\u6570\uff0c\u63d0\u4f9b\u5de5\u5177\u8bbf\u95ee\u4ee5\u4e0b\u4fe1\u606f\u7684\u80fd\u529b\uff1a</p> <ul> <li>State\uff1a\u6267\u884c\u8fc7\u7a0b\u4e2d\u7684\u53ef\u53d8\u6570\u636e\uff08\u6d88\u606f\u3001\u8ba1\u6570\u5668\u3001\u81ea\u5b9a\u4e49\u5b57\u6bb5\uff09</li> <li>Context\uff1a\u4e0d\u53ef\u53d8\u914d\u7f6e\uff08\u7528\u6237 ID\u3001\u4f1a\u8bdd\u8be6\u60c5\u3001\u5e94\u7528\u7279\u5b9a\u914d\u7f6e\uff09</li> <li>Store\uff1a\u8de8\u5bf9\u8bdd\u7684\u6301\u4e45\u957f\u671f\u8bb0\u5fc6</li> <li>Stream Writer\uff1a\u5de5\u5177\u6267\u884c\u65f6\u6d41\u5f0f\u4f20\u8f93\u81ea\u5b9a\u4e49\u66f4\u65b0</li> <li>Config\uff1a\u6267\u884c\u7684 RunnableConfig</li> <li>Tool Call ID\uff1a\u5f53\u524d\u5de5\u5177\u8c03\u7528\u7684 ID</li> </ul>"},{"location":"llmapps/langchain/core-components/tools/#state","title":"\u8bbf\u95ee\u72b6\u6001\uff08State\uff09","text":"<pre><code>from langchain.tools import tool, ToolRuntime\n\n@tool\ndef analyze_conversation(runtime: ToolRuntime) -&gt; str:\n    \"\"\"\u5206\u6790\u5f53\u524d\u5bf9\u8bdd\u72b6\u6001\u3002\"\"\"\n    messages = runtime.state[\"messages\"]\n\n    # \u7edf\u8ba1\u4e0d\u540c\u7c7b\u578b\u7684\u6d88\u606f\n    human_count = sum(1 for m in messages if m.type == \"human\")\n    ai_count = sum(1 for m in messages if m.type == \"ai\")\n    tool_count = sum(1 for m in messages if m.type == \"tool\")\n\n    return f\"\u5bf9\u8bdd\u7edf\u8ba1: {human_count}\u6761\u7528\u6237\u6d88\u606f, {ai_count}\u6761AI\u56de\u590d, {tool_count}\u6761\u5de5\u5177\u7ed3\u679c\"\n\n@tool\ndef get_user_preference(pref_name: str, runtime: ToolRuntime) -&gt; str:\n    \"\"\"\u83b7\u53d6\u7528\u6237\u504f\u597d\u8bbe\u7f6e\u3002\"\"\"\n    preferences = runtime.state.get(\"user_preferences\", {})\n    return preferences.get(pref_name, \"\u672a\u8bbe\u7f6e\")\n</code></pre> <p>\u91cd\u8981\u63d0\u793a\uff1a<code>runtime</code> \u53c2\u6570\u5bf9\u6a21\u578b\u4e0d\u53ef\u89c1\uff0c\u6a21\u578b\u53ea\u80fd\u770b\u5230\u5176\u4ed6\u53c2\u6570\u3002</p>"},{"location":"llmapps/langchain/core-components/tools/#command","title":"\u66f4\u65b0\u72b6\u6001\uff08\u4f7f\u7528 Command\uff09","text":"<pre><code>from langgraph.types import Command\nfrom langchain.messages import RemoveMessage\nfrom langgraph.graph.message import REMOVE_ALL_MESSAGES\n\n@tool\ndef clear_conversation(runtime: ToolRuntime) -&gt; Command:\n    \"\"\"\u6e05\u9664\u5bf9\u8bdd\u5386\u53f2\u3002\"\"\"\n    return Command(\n        update={\n            \"messages\": [RemoveMessage(id=REMOVE_ALL_MESSAGES)],\n        }\n    )\n\n@tool\ndef update_user_profile(name: str, age: int, runtime: ToolRuntime) -&gt; Command:\n    \"\"\"\u66f4\u65b0\u7528\u6237\u6863\u6848\u3002\"\"\"\n    return Command(\n        update={\n            \"user_profile\": {\n                \"name\": name,\n                \"age\": age,\n                \"updated_at\": \"2024-01-01\"\n            }\n        }\n    )\n</code></pre>"},{"location":"llmapps/langchain/core-components/tools/#context","title":"\u8bbf\u95ee\u4e0a\u4e0b\u6587\uff08Context\uff09","text":"<pre><code>from dataclasses import dataclass\nfrom langchain.agents import create_agent\nfrom langchain.tools import tool, ToolRuntime\n\n# \u6a21\u62df\u7528\u6237\u6570\u636e\u5e93\nUSER_DATABASE = {\n    \"user123\": {\n        \"name\": \"\u5f20\u4e09\",\n        \"account_type\": \"\u9ad8\u7ea7\u4f1a\u5458\",\n        \"balance\": 5000,\n        \"email\": \"zhangsan@example.com\"\n    },\n    \"user456\": {\n        \"name\": \"\u674e\u56db\",\n        \"account_type\": \"\u6807\u51c6\u4f1a\u5458\",\n        \"balance\": 1200,\n        \"email\": \"lisi@example.com\"\n    }\n}\n\n@dataclass\nclass UserContext:\n    user_id: str\n\n@tool\ndef get_account_info(runtime: ToolRuntime[UserContext]) -&gt; str:\n    \"\"\"\u83b7\u53d6\u5f53\u524d\u7528\u6237\u7684\u8d26\u6237\u4fe1\u606f\u3002\"\"\"\n    user_id = runtime.context.user_id\n\n    if user_id in USER_DATABASE:\n        user = USER_DATABASE[user_id]\n        return f\"\"\"\n        \u8d26\u6237\u4fe1\u606f:\n        - \u59d3\u540d: {user['name']}\n        - \u8d26\u6237\u7c7b\u578b: {user['account_type']}\n        - \u4f59\u989d: \u00a5{user['balance']}\n        - \u90ae\u7bb1: {user['email']}\n        \"\"\"\n    return \"\u7528\u6237\u672a\u627e\u5230\"\n\n@tool\ndef transfer_funds(amount: float, to_user: str, runtime: ToolRuntime[UserContext]) -&gt; str:\n    \"\"\"\u8f6c\u8d26\u5230\u5176\u4ed6\u7528\u6237\u3002\"\"\"\n    from_user_id = runtime.context.user_id\n\n    if from_user_id not in USER_DATABASE or to_user not in USER_DATABASE:\n        return \"\u7528\u6237\u4e0d\u5b58\u5728\"\n\n    from_user = USER_DATABASE[from_user_id]\n    to_user_info = USER_DATABASE[to_user]\n\n    if from_user[\"balance\"] &lt; amount:\n        return \"\u4f59\u989d\u4e0d\u8db3\"\n\n    # \u6a21\u62df\u8f6c\u8d26\u64cd\u4f5c\n    from_user[\"balance\"] -= amount\n    to_user_info[\"balance\"] += amount\n\n    return f\"\u6210\u529f\u8f6c\u8d26 \u00a5{amount} \u7ed9 {to_user_info['name']}\"\n\n# \u521b\u5efa\u4f7f\u7528\u4e0a\u4e0b\u6587\u7684 Agent\nagent = create_agent(\n    model=\"openai:gpt-4o\",\n    tools=[get_account_info, transfer_funds],\n    context_schema=UserContext,\n    system_prompt=\"\u4f60\u662f\u4e00\u4e2a\u91d1\u878d\u52a9\u624b\u3002\"\n)\n\n# \u4f7f\u7528\u4e0a\u4e0b\u6587\u8c03\u7528\nresult = agent.invoke(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"\u67e5\u770b\u6211\u7684\u8d26\u6237\u4f59\u989d\"}]},\n    context=UserContext(user_id=\"user123\")\n)\n</code></pre>"},{"location":"llmapps/langchain/core-components/tools/#store-","title":"\u8bbf\u95ee\u5b58\u50a8\uff08Store\uff09- \u957f\u671f\u8bb0\u5fc6","text":"<pre><code>from typing import Any\nfrom langgraph.store.memory import InMemoryStore\nfrom langchain.agents import create_agent\nfrom langchain.tools import tool, ToolRuntime\n\n@tool\ndef save_user_preferences(user_id: str, preferences: dict, runtime: ToolRuntime) -&gt; str:\n    \"\"\"\u4fdd\u5b58\u7528\u6237\u504f\u597d\u8bbe\u7f6e\u5230\u957f\u671f\u5b58\u50a8\u3002\"\"\"\n    store = runtime.store\n    store.put((\"user_preferences\",), user_id, preferences)\n    return \"\u7528\u6237\u504f\u597d\u8bbe\u7f6e\u5df2\u4fdd\u5b58\"\n\n@tool\ndef get_user_preferences(user_id: str, runtime: ToolRuntime) -&gt; str:\n    \"\"\"\u4ece\u957f\u671f\u5b58\u50a8\u83b7\u53d6\u7528\u6237\u504f\u597d\u8bbe\u7f6e\u3002\"\"\"\n    store = runtime.store\n    preferences = store.get((\"user_preferences\",), user_id)\n\n    if preferences and preferences.value:\n        prefs = preferences.value\n        return f\"\u7528\u6237 {user_id} \u7684\u504f\u597d\u8bbe\u7f6e: {prefs}\"\n    else:\n        return f\"\u672a\u627e\u5230\u7528\u6237 {user_id} \u7684\u504f\u597d\u8bbe\u7f6e\"\n\n@tool\ndef save_conversation_summary(conversation_id: str, summary: str, runtime: ToolRuntime) -&gt; str:\n    \"\"\"\u4fdd\u5b58\u5bf9\u8bdd\u603b\u7ed3\u5230\u957f\u671f\u5b58\u50a8\u3002\"\"\"\n    store = runtime.store\n    store.put((\"conversations\",), conversation_id, {\n        \"summary\": summary,\n        \"timestamp\": \"2024-01-01T10:00:00\"\n    })\n    return \"\u5bf9\u8bdd\u603b\u7ed3\u5df2\u4fdd\u5b58\"\n\n# \u521b\u5efa\u4f7f\u7528\u5b58\u50a8\u7684 Agent\nstore = InMemoryStore()\nagent = create_agent(\n    model=\"openai:gpt-4o\",\n    tools=[save_user_preferences, get_user_preferences, save_conversation_summary],\n    store=store\n)\n\n# \u7b2c\u4e00\u6b21\u4f1a\u8bdd\uff1a\u4fdd\u5b58\u7528\u6237\u504f\u597d\nagent.invoke({\n    \"messages\": [{\n        \"role\": \"user\", \n        \"content\": \"\u4fdd\u5b58\u7528\u6237123\u7684\u504f\u597d\uff1a\u8bed\u8a00=\u4e2d\u6587\uff0c\u4e3b\u9898=\u6df1\u8272\uff0c\u901a\u77e5=\u5f00\u542f\"\n    }]\n})\n\n# \u540e\u7eed\u4f1a\u8bdd\uff1a\u83b7\u53d6\u7528\u6237\u504f\u597d\nagent.invoke({\n    \"messages\": [{\n        \"role\": \"user\", \n        \"content\": \"\u83b7\u53d6\u7528\u6237123\u7684\u504f\u597d\u8bbe\u7f6e\"\n    }]\n})\n</code></pre>"},{"location":"llmapps/langchain/core-components/tools/#stream-writer","title":"\u4f7f\u7528\u6d41\u5199\u5165\u5668\uff08Stream Writer\uff09","text":"<pre><code>from langchain.tools import tool, ToolRuntime\nimport time\n\n@tool\ndef process_large_data(data_source: str, runtime: ToolRuntime) -&gt; str:\n    \"\"\"\u5904\u7406\u5927\u578b\u6570\u636e\u96c6\u7684\u5de5\u5177\uff0c\u5e26\u8fdb\u5ea6\u53cd\u9988\u3002\"\"\"\n    writer = runtime.stream_writer\n\n    writer(f\"\ud83d\udd04 \u5f00\u59cb\u5904\u7406\u6570\u636e\u6e90: {data_source}\")\n    writer(\"\ud83d\udcca \u8fde\u63a5\u6570\u636e\u6e90...\")\n    time.sleep(0.5)\n\n    writer(\"\ud83d\udd0d \u8bfb\u53d6\u6570\u636e...\")\n    time.sleep(1)\n\n    # \u6a21\u62df\u5904\u7406\u6b65\u9aa4\n    steps = [\"\u6570\u636e\u6e05\u6d17\", \"\u7279\u5f81\u63d0\u53d6\", \"\u6a21\u578b\u8bad\u7ec3\", \"\u7ed3\u679c\u5206\u6790\"]\n    for i, step in enumerate(steps, 1):\n        writer(f\"\u23f3 \u6b65\u9aa4 {i}/{len(steps)}: {step}\")\n        time.sleep(0.8)\n\n    writer(\"\u2705 \u6570\u636e\u5904\u7406\u5b8c\u6210\")\n    return f\"\u6210\u529f\u5904\u7406 {data_source}\uff0c\u751f\u6210\u5206\u6790\u62a5\u544a\"\n\n@tool\ndef search_with_progress(query: str, runtime: ToolRuntime) -&gt; str:\n    \"\"\"\u5e26\u8fdb\u5ea6\u53cd\u9988\u7684\u641c\u7d22\u5de5\u5177\u3002\"\"\"\n    writer = runtime.stream_writer\n\n    writer(f\"\ud83d\udd0d \u5f00\u59cb\u641c\u7d22: {query}\")\n    writer(\"\ud83c\udf10 \u8fde\u63a5\u641c\u7d22\u5f15\u64ce...\")\n    time.sleep(0.3)\n\n    writer(\"\ud83d\udce1 \u53d1\u9001\u641c\u7d22\u8bf7\u6c42...\")\n    time.sleep(0.5)\n\n    writer(\"\ud83d\udcc4 \u89e3\u6790\u641c\u7d22\u7ed3\u679c...\")\n    time.sleep(0.7)\n\n    writer(\"\u2705 \u641c\u7d22\u5b8c\u6210\")\n    return f\"\u627e\u5230\u5173\u4e8e '{query}' \u7684 15 \u4e2a\u76f8\u5173\u7ed3\u679c\"\n</code></pre>"},{"location":"llmapps/langchain/core-components/tools/#_7","title":"\u5b9e\u9645\u5e94\u7528\u573a\u666f","text":""},{"location":"llmapps/langchain/core-components/tools/#1_1","title":"\u573a\u666f1\uff1a\u7535\u5546\u5ba2\u670d\u7cfb\u7edf","text":"<pre><code>from datetime import datetime\nfrom typing import Dict, List\nfrom langchain.tools import tool, ToolRuntime\n\nclass EcommerceTools:\n    \"\"\"\u7535\u5546\u5ba2\u670d\u5de5\u5177\u96c6\"\"\"\n\n    @staticmethod\n    @tool\n    def check_order_status(order_id: str, runtime: ToolRuntime) -&gt; str:\n        \"\"\"\u68c0\u67e5\u8ba2\u5355\u72b6\u6001\u3002\"\"\"\n        # \u6a21\u62df\u8ba2\u5355\u6570\u636e\u5e93\n        orders = {\n            \"ORD001\": {\"status\": \"\u5df2\u53d1\u8d27\", \"tracking\": \"SF123456789\", \"items\": [\"\u5546\u54c1A\", \"\u5546\u54c1B\"]},\n            \"ORD002\": {\"status\": \"\u5904\u7406\u4e2d\", \"tracking\": None, \"items\": [\"\u5546\u54c1C\"]},\n            \"ORD003\": {\"status\": \"\u5df2\u9001\u8fbe\", \"tracking\": \"SF987654321\", \"items\": [\"\u5546\u54c1D\"]}\n        }\n\n        if order_id in orders:\n            order = orders[order_id]\n            result = f\"\u8ba2\u5355 {order_id} \u72b6\u6001: {order['status']}\"\n            if order['tracking']:\n                result += f\"\\n\u7269\u6d41\u5355\u53f7: {order['tracking']}\"\n            result += f\"\\n\u5546\u54c1: {', '.join(order['items'])}\"\n            return result\n        else:\n            return f\"\u672a\u627e\u5230\u8ba2\u5355 {order_id}\"\n\n    @staticmethod\n    @tool\n    def get_product_info(product_id: str, runtime: ToolRuntime) -&gt; str:\n        \"\"\"\u83b7\u53d6\u5546\u54c1\u4fe1\u606f\u3002\"\"\"\n        products = {\n            \"P001\": {\"name\": \"\u667a\u80fd\u624b\u673a\", \"price\": 2999, \"stock\": 50, \"description\": \"\u6700\u65b0\u6b3e\u667a\u80fd\u624b\u673a\"},\n            \"P002\": {\"name\": \"\u7b14\u8bb0\u672c\u7535\u8111\", \"price\": 5999, \"stock\": 25, \"description\": \"\u9ad8\u6027\u80fd\u7b14\u8bb0\u672c\u7535\u8111\"},\n            \"P003\": {\"name\": \"\u65e0\u7ebf\u8033\u673a\", \"price\": 399, \"stock\": 100, \"description\": \"\u964d\u566a\u65e0\u7ebf\u8033\u673a\"}\n        }\n\n        if product_id in products:\n            product = products[product_id]\n            return f\"\"\"\n            {product['name']}\n            - \u4ef7\u683c: \u00a5{product['price']}\n            - \u5e93\u5b58: {product['stock']}\u4ef6\n            - \u63cf\u8ff0: {product['description']}\n            \"\"\"\n        else:\n            return f\"\u672a\u627e\u5230\u5546\u54c1 {product_id}\"\n\n    @staticmethod\n    @tool\n    def process_return(request_id: str, reason: str, runtime: ToolRuntime) -&gt; Command:\n        \"\"\"\u5904\u7406\u9000\u8d27\u7533\u8bf7\u3002\"\"\"\n        from langgraph.types import Command\n\n        # \u6a21\u62df\u5904\u7406\u9000\u8d27\n        return_info = {\n            \"request_id\": request_id,\n            \"reason\": reason,\n            \"status\": \"\u5904\u7406\u4e2d\",\n            \"processed_at\": datetime.now().isoformat()\n        }\n\n        return Command(\n            update={\n                \"return_requests\": runtime.state.get(\"return_requests\", []) + [return_info]\n            }\n        )\n\n# \u521b\u5efa\u7535\u5546\u5ba2\u670d Agent\necommerce_agent = create_agent(\n    model=\"openai:gpt-4o\",\n    tools=[\n        EcommerceTools.check_order_status,\n        EcommerceTools.get_product_info,\n        EcommerceTools.process_return\n    ],\n    system_prompt=\"\u4f60\u662f\u4e00\u4e2a\u4e13\u4e1a\u7684\u7535\u5546\u5ba2\u670d\u52a9\u624b\u3002\"\n)\n</code></pre>"},{"location":"llmapps/langchain/core-components/tools/#2_1","title":"\u573a\u666f2\uff1a\u667a\u80fd\u6570\u636e\u5206\u6790\u5de5\u5177","text":"<pre><code>import pandas as pd\nimport numpy as np\nfrom io import StringIO\nfrom langchain.tools import tool, ToolRuntime\n\nclass DataAnalysisTools:\n    \"\"\"\u6570\u636e\u5206\u6790\u5de5\u5177\u96c6\"\"\"\n\n    @staticmethod\n    @tool\n    def load_csv_data(csv_content: str, runtime: ToolRuntime) -&gt; Command:\n        \"\"\"\u52a0\u8f7d CSV \u6570\u636e\u5230\u5206\u6790\u73af\u5883\u3002\"\"\"\n        from langgraph.types import Command\n\n        try:\n            # \u4ece CSV \u5b57\u7b26\u4e32\u521b\u5efa DataFrame\n            df = pd.read_csv(StringIO(csv_content))\n\n            # \u8fd4\u56de\u6570\u636e\u7edf\u8ba1\u4fe1\u606f\n            stats = {\n                \"rows\": len(df),\n                \"columns\": len(df.columns),\n                \"columns_list\": list(df.columns),\n                \"memory_usage\": df.memory_usage(deep=True).sum()\n            }\n\n            return Command(\n                update={\n                    \"current_dataset\": df.to_dict(),\n                    \"dataset_stats\": stats\n                }\n            )\n        except Exception as e:\n            return f\"\u52a0\u8f7d\u6570\u636e\u5931\u8d25: {str(e)}\"\n\n    @staticmethod\n    @tool\n    def describe_dataset(runtime: ToolRuntime) -&gt; str:\n        \"\"\"\u63cf\u8ff0\u5f53\u524d\u6570\u636e\u96c6\u7684\u57fa\u672c\u4fe1\u606f\u3002\"\"\"\n        stats = runtime.state.get(\"dataset_stats\", {})\n\n        if not stats:\n            return \"\u6ca1\u6709\u52a0\u8f7d\u7684\u6570\u636e\u96c6\"\n\n        return f\"\"\"\n        \u6570\u636e\u96c6\u4fe1\u606f:\n        - \u884c\u6570: {stats['rows']}\n        - \u5217\u6570: {stats['columns']}\n        - \u5217\u540d: {', '.join(stats['columns_list'])}\n        - \u5185\u5b58\u4f7f\u7528: {stats['memory_usage']} \u5b57\u8282\n        \"\"\"\n\n    @staticmethod\n    @tool\n    def calculate_statistics(column: str, runtime: ToolRuntime) -&gt; str:\n        \"\"\"\u8ba1\u7b97\u6307\u5b9a\u5217\u7684\u7edf\u8ba1\u4fe1\u606f\u3002\"\"\"\n        dataset = runtime.state.get(\"current_dataset\", {})\n\n        if not dataset:\n            return \"\u6ca1\u6709\u52a0\u8f7d\u7684\u6570\u636e\u96c6\"\n\n        try:\n            df = pd.DataFrame(dataset)\n\n            if column not in df.columns:\n                return f\"\u5217 '{column}' \u4e0d\u5b58\u5728\"\n\n            series = df[column]\n            stats = {\n                \"count\": len(series),\n                \"mean\": series.mean(),\n                \"std\": series.std(),\n                \"min\": series.min(),\n                \"max\": series.max(),\n                \"null_count\": series.isnull().sum()\n            }\n\n            return f\"\"\"\n            {column} \u5217\u7edf\u8ba1\u4fe1\u606f:\n            - \u6570\u91cf: {stats['count']}\n            - \u5e73\u5747\u503c: {stats['mean']:.2f}\n            - \u6807\u51c6\u5dee: {stats['std']:.2f}\n            - \u6700\u5c0f\u503c: {stats['min']}\n            - \u6700\u5927\u503c: {stats['max']}\n            - \u7a7a\u503c\u6570\u91cf: {stats['null_count']}\n            \"\"\"\n        except Exception as e:\n            return f\"\u8ba1\u7b97\u7edf\u8ba1\u4fe1\u606f\u5931\u8d25: {str(e)}\"\n\n# \u521b\u5efa\u6570\u636e\u5206\u6790 Agent\ndata_analysis_agent = create_agent(\n    model=\"openai:gpt-4o\",\n    tools=[\n        DataAnalysisTools.load_csv_data,\n        DataAnalysisTools.describe_dataset,\n        DataAnalysisTools.calculate_statistics\n    ],\n    system_prompt=\"\u4f60\u662f\u4e00\u4e2a\u6570\u636e\u5206\u6790\u52a9\u624b\uff0c\u5e2e\u52a9\u7528\u6237\u5206\u6790\u548c\u7406\u89e3\u6570\u636e\u3002\"\n)\n</code></pre>"},{"location":"llmapps/langchain/core-components/tools/#3_1","title":"\u573a\u666f3\uff1a\u9879\u76ee\u7ba1\u7406\u5de5\u5177","text":"<pre><code>from typing import List, Dict\nfrom datetime import datetime, timedelta\nfrom langchain.tools import tool, ToolRuntime\n\nclass ProjectManagementTools:\n    \"\"\"\u9879\u76ee\u7ba1\u7406\u5de5\u5177\u96c6\"\"\"\n\n    @staticmethod\n    @tool\n    def create_task(title: str, description: str, assignee: str, due_date: str, runtime: ToolRuntime) -&gt; Command:\n        \"\"\"\u521b\u5efa\u65b0\u4efb\u52a1\u3002\"\"\"\n        from langgraph.types import Command\n\n        task = {\n            \"id\": f\"TASK_{datetime.now().strftime('%Y%m%d_%H%M%S')}\",\n            \"title\": title,\n            \"description\": description,\n            \"assignee\": assignee,\n            \"due_date\": due_date,\n            \"status\": \"\u5f85\u5f00\u59cb\",\n            \"created_at\": datetime.now().isoformat()\n        }\n\n        return Command(\n            update={\n                \"project_tasks\": runtime.state.get(\"project_tasks\", []) + [task]\n            }\n        )\n\n    @staticmethod\n    @tool\n    def update_task_status(task_id: str, new_status: str, runtime: ToolRuntime) -&gt; Command:\n        \"\"\"\u66f4\u65b0\u4efb\u52a1\u72b6\u6001\u3002\"\"\"\n        from langgraph.types import Command\n\n        tasks = runtime.state.get(\"project_tasks\", [])\n        updated_tasks = []\n        task_found = False\n\n        for task in tasks:\n            if task[\"id\"] == task_id:\n                task[\"status\"] = new_status\n                task[\"updated_at\"] = datetime.now().isoformat()\n                task_found = True\n            updated_tasks.append(task)\n\n        if task_found:\n            return Command(update={\"project_tasks\": updated_tasks})\n        else:\n            return f\"\u672a\u627e\u5230\u4efb\u52a1 {task_id}\"\n\n    @staticmethod\n    @tool\n    def get_project_progress(runtime: ToolRuntime) -&gt; str:\n        \"\"\"\u83b7\u53d6\u9879\u76ee\u8fdb\u5ea6\u6982\u89c8\u3002\"\"\"\n        tasks = runtime.state.get(\"project_tasks\", [])\n\n        if not tasks:\n            return \"\u9879\u76ee\u4e2d\u6ca1\u6709\u4efb\u52a1\"\n\n        status_count = {}\n        for task in tasks:\n            status = task[\"status\"]\n            status_count[status] = status_count.get(status, 0) + 1\n\n        total_tasks = len(tasks)\n        completed_tasks = status_count.get(\"\u5df2\u5b8c\u6210\", 0)\n        progress_percentage = (completed_tasks / total_tasks) * 100\n\n        return f\"\"\"\n        \u9879\u76ee\u8fdb\u5ea6\u6982\u89c8:\n        - \u603b\u4efb\u52a1\u6570: {total_tasks}\n        - \u5df2\u5b8c\u6210: {completed_tasks}\n        - \u8fdb\u884c\u4e2d: {status_count.get('\u8fdb\u884c\u4e2d', 0)}\n        - \u5f85\u5f00\u59cb: {status_count.get('\u5f85\u5f00\u59cb', 0)}\n        - \u603b\u4f53\u8fdb\u5ea6: {progress_percentage:.1f}%\n        \"\"\"\n\n    @staticmethod\n    @tool\n    def assign_task(task_id: str, new_assignee: str, runtime: ToolRuntime) -&gt; Command:\n        \"\"\"\u91cd\u65b0\u5206\u914d\u4efb\u52a1\u3002\"\"\"\n        from langgraph.types import Command\n\n        tasks = runtime.state.get(\"project_tasks\", [])\n        updated_tasks = []\n        task_found = False\n\n        for task in tasks:\n            if task[\"id\"] == task_id:\n                old_assignee = task[\"assignee\"]\n                task[\"assignee\"] = new_assignee\n                task[\"updated_at\"] = datetime.now().isoformat()\n                task_found = True\n            updated_tasks.append(task)\n\n        if task_found:\n            return Command(\n                update={\n                    \"project_tasks\": updated_tasks\n                }\n            )\n        else:\n            return f\"\u672a\u627e\u5230\u4efb\u52a1 {task_id}\"\n\n# \u521b\u5efa\u9879\u76ee\u7ba1\u7406 Agent\nproject_agent = create_agent(\n    model=\"openai:gpt-4o\",\n    tools=[\n        ProjectManagementTools.create_task,\n        ProjectManagementTools.update_task_status,\n        ProjectManagementTools.get_project_progress,\n        ProjectManagementTools.assign_task\n    ],\n    system_prompt=\"\u4f60\u662f\u4e00\u4e2a\u9879\u76ee\u7ba1\u7406\u52a9\u624b\uff0c\u5e2e\u52a9\u56e2\u961f\u7ba1\u7406\u4efb\u52a1\u548c\u8ddf\u8e2a\u8fdb\u5ea6\u3002\"\n)\n</code></pre>"},{"location":"llmapps/langchain/core-components/tools/#_8","title":"\u6700\u4f73\u5b9e\u8df5","text":""},{"location":"llmapps/langchain/core-components/tools/#1_2","title":"1. \u5de5\u5177\u8bbe\u8ba1\u539f\u5219","text":"<pre><code>from pydantic import BaseModel, Field\nfrom typing import Optional\n\nclass WellDesignedTool:\n    \"\"\"\u826f\u597d\u8bbe\u8ba1\u7684\u5de5\u5177\u793a\u4f8b\"\"\"\n\n    @staticmethod\n    @tool\n    def search_products(\n        query: str,\n        category: Optional[str] = None,\n        price_range: Optional[str] = None,\n        sort_by: str = \"relevance\",\n        runtime: ToolRuntime\n    ) -&gt; str:\n        \"\"\"\u641c\u7d22\u4ea7\u54c1\u4fe1\u606f\u3002\n\n        Args:\n            query: \u641c\u7d22\u5173\u952e\u8bcd\uff08\u5fc5\u9700\uff09\n            category: \u4ea7\u54c1\u7c7b\u522b\u7b5b\u9009\uff08\u53ef\u9009\uff09\n            price_range: \u4ef7\u683c\u8303\u56f4\u7b5b\u9009\uff0c\u5982 \"100-500\"\uff08\u53ef\u9009\uff09\n            sort_by: \u6392\u5e8f\u65b9\u5f0f\uff1arelevance\uff08\u76f8\u5173\u5ea6\uff09\u3001price_asc\uff08\u4ef7\u683c\u5347\u5e8f\uff09\u3001price_desc\uff08\u4ef7\u683c\u964d\u5e8f\uff09\n        \"\"\"\n        # \u6e05\u6670\u7684\u53c2\u6570\u8bf4\u660e\n        # \u5408\u7406\u7684\u9ed8\u8ba4\u503c\n        # \u5b8c\u6574\u7684\u9519\u8bef\u5904\u7406\n\n        writer = runtime.stream_writer\n        writer(f\"\ud83d\udd0d \u641c\u7d22\u4ea7\u54c1: {query}\")\n\n        if category:\n            writer(f\"\ud83d\udcc1 \u7b5b\u9009\u7c7b\u522b: {category}\")\n        if price_range:\n            writer(f\"\ud83d\udcb0 \u4ef7\u683c\u8303\u56f4: {price_range}\")\n\n        # \u6a21\u62df\u641c\u7d22\u903b\u8f91\n        writer(\"\ud83d\udcca \u83b7\u53d6\u641c\u7d22\u7ed3\u679c...\")\n\n        return f\"\u627e\u5230 15 \u4e2a\u5339\u914d '{query}' \u7684\u4ea7\u54c1\"\n</code></pre>"},{"location":"llmapps/langchain/core-components/tools/#2_2","title":"2. \u9519\u8bef\u5904\u7406","text":"<pre><code>from langchain.tools import tool, ToolRuntime\n\nclass RobustTools:\n    \"\"\"\u5065\u58ee\u7684\u5de5\u5177\u8bbe\u8ba1\"\"\"\n\n    @staticmethod\n    @tool\n    def safe_api_call(api_endpoint: str, params: dict, runtime: ToolRuntime) -&gt; str:\n        \"\"\"\u5b89\u5168\u7684 API \u8c03\u7528\u5de5\u5177\u3002\"\"\"\n        import requests\n        import time\n\n        writer = runtime.stream_writer\n        writer(f\"\ud83c\udf10 \u8c03\u7528 API: {api_endpoint}\")\n\n        max_retries = 3\n        for attempt in range(max_retries):\n            try:\n                response = requests.get(api_endpoint, params=params, timeout=10)\n                response.raise_for_status()\n                return f\"API \u8c03\u7528\u6210\u529f: {response.json()}\"\n\n            except requests.exceptions.Timeout:\n                writer(f\"\u23f0 \u8bf7\u6c42\u8d85\u65f6 (\u5c1d\u8bd5 {attempt + 1}/{max_retries})\")\n                if attempt == max_retries - 1:\n                    return \"\u9519\u8bef: API \u8bf7\u6c42\u8d85\u65f6\"\n                time.sleep(1)\n\n            except requests.exceptions.RequestException as e:\n                return f\"API \u8c03\u7528\u9519\u8bef: {str(e)}\"\n\n    @staticmethod\n    @tool\n    def validate_and_process_data(data: str, runtime: ToolRuntime) -&gt; str:\n        \"\"\"\u9a8c\u8bc1\u548c\u5904\u7406\u6570\u636e\u3002\"\"\"\n        writer = runtime.stream_writer\n\n        # \u6570\u636e\u9a8c\u8bc1\n        if not data or not data.strip():\n            return \"\u9519\u8bef: \u6570\u636e\u4e0d\u80fd\u4e3a\u7a7a\"\n\n        writer(\"\u2705 \u6570\u636e\u9a8c\u8bc1\u901a\u8fc7\")\n        writer(\"\ud83d\udd04 \u5904\u7406\u6570\u636e...\")\n\n        try:\n            # \u6a21\u62df\u6570\u636e\u5904\u7406\n            processed = data.upper()\n            return f\"\u5904\u7406\u540e\u7684\u6570\u636e: {processed}\"\n        except Exception as e:\n            return f\"\u6570\u636e\u5904\u7406\u9519\u8bef: {str(e)}\"\n</code></pre>"},{"location":"llmapps/langchain/core-components/tools/#3_2","title":"3. \u6027\u80fd\u4f18\u5316","text":"<pre><code>from langchain.tools import tool, ToolRuntime\nimport functools\n\nclass OptimizedTools:\n    \"\"\"\u6027\u80fd\u4f18\u5316\u7684\u5de5\u5177\"\"\"\n\n    # \u4f7f\u7528\u7f13\u5b58\u907f\u514d\u91cd\u590d\u8ba1\u7b97\n    @functools.lru_cache(maxsize=100)\n    def _expensive_calculation(self, input_data: str) -&gt; str:\n        \"\"\"\u6a21\u62df\u6602\u8d35\u7684\u8ba1\u7b97\u3002\"\"\"\n        # \u6a21\u62df\u590d\u6742\u8ba1\u7b97\n        return f\"\u8ba1\u7b97\u7ed3\u679c: {input_data.upper()}\"\n\n    @tool\n    def cached_calculation(self, input_data: str, runtime: ToolRuntime) -&gt; str:\n        \"\"\"\u4f7f\u7528\u7f13\u5b58\u7684\u6602\u8d35\u8ba1\u7b97\u3002\"\"\"\n        writer = runtime.stream_writer\n        writer(\"\u26a1 \u4f7f\u7528\u7f13\u5b58\u8ba1\u7b97...\")\n\n        return self._expensive_calculation(input_data)\n\n    @tool\n    def batch_processing(self, items: list, runtime: ToolRuntime) -&gt; str:\n        \"\"\"\u6279\u91cf\u5904\u7406\u5de5\u5177\u3002\"\"\"\n        writer = runtime.stream_writer\n\n        writer(f\"\ud83d\udce6 \u5f00\u59cb\u6279\u91cf\u5904\u7406 {len(items)} \u4e2a\u9879\u76ee\")\n\n        results = []\n        batch_size = 5\n\n        for i in range(0, len(items), batch_size):\n            batch = items[i:i + batch_size]\n            writer(f\"\u5904\u7406\u6279\u6b21 {i//batch_size + 1}/{(len(items)-1)//batch_size + 1}\")\n\n            # \u6a21\u62df\u6279\u91cf\u5904\u7406\n            batch_results = [f\"\u5904\u7406: {item}\" for item in batch]\n            results.extend(batch_results)\n\n        writer(\"\u2705 \u6279\u91cf\u5904\u7406\u5b8c\u6210\")\n        return f\"\u6210\u529f\u5904\u7406 {len(results)} \u4e2a\u9879\u76ee\"\n</code></pre>"},{"location":"llmapps/langchain/core-components/tools/#_9","title":"\u603b\u7ed3","text":"<p>LangChain Tools \u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u80fd\u529b\u6765\u6269\u5c55 AI Agent \u7684\u529f\u80fd\uff1a</p> <ul> <li>\u7b80\u5355\u521b\u5efa\uff1a\u4f7f\u7528 <code>@tool</code> \u88c5\u9970\u5668\u5feb\u901f\u5b9a\u4e49\u5de5\u5177</li> <li>\u7075\u6d3b\u5b9a\u5236\uff1a\u652f\u6301\u81ea\u5b9a\u4e49\u540d\u79f0\u3001\u63cf\u8ff0\u548c\u590d\u6742\u8f93\u5165\u6a21\u5f0f</li> <li>\u4e0a\u4e0b\u6587\u611f\u77e5\uff1a\u901a\u8fc7 <code>ToolRuntime</code> \u8bbf\u95ee\u72b6\u6001\u3001\u4e0a\u4e0b\u6587\u3001\u5b58\u50a8\u7b49</li> <li>\u5b9e\u65f6\u53cd\u9988\uff1a\u4f7f\u7528\u6d41\u5199\u5165\u5668\u63d0\u4f9b\u6267\u884c\u8fdb\u5ea6</li> <li>\u751f\u4ea7\u5c31\u7eea\uff1a\u5305\u542b\u9519\u8bef\u5904\u7406\u3001\u6027\u80fd\u4f18\u5316\u7b49\u6700\u4f73\u5b9e\u8df5</li> </ul> <p>\u901a\u8fc7\u5408\u7406\u8bbe\u8ba1\u548c\u4f7f\u7528 Tools\uff0c\u53ef\u4ee5\u6784\u5efa\u51fa\u80fd\u591f\u4e0e\u5404\u79cd\u5916\u90e8\u7cfb\u7edf\u4ea4\u4e92\u7684\u667a\u80fd Agent\uff0c\u5b9e\u73b0\u771f\u6b63\u7684\u81ea\u52a8\u5316\u5de5\u4f5c\u6d41\u7a0b\u3002</p>"},{"location":"llmapps/langgraph/Local%20server/","title":"LangGraph \u672c\u5730\u670d\u52a1\u5668\u8fd0\u884c\u5b8c\u5168\u6307\u5357","text":"<p>\u672c\u6559\u7a0b\u5c06\u6307\u5bfc\u4f60\u5982\u4f55\u5728\u672c\u5730\u8fd0\u884c LangGraph \u5e94\u7528\u7a0b\u5e8f\uff0c\u5305\u62ec\u5b89\u88c5\u3001\u914d\u7f6e\u3001\u542f\u52a8\u548c\u6d4b\u8bd5\u5b8c\u6574\u6d41\u7a0b\u3002</p>"},{"location":"llmapps/langgraph/Local%20server/#_1","title":"\u524d\u7f6e\u8981\u6c42","text":"<p>\u5f00\u59cb\u4e4b\u524d\uff0c\u8bf7\u786e\u4fdd\u4f60\u5df2\u51c6\u5907\u597d\uff1a</p> <ul> <li>Python 3.11 \u6216\u66f4\u9ad8\u7248\u672c</li> <li>LangSmith API \u5bc6\u94a5\uff08\u514d\u8d39\u6ce8\u518c\uff09</li> </ul>"},{"location":"llmapps/langgraph/Local%20server/#1-langgraph-cli","title":"\u6b65\u9aa4 1\uff1a\u5b89\u88c5 LangGraph CLI","text":"<p>\u9996\u5148\u5b89\u88c5 LangGraph \u547d\u4ee4\u884c\u5de5\u5177\uff1a</p>"},{"location":"llmapps/langgraph/Local%20server/#pip","title":"\u4f7f\u7528 pip \u5b89\u88c5","text":"<pre><code># \u9700\u8981 Python &gt;= 3.11\npip install -U \"langgraph-cli[inmem]\"\n</code></pre>"},{"location":"llmapps/langgraph/Local%20server/#uv","title":"\u4f7f\u7528 uv \u5b89\u88c5","text":"<pre><code># \u9700\u8981 Python &gt;= 3.11\nuv add langgraph-cli[inmem]\n</code></pre>"},{"location":"llmapps/langgraph/Local%20server/#2-langgraph","title":"\u6b65\u9aa4 2\uff1a\u521b\u5efa LangGraph \u5e94\u7528 \ud83c\udf31","text":"<p>\u4ece\u6a21\u677f\u521b\u5efa\u4e00\u4e2a\u65b0\u7684 LangGraph \u5e94\u7528\uff1a</p> <pre><code>langgraph new path/to/your/app --template new-langgraph-project-python\n</code></pre> <p>\u8fd9\u4e2a\u6a21\u677f\u5c55\u793a\u4e86\u4e00\u4e2a\u5355\u8282\u70b9\u5e94\u7528\uff0c\u4f60\u53ef\u4ee5\u57fa\u4e8e\u6b64\u6269\u5c55\u81ea\u5df1\u7684\u903b\u8f91\u3002</p> <p>\u63d0\u793a\uff1a\u66f4\u591a\u6a21\u677f\u9009\u62e9</p> <p>\u5982\u679c\u4f7f\u7528 <code>langgraph new</code> \u65f6\u4e0d\u6307\u5b9a\u6a21\u677f\uff0c\u4f1a\u51fa\u73b0\u4ea4\u4e92\u5f0f\u83dc\u5355\u8ba9\u4f60\u4ece\u53ef\u7528\u6a21\u677f\u5217\u8868\u4e2d\u9009\u62e9\u3002</p>"},{"location":"llmapps/langgraph/Local%20server/#3","title":"\u6b65\u9aa4 3\uff1a\u5b89\u88c5\u4f9d\u8d56","text":"<p>\u8fdb\u5165\u65b0\u521b\u5efa\u7684 LangGraph \u5e94\u7528\u6839\u76ee\u5f55\uff0c\u4ee5 <code>edit</code> \u6a21\u5f0f\u5b89\u88c5\u4f9d\u8d56\uff0c\u8fd9\u6837\u670d\u52a1\u5668\u7684\u66f4\u6539\u4f1a\u7acb\u5373\u751f\u6548\uff1a</p>"},{"location":"llmapps/langgraph/Local%20server/#pip_1","title":"\u4f7f\u7528 pip","text":"<pre><code>cd path/to/your/app\npip install -e .\n</code></pre>"},{"location":"llmapps/langgraph/Local%20server/#uv_1","title":"\u4f7f\u7528 uv","text":"<pre><code>cd path/to/your/app\nuv add .\n</code></pre>"},{"location":"llmapps/langgraph/Local%20server/#4","title":"\u6b65\u9aa4 4\uff1a\u914d\u7f6e\u73af\u5883\u53d8\u91cf","text":"<p>\u5728\u4f60\u7684\u65b0 LangGraph \u5e94\u7528\u6839\u76ee\u5f55\u4e2d\uff0c\u4f60\u4f1a\u627e\u5230 <code>.env.example</code> \u6587\u4ef6\u3002\u521b\u5efa\u4e00\u4e2a <code>.env</code> \u6587\u4ef6\u5e76\u590d\u5236\u5185\u5bb9\uff0c\u586b\u5165\u5fc5\u8981\u7684 API \u5bc6\u94a5\uff1a</p> <pre><code>LANGSMITH_API_KEY=lsv2_\u4f60\u7684\u5b9e\u9645API\u5bc6\u94a5\n</code></pre>"},{"location":"llmapps/langgraph/Local%20server/#5-langgraph","title":"\u6b65\u9aa4 5\uff1a\u542f\u52a8 LangGraph \u670d\u52a1\u5668 \ud83d\ude80","text":"<p>\u5728\u672c\u5730\u542f\u52a8 LangGraph API \u670d\u52a1\u5668\uff1a</p> <pre><code>langgraph dev\n</code></pre> <p>\u6210\u529f\u542f\u52a8\u540e\uff0c\u4f60\u4f1a\u770b\u5230\u7c7b\u4f3c\u4ee5\u4e0b\u8f93\u51fa\uff1a</p> <pre><code>&gt;    Ready!\n&gt;\n&gt;    - API: [http://localhost:2024](http://localhost:2024/)\n&gt;\n&gt;    - Docs: http://localhost:2024/docs\n&gt;\n&gt;    - LangGraph Studio Web UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024\n</code></pre> <p>\u91cd\u8981\u8bf4\u660e\uff1a<code>langgraph dev</code> \u547d\u4ee4\u4ee5\u5185\u5b58\u6a21\u5f0f\u542f\u52a8 LangGraph \u670d\u52a1\u5668\uff0c\u9002\u7528\u4e8e\u5f00\u53d1\u548c\u6d4b\u8bd5\u3002\u751f\u4ea7\u73af\u5883\u8bf7\u4f7f\u7528\u6301\u4e45\u5316\u5b58\u50a8\u540e\u7aef\u90e8\u7f72\u3002</p>"},{"location":"llmapps/langgraph/Local%20server/#6-studio","title":"\u6b65\u9aa4 6\uff1a\u5728 Studio \u4e2d\u6d4b\u8bd5\u5e94\u7528","text":"<p>[Studio]\u662f\u4e00\u4e2a\u4e13\u95e8\u7684 UI \u754c\u9762\uff0c\u53ef\u4ee5\u8fde\u63a5\u5230 LangGraph API \u670d\u52a1\u5668\uff0c\u7528\u4e8e\u53ef\u89c6\u5316\u3001\u4ea4\u4e92\u548c\u8c03\u8bd5\u4f60\u7684\u5e94\u7528\u3002</p> <p>\u8bbf\u95ee <code>langgraph dev</code> \u547d\u4ee4\u8f93\u51fa\u4e2d\u63d0\u4f9b\u7684 URL \u6765\u5728 Studio \u4e2d\u6d4b\u8bd5\u4f60\u7684\u56fe\uff1a</p> <pre><code>&gt;    - LangGraph Studio Web UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024\n</code></pre> <p>\u5982\u679c LangGraph \u670d\u52a1\u5668\u8fd0\u884c\u5728\u81ea\u5b9a\u4e49\u4e3b\u673a/\u7aef\u53e3\u4e0a\uff0c\u8bf7\u66f4\u65b0 baseURL \u53c2\u6570\u3002</p> Safari \u6d4f\u89c8\u5668\u517c\u5bb9\u6027\u8bf4\u660e  \u7531\u4e8e Safari \u5728\u8fde\u63a5 localhost \u670d\u52a1\u5668\u65f6\u6709\u9650\u5236\uff0c\u4f7f\u7528 `--tunnel` \u6807\u5fd7\u521b\u5efa\u5b89\u5168\u96a7\u9053\uff1a   <pre><code>langgraph dev --tunnel\n</code></pre>"},{"location":"llmapps/langgraph/Local%20server/#7-api","title":"\u6b65\u9aa4 7\uff1a\u6d4b\u8bd5 API","text":""},{"location":"llmapps/langgraph/Local%20server/#python-sdk","title":"\u65b9\u6cd5\u4e00\uff1aPython SDK\uff08\u5f02\u6b65\uff09","text":"<ol> <li>\u5b89\u88c5 LangGraph Python SDK\uff1a</li> </ol> <pre><code>pip install langgraph-sdk\n</code></pre> <ol> <li>\u53d1\u9001\u6d88\u606f\u5230\u52a9\u624b\uff08\u65e0\u7ebf\u7a0b\u8fd0\u884c\uff09\uff1a</li> </ol> <pre><code>from langgraph_sdk import get_client\nimport asyncio\n\n# \u8fde\u63a5\u5230\u672c\u5730\u670d\u52a1\u5668\nclient = get_client(url=\"http://localhost:2024\")\n\nasync def main():\n    async for chunk in client.runs.stream(\n        None,  # \u65e0\u7ebf\u7a0b\u8fd0\u884c\n        \"agent\",  # \u52a9\u624b\u540d\u79f0\uff0c\u5728 langgraph.json \u4e2d\u5b9a\u4e49\n        input={\n            \"messages\": [{\n                \"role\": \"human\",\n                \"content\": \"What is LangGraph?\",\n            }],\n        },\n    ):\n        print(f\"\u6536\u5230\u65b0\u4e8b\u4ef6\u7c7b\u578b: {chunk.event}...\")\n        print(chunk.data)\n        print(\"\\n\\n\")\n\nasyncio.run(main())\n</code></pre>"},{"location":"llmapps/langgraph/Local%20server/#python-sdk_1","title":"\u65b9\u6cd5\u4e8c\uff1aPython SDK\uff08\u540c\u6b65\uff09","text":"<ol> <li>\u5b89\u88c5 LangGraph Python SDK\uff1a</li> </ol> <pre><code>pip install langgraph-sdk\n</code></pre> <ol> <li>\u53d1\u9001\u6d88\u606f\u5230\u52a9\u624b\uff1a</li> </ol> <pre><code>from langgraph_sdk import get_sync_client\n\n# \u8fde\u63a5\u5230\u672c\u5730\u670d\u52a1\u5668\nclient = get_sync_client(url=\"http://localhost:2024\")\n\nfor chunk in client.runs.stream(\n    None,  # \u65e0\u7ebf\u7a0b\u8fd0\u884c\n    \"agent\",  # \u52a9\u624b\u540d\u79f0\n    input={\n        \"messages\": [{\n            \"role\": \"human\",\n            \"content\": \"What is LangGraph?\",\n        }],\n    },\n    stream_mode=\"messages-tuple\",\n):\n    print(f\"\u6536\u5230\u65b0\u4e8b\u4ef6\u7c7b\u578b: {chunk.event}...\")\n    print(chunk.data)\n    print(\"\\n\\n\")\n</code></pre>"},{"location":"llmapps/langgraph/Local%20server/#rest-api","title":"\u65b9\u6cd5\u4e09\uff1aREST API","text":"<p>\u4f7f\u7528 curl \u547d\u4ee4\u76f4\u63a5\u6d4b\u8bd5 API\uff1a</p> <pre><code>curl -s --request POST \\\n    --url \"http://localhost:2024/runs/stream\" \\\n    --header 'Content-Type: application/json' \\\n    --data \"{\n        \\\"assistant_id\\\": \\\"agent\\\",\n        \\\"input\\\": {\n            \\\"messages\\\": [\n                {\n                    \\\"role\\\": \\\"human\\\",\n                    \\\"content\\\": \\\"What is LangGraph?\\\"\n                }\n            ]\n        },\n        \\\"stream_mode\\\": \\\"messages-tuple\\\"\n    }\"\n</code></pre>"},{"location":"llmapps/langgraph/Local%20server/#_2","title":"\u6545\u969c\u6392\u9664","text":""},{"location":"llmapps/langgraph/Local%20server/#_3","title":"\u5e38\u89c1\u95ee\u9898","text":"<ol> <li>\u7aef\u53e3\u51b2\u7a81<ul> <li>\u5982\u679c 2024 \u7aef\u53e3\u88ab\u5360\u7528\uff0c\u4f7f\u7528 <code>--port</code> \u53c2\u6570\u6307\u5b9a\u5176\u4ed6\u7aef\u53e3\uff1a</li> </ul> </li> </ol> <pre><code>         langgraph dev --port 3030\n</code></pre> <ol> <li> <p>API \u5bc6\u94a5\u9519\u8bef</p> <ul> <li>\u786e\u4fdd <code>.env</code> \u6587\u4ef6\u4e2d\u7684 <code>LANGSMITH_API_KEY</code> \u8bbe\u7f6e\u6b63\u786e</li> </ul> </li> <li> <p>\u4f9d\u8d56\u5b89\u88c5\u5931\u8d25</p> <ul> <li>\u786e\u4fdd Python \u7248\u672c &gt;= 3.11</li> <li>\u5c1d\u8bd5\u4f7f\u7528\u865a\u62df\u73af\u5883</li> </ul> </li> <li> <p>\u6a21\u677f\u521b\u5efa\u5931\u8d25</p> <ul> <li>\u68c0\u67e5\u7f51\u7edc\u8fde\u63a5</li> <li>\u5c1d\u8bd5\u4f7f\u7528\u4e0d\u540c\u7684\u6a21\u677f\u540d\u79f0</li> </ul> </li> </ol>"},{"location":"llmapps/langgraph/Local%20server/#_4","title":"\u8c03\u8bd5\u6280\u5de7","text":"<ol> <li>\u67e5\u770b\u8be6\u7ec6\u65e5\u5fd7</li> </ol> <pre><code>   langgraph dev --verbose\n</code></pre> <ol> <li> <p>\u68c0\u67e5\u5e94\u7528\u914d\u7f6e</p> <ul> <li>\u786e\u8ba4 <code>langgraph.json</code> \u6587\u4ef6\u914d\u7f6e\u6b63\u786e</li> <li>\u9a8c\u8bc1\u52a9\u624b\u540d\u79f0\u4e0e\u4ee3\u7801\u4e2d\u4f7f\u7528\u7684\u540d\u79f0\u4e00\u81f4</li> </ul> </li> <li> <p>\u6d4b\u8bd5\u8fde\u63a5</p> </li> </ol> <pre><code>   curl http://localhost:2024/health\n</code></pre>"},{"location":"llmapps/langgraph/Local%20server/#_5","title":"\u9879\u76ee\u7ed3\u6784\u8bf4\u660e","text":"<p>\u6210\u529f\u521b\u5efa\u9879\u76ee\u540e\uff0c\u4f60\u4f1a\u770b\u5230\u4ee5\u4e0b\u5178\u578b\u7ed3\u6784\uff1a</p> <pre><code>your-app/\n\u251c\u2500\u2500 langgraph.json          # \u5e94\u7528\u914d\u7f6e\u6587\u4ef6\n\u251c\u2500\u2500 pyproject.toml          # \u9879\u76ee\u4f9d\u8d56\u914d\u7f6e\n\u251c\u2500\u2500 .env.example            # \u73af\u5883\u53d8\u91cf\u793a\u4f8b\n\u251c\u2500\u2500 src/\n\u2502   \u2514\u2500\u2500 your_app/\n\u2502       \u251c\u2500\u2500 __init__.py\n\u2502       \u2514\u2500\u2500 graph.py        # \u4e3b\u8981\u7684\u56fe\u5b9a\u4e49\n\u2514\u2500\u2500 README.md\n</code></pre>"},{"location":"llmapps/langgraph/Subgraphs/","title":"LangGraph \u5b50\u56fe\u4f7f\u7528\u6559\u7a0b","text":""},{"location":"llmapps/langgraph/Subgraphs/#_1","title":"\u6982\u8ff0","text":"<p>\u672c\u6559\u7a0b\u5c06\u8be6\u7ec6\u4ecb\u7ecd\u5982\u4f55\u5728 LangGraph \u4e2d\u4f7f\u7528\u5b50\u56fe\uff08Subgraphs\uff09\u3002\u5b50\u56fe\u662f\u6307\u5728\u4e00\u4e2a\u56fe\u4e2d\u4f5c\u4e3a\u8282\u70b9\u4f7f\u7528\u7684\u53e6\u4e00\u4e2a\u56fe\uff0c\u8fd9\u79cd\u8bbe\u8ba1\u6a21\u5f0f\u5728\u6784\u5efa\u590d\u6742\u7cfb\u7edf\u65f6\u975e\u5e38\u6709\u7528\u3002</p>"},{"location":"llmapps/langgraph/Subgraphs/#_2","title":"\u5b50\u56fe\u7684\u4f18\u52bf","text":"<ul> <li>\u6784\u5efa\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff1a\u6bcf\u4e2a\u667a\u80fd\u4f53\u53ef\u4ee5\u4f5c\u4e3a\u72ec\u7acb\u7684\u5b50\u56fe</li> <li>\u8282\u70b9\u590d\u7528\uff1a\u5728\u591a\u4e2a\u56fe\u4e2d\u91cd\u590d\u4f7f\u7528\u540c\u4e00\u7ec4\u8282\u70b9</li> <li>\u5206\u5e03\u5f0f\u5f00\u53d1\uff1a\u4e0d\u540c\u56e2\u961f\u53ef\u4ee5\u72ec\u7acb\u5f00\u53d1\u4e0d\u540c\u7684\u5b50\u56fe\u90e8\u5206\uff0c\u53ea\u8981\u4fdd\u6301\u63a5\u53e3\u89c4\u8303\u5373\u53ef</li> </ul>"},{"location":"llmapps/langgraph/Subgraphs/#_3","title":"\u73af\u5883\u8bbe\u7f6e","text":"<p>\u9996\u5148\u5b89\u88c5\u5fc5\u8981\u7684\u4f9d\u8d56\uff1a</p> <pre><code># \u4f7f\u7528 pip\npip install -U langgraph\n\n# \u4f7f\u7528 uv\nuv add langgraph\n</code></pre> <p>\u63d0\u793a\uff1a\u5efa\u8bae\u8bbe\u7f6e LangSmith \u6765\u76d1\u63a7\u548c\u8c03\u8bd5 LangGraph \u5e94\u7528\u3002</p>"},{"location":"llmapps/langgraph/Subgraphs/#_4","title":"\u4e24\u79cd\u5b50\u56fe\u5b9e\u73b0\u65b9\u5f0f","text":""},{"location":"llmapps/langgraph/Subgraphs/#1","title":"1. \u4ece\u8282\u70b9\u8c03\u7528\u56fe","text":"<p>\u5f53\u5b50\u56fe\u548c\u7236\u56fe\u6709\u5b8c\u5168\u4e0d\u540c\u7684\u72b6\u6001\u6a21\u5f0f\u65f6\uff0c\u53ef\u4ee5\u4f7f\u7528\u8fd9\u79cd\u65b9\u5f0f\u3002</p> <pre><code>from typing_extensions import TypedDict\nfrom langgraph.graph.state import StateGraph, START\n\n# \u5b9a\u4e49\u5b50\u56fe\u72b6\u6001\nclass SubgraphState(TypedDict):\n    bar: str\n\n# \u5b50\u56fe\u5b9e\u73b0\ndef subgraph_node_1(state: SubgraphState):\n    return {\"bar\": \"hi! \" + state[\"bar\"]}\n\nsubgraph_builder = StateGraph(SubgraphState)\nsubgraph_builder.add_node(subgraph_node_1)\nsubgraph_builder.add_edge(START, \"subgraph_node_1\")\nsubgraph = subgraph_builder.compile()\n\n# \u7236\u56fe\u5b9e\u73b0\nclass State(TypedDict):\n    foo: str\n\ndef call_subgraph(state: State):\n    # \u5c06\u7236\u56fe\u72b6\u6001\u8f6c\u6362\u4e3a\u5b50\u56fe\u72b6\u6001\n    subgraph_output = subgraph.invoke({\"bar\": state[\"foo\"]})\n    # \u5c06\u5b50\u56fe\u54cd\u5e94\u8f6c\u6362\u56de\u7236\u56fe\u72b6\u6001\n    return {\"foo\": subgraph_output[\"bar\"]}\n\nbuilder = StateGraph(State)\nbuilder.add_node(\"node_1\", call_subgraph)\nbuilder.add_edge(START, \"node_1\")\ngraph = builder.compile()\n</code></pre>"},{"location":"llmapps/langgraph/Subgraphs/#2","title":"2. \u5c06\u56fe\u4f5c\u4e3a\u8282\u70b9\u6dfb\u52a0","text":"<p>\u5f53\u5b50\u56fe\u548c\u7236\u56fe\u5171\u4eab\u72b6\u6001\u952e\u65f6\uff0c\u53ef\u4ee5\u76f4\u63a5\u5c06\u5b50\u56fe\u4f5c\u4e3a\u8282\u70b9\u6dfb\u52a0\u5230\u7236\u56fe\u4e2d\u3002</p> <pre><code>from typing_extensions import TypedDict\nfrom langgraph.graph.state import StateGraph, START\n\nclass State(TypedDict):\n    foo: str  # \u5171\u4eab\u7684\u72b6\u6001\u952e\n\n# \u5b50\u56fe\u5b9e\u73b0\ndef subgraph_node_1(state: State):\n    return {\"foo\": \"hi! \" + state[\"foo\"]}\n\nsubgraph_builder = StateGraph(State)\nsubgraph_builder.add_node(subgraph_node_1)\nsubgraph_builder.add_edge(START, \"subgraph_node_1\")\nsubgraph = subgraph_builder.compile()\n\n# \u7236\u56fe\u5b9e\u73b0 - \u76f4\u63a5\u6dfb\u52a0\u5b50\u56fe\u4f5c\u4e3a\u8282\u70b9\nbuilder = StateGraph(State)\nbuilder.add_node(\"node_1\", subgraph)  # \u76f4\u63a5\u4f20\u9012\u7f16\u8bd1\u540e\u7684\u5b50\u56fe\nbuilder.add_edge(START, \"node_1\")\ngraph = builder.compile()\n</code></pre>"},{"location":"llmapps/langgraph/Subgraphs/#_5","title":"\u6dfb\u52a0\u6301\u4e45\u5316","text":""},{"location":"llmapps/langgraph/Subgraphs/#_6","title":"\u4e3a\u7236\u56fe\u548c\u5b50\u56fe\u5171\u4eab\u5b58\u50a8","text":"<pre><code>from langgraph.graph import START, StateGraph\nfrom langgraph.checkpoint.memory import MemorySaver\n\nclass State(TypedDict):\n    foo: str\n\n# \u5b50\u56fe\u5b9e\u73b0\ndef subgraph_node_1(state: State):\n    return {\"foo\": state[\"foo\"] + \"bar\"}\n\nsubgraph_builder = StateGraph(State)\nsubgraph_builder.add_node(subgraph_node_1)\nsubgraph_builder.add_edge(START, \"subgraph_node_1\")\nsubgraph = subgraph_builder.compile()\n\n# \u7236\u56fe\u5b9e\u73b0\nbuilder = StateGraph(State)\nbuilder.add_node(\"node_1\", subgraph)\nbuilder.add_edge(START, \"node_1\")\n\n# \u53ea\u4e3a\u7236\u56fe\u63d0\u4f9b\u68c0\u67e5\u70b9\uff0c\u5b50\u56fe\u4f1a\u81ea\u52a8\u7ee7\u627f\ncheckpointer = MemorySaver()\ngraph = builder.compile(checkpointer=checkpointer)\n</code></pre>"},{"location":"llmapps/langgraph/Subgraphs/#_7","title":"\u4e3a\u5b50\u56fe\u8bbe\u7f6e\u72ec\u7acb\u5b58\u50a8","text":"<p>\u5728\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\uff0c\u53ef\u80fd\u9700\u8981\u4e3a\u6bcf\u4e2a\u5b50\u56fe\u8bbe\u7f6e\u72ec\u7acb\u7684\u5b58\u50a8\uff1a</p> <pre><code>subgraph_builder = StateGraph(State)\nsubgraph = subgraph_builder.compile(checkpointer=True)  # \u5b50\u56fe\u6709\u81ea\u5df1\u7684\u5b58\u50a8\n</code></pre>"},{"location":"llmapps/langgraph/Subgraphs/#_8","title":"\u67e5\u770b\u5b50\u56fe\u72b6\u6001","text":"<p>\u5f53\u542f\u7528\u6301\u4e45\u5316\u65f6\uff0c\u53ef\u4ee5\u67e5\u770b\u5b50\u56fe\u7684\u72b6\u6001\u3002\u6ce8\u610f\uff1a\u53ea\u80fd\u5728\u5b50\u56fe\u88ab\u4e2d\u65ad\u65f6\u67e5\u770b\u5176\u72b6\u6001\u3002</p> <pre><code># \u83b7\u53d6\u7236\u56fe\u72b6\u6001\nparent_state = graph.get_state(config)\n\n# \u83b7\u53d6\u5b50\u56fe\u72b6\u6001\uff08\u4ec5\u5728\u5b50\u56fe\u4e2d\u65ad\u65f6\u53ef\u7528\uff09\nsubgraph_state = graph.get_state(config, subgraphs=True).tasks[0].state\n</code></pre>"},{"location":"llmapps/langgraph/Subgraphs/#_9","title":"\u6d41\u5f0f\u8f93\u51fa\u5b50\u56fe\u7ed3\u679c","text":"<p>\u8981\u5728\u6d41\u5f0f\u8f93\u51fa\u4e2d\u5305\u542b\u5b50\u56fe\u7684\u8f93\u51fa\uff0c\u53ef\u4ee5\u5728\u6d41\u5f0f\u65b9\u6cd5\u4e2d\u8bbe\u7f6e <code>subgraphs=True</code>\uff1a</p> <pre><code>for chunk in graph.stream(\n    {\"foo\": \"foo\"},\n    subgraphs=True,  # \u5305\u542b\u5b50\u56fe\u8f93\u51fa\n    stream_mode=\"updates\",\n):\n    print(chunk)\n</code></pre>"},{"location":"llmapps/langgraph/Subgraphs/#_10","title":"\u5b8c\u6574\u793a\u4f8b","text":""},{"location":"llmapps/langgraph/Subgraphs/#_11","title":"\u5171\u4eab\u72b6\u6001\u6a21\u5f0f\u7684\u5b8c\u6574\u793a\u4f8b","text":"<pre><code>from typing_extensions import TypedDict\nfrom langgraph.graph.state import StateGraph, START\n\n# \u5b9a\u4e49\u5b50\u56fe\u72b6\u6001\nclass SubgraphState(TypedDict):\n    foo: str  # \u4e0e\u7236\u56fe\u5171\u4eab\n    bar: str  # \u5b50\u56fe\u79c1\u6709\n\ndef subgraph_node_1(state: SubgraphState):\n    return {\"bar\": \"bar\"}\n\ndef subgraph_node_2(state: SubgraphState):\n    return {\"foo\": state[\"foo\"] + state[\"bar\"]}\n\nsubgraph_builder = StateGraph(SubgraphState)\nsubgraph_builder.add_node(subgraph_node_1)\nsubgraph_builder.add_node(subgraph_node_2)\nsubgraph_builder.add_edge(START, \"subgraph_node_1\")\nsubgraph_builder.add_edge(\"subgraph_node_1\", \"subgraph_node_2\")\nsubgraph = subgraph_builder.compile()\n\n# \u7236\u56fe\u5b9e\u73b0\nclass ParentState(TypedDict):\n    foo: str\n\ndef node_1(state: ParentState):\n    return {\"foo\": \"hi! \" + state[\"foo\"]}\n\nbuilder = StateGraph(ParentState)\nbuilder.add_node(\"node_1\", node_1)\nbuilder.add_node(\"node_2\", subgraph)\nbuilder.add_edge(START, \"node_1\")\nbuilder.add_edge(\"node_1\", \"node_2\")\ngraph = builder.compile()\n\n# \u6267\u884c\u5e76\u67e5\u770b\u7ed3\u679c\nfor chunk in graph.stream({\"foo\": \"foo\"}):\n    print(chunk)\n</code></pre>"},{"location":"llmapps/langgraph/Subgraphs/#_12","title":"\u4f7f\u7528\u573a\u666f\u5efa\u8bae","text":"<ol> <li>\u9009\u62e9\u4ece\u8282\u70b9\u8c03\u7528\u56fe\uff1a\u5f53\u5b50\u56fe\u548c\u7236\u56fe\u72b6\u6001\u6a21\u5f0f\u5b8c\u5168\u4e0d\u540c\u65f6</li> <li>\u9009\u62e9\u5c06\u56fe\u4f5c\u4e3a\u8282\u70b9\u6dfb\u52a0\uff1a\u5f53\u5b50\u56fe\u548c\u7236\u56fe\u5171\u4eab\u90e8\u5206\u72b6\u6001\u952e\u65f6</li> <li>\u591a\u7ea7\u5b50\u56fe\uff1a\u53ef\u4ee5\u6784\u5efa\u7236\u56fe-&gt;\u5b50\u56fe-&gt;\u5b59\u56fe\u7684\u591a\u7ea7\u7ed3\u6784</li> <li>\u72ec\u7acb\u5b58\u50a8\uff1a\u5728\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\uff0c\u4e3a\u6bcf\u4e2a\u667a\u80fd\u4f53\u8bbe\u7f6e\u72ec\u7acb\u7684\u6d88\u606f\u5386\u53f2\u5b58\u50a8</li> </ol> <p>\u901a\u8fc7\u5408\u7406\u4f7f\u7528\u5b50\u56fe\uff0c\u53ef\u4ee5\u6784\u5efa\u51fa\u7ed3\u6784\u6e05\u6670\u3001\u6613\u4e8e\u7ef4\u62a4\u7684\u590d\u6742\u56fe\u5de5\u4f5c\u6d41\u3002</p>"},{"location":"llmapps/langgraph/application%20structure/","title":"LangGraph \u5e94\u7528\u7ed3\u6784\u5b8c\u6574\u6559\u7a0b","text":""},{"location":"llmapps/langgraph/application%20structure/#_1","title":"\u6982\u8ff0","text":"<p>\u672c\u6559\u7a0b\u5c06\u8be6\u7ec6\u4ecb\u7ecd\u5982\u4f55\u6784\u5efa\u4e00\u4e2a\u5b8c\u6574\u7684 LangGraph \u5e94\u7528\u7a0b\u5e8f\u3002LangGraph \u5e94\u7528\u7531\u4e00\u4e2a\u6216\u591a\u4e2a\u56fe\u3001\u914d\u7f6e\u6587\u4ef6\u3001\u4f9d\u8d56\u6587\u4ef6\u4ee5\u53ca\u53ef\u9009\u7684\u73af\u5883\u53d8\u91cf\u6587\u4ef6\u7ec4\u6210\u3002</p>"},{"location":"llmapps/langgraph/application%20structure/#_2","title":"\u6838\u5fc3\u6982\u5ff5","text":"<p>\u8981\u6210\u529f\u90e8\u7f72 LangGraph \u5e94\u7528\uff0c\u9700\u8981\u63d0\u4f9b\u4ee5\u4e0b\u5173\u952e\u7ec4\u4ef6\uff1a</p>"},{"location":"llmapps/langgraph/application%20structure/#1-langgraphjson","title":"1. \u914d\u7f6e\u6587\u4ef6 (<code>langgraph.json</code>)","text":"<p>\u8fd9\u662f\u5e94\u7528\u7684\u6838\u5fc3\u914d\u7f6e\u6587\u4ef6\uff0c\u6307\u5b9a\u4e86\u4f9d\u8d56\u9879\u3001\u56fe\u548c\u73af\u5883\u53d8\u91cf\u3002</p>"},{"location":"llmapps/langgraph/application%20structure/#2-graphs","title":"2. \u56fe (Graphs)","text":"<p>\u5b9e\u73b0\u5e94\u7528\u903b\u8f91\u7684\u6d41\u7a0b\u56fe\u6216\u72b6\u6001\u673a\u3002</p>"},{"location":"llmapps/langgraph/application%20structure/#3","title":"3. \u4f9d\u8d56\u7ba1\u7406","text":"<p>\u5e94\u7528\u8fd0\u884c\u6240\u9700\u7684\u5305\u4f9d\u8d56\u3002</p>"},{"location":"llmapps/langgraph/application%20structure/#4","title":"4. \u73af\u5883\u53d8\u91cf","text":"<p>\u5e94\u7528\u8fd0\u884c\u6240\u9700\u7684\u73af\u5883\u914d\u7f6e\u3002</p>"},{"location":"llmapps/langgraph/application%20structure/#_3","title":"\u9879\u76ee\u7ed3\u6784\u8be6\u89e3","text":""},{"location":"llmapps/langgraph/application%20structure/#python-requirementstxt","title":"Python \u9879\u76ee\u7ed3\u6784\uff08\u4f7f\u7528 requirements.txt\uff09","text":"<pre><code>my-app/\n\u251c\u2500\u2500 my_agent/                    # \u9879\u76ee\u4e3b\u4ee3\u7801\u76ee\u5f55\n\u2502   \u251c\u2500\u2500 utils/                   # \u5de5\u5177\u548c\u5de5\u5177\u51fd\u6570\u76ee\u5f55\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 tools.py            # \u56fe\u4e2d\u4f7f\u7528\u7684\u5de5\u5177\u51fd\u6570\n\u2502   \u2502   \u251c\u2500\u2500 nodes.py            # \u56fe\u8282\u70b9\u51fd\u6570\n\u2502   \u2502   \u2514\u2500\u2500 state.py            # \u72b6\u6001\u5b9a\u4e49\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2514\u2500\u2500 agent.py                # \u56fe\u6784\u5efa\u4ee3\u7801\n\u251c\u2500\u2500 .env                        # \u73af\u5883\u53d8\u91cf\u6587\u4ef6\n\u251c\u2500\u2500 requirements.txt            # Python \u5305\u4f9d\u8d56\n\u2514\u2500\u2500 langgraph.json             # LangGraph \u914d\u7f6e\u6587\u4ef6\n</code></pre>"},{"location":"llmapps/langgraph/application%20structure/#python-pyprojecttoml","title":"Python \u9879\u76ee\u7ed3\u6784\uff08\u4f7f\u7528 pyproject.toml\uff09","text":"<pre><code>my-app/\n\u251c\u2500\u2500 my_agent/\n\u2502   \u251c\u2500\u2500 utils/\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 tools.py\n\u2502   \u2502   \u251c\u2500\u2500 nodes.py\n\u2502   \u2502   \u2514\u2500\u2500 state.py\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2514\u2500\u2500 agent.py\n\u251c\u2500\u2500 .env\n\u251c\u2500\u2500 langgraph.json\n\u2514\u2500\u2500 pyproject.toml             # \u9879\u76ee\u4f9d\u8d56\u914d\u7f6e\n</code></pre>"},{"location":"llmapps/langgraph/application%20structure/#_4","title":"\u914d\u7f6e\u6587\u4ef6\u8be6\u89e3","text":""},{"location":"llmapps/langgraph/application%20structure/#langgraphjson","title":"langgraph.json \u7ed3\u6784","text":"<pre><code>{\n  \"dependencies\": [\"langchain_openai\", \"./your_package\"],\n  \"graphs\": {\n    \"my_agent\": \"./your_package/your_file.py:agent\"\n  },\n  \"env\": \"./.env\"\n}\n</code></pre>"},{"location":"llmapps/langgraph/application%20structure/#_5","title":"\u914d\u7f6e\u53c2\u6570\u8bf4\u660e","text":"<ul> <li>dependencies: \u4f9d\u8d56\u5305\u5217\u8868\uff0c\u652f\u6301\u672c\u5730\u5305\u548c PyPI \u5305</li> <li>graphs: \u56fe\u5b9a\u4e49\uff0c\u683c\u5f0f\u4e3a <code>\"\u56fe\u540d\": \"\u6587\u4ef6\u8def\u5f84:\u53d8\u91cf\u540d\"</code></li> <li>env: \u73af\u5883\u53d8\u91cf\u6587\u4ef6\u8def\u5f84</li> </ul>"},{"location":"llmapps/langgraph/application%20structure/#_6","title":"\u4f9d\u8d56\u7ba1\u7406","text":""},{"location":"llmapps/langgraph/application%20structure/#requirementstxt","title":"\u65b9\u6cd5\u4e00\uff1arequirements.txt","text":"<pre><code>langchain_openai&gt;=0.1.0\nlanggraph&gt;=0.1.0\nrequests&gt;=2.31.0\n</code></pre>"},{"location":"llmapps/langgraph/application%20structure/#pyprojecttoml","title":"\u65b9\u6cd5\u4e8c\uff1apyproject.toml","text":"<pre><code>[build-system]\nrequires = [\"setuptools\", \"wheel\"]\n\n[project]\nname = \"my-agent\"\ndependencies = [\n    \"langchain_openai&gt;=0.1.0\",\n    \"langgraph&gt;=0.1.0\",\n]\n\n[tool.setuptools.packages.find]\nwhere = [\".\"]\n</code></pre>"},{"location":"llmapps/langgraph/application%20structure/#_7","title":"\u56fe\u5b9a\u4e49\u793a\u4f8b","text":""},{"location":"llmapps/langgraph/application%20structure/#agentpy-","title":"agent.py - \u56fe\u6784\u5efa\u4ee3\u7801","text":"<pre><code>from langgraph.graph import Graph\nfrom .utils.nodes import process_input, generate_response\nfrom .utils.state import AgentState\n\ndef create_agent_graph():\n    \"\"\"\u521b\u5efa\u4ee3\u7406\u56fe\"\"\"\n    graph = Graph()\n\n    # \u6dfb\u52a0\u8282\u70b9\n    graph.add_node(\"process\", process_input)\n    graph.add_node(\"generate\", generate_response)\n\n    # \u8bbe\u7f6e\u8fb9\n    graph.set_entry_point(\"process\")\n    graph.add_edge(\"process\", \"generate\")\n    graph.set_finish_point(\"generate\")\n\n    return graph.compile()\n\n# \u5bfc\u51fa\u7684\u56fe\u5b9e\u4f8b\nagent = create_agent_graph()\n</code></pre>"},{"location":"llmapps/langgraph/application%20structure/#statepy-","title":"state.py - \u72b6\u6001\u5b9a\u4e49","text":"<pre><code>from typing import TypedDict, List, Annotated\nfrom langgraph.graph import add_messages\n\nclass AgentState(TypedDict):\n    messages: Annotated[List, add_messages]\n    input_data: str\n    processed_data: dict\n</code></pre>"},{"location":"llmapps/langgraph/application%20structure/#nodespy-","title":"nodes.py - \u8282\u70b9\u51fd\u6570","text":"<pre><code>from .state import AgentState\n\ndef process_input(state: AgentState) -&gt; AgentState:\n    \"\"\"\u5904\u7406\u8f93\u5165\u6570\u636e\u7684\u8282\u70b9\"\"\"\n    # \u5904\u7406\u903b\u8f91\n    state[\"processed_data\"] = {\"content\": state[\"input_data\"]}\n    return state\n\ndef generate_response(state: AgentState) -&gt; AgentState:\n    \"\"\"\u751f\u6210\u54cd\u5e94\u7684\u8282\u70b9\"\"\"\n    # \u54cd\u5e94\u751f\u6210\u903b\u8f91\n    state[\"messages\"].append({\"role\": \"assistant\", \"content\": \"Response\"})\n    return state\n</code></pre>"},{"location":"llmapps/langgraph/application%20structure/#toolspy-","title":"tools.py - \u5de5\u5177\u51fd\u6570","text":"<pre><code>from langchain.tools import tool\n\n@tool\ndef search_tool(query: str) -&gt; str:\n    \"\"\"\u641c\u7d22\u5de5\u5177\"\"\"\n    # \u5b9e\u73b0\u641c\u7d22\u903b\u8f91\n    return f\"Search results for: {query}\"\n</code></pre>"},{"location":"llmapps/langgraph/application%20structure/#_8","title":"\u73af\u5883\u53d8\u91cf\u914d\u7f6e","text":""},{"location":"llmapps/langgraph/application%20structure/#env","title":".env \u6587\u4ef6\u793a\u4f8b","text":"<pre><code>OPENAI_API_KEY=your_openai_api_key_here\nLANGCHAIN_API_KEY=your_langchain_api_key\nDATABASE_URL=your_database_connection_string\n</code></pre>"},{"location":"llmapps/langgraph/application%20structure/#_9","title":"\u90e8\u7f72\u914d\u7f6e\u6700\u4f73\u5b9e\u8df5","text":""},{"location":"llmapps/langgraph/application%20structure/#1-langgraphjson_1","title":"1. \u5b8c\u6574\u7684 langgraph.json \u914d\u7f6e","text":"<pre><code>{\n  \"dependencies\": [\n    \"langchain_openai\",\n    \"langgraph\",\n    \"pydantic&gt;=2.0.0\",\n    \"./my_agent\"\n  ],\n  \"graphs\": {\n    \"chat_agent\": \"./my_agent/agent.py:agent\",\n    \"analysis_agent\": \"./my_agent/analysis.py:analyzer\"\n  },\n  \"env\": \"./.env\",\n  \"dockerfile_lines\": [\n    \"RUN apt-get update &amp;&amp; apt-get install -y curl\",\n    \"RUN pip install --upgrade pip\"\n  ]\n}\n</code></pre>"},{"location":"llmapps/langgraph/application%20structure/#2","title":"2. \u591a\u56fe\u5e94\u7528\u7ed3\u6784","text":"<p>\u5bf9\u4e8e\u5305\u542b\u591a\u4e2a\u56fe\u7684\u5e94\u7528\uff1a</p> <pre><code>multi-agent-app/\n\u251c\u2500\u2500 agents/\n\u2502   \u251c\u2500\u2500 chat_agent.py\n\u2502   \u251c\u2500\u2500 analysis_agent.py\n\u2502   \u2514\u2500\u2500 utils/\n\u251c\u2500\u2500 shared/\n\u2502   \u251c\u2500\u2500 state.py\n\u2502   \u2514\u2500\u2500 tools.py\n\u251c\u2500\u2500 .env\n\u251c\u2500\u2500 requirements.txt\n\u2514\u2500\u2500 langgraph.json\n</code></pre>"},{"location":"llmapps/langgraph/application%20structure/#_10","title":"\u5f00\u53d1\u5de5\u4f5c\u6d41\u7a0b","text":""},{"location":"llmapps/langgraph/application%20structure/#1","title":"\u6b65\u9aa4 1\uff1a\u521d\u59cb\u5316\u9879\u76ee\u7ed3\u6784","text":"<pre><code>mkdir my-langgraph-app\ncd my-langgraph-app\nmkdir -p my_agent/utils\ntouch my_agent/__init__.py my_agent/utils/__init__.py\n</code></pre>"},{"location":"llmapps/langgraph/application%20structure/#2_1","title":"\u6b65\u9aa4 2\uff1a\u521b\u5efa\u6838\u5fc3\u6587\u4ef6","text":"<pre><code>touch my_agent/agent.py my_agent/utils/state.py\ntouch my_agent/utils/nodes.py my_agent/utils/tools.py\ntouch .env requirements.txt langgraph.json\n</code></pre>"},{"location":"llmapps/langgraph/application%20structure/#3_1","title":"\u6b65\u9aa4 3\uff1a\u914d\u7f6e\u4f9d\u8d56\u548c\u73af\u5883","text":"<pre><code># requirements.txt\necho \"langchain_openai\" &gt;&gt; requirements.txt\necho \"langgraph\" &gt;&gt; requirements.txt\n\n# .env\necho \"OPENAI_API_KEY=your_key_here\" &gt;&gt; .env\n</code></pre>"},{"location":"llmapps/langgraph/application%20structure/#4_1","title":"\u6b65\u9aa4 4\uff1a\u6d4b\u8bd5\u548c\u90e8\u7f72","text":"<pre><code># \u672c\u5730\u6d4b\u8bd5\npython -c \"from my_agent.agent import agent; print('Graph compiled successfully')\"\n\n# \u4f7f\u7528 LangGraph CLI \u90e8\u7f72\nlanggraph deploy\n</code></pre>"},{"location":"llmapps/langgraph/application%20structure/#_11","title":"\u6545\u969c\u6392\u9664","text":""},{"location":"llmapps/langgraph/application%20structure/#_12","title":"\u5e38\u89c1\u95ee\u9898","text":"<ol> <li>\u4f9d\u8d56\u89e3\u6790\u5931\u8d25</li> <li>\u68c0\u67e5\u4f9d\u8d56\u5305\u540d\u79f0\u548c\u7248\u672c</li> <li> <p>\u9a8c\u8bc1\u672c\u5730\u5305\u8def\u5f84\u662f\u5426\u6b63\u786e</p> </li> <li> <p>\u56fe\u52a0\u8f7d\u9519\u8bef</p> </li> <li>\u786e\u8ba4\u6587\u4ef6\u8def\u5f84\u548c\u53d8\u91cf\u540d\u6b63\u786e</li> <li> <p>\u68c0\u67e5\u56fe\u7f16\u8bd1\u662f\u5426\u6709\u8bed\u6cd5\u9519\u8bef</p> </li> <li> <p>\u73af\u5883\u53d8\u91cf\u7f3a\u5931</p> </li> <li>\u9a8c\u8bc1 <code>.env</code> \u6587\u4ef6\u5b58\u5728\u4e14\u683c\u5f0f\u6b63\u786e</li> <li>\u68c0\u67e5\u751f\u4ea7\u73af\u5883\u53d8\u91cf\u914d\u7f6e</li> </ol>"},{"location":"llmapps/langgraph/application%20structure/#_13","title":"\u8c03\u8bd5\u6280\u5de7","text":"<pre><code># \u5728 agent.py \u4e2d\u6dfb\u52a0\u8c03\u8bd5\u4fe1\u606f\ndef create_agent_graph():\n    print(\"\u5f00\u59cb\u6784\u5efa\u56fe...\")\n    graph = Graph()\n    # ... \u6784\u5efa\u903b\u8f91\n    compiled_graph = graph.compile()\n    print(\"\u56fe\u6784\u5efa\u5b8c\u6210\")\n    return compiled_graph\n</code></pre>"},{"location":"llmapps/langgraph/application%20structure/#_14","title":"\u603b\u7ed3","text":"<p>\u901a\u8fc7\u672c\u6559\u7a0b\uff0c\u60a8\u5e94\u8be5\u80fd\u591f\uff1a</p> <ul> <li>\u2705 \u7406\u89e3 LangGraph \u5e94\u7528\u7684\u6838\u5fc3\u7ec4\u4ef6</li> <li>\u2705 \u521b\u5efa\u6807\u51c6\u7684\u9879\u76ee\u7ed3\u6784</li> <li>\u2705 \u914d\u7f6e\u6b63\u786e\u7684\u4f9d\u8d56\u7ba1\u7406</li> <li>\u2705 \u5b9a\u4e49\u548c\u6784\u5efa\u529f\u80fd\u56fe</li> <li>\u2705 \u8bbe\u7f6e\u73af\u5883\u53d8\u91cf\u548c\u914d\u7f6e\u6587\u4ef6</li> <li>\u2705 \u51c6\u5907\u5e94\u7528\u8fdb\u884c\u90e8\u7f72</li> </ul> <p>\u9075\u5faa\u8fd9\u4e9b\u6700\u4f73\u5b9e\u8df5\u5c06\u786e\u4fdd\u60a8\u7684 LangGraph \u5e94\u7528\u7ed3\u6784\u6e05\u6670\u3001\u6613\u4e8e\u7ef4\u62a4\uff0c\u5e76\u80fd\u591f\u987a\u5229\u90e8\u7f72\u5230\u751f\u4ea7\u73af\u5883\u3002</p>"},{"location":"llmapps/langgraph/durable%20execution/","title":"LangGraph \u6301\u4e45\u5316\u6267\u884c\u6559\u7a0b","text":""},{"location":"llmapps/langgraph/durable%20execution/#_1","title":"\u4ec0\u4e48\u662f\u6301\u4e45\u5316\u6267\u884c\uff1f","text":"<p>\u6301\u4e45\u5316\u6267\u884c\u662f\u4e00\u79cd\u6280\u672f\uff0c\u5141\u8bb8\u6d41\u7a0b\u6216\u5de5\u4f5c\u6d41\u5728\u5173\u952e\u70b9\u4fdd\u5b58\u8fdb\u5ea6\uff0c\u4ece\u800c\u80fd\u591f\u6682\u505c\u5e76\u5728\u4e4b\u540e\u4ece\u79bb\u5f00\u7684\u5730\u65b9\u51c6\u786e\u6062\u590d\u3002\u8fd9\u5728\u4ee5\u4e0b\u573a\u666f\u4e2d\u7279\u522b\u6709\u7528\uff1a</p> <ul> <li>\u4eba\u5de5\u4ecb\u5165\u573a\u666f\uff1a\u7528\u6237\u53ef\u4ee5\u5728\u7ee7\u7eed\u4e4b\u524d\u68c0\u67e5\u3001\u9a8c\u8bc1\u6216\u4fee\u6539\u6d41\u7a0b</li> <li>\u957f\u65f6\u95f4\u8fd0\u884c\u4efb\u52a1\uff1a\u53ef\u80fd\u9047\u5230\u4e2d\u65ad\u6216\u9519\u8bef\u7684\u4efb\u52a1\uff08\u5982 LLM \u8c03\u7528\u8d85\u65f6\uff09</li> </ul> <p>\u901a\u8fc7\u4fdd\u5b58\u5df2\u5b8c\u6210\u7684\u5de5\u4f5c\uff0c\u6301\u4e45\u5316\u6267\u884c\u786e\u4fdd\u6d41\u7a0b\u53ef\u4ee5\u5728\u4e0d\u91cd\u65b0\u5904\u7406\u5148\u524d\u6b65\u9aa4\u7684\u60c5\u51b5\u4e0b\u6062\u590d\u2014\u2014\u5373\u4f7f\u5728\u957f\u65f6\u95f4\u5ef6\u8fdf\u540e\uff08\u5982\u4e00\u5468\u540e\uff09\u3002</p>"},{"location":"llmapps/langgraph/durable%20execution/#_2","title":"\u542f\u7528\u6301\u4e45\u5316\u6267\u884c","text":""},{"location":"llmapps/langgraph/durable%20execution/#1","title":"1. \u914d\u7f6e\u6301\u4e45\u5316\u5b58\u50a8","text":"<p>\u8981\u542f\u7528\u6301\u4e45\u5316\u6267\u884c\uff0c\u9700\u8981\u5728\u7f16\u8bd1\u56fe\u65f6\u6307\u5b9a\u4e00\u4e2a\u68c0\u67e5\u70b9\u5b58\u50a8\u5668\uff1a</p> <pre><code>from langgraph.checkpoint.memory import InMemorySaver\nfrom langgraph.graph import StateGraph\n\n# \u521b\u5efa\u72b6\u6001\u56fe\nbuilder = StateGraph(State)\nbuilder.add_node(\"process_data\", process_data)\nbuilder.add_edge(START, \"process_data\")\n\n# \u6307\u5b9a\u68c0\u67e5\u70b9\u5b58\u50a8\u5668\ncheckpointer = InMemorySaver()\n\n# \u7f16\u8bd1\u56fe\u5e76\u542f\u7528\u6301\u4e45\u5316\ngraph = builder.compile(checkpointer=checkpointer)\n</code></pre>"},{"location":"llmapps/langgraph/durable%20execution/#2","title":"2. \u6307\u5b9a\u7ebf\u7a0b\u6807\u8bc6\u7b26","text":"<p>\u6267\u884c\u5de5\u4f5c\u6d41\u65f6\u9700\u8981\u63d0\u4f9b\u7ebf\u7a0bID\u6765\u8ddf\u8e2a\u7279\u5b9a\u5b9e\u4f8b\u7684\u6267\u884c\u5386\u53f2\uff1a</p> <pre><code>import uuid\n\n# \u751f\u6210\u552f\u4e00\u7684\u7ebf\u7a0bID\nthread_id = uuid.uuid4()\nconfig = {\"configurable\": {\"thread_id\": thread_id}}\n\n# \u6267\u884c\u5de5\u4f5c\u6d41\ngraph.invoke({\"input\": \"data\"}, config)\n</code></pre>"},{"location":"llmapps/langgraph/durable%20execution/#_3","title":"\u786e\u4fdd\u786e\u5b9a\u6027\u548c\u4e00\u81f4\u6027\u91cd\u653e","text":"<p>\u5f53\u5de5\u4f5c\u6d41\u6062\u590d\u65f6\uff0c\u4ee3\u7801\u4e0d\u4f1a\u4ece\u505c\u6b62\u7684\u540c\u4e00\u884c\u4ee3\u7801\u6062\u590d\uff0c\u800c\u662f\u4ece\u9002\u5f53\u7684\u8d77\u70b9\u91cd\u65b0\u5f00\u59cb\u3002\u56e0\u6b64\uff0c\u5fc5\u987b\u9075\u5faa\u4ee5\u4e0b\u51c6\u5219\uff1a</p>"},{"location":"llmapps/langgraph/durable%20execution/#_4","title":"\u4f7f\u7528\u4efb\u52a1\u5305\u88c5\u975e\u786e\u5b9a\u6027\u64cd\u4f5c","text":"<p>\u5c06\u4efb\u4f55\u975e\u786e\u5b9a\u6027\u64cd\u4f5c\uff08\u5982\u968f\u673a\u6570\u751f\u6210\uff09\u6216\u5177\u6709\u526f\u4f5c\u7528\u7684\u64cd\u4f5c\uff08\u5982\u6587\u4ef6\u5199\u5165\u3001API\u8c03\u7528\uff09\u5305\u88c5\u5728 <code>@task</code> \u88c5\u9970\u5668\u4e2d\uff1a</p> <pre><code>from langgraph.func import task\nimport requests\n\n@task\ndef make_api_call(url: str):\n    \"\"\"\u5305\u88c5API\u8c03\u7528\"\"\"\n    return requests.get(url).text[:100]\n\ndef process_data(state: State):\n    \"\"\"\u5904\u7406\u6570\u636e\u7684\u8282\u70b9\"\"\"\n    # \u4f7f\u7528\u4efb\u52a1\u6765\u786e\u4fdd\u786e\u5b9a\u6027\n    api_results = [make_api_call(url) for url in state['urls']]\n    results = [result.result() for result in api_results]\n    return {\"results\": results}\n</code></pre>"},{"location":"llmapps/langgraph/durable%20execution/#_5","title":"\u6700\u4f73\u5b9e\u8df5","text":"<ul> <li>\u907f\u514d\u91cd\u590d\u5de5\u4f5c\uff1a\u5c06\u591a\u4e2a\u526f\u4f5c\u7528\u64cd\u4f5c\u5305\u88c5\u5728\u5355\u72ec\u7684\u4efb\u52a1\u4e2d</li> <li>\u5c01\u88c5\u975e\u786e\u5b9a\u6027\u64cd\u4f5c\uff1a\u786e\u4fdd\u5de5\u4f5c\u6d41\u9075\u5faa\u7cbe\u786e\u8bb0\u5f55\u7684\u6267\u884c\u5e8f\u5217</li> <li>\u4f7f\u7528\u5e42\u7b49\u64cd\u4f5c\uff1a\u786e\u4fdd\u526f\u4f5c\u7528\u64cd\u4f5c\u53ef\u4ee5\u5b89\u5168\u91cd\u8bd5</li> </ul>"},{"location":"llmapps/langgraph/durable%20execution/#_6","title":"\u6301\u4e45\u5316\u6a21\u5f0f","text":"<p>LangGraph \u63d0\u4f9b\u4e09\u79cd\u6301\u4e45\u5316\u6a21\u5f0f\uff0c\u5e73\u8861\u6027\u80fd\u548c\u6570\u636e\u4e00\u81f4\u6027\uff1a</p>"},{"location":"llmapps/langgraph/durable%20execution/#1-exit","title":"1. <code>\"exit\"</code> \u6a21\u5f0f","text":"<p>\u4ec5\u5728\u56fe\u6267\u884c\u5b8c\u6210\u65f6\u6301\u4e45\u5316\u66f4\u6539\u3002\u6027\u80fd\u6700\u4f73\uff0c\u4f46\u4e0d\u4fdd\u5b58\u4e2d\u95f4\u72b6\u6001\u3002</p> <pre><code>graph.stream(\n    {\"input\": \"test\"},\n    durability=\"exit\",\n    config=config\n)\n</code></pre>"},{"location":"llmapps/langgraph/durable%20execution/#2-async","title":"2. <code>\"async\"</code> \u6a21\u5f0f","text":"<p>\u5728\u4e0b\u4e00\u6b65\u6267\u884c\u65f6\u5f02\u6b65\u6301\u4e45\u5316\u66f4\u6539\u3002\u63d0\u4f9b\u826f\u597d\u7684\u6027\u80fd\u548c\u6301\u4e45\u6027\u5e73\u8861\u3002</p> <pre><code>graph.stream(\n    {\"input\": \"test\"},\n    durability=\"async\", \n    config=config\n)\n</code></pre>"},{"location":"llmapps/langgraph/durable%20execution/#3-sync","title":"3. <code>\"sync\"</code> \u6a21\u5f0f","text":"<p>\u5728\u4e0b\u4e00\u6b65\u5f00\u59cb\u524d\u540c\u6b65\u6301\u4e45\u5316\u66f4\u6539\u3002\u63d0\u4f9b\u6700\u9ad8\u7684\u6301\u4e45\u6027\u4fdd\u8bc1\u3002</p> <pre><code>graph.stream(\n    {\"input\": \"test\"},\n    durability=\"sync\",\n    config=config\n)\n</code></pre>"},{"location":"llmapps/langgraph/durable%20execution/#_7","title":"\u5728\u8282\u70b9\u4e2d\u4f7f\u7528\u4efb\u52a1","text":"<p>\u5982\u679c\u8282\u70b9\u5305\u542b\u591a\u4e2a\u64cd\u4f5c\uff0c\u53ef\u4ee5\u5c06\u6bcf\u4e2a\u64cd\u4f5c\u8f6c\u6362\u4e3a\u4efb\u52a1\uff1a</p>"},{"location":"llmapps/langgraph/durable%20execution/#_8","title":"\u539f\u59cb\u5b9e\u73b0\uff08\u6709\u95ee\u9898\uff09","text":"<pre><code>def call_api(state: State):\n    \"\"\"\u6709\u95ee\u9898\u7684\u5b9e\u73b0 - \u76f4\u63a5\u8fdb\u884cAPI\u8c03\u7528\"\"\"\n    result = requests.get(state['url']).text[:100]  # \u526f\u4f5c\u7528\u64cd\u4f5c\n    return {\"result\": result}\n</code></pre>"},{"location":"llmapps/langgraph/durable%20execution/#_9","title":"\u4f7f\u7528\u4efb\u52a1\u7684\u6539\u8fdb\u5b9e\u73b0","text":"<pre><code>@task\ndef _make_request(url: str):\n    \"\"\"\u5c06API\u8c03\u7528\u5305\u88c5\u4e3a\u4efb\u52a1\"\"\"\n    return requests.get(url).text[:100]\n\ndef call_api(state: State):\n    \"\"\"\u6539\u8fdb\u7684\u5b9e\u73b0 - \u4f7f\u7528\u4efb\u52a1\"\"\"\n    requests = [_make_request(url) for url in state['urls']]\n    results = [request.result() for request in requests]\n    return {\"results\": results}\n</code></pre>"},{"location":"llmapps/langgraph/durable%20execution/#_10","title":"\u6062\u590d\u5de5\u4f5c\u6d41","text":""},{"location":"llmapps/langgraph/durable%20execution/#1_1","title":"1. \u6682\u505c\u548c\u6062\u590d\u5de5\u4f5c\u6d41","text":"<p>\u4f7f\u7528\u4e2d\u65ad\u673a\u5236\u5728\u7279\u5b9a\u70b9\u6682\u505c\u5de5\u4f5c\u6d41\uff1a</p> <pre><code>from langgraph.types import interrupt, Command\n\n# \u5728\u8282\u70b9\u4e2d\u8bbe\u7f6e\u4e2d\u65ad\u70b9\ndef review_step(state: State):\n    # ... \u5904\u7406\u903b\u8f91\n    interrupt()  # \u6682\u505c\u6267\u884c\u7b49\u5f85\u4eba\u5de5\u5ba1\u6838\n    return state\n\n# \u6062\u590d\u5de5\u4f5c\u6d41\ncommand = Command(resume=True, update={\"approved\": True})\ngraph.stream(None, config=config, command=command)\n</code></pre>"},{"location":"llmapps/langgraph/durable%20execution/#2_1","title":"2. \u4ece\u9519\u8bef\u4e2d\u6062\u590d","text":"<p>\u5de5\u4f5c\u6d41\u53ef\u4ee5\u4ece\u6700\u540e\u4e00\u4e2a\u6210\u529f\u7684\u68c0\u67e5\u70b9\u81ea\u52a8\u6062\u590d\uff1a</p> <pre><code>try:\n    # \u9996\u6b21\u6267\u884c\n    graph.invoke({\"input\": \"data\"}, config)\nexcept Exception:\n    # \u4ece\u9519\u8bef\u4e2d\u6062\u590d - \u8f93\u5165\u4e3a None\n    graph.invoke(None, config)\n</code></pre>"},{"location":"llmapps/langgraph/durable%20execution/#_11","title":"\u6062\u590d\u8d77\u70b9","text":"<p>\u5de5\u4f5c\u6d41\u6062\u590d\u65f6\u7684\u8d77\u70b9\u53d6\u51b3\u4e8e\u4f7f\u7528\u7684API\uff1a</p> <ul> <li>StateGraph\uff1a\u4ece\u6267\u884c\u505c\u6b62\u7684\u8282\u70b9\u5f00\u59cb</li> <li>\u5b50\u56fe\u8c03\u7528\uff1a\u4ece\u8c03\u7528\u88ab\u505c\u6b62\u5b50\u56fe\u7684\u7236\u8282\u70b9\u5f00\u59cb</li> <li>Functional API\uff1a\u4ece\u6267\u884c\u505c\u6b62\u7684\u5165\u53e3\u70b9\u5f00\u59cb</li> </ul>"},{"location":"llmapps/langgraph/durable%20execution/#_12","title":"\u5b8c\u6574\u793a\u4f8b","text":"<pre><code>from typing import List, Optional\nfrom typing_extensions import TypedDict\nimport uuid\nfrom langgraph.checkpoint.memory import InMemorySaver\nfrom langgraph.func import task\nfrom langgraph.graph import StateGraph, START, END\nimport requests\n\n# \u5b9a\u4e49\u72b6\u6001\nclass ProcessingState(TypedDict):\n    urls: List[str]\n    results: Optional[List[str]]\n    processed: bool\n\n# \u5305\u88c5API\u8c03\u7528\u4e3a\u4efb\u52a1\n@task\ndef fetch_url_content(url: str):\n    \"\"\"\u83b7\u53d6URL\u5185\u5bb9\"\"\"\n    return requests.get(url).text[:500]\n\ndef process_urls(state: ProcessingState):\n    \"\"\"\u5904\u7406URL\u7684\u8282\u70b9\"\"\"\n    # \u4f7f\u7528\u4efb\u52a1\u5e76\u884c\u5904\u7406URL\n    fetch_tasks = [fetch_url_content(url) for url in state['urls']]\n    results = [task.result() for task in fetch_tasks]\n\n    return {\n        \"results\": results,\n        \"processed\": True\n    }\n\n# \u6784\u5efa\u56fe\nbuilder = StateGraph(ProcessingState)\nbuilder.add_node(\"process_urls\", process_urls)\nbuilder.add_edge(START, \"process_urls\")\nbuilder.add_edge(\"process_urls\", END)\n\n# \u542f\u7528\u6301\u4e45\u5316\ncheckpointer = InMemorySaver()\ngraph = builder.compile(checkpointer=checkpointer)\n\n# \u6267\u884c\u5de5\u4f5c\u6d41\nthread_id = uuid.uuid4()\nconfig = {\"configurable\": {\"thread_id\": thread_id}}\n\ntry:\n    # \u9996\u6b21\u6267\u884c\n    result = graph.invoke({\n        \"urls\": [\"https://example.com\", \"https://example.org\"]\n    }, config)\n    print(\"\u5904\u7406\u5b8c\u6210:\", result)\n\nexcept Exception as e:\n    print(f\"\u6267\u884c\u51fa\u9519: {e}\")\n    # \u4ece\u9519\u8bef\u4e2d\u6062\u590d\n    recovery_result = graph.invoke(None, config)\n    print(\"\u6062\u590d\u540e\u7684\u7ed3\u679c:\", recovery_result)\n</code></pre> <p>\u901a\u8fc7\u9075\u5faa\u672c\u6559\u7a0b\u4e2d\u7684\u6a21\u5f0f\uff0c\u60a8\u53ef\u4ee5\u6784\u5efa\u5065\u58ee\u7684\u3001\u652f\u6301\u6301\u4e45\u5316\u6267\u884c\u7684 LangGraph \u5de5\u4f5c\u6d41\uff0c\u786e\u4fdd\u5728\u4e2d\u65ad\u6216\u9519\u8bef\u540e\u80fd\u591f\u53ef\u9760\u6062\u590d\u3002</p>"},{"location":"llmapps/langgraph/graph%20api%20overview/","title":"LangGraph \u5165\u95e8\u6559\u7a0b\uff1a\u6784\u5efa\u667a\u80fd\u4ee3\u7406\u5de5\u4f5c\u6d41","text":""},{"location":"llmapps/langgraph/graph%20api%20overview/#_1","title":"\u6982\u8ff0","text":"<p>LangGraph \u662f\u4e00\u4e2a\u7528\u4e8e\u6784\u5efa\u667a\u80fd\u4ee3\u7406\u5de5\u4f5c\u6d41\u7684\u6846\u67b6\uff0c\u5b83\u5c06\u5de5\u4f5c\u6d41\u7a0b\u5efa\u6a21\u4e3a\u56fe\u3002\u901a\u8fc7\u5b9a\u4e49\u72b6\u6001\u3001\u8282\u70b9\u548c\u8fb9\uff0c\u4f60\u53ef\u4ee5\u521b\u5efa\u590d\u6742\u3001\u53ef\u5faa\u73af\u7684\u5de5\u4f5c\u6d41\u3002</p>"},{"location":"llmapps/langgraph/graph%20api%20overview/#_2","title":"\u6838\u5fc3\u6982\u5ff5","text":""},{"location":"llmapps/langgraph/graph%20api%20overview/#1","title":"1. \u56fe\u7684\u57fa\u672c\u7ec4\u6210","text":"<p>LangGraph \u5de5\u4f5c\u6d41\u7531\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\u6784\u6210\uff1a</p> <ul> <li>State\uff08\u72b6\u6001\uff09\uff1a\u5171\u4eab\u6570\u636e\u7ed3\u6784\uff0c\u8868\u793a\u5e94\u7528\u7684\u5f53\u524d\u5feb\u7167</li> <li>Nodes\uff08\u8282\u70b9\uff09\uff1a\u6267\u884c\u5177\u4f53\u903b\u8f91\u7684\u51fd\u6570\uff0c\u63a5\u6536\u72b6\u6001\u5e76\u8fd4\u56de\u66f4\u65b0</li> <li>Edges\uff08\u8fb9\uff09\uff1a\u51b3\u5b9a\u4e0b\u4e00\u4e2a\u6267\u884c\u8282\u70b9\u7684\u8def\u7531\u903b\u8f91</li> </ul> <p>\u6838\u5fc3\u539f\u5219\uff1a\u8282\u70b9\u6267\u884c\u5de5\u4f5c\uff0c\u8fb9\u51b3\u5b9a\u4e0b\u4e00\u6b65\u505a\u4ec0\u4e48</p>"},{"location":"llmapps/langgraph/graph%20api%20overview/#_3","title":"\u5feb\u901f\u5f00\u59cb","text":""},{"location":"llmapps/langgraph/graph%20api%20overview/#1_1","title":"\u6b65\u9aa41\uff1a\u5b9a\u4e49\u72b6\u6001","text":"<p>\u9996\u5148\u5b9a\u4e49\u56fe\u7684\u72b6\u6001\u7ed3\u6784\uff0c\u901a\u5e38\u4f7f\u7528 <code>TypedDict</code>\uff1a</p> <pre><code>from typing_extensions import TypedDict\n\nclass State(TypedDict):\n    user_input: str\n    processed_result: str\n    conversation_history: list\n</code></pre>"},{"location":"llmapps/langgraph/graph%20api%20overview/#2","title":"\u6b65\u9aa42\uff1a\u521b\u5efa\u56fe\u6784\u5efa\u5668","text":"<pre><code>from langgraph.graph import StateGraph\n\nbuilder = StateGraph(State)\n</code></pre>"},{"location":"llmapps/langgraph/graph%20api%20overview/#3","title":"\u6b65\u9aa43\uff1a\u6dfb\u52a0\u8282\u70b9","text":"<p>\u8282\u70b9\u662f\u6267\u884c\u5177\u4f53\u5de5\u4f5c\u7684\u51fd\u6570\uff1a</p> <pre><code>def process_input(state: State):\n    # \u5904\u7406\u7528\u6237\u8f93\u5165\n    processed = state[\"user_input\"].upper()\n    return {\"processed_result\": processed}\n\ndef generate_response(state: State):\n    # \u751f\u6210\u54cd\u5e94\n    response = f\"Processed: {state['processed_result']}\"\n    return {\"conversation_history\": [response]}\n\n# \u6dfb\u52a0\u8282\u70b9\u5230\u56fe\u4e2d\nbuilder.add_node(\"process_input\", process_input)\nbuilder.add_node(\"generate_response\", generate_response)\n</code></pre>"},{"location":"llmapps/langgraph/graph%20api%20overview/#4","title":"\u6b65\u9aa44\uff1a\u5b9a\u4e49\u8fb9","text":"<p>\u8fde\u63a5\u8282\u70b9\uff0c\u5b9a\u4e49\u6267\u884c\u6d41\u7a0b\uff1a</p> <pre><code>from langgraph.graph import START, END\n\n# \u8bbe\u7f6e\u5165\u53e3\u70b9\nbuilder.add_edge(START, \"process_input\")\n# \u8fde\u63a5\u5904\u7406\u8282\u70b9\u5230\u54cd\u5e94\u8282\u70b9\nbuilder.add_edge(\"process_input\", \"generate_response\")\n# \u8bbe\u7f6e\u7ed3\u675f\u70b9\nbuilder.add_edge(\"generate_response\", END)\n</code></pre>"},{"location":"llmapps/langgraph/graph%20api%20overview/#5","title":"\u6b65\u9aa45\uff1a\u7f16\u8bd1\u56fe","text":"<p>\u5fc5\u987b\u7f16\u8bd1\u540e\u624d\u80fd\u4f7f\u7528\uff1a</p> <pre><code>graph = builder.compile()\n</code></pre>"},{"location":"llmapps/langgraph/graph%20api%20overview/#6","title":"\u6b65\u9aa46\uff1a\u6267\u884c\u56fe","text":"<pre><code># \u8f93\u5165\u521d\u59cb\u72b6\u6001\nresult = graph.invoke({\"user_input\": \"hello world\"})\nprint(result)\n# \u8f93\u51fa: {'user_input': 'hello world', 'processed_result': 'HELLO WORLD', 'conversation_history': ['Processed: HELLO WORLD']}\n</code></pre>"},{"location":"llmapps/langgraph/graph%20api%20overview/#_4","title":"\u6df1\u5165\u7406\u89e3\u72b6\u6001\u7ba1\u7406","text":""},{"location":"llmapps/langgraph/graph%20api%20overview/#_5","title":"\u72b6\u6001\u5f52\u7ea6\u5668","text":"<p>\u5f52\u7ea6\u5668\u5b9a\u4e49\u5982\u4f55\u66f4\u65b0\u72b6\u6001\uff1a</p> <pre><code>from typing import Annotated\nfrom operator import add\n\nclass State(TypedDict):\n    # \u9ed8\u8ba4\u5f52\u7ea6\u5668\uff1a\u8986\u76d6\u66f4\u65b0\n    current_value: int\n    # \u4f7f\u7528add\u5f52\u7ea6\u5668\uff1a\u8ffd\u52a0\u66f4\u65b0\n    history: Annotated[list, add]\n</code></pre>"},{"location":"llmapps/langgraph/graph%20api%20overview/#_6","title":"\u6d88\u606f\u5904\u7406","text":"<p>\u5904\u7406\u5bf9\u8bdd\u6d88\u606f\u7684\u5e38\u7528\u6a21\u5f0f\uff1a</p> <pre><code>from langchain.messages import AnyMessage\nfrom langgraph.graph.message import add_messages\n\nclass GraphState(TypedDict):\n    messages: Annotated[list[AnyMessage], add_messages]\n</code></pre> <p>\u6216\u8005\u4f7f\u7528\u9884\u5b9a\u4e49\u7684 <code>MessagesState</code>\uff1a</p> <pre><code>from langgraph.graph import MessagesState\n\nclass State(MessagesState):\n    additional_data: str\n</code></pre>"},{"location":"llmapps/langgraph/graph%20api%20overview/#_7","title":"\u9ad8\u7ea7\u8282\u70b9\u529f\u80fd","text":""},{"location":"llmapps/langgraph/graph%20api%20overview/#_8","title":"\u8282\u70b9\u53c2\u6570","text":"<p>\u8282\u70b9\u53ef\u4ee5\u63a5\u6536\u591a\u79cd\u53c2\u6570\uff1a</p> <pre><code>def advanced_node(\n    state: State, \n    config: RunnableConfig, \n    runtime: Runtime\n):\n    print(f\"Thread ID: {config['configurable']['thread_id']}\")\n    # \u6267\u884c\u8282\u70b9\u903b\u8f91\n    return {\"result\": \"success\"}\n</code></pre>"},{"location":"llmapps/langgraph/graph%20api%20overview/#_9","title":"\u8282\u70b9\u7f13\u5b58","text":"<p>\u5bf9\u8ba1\u7b97\u5bc6\u96c6\u578b\u8282\u70b9\u542f\u7528\u7f13\u5b58\uff1a</p> <pre><code>from langgraph.types import CachePolicy\n\n# \u8bbe\u7f6e\u7f13\u5b58\u7b56\u7565\uff08TTL=5\u79d2\uff09\ncache_policy = CachePolicy(ttl=5)\nbuilder.add_node(\"expensive_node\", expensive_function, cache_policy=cache_policy)\n</code></pre>"},{"location":"llmapps/langgraph/graph%20api%20overview/#_10","title":"\u590d\u6742\u8def\u7531\u63a7\u5236","text":""},{"location":"llmapps/langgraph/graph%20api%20overview/#_11","title":"\u6761\u4ef6\u8fb9","text":"<p>\u6839\u636e\u6761\u4ef6\u51b3\u5b9a\u4e0b\u4e00\u4e2a\u8282\u70b9\uff1a</p> <pre><code>def routing_function(state: State):\n    if len(state[\"user_input\"]) &gt; 10:\n        return \"long_input_node\"\n    else:\n        return \"short_input_node\"\n\nbuilder.add_conditional_edges(\"process_input\", routing_function)\n</code></pre>"},{"location":"llmapps/langgraph/graph%20api%20overview/#_12","title":"\u4f7f\u7528\u6620\u5c04\u8868","text":"<pre><code>route_map = {\n    \"long\": \"long_input_node\",\n    \"short\": \"short_input_node\"\n}\nbuilder.add_conditional_edges(\"process_input\", routing_function, route_map)\n</code></pre>"},{"location":"llmapps/langgraph/graph%20api%20overview/#_13","title":"\u9ad8\u7ea7\u7279\u6027","text":""},{"location":"llmapps/langgraph/graph%20api%20overview/#send-api","title":"Send API","text":"<p>\u7528\u4e8e\u52a8\u6001\u751f\u6210\u8fb9\uff08\u5982map-reduce\u6a21\u5f0f\uff09\uff1a</p> <pre><code>from langgraph.types import Send\n\ndef split_and_process(state: State):\n    words = state[\"user_input\"].split()\n    return [Send(\"process_word\", {\"word\": word}) for word in words]\n</code></pre>"},{"location":"llmapps/langgraph/graph%20api%20overview/#command-api","title":"Command API","text":"<p>\u7ed3\u5408\u72b6\u6001\u66f4\u65b0\u548c\u8def\u7531\u63a7\u5236\uff1a</p> <pre><code>from langgraph.types import Command\nfrom typing import Literal\n\ndef smart_node(state: State) -&gt; Command[Literal[\"next_node\"]]:\n    if state[\"value\"] &gt; 100:\n        return Command(\n            update={\"status\": \"high\"},\n            goto=\"handle_high_value\"\n        )\n    else:\n        return Command(\n            update={\"status\": \"low\"}, \n            goto=\"handle_low_value\"\n        )\n</code></pre>"},{"location":"llmapps/langgraph/graph%20api%20overview/#_14","title":"\u8fd0\u884c\u65f6\u914d\u7f6e","text":""},{"location":"llmapps/langgraph/graph%20api%20overview/#_15","title":"\u6dfb\u52a0\u4e0a\u4e0b\u6587","text":"<pre><code>from dataclasses import dataclass\n\n@dataclass\nclass ContextSchema:\n    user_id: str\n    api_key: str\n\ngraph = StateGraph(State, context_schema=ContextSchema)\n\n# \u4f7f\u7528\u4e0a\u4e0b\u6587\ndef context_aware_node(state: State, runtime: Runtime[ContextSchema]):\n    user_id = runtime.context.user_id\n    # \u4f7f\u7528\u4e0a\u4e0b\u6587\u4fe1\u606f\n</code></pre>"},{"location":"llmapps/langgraph/graph%20api%20overview/#_16","title":"\u9012\u5f52\u9650\u5236","text":"<p>\u9632\u6b62\u65e0\u9650\u5faa\u73af\uff1a</p> <pre><code># \u9650\u5236\u6700\u5927\u6267\u884c\u6b65\u6570\nresult = graph.invoke(\n    inputs, \n    config={\"recursion_limit\": 50}\n)\n</code></pre>"},{"location":"llmapps/langgraph/graph%20api%20overview/#_17","title":"\u5b8c\u6574\u793a\u4f8b","text":"<p>\u4e0b\u9762\u662f\u4e00\u4e2a\u5b8c\u6574\u7684\u5bf9\u8bdd\u4ee3\u7406\u793a\u4f8b\uff1a</p> <pre><code>from typing_extensions import TypedDict\nfrom typing import Annotated\nfrom langgraph.graph import StateGraph, MessagesState, add_messages\nfrom langchain.messages import HumanMessage, AIMessage\n\nclass State(MessagesState):\n    needs_clarification: bool = False\n\ndef process_input(state: State):\n    last_message = state[\"messages\"][-1]\n\n    if \"?\" in last_message.content:\n        return {\"needs_clarification\": True}\n    return {\"needs_clarification\": False}\n\ndef generate_clarification(state: State):\n    return {\"messages\": [AIMessage(content=\"Could you please clarify your question?\")]}\n\ndef generate_response(state: State):\n    last_message = state[\"messages\"][-1]\n    response = f\"I understand you said: {last_message.content}\"\n    return {\"messages\": [AIMessage(content=response)]}\n\ndef route_conversation(state: State):\n    if state[\"needs_clarification\"]:\n        return \"generate_clarification\"\n    else:\n        return \"generate_response\"\n\n# \u6784\u5efa\u56fe\nbuilder = StateGraph(State)\nbuilder.add_node(\"process_input\", process_input)\nbuilder.add_node(\"generate_clarification\", generate_clarification)\nbuilder.add_node(\"generate_response\", generate_response)\n\nbuilder.add_edge(START, \"process_input\")\nbuilder.add_conditional_edges(\"process_input\", route_conversation)\nbuilder.add_edge(\"generate_clarification\", END)\nbuilder.add_edge(\"generate_response\", END)\n\ngraph = builder.compile()\n\n# \u4f7f\u7528\u56fe\nresult = graph.invoke({\n    \"messages\": [HumanMessage(content=\"Hello, how are you?\")]\n})\n</code></pre>"},{"location":"llmapps/langgraph/graph%20api%20overview/#_18","title":"\u6700\u4f73\u5b9e\u8df5","text":"<ol> <li>\u72b6\u6001\u8bbe\u8ba1\uff1a\u4fdd\u6301\u72b6\u6001\u7b80\u6d01\uff0c\u53ea\u5305\u542b\u5fc5\u8981\u7684\u6570\u636e</li> <li>\u8282\u70b9\u804c\u8d23\uff1a\u6bcf\u4e2a\u8282\u70b9\u5e94\u8be5\u53ea\u8d1f\u8d23\u4e00\u4e2a\u660e\u786e\u7684\u804c\u8d23</li> <li>\u9519\u8bef\u5904\u7406\uff1a\u5728\u8282\u70b9\u4e2d\u6dfb\u52a0\u9002\u5f53\u7684\u9519\u8bef\u5904\u7406\u903b\u8f91</li> <li>\u6d4b\u8bd5\uff1a\u5bf9\u6bcf\u4e2a\u8282\u70b9\u8fdb\u884c\u5355\u5143\u6d4b\u8bd5\uff0c\u5bf9\u6574\u4e2a\u5de5\u4f5c\u6d41\u8fdb\u884c\u96c6\u6210\u6d4b\u8bd5</li> <li>\u76d1\u63a7\uff1a\u5229\u7528LangGraph\u7684\u8ffd\u8e2a\u529f\u80fd\u76d1\u63a7\u5de5\u4f5c\u6d41\u6267\u884c</li> </ol>"},{"location":"llmapps/langgraph/graph%20api%20overview/#_19","title":"\u603b\u7ed3","text":"<p>LangGraph \u63d0\u4f9b\u4e86\u4e00\u4e2a\u5f3a\u5927\u7684\u6846\u67b6\u6765\u6784\u5efa\u590d\u6742\u7684\u4ee3\u7406\u5de5\u4f5c\u6d41\u3002\u901a\u8fc7\u7406\u89e3\u72b6\u6001\u7ba1\u7406\u3001\u8282\u70b9\u6267\u884c\u548c\u8def\u7531\u63a7\u5236\uff0c\u4f60\u53ef\u4ee5\u521b\u5efa\u9ad8\u6548\u3001\u53ef\u7ef4\u62a4\u7684\u667a\u80fd\u5e94\u7528\u3002\u8bb0\u4f4f\u5173\u952e\u7684\u5de5\u4f5c\u6d41\u7a0b\uff1a\u5b9a\u4e49\u72b6\u6001 \u2192 \u6dfb\u52a0\u8282\u70b9 \u2192 \u8fde\u63a5\u8fb9 \u2192 \u7f16\u8bd1\u6267\u884c\u3002</p> <p>\u5f00\u59cb\u6784\u5efa\u4f60\u7684\u7b2c\u4e00\u4e2aLangGraph\u5de5\u4f5c\u6d41\u5427\uff01</p>"},{"location":"llmapps/langgraph/interrupts/","title":"LangGraph \u4e2d\u65ad\u529f\u80fd\u5b8c\u6574\u6559\u7a0b","text":""},{"location":"llmapps/langgraph/interrupts/#_1","title":"\u4ec0\u4e48\u662f\u4e2d\u65ad\uff1f","text":"<p>\u4e2d\u65ad\uff08Interrupts\uff09\u5141\u8bb8\u4f60\u5728\u56fe\u6267\u884c\u7684\u7279\u5b9a\u70b9\u6682\u505c\uff0c\u5e76\u5728\u7ee7\u7eed\u4e4b\u524d\u7b49\u5f85\u5916\u90e8\u8f93\u5165\u3002\u8fd9\u5b9e\u73b0\u4e86\"\u4eba\u5728\u56de\u8def\"\uff08human-in-the-loop\uff09\u6a21\u5f0f\uff0c\u8ba9\u4f60\u80fd\u591f\u5728\u9700\u8981\u5916\u90e8\u8f93\u5165\u65f6\u6682\u505c\u6267\u884c\u3002</p>"},{"location":"llmapps/langgraph/interrupts/#_2","title":"\u6838\u5fc3\u7279\u6027","text":"<ul> <li>\u52a8\u6001\u4e2d\u65ad\uff1a\u53ef\u4ee5\u5728\u4ee3\u7801\u7684\u4efb\u4f55\u4f4d\u7f6e\u653e\u7f6e\u4e2d\u65ad\uff0c\u5e76\u57fa\u4e8e\u5e94\u7528\u903b\u8f91\u6761\u4ef6\u89e6\u53d1</li> <li>\u72b6\u6001\u6301\u4e45\u5316\uff1a\u89e6\u53d1\u4e2d\u65ad\u65f6\uff0cLangGraph \u4f7f\u7528\u6301\u4e45\u5316\u5c42\u4fdd\u5b58\u56fe\u72b6\u6001</li> <li>\u65e0\u9650\u7b49\u5f85\uff1a\u4e2d\u65ad\u540e\u4f1a\u4e00\u76f4\u7b49\u5f85\uff0c\u76f4\u5230\u4f60\u660e\u786e\u6062\u590d\u6267\u884c</li> </ul>"},{"location":"llmapps/langgraph/interrupts/#_3","title":"\u57fa\u7840\u4f7f\u7528","text":""},{"location":"llmapps/langgraph/interrupts/#_4","title":"\u8bbe\u7f6e\u4e2d\u65ad","text":"<p>\u8981\u4f7f\u7528\u4e2d\u65ad\u529f\u80fd\uff0c\u4f60\u9700\u8981\u4e09\u4e2a\u5173\u952e\u7ec4\u4ef6\uff1a</p> <pre><code>from langgraph.types import interrupt\n\ndef approval_node(state: State):\n    # \u6682\u505c\u6267\u884c\u5e76\u8bf7\u6c42\u6279\u51c6\n    approved = interrupt(\"\u4f60\u662f\u5426\u6279\u51c6\u6b64\u64cd\u4f5c\uff1f\")\n\n    # \u6062\u590d\u65f6\uff0cCommand(resume=...)\u7684\u503c\u4f1a\u5728\u8fd9\u91cc\u8fd4\u56de\n    return {\"approved\": approved}\n</code></pre>"},{"location":"llmapps/langgraph/interrupts/#_5","title":"\u914d\u7f6e\u8981\u6c42","text":"<ol> <li>\u68c0\u67e5\u70b9\u5668\uff08Checkpointer\uff09\uff1a\u7528\u4e8e\u6301\u4e45\u5316\u56fe\u72b6\u6001\uff08\u751f\u4ea7\u73af\u5883\u4f7f\u7528\u6301\u4e45\u5316\u68c0\u67e5\u70b9\u5668\uff09</li> <li>\u7ebf\u7a0bID\uff08thread_id\uff09\uff1a\u5728\u914d\u7f6e\u4e2d\u6307\u5b9a\uff0c\u7528\u4e8e\u6807\u8bc6\u8981\u6062\u590d\u7684\u72b6\u6001</li> <li>JSON\u53ef\u5e8f\u5217\u5316\uff1a\u4f20\u9012\u7ed9 <code>interrupt()</code> \u7684\u503c\u5fc5\u987b\u662f JSON \u53ef\u5e8f\u5217\u5316\u7684</li> </ol>"},{"location":"llmapps/langgraph/interrupts/#_6","title":"\u4e2d\u65ad\u5de5\u4f5c\u6d41\u7a0b","text":""},{"location":"llmapps/langgraph/interrupts/#1","title":"1. \u89e6\u53d1\u4e2d\u65ad","text":"<p>\u5f53\u8c03\u7528 <code>interrupt()</code> \u65f6\uff1a</p> <ol> <li>\u56fe\u6267\u884c\u6682\u505c\uff1a\u5728\u8c03\u7528 <code>interrupt</code> \u7684\u7cbe\u786e\u70b9\u6682\u505c</li> <li>\u72b6\u6001\u4fdd\u5b58\uff1a\u4f7f\u7528\u68c0\u67e5\u70b9\u5668\u4fdd\u5b58\u5f53\u524d\u72b6\u6001</li> <li>\u8fd4\u56de\u503c\uff1a\u4e2d\u65ad\u503c\u901a\u8fc7 <code>__interrupt__</code> \u5b57\u6bb5\u8fd4\u56de\u7ed9\u8c03\u7528\u8005</li> <li>\u65e0\u9650\u7b49\u5f85\uff1a\u56fe\u4f1a\u4e00\u76f4\u7b49\u5f85\uff0c\u76f4\u5230\u4f60\u6062\u590d\u6267\u884c</li> <li>\u503c\u4f20\u9012\uff1a\u6062\u590d\u65f6\u7684\u54cd\u5e94\u503c\u4f1a\u6210\u4e3a <code>interrupt()</code> \u8c03\u7528\u7684\u8fd4\u56de\u503c</li> </ol>"},{"location":"llmapps/langgraph/interrupts/#2","title":"2. \u6062\u590d\u4e2d\u65ad","text":"<pre><code>from langgraph.types import Command\n\n# \u521d\u59cb\u8fd0\u884c - \u9047\u5230\u4e2d\u65ad\u5e76\u6682\u505c\nconfig = {\"configurable\": {\"thread_id\": \"thread-1\"}}\nresult = graph.invoke({\"input\": \"data\"}, config=config)\n\n# \u68c0\u67e5\u4e2d\u65ad\u5185\u5bb9\nprint(result[\"__interrupt__\"])\n# \u8f93\u51fa: [Interrupt(value='\u4f60\u662f\u5426\u6279\u51c6\u6b64\u64cd\u4f5c\uff1f')]\n\n# \u4f7f\u7528\u4eba\u7c7b\u54cd\u5e94\u6062\u590d\u6267\u884c\n# resume \u7684\u503c\u4f1a\u6210\u4e3a\u8282\u70b9\u5185 interrupt() \u7684\u8fd4\u56de\u503c\ngraph.invoke(Command(resume=True), config=config)\n</code></pre> <p>\u6062\u590d\u8981\u70b9\uff1a</p> <ul> <li>\u5fc5\u987b\u4f7f\u7528\u76f8\u540c\u7684\u7ebf\u7a0bID</li> <li><code>Command(resume=...)</code> \u7684\u503c\u6210\u4e3a <code>interrupt()</code> \u7684\u8fd4\u56de\u503c</li> <li>\u8282\u70b9\u4f1a\u4ece\u5934\u5f00\u59cb\u91cd\u65b0\u6267\u884c</li> </ul>"},{"location":"llmapps/langgraph/interrupts/#_7","title":"\u5e38\u89c1\u4f7f\u7528\u6a21\u5f0f","text":""},{"location":"llmapps/langgraph/interrupts/#1_1","title":"1. \u5ba1\u6279\u5de5\u4f5c\u6d41","text":"<p>\u5728\u5173\u952e\u64cd\u4f5c\u524d\u6682\u505c\u5e76\u8bf7\u6c42\u6279\u51c6\uff1a</p> <pre><code>from typing import Literal\nfrom langgraph.types import interrupt, Command\n\ndef approval_node(state: State) -&gt; Command[Literal[\"proceed\", \"cancel\"]]:\n    # \u6682\u505c\u6267\u884c\uff0cpayload \u4f1a\u51fa\u73b0\u5728 result[\"__interrupt__\"] \u4e2d\n    is_approved = interrupt({\n        \"question\": \"\u662f\u5426\u8981\u7ee7\u7eed\u6267\u884c\u6b64\u64cd\u4f5c\uff1f\",\n        \"details\": state[\"action_details\"]\n    })\n\n    # \u57fa\u4e8e\u54cd\u5e94\u8def\u7531\n    if is_approved:\n        return Command(goto=\"proceed\")\n    else:\n        return Command(goto=\"cancel\")\n</code></pre> <p>\u6062\u590d\u65b9\u5f0f\uff1a</p> <pre><code># \u6279\u51c6\ngraph.invoke(Command(resume=True), config=config)\n\n# \u62d2\u7edd\ngraph.invoke(Command(resume=False), config=config)\n</code></pre>"},{"location":"llmapps/langgraph/interrupts/#2_1","title":"2. \u5ba1\u67e5\u548c\u7f16\u8f91\u72b6\u6001","text":"<p>\u8ba9\u4eba\u7c7b\u5728\u7ee7\u7eed\u4e4b\u524d\u5ba1\u67e5\u548c\u7f16\u8f91\u56fe\u72b6\u6001\uff1a</p> <pre><code>def review_node(state: State):\n    # \u6682\u505c\u5e76\u663e\u793a\u5f53\u524d\u5185\u5bb9\u4f9b\u5ba1\u67e5\n    edited_content = interrupt({\n        \"instruction\": \"\u5ba1\u67e5\u5e76\u7f16\u8f91\u6b64\u5185\u5bb9\",\n        \"content\": state[\"generated_text\"]\n    })\n\n    # \u4f7f\u7528\u7f16\u8f91\u540e\u7684\u7248\u672c\u66f4\u65b0\u72b6\u6001\n    return {\"generated_text\": edited_content}\n</code></pre> <p>\u6062\u590d\u65f6\u63d0\u4f9b\u7f16\u8f91\u5185\u5bb9\uff1a</p> <pre><code>graph.invoke(\n    Command(resume=\"\u7f16\u8f91\u548c\u6539\u8fdb\u540e\u7684\u6587\u672c\"),\n    config=config\n)\n</code></pre>"},{"location":"llmapps/langgraph/interrupts/#3","title":"3. \u5728\u5de5\u5177\u4e2d\u4f7f\u7528\u4e2d\u65ad","text":"<p>\u5728\u5de5\u5177\u51fd\u6570\u5185\u90e8\u76f4\u63a5\u653e\u7f6e\u4e2d\u65ad\uff1a</p> <pre><code>from langchain.tools import tool\nfrom langgraph.types import interrupt\n\n@tool\ndef send_email(to: str, subject: str, body: str):\n    \"\"\"\u53d1\u9001\u90ae\u4ef6\u7ed9\u6536\u4ef6\u4eba\"\"\"\n\n    # \u5728\u53d1\u9001\u524d\u6682\u505c\n    response = interrupt({\n        \"action\": \"send_email\",\n        \"to\": to,\n        \"subject\": subject,\n        \"body\": body,\n        \"message\": \"\u662f\u5426\u6279\u51c6\u53d1\u9001\u6b64\u90ae\u4ef6\uff1f\"\n    })\n\n    if response.get(\"action\") == \"approve\":\n        # \u6062\u590d\u503c\u53ef\u4ee5\u5728\u6267\u884c\u524d\u8986\u76d6\u8f93\u5165\n        final_to = response.get(\"to\", to)\n        final_subject = response.get(\"subject\", subject)\n        final_body = response.get(\"body\", body)\n        return f\"\u90ae\u4ef6\u5df2\u53d1\u9001\u81f3 {final_to}\"\n    return \"\u7528\u6237\u53d6\u6d88\u4e86\u90ae\u4ef6\"\n</code></pre>"},{"location":"llmapps/langgraph/interrupts/#4","title":"4. \u9a8c\u8bc1\u4eba\u7c7b\u8f93\u5165","text":"<p>\u4f7f\u7528\u591a\u4e2a <code>interrupt</code> \u8c03\u7528\u6765\u9a8c\u8bc1\u8f93\u5165\uff1a</p> <pre><code>def get_age_node(state: State):\n    prompt = \"\u4f60\u7684\u5e74\u9f84\u662f\u591a\u5c11\uff1f\"\n\n    while True:\n        answer = interrupt(prompt)\n\n        # \u9a8c\u8bc1\u8f93\u5165\n        if isinstance(answer, int) and answer &gt; 0:\n            # \u6709\u6548\u8f93\u5165 - \u7ee7\u7eed\n            break\n        else:\n            # \u65e0\u6548\u8f93\u5165 - \u7528\u66f4\u660e\u786e\u7684\u63d0\u793a\u91cd\u65b0\u8be2\u95ee\n            prompt = f\"'{answer}' \u4e0d\u662f\u6709\u6548\u7684\u5e74\u9f84\u3002\u8bf7\u8f93\u5165\u6b63\u6570\u3002\"\n\n    return {\"age\": answer}\n</code></pre>"},{"location":"llmapps/langgraph/interrupts/#_8","title":"\u4e2d\u65ad\u7684\u91cd\u8981\u89c4\u5219","text":""},{"location":"llmapps/langgraph/interrupts/#1-interrupt-tryexcept","title":"1. \u4e0d\u8981\u5c06 <code>interrupt</code> \u8c03\u7528\u5305\u88f9\u5728 try/except \u4e2d","text":"<p>\u2705 \u6b63\u786e\u505a\u6cd5\uff1a</p> <pre><code>def node_a(state: State):\n    # \u5148\u5904\u7406\u4e2d\u65ad\uff0c\u518d\u5355\u72ec\u5904\u7406\u9519\u8bef\u6761\u4ef6\n    interrupt(\"\u4f60\u7684\u540d\u5b57\u662f\u4ec0\u4e48\uff1f\")\n    try:\n        fetch_data()  # \u8fd9\u91cc\u53ef\u80fd\u5931\u8d25\n    except Exception as e:\n        print(e)\n    return state\n</code></pre> <p>\u274c \u9519\u8bef\u505a\u6cd5\uff1a</p> <pre><code>def node_a(state: State):\n    try:\n        interrupt(\"\u4f60\u7684\u540d\u5b57\u662f\u4ec0\u4e48\uff1f\")\n    except Exception as e:\n        print(e)  # \u8fd9\u4f1a\u6355\u83b7\u4e2d\u65ad\u5f02\u5e38\uff01\n    return state\n</code></pre>"},{"location":"llmapps/langgraph/interrupts/#2-interrupt","title":"2. \u4e0d\u8981\u5728\u8282\u70b9\u5185\u91cd\u65b0\u6392\u5e8f <code>interrupt</code> \u8c03\u7528","text":"<p>\u2705 \u6b63\u786e\u505a\u6cd5 - \u4fdd\u6301\u4e00\u81f4\u7684\u8c03\u7528\u987a\u5e8f\uff1a</p> <pre><code>def node_a(state: State):\n    name = interrupt(\"\u4f60\u7684\u540d\u5b57\uff1f\")\n    age = interrupt(\"\u4f60\u7684\u5e74\u9f84\uff1f\")\n    city = interrupt(\"\u4f60\u7684\u57ce\u5e02\uff1f\")\n    return {\"name\": name, \"age\": age, \"city\": city}\n</code></pre> <p>\u274c \u9519\u8bef\u505a\u6cd5 - \u6761\u4ef6\u6027\u8df3\u8fc7\u4e2d\u65ad\uff1a</p> <pre><code>def node_a(state: State):\n    name = interrupt(\"\u4f60\u7684\u540d\u5b57\uff1f\")\n\n    # \u7b2c\u4e00\u6b21\u8fd0\u884c\u53ef\u80fd\u8df3\u8fc7\u6b64\u4e2d\u65ad\n    # \u6062\u590d\u65f6\u53ef\u80fd\u4e0d\u4f1a\u8df3\u8fc7 - \u5bfc\u81f4\u7d22\u5f15\u4e0d\u5339\u914d\n    if state.get(\"needs_age\"):\n        age = interrupt(\"\u4f60\u7684\u5e74\u9f84\uff1f\")\n\n    city = interrupt(\"\u4f60\u7684\u57ce\u5e02\uff1f\")\n    return {\"name\": name, \"city\": city}\n</code></pre>"},{"location":"llmapps/langgraph/interrupts/#3-interrupt","title":"3. \u4e0d\u8981\u5728 <code>interrupt</code> \u8c03\u7528\u4e2d\u4f20\u9012\u590d\u6742\u503c","text":"<p>\u2705 \u6b63\u786e\u505a\u6cd5 - \u4f7f\u7528\u7b80\u5355\u53ef\u5e8f\u5217\u5316\u7c7b\u578b\uff1a</p> <pre><code>def node_a(state: State):\n    # \u4f20\u9012\u7b80\u5355\u7c7b\u578b\n    name = interrupt(\"\u4f60\u7684\u540d\u5b57\uff1f\")\n\n    # \u4f20\u9012\u5305\u542b\u7b80\u5355\u503c\u7684\u5b57\u5178\n    response = interrupt({\n        \"question\": \"\u8f93\u5165\u7528\u6237\u8be6\u60c5\",\n        \"fields\": [\"name\", \"email\", \"age\"]\n    })\n    return {\"user\": response}\n</code></pre> <p>\u274c \u9519\u8bef\u505a\u6cd5 - \u4f20\u9012\u590d\u6742\u5bf9\u8c61\uff1a</p> <pre><code>def node_a(state: State):\n    class DataProcessor:\n        def __init__(self, config):\n            self.config = config\n\n    processor = DataProcessor({\"mode\": \"strict\"})\n\n    # \u8fd9\u4f1a\u5931\u8d25\uff0c\u56e0\u4e3a\u5b9e\u4f8b\u65e0\u6cd5\u5e8f\u5217\u5316\n    response = interrupt({\n        \"question\": \"\u8f93\u5165\u8981\u5904\u7406\u7684\u6570\u636e\",\n        \"processor\": processor  # \u65e0\u6cd5\u5e8f\u5217\u5316\uff01\n    })\n    return {\"result\": response}\n</code></pre>"},{"location":"llmapps/langgraph/interrupts/#4-interrupt","title":"4. <code>interrupt</code> \u8c03\u7528\u524d\u7684\u526f\u4f5c\u7528\u5fc5\u987b\u662f\u5e42\u7b49\u7684","text":"<p>\u2705 \u6b63\u786e\u505a\u6cd5 - \u4f7f\u7528\u5e42\u7b49\u64cd\u4f5c\u6216\u5728\u4e2d\u65ad\u540e\u6267\u884c\u526f\u4f5c\u7528\uff1a</p> <pre><code>def node_a(state: State):\n    # \u2705 \u4f7f\u7528\u5e42\u7b49\u7684 upsert \u64cd\u4f5c\n    db.upsert_user(user_id=state[\"user_id\"], status=\"pending_approval\")\n\n    approved = interrupt(\"\u662f\u5426\u6279\u51c6\u6b64\u66f4\u6539\uff1f\")\n\n    # \u2705 \u526f\u4f5c\u7528\u653e\u5728\u4e2d\u65ad\u4e4b\u540e\n    if approved:\n        db.create_audit_log(user_id=state[\"user_id\"], action=\"approved\")\n\n    return {\"approved\": approved}\n</code></pre> <p>\u274c \u9519\u8bef\u505a\u6cd5 - \u5728\u4e2d\u65ad\u524d\u6267\u884c\u975e\u5e42\u7b49\u64cd\u4f5c\uff1a</p> <pre><code>def node_a(state: State):\n    # \u274c \u5728\u4e2d\u65ad\u524d\u521b\u5efa\u65b0\u8bb0\u5f55\n    # \u6bcf\u6b21\u6062\u590d\u90fd\u4f1a\u521b\u5efa\u91cd\u590d\u8bb0\u5f55\n    audit_id = db.create_audit_log({\n        \"user_id\": state[\"user_id\"],\n        \"action\": \"pending_approval\"\n    })\n\n    approved = interrupt(\"\u662f\u5426\u6279\u51c6\u6b64\u66f4\u6539\uff1f\")\n    return {\"approved\": approved, \"audit_id\": audit_id}\n</code></pre>"},{"location":"llmapps/langgraph/interrupts/#_9","title":"\u8c03\u8bd5\u6280\u5de7","text":""},{"location":"llmapps/langgraph/interrupts/#_10","title":"\u4f7f\u7528\u9759\u6001\u4e2d\u65ad\u4f5c\u4e3a\u65ad\u70b9","text":"<p>\u5728\u7f16\u8bd1\u65f6\u8bbe\u7f6e\u65ad\u70b9\uff1a</p> <pre><code>graph = builder.compile(\n    interrupt_before=[\"node_a\"],      # \u5728\u8282\u70b9\u6267\u884c\u524d\u6682\u505c\n    interrupt_after=[\"node_b\", \"node_c\"],  # \u5728\u8282\u70b9\u6267\u884c\u540e\u6682\u505c\n    checkpointer=checkpointer,\n)\n\n# \u8fd0\u884c\u5230\u7b2c\u4e00\u4e2a\u65ad\u70b9\ngraph.invoke(inputs, config=config)\n\n# \u7ee7\u7eed\u6267\u884c\u5230\u4e0b\u4e00\u4e2a\u65ad\u70b9\ngraph.invoke(None, config=config)\n</code></pre> <p>\u5728\u8fd0\u884c\u65f6\u8bbe\u7f6e\u65ad\u70b9\uff1a</p> <pre><code>graph.invoke(\n    inputs,\n    interrupt_before=[\"node_a\"],\n    interrupt_after=[\"node_b\", \"node_c\"],\n    config=config,\n)\n</code></pre>"},{"location":"llmapps/langgraph/interrupts/#langgraph-studio","title":"\u4f7f\u7528 LangGraph Studio","text":"<p>\u4f60\u53ef\u4ee5\u4f7f\u7528 LangGraph Studio \u5728 UI \u4e2d\u8bbe\u7f6e\u9759\u6001\u4e2d\u65ad\uff0c\u5e76\u5728\u6267\u884c\u8fc7\u7a0b\u4e2d\u968f\u65f6\u68c0\u67e5\u56fe\u72b6\u6001\u3002</p>"},{"location":"llmapps/langgraph/interrupts/#_11","title":"\u603b\u7ed3","text":"<p>\u4e2d\u65ad\u529f\u80fd\u4e3a LangGraph \u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u4eba\u673a\u534f\u4f5c\u80fd\u529b\u3002\u5173\u952e\u8981\u70b9\uff1a</p> <ol> <li>\u52a8\u6001\u63a7\u5236\uff1a\u53ef\u4ee5\u5728\u4ee3\u7801\u7684\u4efb\u4f55\u4f4d\u7f6e\u6761\u4ef6\u6027\u5730\u89e6\u53d1\u4e2d\u65ad</li> <li>\u72b6\u6001\u6301\u4e45\u5316\uff1a\u4e2d\u65ad\u72b6\u6001\u4f1a\u88ab\u5b89\u5168\u4fdd\u5b58\uff0c\u652f\u6301\u957f\u65f6\u95f4\u6682\u505c</li> <li>\u7075\u6d3b\u6062\u590d\uff1a\u6062\u590d\u65f6\u53ef\u4ee5\u4f20\u9012\u4efb\u610f JSON \u53ef\u5e8f\u5217\u5316\u7684\u503c</li> <li>\u6a21\u5f0f\u4e30\u5bcc\uff1a\u652f\u6301\u5ba1\u6279\u3001\u5ba1\u67e5\u3001\u9a8c\u8bc1\u7b49\u591a\u79cd\u4eba\u673a\u4ea4\u4e92\u6a21\u5f0f</li> <li>\u9075\u5faa\u89c4\u5219\uff1a\u6ce8\u610f\u4e2d\u65ad\u7684\u4f7f\u7528\u89c4\u5219\uff0c\u907f\u514d\u5e38\u89c1\u9677\u9631</li> </ol> <p>\u901a\u8fc7\u5408\u7406\u4f7f\u7528\u4e2d\u65ad\uff0c\u4f60\u53ef\u4ee5\u6784\u5efa\u51fa\u66f4\u52a0\u7075\u6d3b\u3001\u5b89\u5168\u3001\u53ef\u63a7\u7684 AI \u5e94\u7528\u7cfb\u7edf\u3002</p>"},{"location":"llmapps/langgraph/memory/","title":"LangGraph \u5185\u5b58\u7ba1\u7406\u5b8c\u6574\u6559\u7a0b","text":""},{"location":"llmapps/langgraph/memory/#_1","title":"\u6982\u8ff0","text":"<p>\u5728AI\u5e94\u7528\u4e2d\uff0c\u5185\u5b58\uff08Memory\uff09\u662f\u5b9e\u73b0\u591a\u8f6e\u5bf9\u8bdd\u548c\u4e0a\u4e0b\u6587\u5171\u4eab\u7684\u5173\u952e\u7ec4\u4ef6\u3002LangGraph\u63d0\u4f9b\u4e86\u4e24\u79cd\u7c7b\u578b\u7684\u5185\u5b58\u7ba1\u7406\uff1a</p> <ul> <li>\u77ed\u671f\u5185\u5b58\uff1a\u7528\u4e8e\u8ddf\u8e2a\u591a\u8f6e\u5bf9\u8bdd\u7684\u7ebf\u7a0b\u7ea7\u6301\u4e45\u5316</li> <li>\u957f\u671f\u5185\u5b58\uff1a\u7528\u4e8e\u8de8\u4f1a\u8bdd\u5b58\u50a8\u7528\u6237\u7279\u5b9a\u6216\u5e94\u7528\u7ea7\u522b\u7684\u6570\u636e</li> </ul>"},{"location":"llmapps/langgraph/memory/#_2","title":"\u77ed\u671f\u5185\u5b58\u914d\u7f6e","text":""},{"location":"llmapps/langgraph/memory/#_3","title":"\u57fa\u7840\u914d\u7f6e","text":"<pre><code>from langgraph.checkpoint.memory import InMemorySaver\nfrom langgraph.graph import StateGraph\n\n# \u521b\u5efa\u5185\u5b58\u68c0\u67e5\u70b9\u4fdd\u5b58\u5668\ncheckpointer = InMemorySaver()\n\n# \u6784\u5efa\u56fe\u5e76\u914d\u7f6e\u68c0\u67e5\u70b9\nbuilder = StateGraph(...)\ngraph = builder.compile(checkpointer=checkpointer)\n\n# \u4f7f\u7528\u7ebf\u7a0bID\u8c03\u7528\u56fe\ngraph.invoke(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"hi! i am Bob\"}]},\n    {\"configurable\": {\"thread_id\": \"1\"}},\n)\n</code></pre>"},{"location":"llmapps/langgraph/memory/#_4","title":"\u751f\u4ea7\u73af\u5883\u914d\u7f6e","text":"<p>\u5728\u751f\u4ea7\u73af\u5883\u4e2d\uff0c\u5efa\u8bae\u4f7f\u7528\u6570\u636e\u5e93\u652f\u6301\u7684\u68c0\u67e5\u70b9\uff1a</p> <pre><code>from langgraph.checkpoint.postgres import PostgresSaver\n\nDB_URI = \"postgresql://postgres:postgres@localhost:5442/postgres?sslmode=disable\"\nwith PostgresSaver.from_conn_string(DB_URI) as checkpointer:\n    builder = StateGraph(...)\n    graph = builder.compile(checkpointer=checkpointer)\n</code></pre>"},{"location":"llmapps/langgraph/memory/#postgresql","title":"PostgreSQL \u793a\u4f8b","text":"<pre><code>pip install -U \"psycopg[binary,pool]\" langgraph langgraph-checkpoint-postgres\n</code></pre> <p>\u540c\u6b65\u7248\u672c\uff1a</p> <pre><code>from langchain.chat_models import init_chat_model\nfrom langgraph.graph import StateGraph, MessagesState, START\nfrom langgraph.checkpoint.postgres import PostgresSaver\n\nmodel = init_chat_model(model=\"anthropic:claude-3-5-haiku-latest\")\n\nDB_URI = \"postgresql://postgres:postgres@localhost:5442/postgres?sslmode=disable\"\nwith PostgresSaver.from_conn_string(DB_URI) as checkpointer:\n    # \u9996\u6b21\u4f7f\u7528\u65f6\u9700\u8981\u8bbe\u7f6e\uff1acheckpointer.setup()\n\n    def call_model(state: MessagesState):\n        response = model.invoke(state[\"messages\"])\n        return {\"messages\": response}\n\n    builder = StateGraph(MessagesState)\n    builder.add_node(call_model)\n    builder.add_edge(START, \"call_model\")\n\n    graph = builder.compile(checkpointer=checkpointer)\n\n    config = {\"configurable\": {\"thread_id\": \"1\"}}\n\n    # \u591a\u8f6e\u5bf9\u8bdd\u793a\u4f8b\n    for chunk in graph.stream(\n        {\"messages\": [{\"role\": \"user\", \"content\": \"hi! I'm bob\"}]},\n        config,\n        stream_mode=\"values\"\n    ):\n        chunk[\"messages\"][-1].pretty_print()\n\n    for chunk in graph.stream(\n        {\"messages\": [{\"role\": \"user\", \"content\": \"what's my name?\"}]},\n        config,\n        stream_mode=\"values\"\n    ):\n        chunk[\"messages\"][-1].pretty_print()\n</code></pre>"},{"location":"llmapps/langgraph/memory/#mongodb","title":"MongoDB \u793a\u4f8b","text":"<pre><code>pip install -U pymongo langgraph langgraph-checkpoint-mongodb\n</code></pre> <pre><code>from langgraph.checkpoint.mongodb import MongoDBSaver\n\nDB_URI = \"localhost:27017\"\nwith MongoDBSaver.from_conn_string(DB_URI) as checkpointer:\n    # \u914d\u7f6e\u56fe...\n</code></pre>"},{"location":"llmapps/langgraph/memory/#redis","title":"Redis \u793a\u4f8b","text":"<pre><code>pip install -U langgraph langgraph-checkpoint-redis\n</code></pre> <pre><code>from langgraph.checkpoint.redis import RedisSaver\n\nDB_URI = \"redis://localhost:6379\"\nwith RedisSaver.from_conn_string(DB_URI) as checkpointer:\n    # \u9996\u6b21\u4f7f\u7528\u65f6\u9700\u8981\u8bbe\u7f6e\uff1acheckpointer.setup()\n    # \u914d\u7f6e\u56fe...\n</code></pre>"},{"location":"llmapps/langgraph/memory/#_5","title":"\u5728\u5b50\u56fe\u4e2d\u4f7f\u7528\u5185\u5b58","text":"<p>\u5982\u679c\u56fe\u4e2d\u5305\u542b\u5b50\u56fe\uff0c\u53ea\u9700\u5728\u7236\u56fe\u7f16\u8bd1\u65f6\u63d0\u4f9b\u68c0\u67e5\u70b9\uff0cLangGraph\u4f1a\u81ea\u52a8\u4f20\u64ad\u5230\u5b50\u56fe\uff1a</p> <pre><code>from langgraph.graph import START, StateGraph\nfrom langgraph.checkpoint.memory import InMemorySaver\nfrom typing import TypedDict\n\nclass State(TypedDict):\n    foo: str\n\n# \u5b50\u56fe\u914d\u7f6e\ndef subgraph_node_1(state: State):\n    return {\"foo\": state[\"foo\"] + \"bar\"}\n\nsubgraph_builder = StateGraph(State)\nsubgraph_builder.add_node(subgraph_node_1)\nsubgraph_builder.add_edge(START, \"subgraph_node_1\")\nsubgraph = subgraph_builder.compile()\n\n# \u7236\u56fe\u914d\u7f6e\nbuilder = StateGraph(State)\nbuilder.add_node(\"node_1\", subgraph)\nbuilder.add_edge(START, \"node_1\")\n\ncheckpointer = InMemorySaver()\ngraph = builder.compile(checkpointer=checkpointer)\n</code></pre> <p>\u5982\u679c\u5e0c\u671b\u5b50\u56fe\u62e5\u6709\u72ec\u7acb\u5185\u5b58\uff1a</p> <pre><code>subgraph_builder = StateGraph(...)\nsubgraph = subgraph_builder.compile(checkpointer=True)\n</code></pre>"},{"location":"llmapps/langgraph/memory/#_6","title":"\u957f\u671f\u5185\u5b58\u914d\u7f6e","text":""},{"location":"llmapps/langgraph/memory/#_7","title":"\u57fa\u7840\u914d\u7f6e","text":"<pre><code>from langgraph.store.memory import InMemoryStore\nfrom langgraph.graph import StateGraph\n\nstore = InMemoryStore()\n\nbuilder = StateGraph(...)\ngraph = builder.compile(store=store)\n</code></pre>"},{"location":"llmapps/langgraph/memory/#_8","title":"\u751f\u4ea7\u73af\u5883\u914d\u7f6e","text":"<pre><code>from langgraph.store.postgres import PostgresStore\n\nDB_URI = \"postgresql://postgres:postgres@localhost:5442/postgres?sslmode=disable\"\nwith PostgresStore.from_conn_string(DB_URI) as store:\n    builder = StateGraph(...)\n    graph = builder.compile(store=store)\n</code></pre>"},{"location":"llmapps/langgraph/memory/#postgresql_1","title":"PostgreSQL \u5b58\u50a8\u793a\u4f8b","text":"<pre><code>from langchain_core.runnables import RunnableConfig\nfrom langchain.chat_models import init_chat_model\nfrom langgraph.graph import StateGraph, MessagesState, START\nfrom langgraph.checkpoint.postgres import PostgresSaver\nfrom langgraph.store.postgres import PostgresStore\nfrom langgraph.store.base import BaseStore\nimport uuid\n\nmodel = init_chat_model(model=\"anthropic:claude-3-5-haiku-latest\")\n\nDB_URI = \"postgresql://postgres:postgres@localhost:5442/postgres?sslmode=disable\"\n\nwith (\n    PostgresStore.from_conn_string(DB_URI) as store,\n    PostgresSaver.from_conn_string(DB_URI) as checkpointer,\n):\n    # store.setup()  # \u9996\u6b21\u4f7f\u7528\u65f6\u9700\u8981\u8bbe\u7f6e\n    # checkpointer.setup()\n\n    def call_model(\n        state: MessagesState,\n        config: RunnableConfig,\n        *,\n        store: BaseStore,\n    ):\n        user_id = config[\"configurable\"][\"user_id\"]\n        namespace = (\"memories\", user_id)\n\n        # \u641c\u7d22\u76f8\u5173\u8bb0\u5fc6\n        memories = store.search(namespace, query=str(state[\"messages\"][-1].content))\n        info = \"\\n\".join([d.value[\"data\"] for d in memories])\n        system_msg = f\"You are a helpful assistant talking to the user. User info: {info}\"\n\n        # \u5982\u679c\u7528\u6237\u8981\u6c42\u8bb0\u4f4f\uff0c\u5b58\u50a8\u65b0\u8bb0\u5fc6\n        last_message = state[\"messages\"][-1]\n        if \"remember\" in last_message.content.lower():\n            memory = \"User name is Bob\"\n            store.put(namespace, str(uuid.uuid4()), {\"data\": memory})\n\n        response = model.invoke(\n            [{\"role\": \"system\", \"content\": system_msg}] + state[\"messages\"]\n        )\n        return {\"messages\": response}\n\n    builder = StateGraph(MessagesState)\n    builder.add_node(call_model)\n    builder.add_edge(START, \"call_model\")\n\n    graph = builder.compile(\n        checkpointer=checkpointer,\n        store=store,\n    )\n\n    # \u8de8\u7ebf\u7a0b\u5171\u4eab\u7528\u6237\u8bb0\u5fc6\n    config1 = {\"configurable\": {\"thread_id\": \"1\", \"user_id\": \"1\"}}\n    config2 = {\"configurable\": {\"thread_id\": \"2\", \"user_id\": \"1\"}}\n</code></pre>"},{"location":"llmapps/langgraph/memory/#_9","title":"\u8bed\u4e49\u641c\u7d22","text":"<p>\u542f\u7528\u8bed\u4e49\u641c\u7d22\u529f\u80fd\uff1a</p> <pre><code>from langchain.embeddings import init_embeddings\nfrom langgraph.store.memory import InMemoryStore\n\n# \u521b\u5efa\u652f\u6301\u8bed\u4e49\u641c\u7d22\u7684\u5b58\u50a8\nembeddings = init_embeddings(\"openai:text-embedding-3-small\")\nstore = InMemoryStore(\n    index={\n        \"embed\": embeddings,\n        \"dims\": 1536,\n    }\n)\n\n# \u5b58\u50a8\u6570\u636e\nstore.put((\"user_123\", \"memories\"), \"1\", {\"text\": \"I love pizza\"})\nstore.put((\"user_123\", \"memories\"), \"2\", {\"text\": \"I am a plumber\"})\n\n# \u8bed\u4e49\u641c\u7d22\nitems = store.search(\n    (\"user_123\", \"memories\"), query=\"I'm hungry\", limit=1\n)\n</code></pre>"},{"location":"llmapps/langgraph/memory/#_10","title":"\u77ed\u671f\u5185\u5b58\u7ba1\u7406\u7b56\u7565","text":""},{"location":"llmapps/langgraph/memory/#_11","title":"\u6d88\u606f\u4fee\u526a","text":"<p>\u5f53\u5bf9\u8bdd\u5386\u53f2\u8d85\u8fc7LLM\u4e0a\u4e0b\u6587\u7a97\u53e3\u65f6\uff0c\u53ef\u4ee5\u4fee\u526a\u6d88\u606f\uff1a</p> <pre><code>from langchain_core.messages.utils import trim_messages, count_tokens_approximately\n\ndef call_model(state: MessagesState):\n    messages = trim_messages(\n        state[\"messages\"],\n        strategy=\"last\",  # \u4fdd\u7559\u6700\u540e\u7684\u6d88\u606f\n        token_counter=count_tokens_approximately,\n        max_tokens=128,   # \u6700\u5927token\u6570\n        start_on=\"human\",\n        end_on=(\"human\", \"tool\"),\n    )\n    response = model.invoke(messages)\n    return {\"messages\": [response]}\n</code></pre>"},{"location":"llmapps/langgraph/memory/#_12","title":"\u6d88\u606f\u5220\u9664","text":"<p>\u5220\u9664\u7279\u5b9a\u6d88\u606f\uff1a</p> <pre><code>from langchain.messages import RemoveMessage\n\ndef delete_messages(state):\n    messages = state[\"messages\"]\n    if len(messages) &gt; 2:\n        # \u5220\u9664\u6700\u65e9\u7684\u4e24\u6761\u6d88\u606f\n        return {\"messages\": [RemoveMessage(id=m.id) for m in messages[:2]]}\n</code></pre> <p>\u5220\u9664\u6240\u6709\u6d88\u606f\uff1a</p> <pre><code>from langgraph.graph.message import REMOVE_ALL_MESSAGES\n\ndef delete_all_messages(state):\n    return {\"messages\": [RemoveMessage(id=REMOVE_ALL_MESSAGES)]}\n</code></pre>"},{"location":"llmapps/langgraph/memory/#_13","title":"\u6d88\u606f\u6458\u8981","text":"<p>\u4f7f\u7528\u6458\u8981\u6765\u538b\u7f29\u5bf9\u8bdd\u5386\u53f2\uff1a</p> <pre><code>from typing import Any, TypedDict\nfrom langchain.messages import AnyMessage\nfrom langgraph.graph import StateGraph, START, MessagesState\nfrom langmem.short_term import SummarizationNode, RunningSummary\n\nclass State(MessagesState):\n    context: dict[str, RunningSummary]\n\nsummarization_node = SummarizationNode(\n    token_counter=count_tokens_approximately,\n    model=summarization_model,\n    max_tokens=256,\n    max_tokens_before_summary=256,\n    max_summary_tokens=128,\n)\n\n# \u5728\u56fe\u4e2d\u4f7f\u7528\u6458\u8981\u8282\u70b9\nbuilder = StateGraph(State)\nbuilder.add_node(call_model)\nbuilder.add_node(\"summarize\", summarization_node)\nbuilder.add_edge(START, \"summarize\")\nbuilder.add_edge(\"summarize\", \"call_model\")\n</code></pre>"},{"location":"llmapps/langgraph/memory/#_14","title":"\u68c0\u67e5\u70b9\u7ba1\u7406","text":""},{"location":"llmapps/langgraph/memory/#_15","title":"\u67e5\u770b\u7ebf\u7a0b\u72b6\u6001","text":"<pre><code>config = {\"configurable\": {\"thread_id\": \"1\"}}\n\n# \u4f7f\u7528\u56feAPI\nstate_snapshot = graph.get_state(config)\n\n# \u4f7f\u7528\u68c0\u67e5\u70b9API\ncheckpoint_tuple = checkpointer.get_tuple(config)\n</code></pre>"},{"location":"llmapps/langgraph/memory/#_16","title":"\u67e5\u770b\u7ebf\u7a0b\u5386\u53f2","text":"<pre><code>config = {\"configurable\": {\"thread_id\": \"1\"}}\n\n# \u83b7\u53d6\u72b6\u6001\u5386\u53f2\nhistory = list(graph.get_state_history(config))\n\n# \u83b7\u53d6\u68c0\u67e5\u70b9\u5386\u53f2\ncheckpoints = list(checkpointer.list(config))\n</code></pre>"},{"location":"llmapps/langgraph/memory/#_17","title":"\u5220\u9664\u7ebf\u7a0b\u68c0\u67e5\u70b9","text":"<pre><code>thread_id = \"1\"\ncheckpointer.delete_thread(thread_id)\n</code></pre>"},{"location":"llmapps/langgraph/memory/#_18","title":"\u6700\u4f73\u5b9e\u8df5","text":"<ol> <li>\u751f\u4ea7\u73af\u5883\uff1a\u59cb\u7ec8\u4f7f\u7528\u6570\u636e\u5e93\u652f\u6301\u7684\u68c0\u67e5\u70b9\u548c\u5b58\u50a8</li> <li>\u5185\u5b58\u7ba1\u7406\uff1a\u6839\u636e\u5bf9\u8bdd\u957f\u5ea6\u9009\u62e9\u5408\u9002\u7684\u7b56\u7565\uff08\u4fee\u526a\u3001\u5220\u9664\u6216\u6458\u8981\uff09</li> <li>\u9519\u8bef\u5904\u7406\uff1a\u786e\u4fdd\u6d88\u606f\u5220\u9664\u540e\u7684\u5386\u53f2\u4ecd\u7136\u6709\u6548</li> <li>\u6027\u80fd\u4f18\u5316\uff1a\u4f7f\u7528\u8bed\u4e49\u641c\u7d22\u63d0\u9ad8\u957f\u671f\u5185\u5b58\u7684\u68c0\u7d22\u6548\u7387</li> <li>\u591a\u79df\u6237\uff1a\u4f7f\u7528\u4e0d\u540c\u7684\u547d\u540d\u7a7a\u95f4\u9694\u79bb\u4e0d\u540c\u7528\u6237\u7684\u6570\u636e</li> </ol>"},{"location":"llmapps/langgraph/memory/#_19","title":"\u9884\u6784\u5efa\u5185\u5b58\u5de5\u5177","text":"<p>LangMem\u662fLangChain\u7ef4\u62a4\u7684\u5e93\uff0c\u63d0\u4f9b\u4e86\u7ba1\u7406\u957f\u671f\u8bb0\u5fc6\u7684\u5de5\u5177\u3002\u53c2\u8003LangMem\u6587\u6863\u83b7\u53d6\u66f4\u591a\u4f7f\u7528\u793a\u4f8b\u3002</p> <p>\u901a\u8fc7\u5408\u7406\u914d\u7f6e\u77ed\u671f\u548c\u957f\u671f\u5185\u5b58\uff0c\u53ef\u4ee5\u6784\u5efa\u51fa\u80fd\u591f\u8fdb\u884c\u590d\u6742\u591a\u8f6e\u5bf9\u8bdd\u5e76\u4fdd\u6301\u4e0a\u4e0b\u6587\u8fde\u8d2f\u6027\u7684AI\u5e94\u7528\u3002</p>"},{"location":"llmapps/langgraph/overview/","title":"LangGraph \u5b8c\u5168\u5165\u95e8\u6559\u7a0b","text":""},{"location":"llmapps/langgraph/overview/#langgraph_1","title":"\u4ec0\u4e48\u662f LangGraph\uff1f","text":"<p>LangGraph \u662f\u4e00\u4e2a\u4f4e\u7ea7\u522b\u7684\u7f16\u6392\u6846\u67b6\u548c\u8fd0\u884c\u65f6\uff0c\u4e13\u95e8\u7528\u4e8e\u6784\u5efa\u3001\u7ba1\u7406\u548c\u90e8\u7f72\u957f\u65f6\u95f4\u8fd0\u884c\u7684\u6709\u72b6\u6001\u667a\u80fd\u4f53\u3002\u5b83\u88ab Klarna\u3001Replit\u3001Elastic \u7b49\u9886\u5148\u516c\u53f8\u5e7f\u6cdb\u4f7f\u7528\uff0c\u4e13\u6ce8\u4e8e\u667a\u80fd\u4f53\u7684\u7f16\u6392\u6838\u5fc3\u80fd\u529b\u3002</p> <p>\u91cd\u8981\u901a\u77e5: LangGraph v1.0 \u5df2\u6b63\u5f0f\u53d1\u5e03\uff01\u5982\u9700\u67e5\u770b\u5b8c\u6574\u53d8\u66f4\u5217\u8868\u548c\u5347\u7ea7\u6307\u5357\u3002</p>"},{"location":"llmapps/langgraph/overview/#_1","title":"\u6838\u5fc3\u4f18\u52bf","text":""},{"location":"llmapps/langgraph/overview/#durable-execution","title":"\ud83d\udee1\ufe0f \u6301\u4e45\u6267\u884c (Durable Execution)","text":"<p>\u6784\u5efa\u80fd\u591f\u4ece\u6545\u969c\u4e2d\u6062\u590d\u5e76\u957f\u671f\u8fd0\u884c\u7684\u667a\u80fd\u4f53\uff0c\u652f\u6301\u4ece\u4e2d\u65ad\u5904\u7ee7\u7eed\u6267\u884c\u3002</p>"},{"location":"llmapps/langgraph/overview/#human-in-the-loop","title":"\ud83d\udc65 \u4eba\u5de5\u5e72\u9884 (Human-in-the-loop)","text":"<p>\u5728\u4efb\u4f55\u65f6\u95f4\u70b9\u68c0\u67e5\u548c\u4fee\u6539\u667a\u80fd\u4f53\u72b6\u6001\uff0c\u5b9e\u73b0\u4eba\u5de5\u76d1\u7763\u3002</p>"},{"location":"llmapps/langgraph/overview/#comprehensive-memory","title":"\ud83e\udde0 \u5168\u9762\u8bb0\u5fc6\u7cfb\u7edf (Comprehensive Memory)","text":"<p>\u521b\u5efa\u5177\u6709\u77ed\u671f\u5de5\u4f5c\u8bb0\u5fc6\u548c\u957f\u671f\u4f1a\u8bdd\u8bb0\u5fc6\u7684\u6709\u72b6\u6001\u667a\u80fd\u4f53\u3002</p>"},{"location":"llmapps/langgraph/overview/#langsmith","title":"\ud83d\udd0d LangSmith \u8c03\u8bd5","text":"<p>\u901a\u8fc7\u53ef\u89c6\u5316\u5de5\u5177\u6df1\u5ea6\u6d1e\u5bdf\u590d\u6742\u667a\u80fd\u4f53\u884c\u4e3a\uff0c\u8ffd\u8e2a\u6267\u884c\u8def\u5f84\u548c\u72b6\u6001\u8f6c\u6362\u3002</p>"},{"location":"llmapps/langgraph/overview/#_2","title":"\ud83d\ude80 \u751f\u4ea7\u5c31\u7eea\u90e8\u7f72","text":"<p>\u4e3a\u6709\u72b6\u6001\u3001\u957f\u65f6\u95f4\u8fd0\u884c\u7684\u5de5\u4f5c\u6d41\u63d0\u4f9b\u53ef\u6269\u5c55\u7684\u57fa\u7840\u8bbe\u65bd\u3002</p>"},{"location":"llmapps/langgraph/overview/#_3","title":"\u5b89\u88c5\u6307\u5357","text":""},{"location":"llmapps/langgraph/overview/#pip","title":"\u4f7f\u7528 pip \u5b89\u88c5","text":"<pre><code>pip install -U langgraph\n</code></pre>"},{"location":"llmapps/langgraph/overview/#uv","title":"\u4f7f\u7528 uv \u5b89\u88c5","text":"<pre><code>uv add langgraph\n</code></pre>"},{"location":"llmapps/langgraph/overview/#hello-world","title":"\u5feb\u901f\u5f00\u59cb\uff1aHello World \u793a\u4f8b","text":"<p>\u8ba9\u6211\u4eec\u521b\u5efa\u4e00\u4e2a\u7b80\u5355\u7684 LangGraph \u5e94\u7528\u6765\u7406\u89e3\u57fa\u672c\u6982\u5ff5\uff1a</p> <pre><code>from langgraph.graph import StateGraph, MessagesState, START, END\n\n# \u5b9a\u4e49\u6a21\u62df\u7684 LLM \u8282\u70b9\ndef mock_llm(state: MessagesState):\n    return {\"messages\": [{\"role\": \"ai\", \"content\": \"hello world\"}]}\n\n# \u521b\u5efa\u72b6\u6001\u56fe\ngraph = StateGraph(MessagesState)\n\n# \u6dfb\u52a0\u8282\u70b9\ngraph.add_node(\"mock_llm\", mock_llm)\n\n# \u5efa\u7acb\u8fde\u63a5\u5173\u7cfb\ngraph.add_edge(START, \"mock_llm\")  # \u4ece\u5f00\u59cb\u5230 LLM \u8282\u70b9\ngraph.add_edge(\"mock_llm\", END)   # \u4ece LLM \u8282\u70b9\u5230\u7ed3\u675f\n\n# \u7f16\u8bd1\u56fe\ngraph = graph.compile()\n\n# \u6267\u884c\u56fe\nresult = graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"hi!\"}]})\nprint(result)\n</code></pre>"},{"location":"llmapps/langgraph/overview/#_4","title":"\u6838\u5fc3\u6982\u5ff5\u8be6\u89e3","text":""},{"location":"llmapps/langgraph/overview/#stategraph","title":"\u72b6\u6001\u56fe (StateGraph)","text":"<p>LangGraph \u7684\u6838\u5fc3\u662f\u72b6\u6001\u56fe\uff0c\u5b83\u5b9a\u4e49\u4e86\u667a\u80fd\u4f53\u7684\u6267\u884c\u6d41\u7a0b\uff1a</p> <pre><code># \u521b\u5efa\u72b6\u6001\u56fe\uff0c\u6307\u5b9a\u72b6\u6001\u7c7b\u578b\ngraph = StateGraph(MessagesState)\n</code></pre>"},{"location":"llmapps/langgraph/overview/#nodes","title":"\u8282\u70b9 (Nodes)","text":"<p>\u8282\u70b9\u662f\u56fe\u7684\u57fa\u672c\u6784\u5efa\u5757\uff0c\u6bcf\u4e2a\u8282\u70b9\u6267\u884c\u7279\u5b9a\u7684\u4efb\u52a1\uff1a</p> <pre><code>def my_node(state: MessagesState):\n    # \u5904\u7406\u72b6\u6001\u5e76\u8fd4\u56de\u66f4\u65b0\n    new_message = {\"role\": \"ai\", \"content\": \"\u5904\u7406\u5b8c\u6210\"}\n    return {\"messages\": state[\"messages\"] + [new_message]}\n</code></pre>"},{"location":"llmapps/langgraph/overview/#edges","title":"\u8fb9 (Edges)","text":"<p>\u8fb9\u5b9a\u4e49\u4e86\u8282\u70b9\u4e4b\u95f4\u7684\u6267\u884c\u8def\u5f84\uff1a</p> <pre><code>graph.add_edge(START, \"first_node\")      # \u4ece\u5f00\u59cb\u5230\u7b2c\u4e00\u4e2a\u8282\u70b9\ngraph.add_edge(\"first_node\", \"second_node\")  # \u8282\u70b9\u4e4b\u95f4\u7684\u8fde\u63a5\ngraph.add_edge(\"second_node\", END)       # \u4ece\u8282\u70b9\u5230\u7ed3\u675f\n</code></pre>"},{"location":"llmapps/langgraph/overview/#_5","title":"\u8fdb\u9636\u793a\u4f8b\uff1a\u6761\u4ef6\u5de5\u4f5c\u6d41","text":"<p>\u521b\u5efa\u66f4\u590d\u6742\u7684\u6709\u6761\u4ef6\u6267\u884c\u7684\u5de5\u4f5c\u6d41\uff1a</p> <pre><code>from langgraph.graph import StateGraph, MessagesState, START, END\nfrom typing import Literal\n\ndef router(state: MessagesState) -&gt; Literal[\"end\", \"continue\"]:\n    last_message = state[\"messages\"][-1][\"content\"]\n    if \"\u7ed3\u675f\" in last_message or \"stop\" in last_message.lower():\n        return \"end\"\n    else:\n        return \"continue\"\n\ndef process_message(state: MessagesState):\n    last_message = state[\"messages\"][-1][\"content\"]\n    response = f\"\u5df2\u5904\u7406\u60a8\u7684\u6d88\u606f: {last_message}\"\n    return {\"messages\": [{\"role\": \"ai\", \"content\": response}]}\n\ndef final_response(state: MessagesState):\n    return {\"messages\": [{\"role\": \"ai\", \"content\": \"\u5bf9\u8bdd\u7ed3\u675f\uff0c\u611f\u8c22\u4f7f\u7528\uff01\"}]}\n\n# \u6784\u5efa\u56fe\ngraph = StateGraph(MessagesState)\ngraph.add_node(\"router\", router)\ngraph.add_node(\"process\", process_message)\ngraph.add_node(\"final\", final_response)\n\n# \u8bbe\u7f6e\u6761\u4ef6\u8fb9\ngraph.add_conditional_edges(\n    \"router\",\n    router,\n    {\n        \"continue\": \"process\",\n        \"end\": \"final\"\n    }\n)\n\ngraph.add_edge(\"process\", \"router\")  # \u5faa\u73af\u56de\u5230\u8def\u7531\u8282\u70b9\ngraph.add_edge(\"final\", END)\n\ngraph = graph.compile()\n</code></pre>"},{"location":"llmapps/langgraph/overview/#langgraph_2","title":"LangGraph \u751f\u6001\u7cfb\u7edf\u96c6\u6210","text":""},{"location":"llmapps/langgraph/overview/#langsmith_1","title":"\u4e0e LangSmith \u96c6\u6210","text":"<p>\u83b7\u5f97\u5b8c\u6574\u7684\u53ef\u89c2\u6d4b\u6027\uff1a</p> <pre><code># \u8bbe\u7f6e\u73af\u5883\u53d8\u91cf\nimport os\nos.environ[\"LANGSMITH_API_KEY\"] = \"your-api-key\"\nos.environ[\"LANGSMITH_PROJECT\"] = \"your-project-name\"\n\n# \u73b0\u5728\u6240\u6709\u7684\u8c03\u7528\u90fd\u4f1a\u88ab\u8ffd\u8e2a\nresult = graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"hi\"}]})\n</code></pre>"},{"location":"llmapps/langgraph/overview/#langchain","title":"\u4e0e LangChain \u7ec4\u4ef6\u96c6\u6210","text":"<p>\u867d\u7136 LangGraph \u53ef\u4ee5\u72ec\u7acb\u4f7f\u7528\uff0c\u4f46\u4e0e LangChain \u96c6\u6210\u53ef\u4ee5\u63d0\u4f9b\u66f4\u4e30\u5bcc\u7684\u529f\u80fd\uff1a</p> <pre><code>from langchain_community.chat_models import ChatOpenAI\nfrom langchain_core.messages import HumanMessage\n\ndef llm_node(state: MessagesState):\n    llm = ChatOpenAI(model=\"gpt-4\")\n    response = llm.invoke(state[\"messages\"])\n    return {\"messages\": [response]}\n</code></pre>"},{"location":"llmapps/langgraph/overview/#_6","title":"\u751f\u4ea7\u73af\u5883\u6700\u4f73\u5b9e\u8df5","text":""},{"location":"llmapps/langgraph/overview/#1","title":"1. \u9519\u8bef\u5904\u7406","text":"<pre><code>def robust_node(state: MessagesState):\n    try:\n        # \u4f60\u7684\u4e1a\u52a1\u903b\u8f91\n        return {\"messages\": [{\"role\": \"ai\", \"content\": \"\u6210\u529f\"}]}\n    except Exception as e:\n        return {\"messages\": [{\"role\": \"ai\", \"content\": f\"\u5904\u7406\u51fa\u9519: {str(e)}\"}]}\n</code></pre>"},{"location":"llmapps/langgraph/overview/#2","title":"2. \u72b6\u6001\u6301\u4e45\u5316","text":"<pre><code># \u4fdd\u5b58\u68c0\u67e5\u70b9\ncheckpoint = graph.get_state()\n# \u6062\u590d\u6267\u884c\ngraph.invoke({\"messages\": [...]}, config={\"configurable\": {\"thread_id\": \"123\"}})\n</code></pre>"},{"location":"llmapps/langgraph/overview/#3","title":"3. \u6d41\u5f0f\u8f93\u51fa","text":"<pre><code>for chunk in graph.stream({\"messages\": [...]}):\n    print(\"\u6536\u5230\u66f4\u65b0:\", chunk)\n</code></pre>"},{"location":"llmapps/langgraph/overview/#_7","title":"\u6545\u969c\u6392\u9664","text":""},{"location":"llmapps/langgraph/overview/#_8","title":"\u5e38\u89c1\u95ee\u9898","text":"<ol> <li>\u72b6\u6001\u7c7b\u578b\u4e0d\u5339\u914d</li> <li> <p>\u786e\u4fdd\u6240\u6709\u8282\u70b9\u8fd4\u56de\u7684\u72b6\u6001\u7ed3\u6784\u4e0e\u56fe\u5b9a\u4e49\u7684\u7c7b\u578b\u4e00\u81f4</p> </li> <li> <p>\u5faa\u73af\u4f9d\u8d56</p> </li> <li> <p>\u4f7f\u7528\u6761\u4ef6\u8fb9\u907f\u514d\u65e0\u9650\u5faa\u73af</p> </li> <li> <p>\u5185\u5b58\u7ba1\u7406</p> </li> <li>\u5bf9\u4e8e\u957f\u65f6\u95f4\u8fd0\u884c\u7684\u5de5\u4f5c\u6d41\uff0c\u5b9a\u671f\u6e05\u7406\u4e0d\u9700\u8981\u7684\u72b6\u6001</li> </ol>"},{"location":"llmapps/langgraph/persistence/","title":"\ud83e\udde0 LangGraph \u6301\u4e45\u5316\u673a\u5236\u6559\u7a0b\uff08Persistence Tutorial\uff09","text":"<p>LangGraph \u662f LangChain \u56e2\u961f\u63a8\u51fa\u7684\u4e00\u4e2a\u7528\u4e8e\u53ef\u89c6\u5316\u4e0e\u53ef\u7f16\u7a0b\u5316\u8bed\u8a00\u6a21\u578b\u5de5\u4f5c\u6d41\u7684\u6846\u67b6\u3002 \u5b83\u7684\u4e00\u5927\u6838\u5fc3\u80fd\u529b\u2014\u2014\u6301\u4e45\u5316\uff08Persistence\uff09\uff0c\u901a\u8fc7\u201c\u68c0\u67e5\u70b9\uff08Checkpoint\uff09\u201d\u4e0e\u201c\u7ebf\u7a0b\uff08Thread\uff09\u201d\u7cfb\u7edf\uff0c\u5b9e\u73b0\u4e86\u72b6\u6001\u7684\u4fdd\u5b58\u3001\u6062\u590d\u3001\u5206\u652f\u3001\u56de\u653e\u4e0e\u5171\u4eab\u3002</p> <p>\u8fd9\u4f7f\u5f97\u4f60\u80fd\u50cf\u73a9\u65f6\u95f4\u673a\u5668\u4e00\u6837\u5728\u5bf9\u8bdd\u4e0e\u4efb\u52a1\u6d41\u4e2d\u7a7f\u68ad\uff1a\u4fdd\u5b58\u8fc7\u53bb\u3001\u7f16\u8f91\u73b0\u5728\u3001\u5206\u53c9\u672a\u6765\u3002</p>"},{"location":"llmapps/langgraph/persistence/#_1","title":"\u4e00\u3001\u6301\u4e45\u5316\u7684\u6838\u5fc3\u6982\u5ff5","text":"<p>LangGraph \u5185\u7f6e\u4e00\u4e2a\u201c\u68c0\u67e5\u70b9\u7cfb\u7edf\uff08Checkpointer\uff09\u201d\uff0c\u6bcf\u5f53\u56fe\uff08Graph\uff09\u8fd0\u884c\u4e00\u4e2a\u201c\u8d85\u7ea7\u6b65\u9aa4\uff08super-step\uff09\u201d\uff0c\u5b83\u5c31\u81ea\u52a8\u4fdd\u5b58\u5f53\u524d\u72b6\u6001\uff08State\uff09\u7684\u5feb\u7167\uff0c\u79f0\u4e3a Checkpoint\u3002 \u8fd9\u4e9b\u68c0\u67e5\u70b9\u5c5e\u4e8e\u67d0\u4e2a\u201c\u7ebf\u7a0b\uff08Thread\uff09\u201d\uff0c\u6bcf\u4e2a\u7ebf\u7a0b\u5c31\u50cf\u4e00\u6b21\u72ec\u7acb\u7684\u6267\u884c\u4f1a\u8bdd\u6216\u5bf9\u8bdd\u5386\u53f2\u3002</p> <p>\u5f97\u76ca\u4e8e\u8fd9\u79cd\u673a\u5236\uff0cLangGraph \u80fd\u591f\u5b9e\u73b0\uff1a</p> <ul> <li>\u4eba\u7c7b\u4ecb\u5165\uff08Human-in-the-loop\uff09\uff1a\u968f\u65f6\u67e5\u770b\u4e0e\u4fee\u6539\u72b6\u6001\uff1b</li> <li>\u8bb0\u5fc6\uff08Memory\uff09\uff1a\u4fdd\u5b58\u957f\u671f\u4e0a\u4e0b\u6587\uff1b</li> <li>\u65f6\u95f4\u65c5\u884c\uff08Time Travel\uff09\uff1a\u56de\u653e\u4efb\u610f\u5386\u53f2\u72b6\u6001\uff1b</li> <li>\u5bb9\u9519\uff08Fault-tolerance\uff09\uff1a\u4efb\u52a1\u4e2d\u65ad\u53ef\u6062\u590d\u3002</li> </ul> <p>\u2705 \u63d0\u793a\uff1a\u4f7f\u7528 LangGraph API \u65f6\uff0c\u8fd9\u4e00\u5207\u90fd\u81ea\u52a8\u5b8c\u6210\uff0c\u65e0\u9700\u624b\u52a8\u7ba1\u7406\u3002</p>"},{"location":"llmapps/langgraph/persistence/#threads","title":"\u4e8c\u3001\u7ebf\u7a0b\uff08Threads\uff09","text":"<p>\u7ebf\u7a0b\u662f\u6301\u4e45\u5316\u72b6\u6001\u7684\u8f7d\u4f53\u3002 \u6bcf\u5f53\u4f60\u6267\u884c\u4e00\u4e2a\u5e26\u6709 checkpointer \u7684\u56fe\u65f6\uff0c\u5fc5\u987b\u6307\u5b9a\u4e00\u4e2a\u552f\u4e00\u7684 <code>thread_id</code>\uff1a</p> <pre><code>config = {\"configurable\": {\"thread_id\": \"1\"}}\n</code></pre> <p>\u8fd9\u4e2a\u7ebf\u7a0b\u4f1a\u4fdd\u5b58\u6574\u4e2a\u6267\u884c\u8fc7\u7a0b\u4e2d\u4ea7\u751f\u7684\u6240\u6709\u68c0\u67e5\u70b9\uff08checkpoints\uff09\u3002 \u7a0d\u540e\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7 <code>thread_id</code> \u6765\u8bbf\u95ee\uff1a</p> <ul> <li>\u6700\u65b0\u72b6\u6001\uff1b</li> <li>\u5386\u53f2\u72b6\u6001\uff1b</li> <li>\u4efb\u610f\u65f6\u95f4\u70b9\u7684\u5feb\u7167\uff1b</li> <li>\u4ece\u4efb\u610f\u68c0\u67e5\u70b9\u7ee7\u7eed\u6267\u884c\u3002</li> </ul>"},{"location":"llmapps/langgraph/persistence/#checkpoints","title":"\u4e09\u3001\u68c0\u67e5\u70b9\uff08Checkpoints\uff09","text":"<p>\u6bcf\u4e2a Checkpoint \u5c31\u662f\u4e00\u5f20\u72b6\u6001\u5feb\u7167\uff0c\u5305\u542b\u4ee5\u4e0b\u6838\u5fc3\u4fe1\u606f\uff1a</p> <ul> <li><code>values</code>: \u5f53\u524d\u56fe\u4e2d\u5404\u901a\u9053\uff08channel\uff09\u7684\u72b6\u6001\u503c\uff1b</li> <li><code>config</code>: \u8fd0\u884c\u65f6\u914d\u7f6e\uff1b</li> <li><code>metadata</code>: \u5143\u6570\u636e\uff08\u5982\u6267\u884c\u8282\u70b9\u3001\u9519\u8bef\u3001\u6b65\u9aa4\u7f16\u53f7\u7b49\uff09\uff1b</li> <li><code>next</code>: \u4e0b\u4e00\u4e2a\u5f85\u6267\u884c\u8282\u70b9\uff1b</li> <li><code>tasks</code>: \u5f53\u524d\u4efb\u52a1\u4fe1\u606f\uff08\u53ef\u542b\u9519\u8bef\u3001\u6682\u505c\u3001\u6216\u4e2d\u65ad\u6570\u636e\uff09\u3002</li> </ul> <p>\u8fd9\u4e9b\u5feb\u7167\u88ab\u8fde\u7eed\u4fdd\u5b58\uff0c\u5c31\u6784\u6210\u4e86\u5b8c\u6574\u7684\u7ebf\u7a0b\u6267\u884c\u5386\u53f2\u3002</p>"},{"location":"llmapps/langgraph/persistence/#_2","title":"\u793a\u4f8b\uff1a\u521b\u5efa\u5e76\u8fd0\u884c\u4e00\u4e2a\u7b80\u5355\u56fe","text":"<pre><code>from langgraph.graph import StateGraph, START, END\nfrom langgraph.checkpoint.memory import InMemorySaver\nfrom typing import Annotated\nfrom typing_extensions import TypedDict\nfrom operator import add\n\nclass State(TypedDict):\n    foo: str\n    bar: Annotated[list[str], add]\n\ndef node_a(state: State):\n    return {\"foo\": \"a\", \"bar\": [\"a\"]}\n\ndef node_b(state: State):\n    return {\"foo\": \"b\", \"bar\": [\"b\"]}\n\n# \u5b9a\u4e49\u56fe\u7ed3\u6784\nworkflow = StateGraph(State)\nworkflow.add_node(node_a)\nworkflow.add_node(node_b)\nworkflow.add_edge(START, \"node_a\")\nworkflow.add_edge(\"node_a\", \"node_b\")\nworkflow.add_edge(\"node_b\", END)\n\n# \u6dfb\u52a0\u5185\u5b58\u578b checkpointer\ncheckpointer = InMemorySaver()\ngraph = workflow.compile(checkpointer=checkpointer)\n\n# \u6307\u5b9a\u7ebf\u7a0b\u5e76\u6267\u884c\nconfig = {\"configurable\": {\"thread_id\": \"1\"}}\ngraph.invoke({\"foo\": \"\"}, config)\n</code></pre> <p>\u6267\u884c\u540e\uff0cLangGraph \u81ea\u52a8\u751f\u6210 4 \u4e2a\u68c0\u67e5\u70b9\uff0c\u5206\u522b\u5bf9\u5e94\uff1a</p> <ol> <li>\u521d\u59cb\u72b6\u6001\uff08\u5f85\u6267\u884c\u8282\u70b9\uff1aSTART\uff09</li> <li>\u8f93\u5165\u52a0\u8f7d\uff08\u5f85\u6267\u884c\u8282\u70b9\uff1anode_a\uff09</li> <li>node_a \u6267\u884c\u540e\uff08\u5f85\u6267\u884c\u8282\u70b9\uff1anode_b\uff09</li> <li>node_b \u6267\u884c\u540e\uff08\u6267\u884c\u7ed3\u675f\uff09</li> </ol>"},{"location":"llmapps/langgraph/persistence/#_3","title":"\u56db\u3001\u8bfb\u53d6\u72b6\u6001","text":""},{"location":"llmapps/langgraph/persistence/#1","title":"1. \u83b7\u53d6\u6700\u65b0\u72b6\u6001","text":"<pre><code>graph.get_state({\"configurable\": {\"thread_id\": \"1\"}})\n</code></pre> <p>\u8fd4\u56de\u503c\u662f\u4e00\u4e2a <code>StateSnapshot</code> \u5bf9\u8c61\u3002</p>"},{"location":"llmapps/langgraph/persistence/#2","title":"2. \u83b7\u53d6\u7279\u5b9a\u68c0\u67e5\u70b9\u7684\u72b6\u6001","text":"<pre><code>config = {\"configurable\": {\n    \"thread_id\": \"1\",\n    \"checkpoint_id\": \"1ef663ba-28fe-6528-8002-5a559208592c\"\n}}\ngraph.get_state(config)\n</code></pre>"},{"location":"llmapps/langgraph/persistence/#3","title":"3. \u83b7\u53d6\u6574\u4e2a\u72b6\u6001\u5386\u53f2","text":"<pre><code>config = {\"configurable\": {\"thread_id\": \"1\"}}\nhistory = list(graph.get_state_history(config))\n</code></pre> <p>\u8fd4\u56de\u4e00\u4e2a\u65f6\u95f4\u5012\u5e8f\u6392\u5217\u7684 <code>StateSnapshot</code> \u5217\u8868\u3002</p>"},{"location":"llmapps/langgraph/persistence/#replay","title":"\u4e94\u3001\u91cd\u653e\uff08Replay\uff09","text":"<p>\u201c\u91cd\u653e\u201d\u5141\u8bb8\u4f60\u4ece\u4efb\u610f\u5386\u53f2\u72b6\u6001\u91cd\u65b0\u8fd0\u884c\u56fe\u3002 \u8fd9\u76f8\u5f53\u4e8e\u201c\u65f6\u95f4\u65c5\u884c\u201d\u5230\u4e00\u4e2a\u65e7\u72b6\u6001\uff0c\u7136\u540e\u4ece\u90a3\u91cc\u521b\u5efa\u65b0\u7684\u5206\u652f\u3002</p> <pre><code>config = {\n    \"configurable\": {\n        \"thread_id\": \"1\",\n        \"checkpoint_id\": \"0c62ca34-ac19-445d-bbb0-5b4984975b2a\"\n    }\n}\ngraph.invoke(None, config=config)\n</code></pre> <p>LangGraph \u4f1a\u81ea\u52a8\u8bc6\u522b\u54ea\u4e9b\u6b65\u9aa4\u5df2\u6267\u884c\u8fc7\uff0c\u53ea\u201c\u91cd\u653e\u201d\u8fd9\u4e9b\u6b65\u9aa4\uff0c\u800c\u4e0d\u662f\u91cd\u65b0\u8ba1\u7b97\u3002\u4e4b\u540e\u7684\u6b65\u9aa4\u5219\u4f1a\u88ab\u771f\u6b63\u6267\u884c\uff08\u76f8\u5f53\u4e8e\u65f6\u95f4\u7ebf\u5206\u53c9\uff09\u3002</p>"},{"location":"llmapps/langgraph/persistence/#update-state","title":"\u516d\u3001\u7f16\u8f91\u72b6\u6001\uff08Update State\uff09","text":"<p><code>update_state()</code> \u65b9\u6cd5\u5141\u8bb8\u4f60\u76f4\u63a5\u4fee\u6539\u72b6\u6001\uff0c\u751a\u81f3\u201c\u4f2a\u9020\u201d\u8282\u70b9\u8f93\u51fa\u3002</p> <pre><code>graph.update_state(config, {\"foo\": 2, \"bar\": [\"b\"]})\n</code></pre> <p>\u5982\u679c <code>bar</code> \u6709 reducer\uff08\u5982 <code>add</code>\uff09\uff0c\u5219\u4f1a\u5408\u5e76\uff1a</p> <pre><code>\u539f\u72b6\u6001: {\"foo\": 1, \"bar\": [\"a\"]}\n\u66f4\u65b0\u540e: {\"foo\": 2, \"bar\": [\"a\", \"b\"]}\n</code></pre> <p>\u5982\u679c\u8981\u6a21\u62df\u8282\u70b9\u6267\u884c\uff0c\u53ef\u4f7f\u7528 <code>as_node</code> \u53c2\u6570\uff1a</p> <pre><code>graph.update_state(config, {\"foo\": 3}, as_node=\"node_b\")\n</code></pre>"},{"location":"llmapps/langgraph/persistence/#memory-store","title":"\u4e03\u3001\u8de8\u7ebf\u7a0b\u5171\u4eab\u8bb0\u5fc6\uff08Memory Store\uff09","text":"<p>Checkpointer \u4fdd\u5b58\u72b6\u6001\u5728\u5355\u4e2a\u7ebf\u7a0b\u5185\uff0c\u800c\u6709\u65f6\u6211\u4eec\u5e0c\u671b\u5728\u4e0d\u540c\u7ebf\u7a0b\u4e4b\u95f4\u5171\u4eab\u8bb0\u5fc6\uff08\u5982\u540c\u4e00\u4e2a\u7528\u6237\u7684\u591a\u8f6e\u5bf9\u8bdd\uff09\u3002 \u8fd9\u5c31\u9700\u8981 Store\uff08\u5b58\u50a8\uff09 \u63a5\u53e3\u3002</p> <p>LangGraph \u63d0\u4f9b <code>InMemoryStore</code>\uff0c\u7528\u4e8e\u8de8\u7ebf\u7a0b\u5b58\u50a8\u4e0e\u68c0\u7d22\u4fe1\u606f\u3002</p> <pre><code>from langgraph.store.memory import InMemoryStore\nstore = InMemoryStore()\n</code></pre>"},{"location":"llmapps/langgraph/persistence/#_4","title":"\u5b58\u50a8\u7528\u6237\u8bb0\u5fc6","text":"<pre><code>import uuid\nuser_id = \"1\"\nnamespace = (user_id, \"memories\")\nmemory_id = str(uuid.uuid4())\nmemory = {\"food_preference\": \"I like pizza\"}\n\nstore.put(namespace, memory_id, memory)\n</code></pre>"},{"location":"llmapps/langgraph/persistence/#_5","title":"\u68c0\u7d22\u8bb0\u5fc6","text":"<pre><code>memories = store.search(namespace)\nprint(memories[-1].dict())\n</code></pre> <p>\u8fd4\u56de\u7684\u5bf9\u8c61\u5305\u542b\uff1a</p> <ul> <li><code>value</code>: \u5b9e\u9645\u5185\u5bb9\uff1b</li> <li><code>namespace</code>: \u547d\u540d\u7a7a\u95f4\uff1b</li> <li><code>created_at</code> / <code>updated_at</code>: \u65f6\u95f4\u6233\u3002</li> </ul>"},{"location":"llmapps/langgraph/persistence/#semantic-search","title":"\u516b\u3001\u8bed\u4e49\u68c0\u7d22\uff08Semantic Search\uff09","text":"<p>Store \u4e0d\u4ec5\u80fd\u505a\u5173\u952e\u8bcd\u68c0\u7d22\uff0c\u8fd8\u80fd\u8fdb\u884c\u8bed\u4e49\u5339\u914d\u3002</p> <p>\u542f\u7528\u65b9\u6cd5\uff1a</p> <pre><code>from langchain.embeddings import init_embeddings\n\nstore = InMemoryStore(\n    index={\n        \"embed\": init_embeddings(\"openai:text-embedding-3-small\"),\n        \"dims\": 1536,\n        \"fields\": [\"food_preference\", \"$\"]\n    }\n)\n</code></pre> <p>\u67e5\u8be2\uff1a</p> <pre><code>store.search(namespace, query=\"\u7528\u6237\u559c\u6b22\u5403\u4ec0\u4e48\uff1f\", limit=3)\n</code></pre>"},{"location":"llmapps/langgraph/persistence/#langgraph-store","title":"\u4e5d\u3001\u5728 LangGraph \u4e2d\u96c6\u6210 Store","text":"<p>\u4f60\u53ef\u4ee5\u540c\u65f6\u5728\u7f16\u8bd1\u65f6\u4f20\u5165 checkpointer \u4e0e store\uff1a</p> <pre><code>from langgraph.checkpoint.memory import InMemorySaver\n\ncheckpointer = InMemorySaver()\ngraph = graph.compile(checkpointer=checkpointer, store=store)\n</code></pre> <p>\u5728\u8282\u70b9\u4e2d\u5373\u53ef\u4f7f\u7528 Store\uff1a</p> <pre><code>def update_memory(state, config, *, store):\n    user_id = config[\"configurable\"][\"user_id\"]\n    namespace = (user_id, \"memories\")\n    store.put(namespace, str(uuid.uuid4()), {\"memory\": \"User likes pizza\"})\n</code></pre> <p>\u591a\u4e2a\u7ebf\u7a0b\uff08thread_id \u4e0d\u540c\uff09\u5171\u4eab\u540c\u4e00 user_id \u5373\u53ef\u8bbf\u95ee\u540c\u4e00\u8bb0\u5fc6\u3002</p>"},{"location":"llmapps/langgraph/persistence/#checkpointer","title":"\u5341\u3001Checkpointer \u5b9e\u73b0\u5e93","text":"<p>LangGraph \u7684\u6301\u4e45\u5316\u5e95\u5c42\u7531\u591a\u4e2a\u53ef\u9009\u7684 Checkpointer \u5e93\u5b9e\u73b0\uff1a</p> \u5e93 \u5b58\u50a8\u7c7b\u578b \u9002\u7528\u573a\u666f <code>langgraph-checkpoint</code> \u5185\u5b58 \u9ed8\u8ba4\u5185\u7f6e\uff0c\u5feb\u901f\u5b9e\u9a8c <code>langgraph-checkpoint-sqlite</code> SQLite \u672c\u5730\u6301\u4e45\u5316 <code>langgraph-checkpoint-postgres</code> PostgreSQL \u751f\u4ea7\u73af\u5883\u7ea7\u6301\u4e45\u5316 <p>\u6240\u6709\u5b9e\u73b0\u90fd\u7b26\u5408 <code>BaseCheckpointSaver</code> \u63a5\u53e3\u3002</p>"},{"location":"llmapps/langgraph/persistence/#_6","title":"\ud83c\udfaf \u603b\u7ed3","text":"<p>LangGraph \u7684\u6301\u4e45\u5316\u7cfb\u7edf\u8ba9\u5de5\u4f5c\u6d41\u4e0d\u518d\u662f\u201c\u4e00\u6b21\u6027\u201d\u7684\u3002 \u901a\u8fc7 Checkpointer + Thread + Store \u7684\u4e09\u5c42\u67b6\u6784\uff0c\u5b83\u8ba9\u4f60\u7684 AI \u7cfb\u7edf\u62e5\u6709\uff1a</p> <ul> <li>\u53ef\u56de\u6eaf\u7684\u72b6\u6001\uff1b</li> <li>\u53ef\u6301\u4e45\u5316\u7684\u4e0a\u4e0b\u6587\uff1b</li> <li>\u53ef\u5171\u4eab\u7684\u957f\u671f\u8bb0\u5fc6\uff1b</li> <li>\u53ef\u91cd\u653e\u4e0e\u5206\u53c9\u7684\u6267\u884c\u8def\u5f84\u3002</li> </ul> <p>\u6362\u53e5\u8bdd\u8bf4\uff0cLangGraph \u8ba9\u201cAI \u7a0b\u5e8f\u7684\u65f6\u95f4\u201d\u6210\u4e3a\u4e00\u79cd\u53ef\u7f16\u7a0b\u8d44\u6e90\u3002</p> <p>\u5982\u679c\u4f60\u5e0c\u671b\u6211\u7ee7\u7eed\u8865\u5145\u4e0b\u4e00\u7bc7\u6559\u7a0b\uff0c\u6bd4\u5982 \ud83d\udc49\u300cLangGraph \u65f6\u95f4\u65c5\u884c (Time Travel) \u5b9e\u6218\u300d \u6216 \ud83d\udc49\u300cLangGraph \u4e2d\u7684 Store \u4e0e\u8bed\u4e49\u68c0\u7d22\u5b9e\u6218\u6307\u5357\u300d \u6211\u53ef\u4ee5\u76f4\u63a5\u5728\u6b64\u57fa\u7840\u4e0a\u7eed\u5199\u3002 \u4f60\u60f3\u6211\u5f80\u54ea\u4e2a\u65b9\u5411\u5c55\u5f00\uff1f</p>"},{"location":"llmapps/langgraph/quickstart/","title":"LangGraph \u5feb\u901f\u5165\u95e8\u6559\u7a0b\uff1a\u6784\u5efa\u8ba1\u7b97\u5668\u667a\u80fd\u4f53","text":"<p>\u672c\u6559\u7a0b\u5c06\u6559\u4f60\u4f7f\u7528 LangGraph \u7684\u4e24\u79cd\u4e0d\u540c API \u6765\u6784\u5efa\u4e00\u4e2a\u8ba1\u7b97\u5668\u667a\u80fd\u4f53\uff1a</p> <ul> <li>Graph API\uff1a\u901a\u8fc7\u5b9a\u4e49\u8282\u70b9\u548c\u8fb9\u6765\u6784\u5efa\u667a\u80fd\u4f53\u56fe</li> <li>Functional API\uff1a\u901a\u8fc7\u5355\u4e2a\u51fd\u6570\u5b9a\u4e49\u667a\u80fd\u4f53\u903b\u8f91</li> </ul> <p>\u524d\u7f6e\u8981\u6c42\uff1a\u4f60\u9700\u8981\u8bbe\u7f6e Claude (Anthropic) \u8d26\u6237\u5e76\u83b7\u53d6 API \u5bc6\u94a5\uff0c\u7136\u540e\u5728\u7ec8\u7aef\u4e2d\u8bbe\u7f6e <code>ANTHROPIC_API_KEY</code> \u73af\u5883\u53d8\u91cf\u3002</p>"},{"location":"llmapps/langgraph/quickstart/#graph-api","title":"\u65b9\u6cd5\u4e00\uff1a\u4f7f\u7528 Graph API","text":"<p>Graph API \u9002\u5408\u559c\u6b22\u901a\u8fc7\u53ef\u89c6\u5316\u8282\u70b9\u548c\u8fb9\u6765\u6784\u5efa\u667a\u80fd\u4f53\u7684\u5f00\u53d1\u8005\u3002</p>"},{"location":"llmapps/langgraph/quickstart/#1","title":"\u6b65\u9aa4 1\uff1a\u5b9a\u4e49\u5de5\u5177\u548c\u6a21\u578b","text":"<p>\u9996\u5148\uff0c\u6211\u4eec\u5b9a\u4e49 Claude Sonnet 4.5 \u6a21\u578b\u548c\u6570\u5b66\u8ba1\u7b97\u5de5\u5177\uff1a</p> <pre><code>from langchain.tools import tool\nfrom langchain.chat_models import init_chat_model\n\n# \u521d\u59cb\u5316\u6a21\u578b\nmodel = init_chat_model(\n    \"anthropic:claude-sonnet-4-5\",\n    temperature=0\n)\n\n# \u5b9a\u4e49\u6570\u5b66\u5de5\u5177\n@tool\ndef multiply(a: int, b: int) -&gt; int:\n    \"\"\"Multiply `a` and `b`.\"\"\"\n    return a * b\n\n@tool\ndef add(a: int, b: int) -&gt; int:\n    \"\"\"Adds `a` and `b`.\"\"\"\n    return a + b\n\n@tool\ndef divide(a: int, b: int) -&gt; float:\n    \"\"\"Divide `a` and `b`.\"\"\"\n    return a / b\n\n# \u5c06\u5de5\u5177\u7ed1\u5b9a\u5230\u6a21\u578b\ntools = [add, multiply, divide]\ntools_by_name = {tool.name: tool for tool in tools}\nmodel_with_tools = model.bind_tools(tools)\n</code></pre>"},{"location":"llmapps/langgraph/quickstart/#2","title":"\u6b65\u9aa4 2\uff1a\u5b9a\u4e49\u72b6\u6001","text":"<p>\u72b6\u6001\u7528\u4e8e\u5b58\u50a8\u6d88\u606f\u548c\u8ffd\u8e2a LLM \u8c03\u7528\u6b21\u6570\uff1a</p> <pre><code>from langchain.messages import AnyMessage\nfrom typing_extensions import TypedDict, Annotated\nimport operator\n\nclass MessagesState(TypedDict):\n    messages: Annotated[list[AnyMessage], operator.add]  # \u81ea\u52a8\u8ffd\u52a0\u65b0\u6d88\u606f\n    llm_calls: int\n</code></pre> <p>\u63d0\u793a\uff1a<code>Annotated</code> \u7c7b\u578b\u914d\u5408 <code>operator.add</code> \u786e\u4fdd\u65b0\u6d88\u606f\u4f1a\u8ffd\u52a0\u5230\u73b0\u6709\u5217\u8868\u4e2d\uff0c\u800c\u4e0d\u662f\u66ff\u6362\u5b83\u3002</p>"},{"location":"llmapps/langgraph/quickstart/#3","title":"\u6b65\u9aa4 3\uff1a\u5b9a\u4e49\u6a21\u578b\u8282\u70b9","text":"<p>\u8fd9\u4e2a\u8282\u70b9\u8d1f\u8d23\u8c03\u7528 LLM \u5e76\u51b3\u5b9a\u662f\u5426\u8c03\u7528\u5de5\u5177\uff1a</p> <pre><code>from langchain.messages import SystemMessage\n\ndef llm_call(state: dict):\n    \"\"\"LLM \u51b3\u5b9a\u662f\u5426\u8c03\u7528\u5de5\u5177\"\"\"\n    return {\n        \"messages\": [\n            model_with_tools.invoke(\n                [\n                    SystemMessage(\n                        content=\"You are a helpful assistant tasked with performing arithmetic on a set of inputs.\"\n                    )\n                ] + state[\"messages\"]\n            )\n        ],\n        \"llm_calls\": state.get('llm_calls', 0) + 1  # \u8ffd\u8e2a\u8c03\u7528\u6b21\u6570\n    }\n</code></pre>"},{"location":"llmapps/langgraph/quickstart/#4","title":"\u6b65\u9aa4 4\uff1a\u5b9a\u4e49\u5de5\u5177\u8282\u70b9","text":"<p>\u8fd9\u4e2a\u8282\u70b9\u8d1f\u8d23\u6267\u884c\u5de5\u5177\u8c03\u7528\u5e76\u8fd4\u56de\u7ed3\u679c\uff1a</p> <pre><code>from langchain.messages import ToolMessage\n\ndef tool_node(state: dict):\n    \"\"\"\u6267\u884c\u5de5\u5177\u8c03\u7528\"\"\"\n    result = []\n    for tool_call in state[\"messages\"][-1].tool_calls:\n        tool = tools_by_name[tool_call[\"name\"]]\n        observation = tool.invoke(tool_call[\"args\"])\n        result.append(ToolMessage(content=observation, tool_call_id=tool_call[\"id\"]))\n    return {\"messages\": result}\n</code></pre>"},{"location":"llmapps/langgraph/quickstart/#5","title":"\u6b65\u9aa4 5\uff1a\u5b9a\u4e49\u7ed3\u675f\u903b\u8f91","text":"<p>\u6761\u4ef6\u8fb9\u51fd\u6570\u51b3\u5b9a\u662f\u7ee7\u7eed\u8c03\u7528\u5de5\u5177\u8fd8\u662f\u7ed3\u675f\u5bf9\u8bdd\uff1a</p> <pre><code>from typing import Literal\nfrom langgraph.graph import StateGraph, START, END\n\ndef should_continue(state: MessagesState) -&gt; Literal[\"tool_node\", END]:\n    \"\"\"\u6839\u636e LLM \u662f\u5426\u8c03\u7528\u5de5\u5177\u6765\u51b3\u5b9a\u7ee7\u7eed\u8fd8\u662f\u505c\u6b62\"\"\"\n    messages = state[\"messages\"]\n    last_message = messages[-1]\n\n    # \u5982\u679c LLM \u8c03\u7528\u4e86\u5de5\u5177\uff0c\u5219\u6267\u884c\u5de5\u5177\u8282\u70b9\n    if last_message.tool_calls:\n        return \"tool_node\"\n\n    # \u5426\u5219\u7ed3\u675f\u5bf9\u8bdd\uff08\u56de\u590d\u7528\u6237\uff09\n    return END\n</code></pre>"},{"location":"llmapps/langgraph/quickstart/#6","title":"\u6b65\u9aa4 6\uff1a\u6784\u5efa\u548c\u7f16\u8bd1\u667a\u80fd\u4f53","text":"<p>\u4f7f\u7528 <code>StateGraph</code> \u7c7b\u6784\u5efa\u5de5\u4f5c\u6d41\u5e76\u7f16\u8bd1\uff1a</p> <pre><code># \u6784\u5efa\u5de5\u4f5c\u6d41\nagent_builder = StateGraph(MessagesState)\n\n# \u6dfb\u52a0\u8282\u70b9\nagent_builder.add_node(\"llm_call\", llm_call)\nagent_builder.add_node(\"tool_node\", tool_node)\n\n# \u6dfb\u52a0\u8fb9\u8fde\u63a5\u8282\u70b9\nagent_builder.add_edge(START, \"llm_call\")\nagent_builder.add_conditional_edges(\n    \"llm_call\",\n    should_continue,\n    [\"tool_node\", END]\n)\nagent_builder.add_edge(\"tool_node\", \"llm_call\")\n\n# \u7f16\u8bd1\u667a\u80fd\u4f53\nagent = agent_builder.compile()\n\n# \u53ef\u89c6\u5316\u667a\u80fd\u4f53\u56fe\nfrom IPython.display import Image, display\ndisplay(Image(agent.get_graph(xray=True).draw_mermaid_png()))\n\n# \u6d4b\u8bd5\u667a\u80fd\u4f53\nfrom langchain.messages import HumanMessage\nmessages = [HumanMessage(content=\"Add 3 and 4.\")]\nresult = agent.invoke({\"messages\": messages})\nfor m in result[\"messages\"]:\n    m.pretty_print()\n</code></pre> <p>\u606d\u559c\uff01 \u4f60\u5df2\u7ecf\u4f7f\u7528 Graph API \u6210\u529f\u6784\u5efa\u4e86\u7b2c\u4e00\u4e2a\u667a\u80fd\u4f53\uff01</p>"},{"location":"llmapps/langgraph/quickstart/#functional-api","title":"\u65b9\u6cd5\u4e8c\uff1a\u4f7f\u7528 Functional API","text":"<p>Functional API \u9002\u5408\u559c\u6b22\u5728\u5355\u4e2a\u51fd\u6570\u4e2d\u5b9a\u4e49\u903b\u8f91\u7684\u5f00\u53d1\u8005\u3002</p>"},{"location":"llmapps/langgraph/quickstart/#1_1","title":"\u6b65\u9aa4 1\uff1a\u5b9a\u4e49\u5de5\u5177\u548c\u6a21\u578b","text":"<p>\u5de5\u5177\u548c\u6a21\u578b\u5b9a\u4e49\u4e0e Graph API \u76f8\u540c\uff1a</p> <pre><code>from langchain.tools import tool\nfrom langchain.chat_models import init_chat_model\n\nmodel = init_chat_model(\n    \"anthropic:claude-sonnet-4-5\",\n    temperature=0\n)\n\n# \u5b9a\u4e49\u76f8\u540c\u7684\u6570\u5b66\u5de5\u5177\n@tool\ndef multiply(a: int, b: int) -&gt; int:\n    \"\"\"Multiply `a` and `b`.\"\"\"\n    return a * b\n\n@tool\ndef add(a: int, b: int) -&gt; int:\n    \"\"\"Adds `a` and `b`.\"\"\"\n    return a + b\n\n@tool\ndef divide(a: int, b: int) -&gt; float:\n    \"\"\"Divide `a` and `b`.\"\"\"\n    return a / b\n\n# \u7ed1\u5b9a\u5de5\u5177\u5230\u6a21\u578b\ntools = [add, multiply, divide]\ntools_by_name = {tool.name: tool for tool in tools}\nmodel_with_tools = model.bind_tools(tools)\n\nfrom langgraph.graph import add_messages\nfrom langchain.messages import SystemMessage, HumanMessage, ToolCall\nfrom langchain_core.messages import BaseMessage\nfrom langgraph.func import entrypoint, task\n</code></pre>"},{"location":"llmapps/langgraph/quickstart/#2_1","title":"\u6b65\u9aa4 2\uff1a\u5b9a\u4e49\u6a21\u578b\u8282\u70b9","text":"<p>\u4f7f\u7528 <code>@task</code> \u88c5\u9970\u5668\u6807\u8bb0\u53ef\u6267\u884c\u4efb\u52a1\uff1a</p> <pre><code>@task\ndef call_llm(messages: list[BaseMessage]):\n    \"\"\"LLM \u51b3\u5b9a\u662f\u5426\u8c03\u7528\u5de5\u5177\"\"\"\n    return model_with_tools.invoke(\n        [\n            SystemMessage(\n                content=\"You are a helpful assistant tasked with performing arithmetic on a set of inputs.\"\n            )\n        ] + messages\n    )\n</code></pre> <p>\u63d0\u793a\uff1a<code>@task</code> \u88c5\u9970\u5668\u6807\u8bb0\u7684\u51fd\u6570\u53ef\u4ee5\u4f5c\u4e3a\u667a\u80fd\u4f53\u7684\u4e00\u90e8\u5206\u6267\u884c\uff0c\u53ef\u4ee5\u540c\u6b65\u6216\u5f02\u6b65\u8c03\u7528\u3002</p>"},{"location":"llmapps/langgraph/quickstart/#3_1","title":"\u6b65\u9aa4 3\uff1a\u5b9a\u4e49\u5de5\u5177\u8282\u70b9","text":"<pre><code>@task\ndef call_tool(tool_call: ToolCall):\n    \"\"\"\u6267\u884c\u5de5\u5177\u8c03\u7528\"\"\"\n    tool = tools_by_name[tool_call[\"name\"]]\n    return tool.invoke(tool_call)\n</code></pre>"},{"location":"llmapps/langgraph/quickstart/#4_1","title":"\u6b65\u9aa4 4\uff1a\u5b9a\u4e49\u667a\u80fd\u4f53","text":"<p>\u4f7f\u7528 <code>@entrypoint</code> \u51fd\u6570\u6784\u5efa\u667a\u80fd\u4f53\uff1a</p> <pre><code>@entrypoint()\ndef agent(messages: list[BaseMessage]):\n    model_response = call_llm(messages).result()\n\n    while True:\n        if not model_response.tool_calls:\n            break\n\n        # \u6267\u884c\u5de5\u5177\n        tool_result_futures = [\n            call_tool(tool_call) for tool_call in model_response.tool_calls\n        ]\n        tool_results = [fut.result() for fut in tool_result_futures]\n        messages = add_messages(messages, [model_response, *tool_results])\n        model_response = call_llm(messages).result()\n\n    messages = add_messages(messages, model_response)\n    return messages\n\n# \u6d4b\u8bd5\u667a\u80fd\u4f53\nmessages = [HumanMessage(content=\"Add 3 and 4.\")]\nfor chunk in agent.stream(messages, stream_mode=\"updates\"):\n    print(chunk)\n    print(\"\\n\")\n</code></pre> <p>\u6ce8\u610f\uff1a\u5728 Functional API \u4e2d\uff0c\u4f60\u4e0d\u9700\u8981\u663e\u5f0f\u5b9a\u4e49\u8282\u70b9\u548c\u8fb9\uff0c\u800c\u662f\u5728\u5355\u4e2a\u51fd\u6570\u4e2d\u4f7f\u7528\u6807\u51c6\u7684\u63a7\u5236\u6d41\u903b\u8f91\uff08\u5faa\u73af\u3001\u6761\u4ef6\u8bed\u53e5\uff09\u3002</p> <p>\u606d\u559c\uff01 \u4f60\u5df2\u7ecf\u4f7f\u7528 Functional API \u6210\u529f\u6784\u5efa\u4e86\u7b2c\u4e00\u4e2a\u667a\u80fd\u4f53\uff01</p>"},{"location":"llmapps/langgraph/quickstart/#_1","title":"\u4e24\u79cd\u65b9\u6cd5\u7684\u6bd4\u8f83","text":"\u7279\u6027 Graph API Functional API \u53ef\u89c6\u5316 \u2705 \u652f\u6301\u56fe\u53ef\u89c6\u5316 \u274c \u65e0\u53ef\u89c6\u5316 \u63a7\u5236\u7cbe\u5ea6 \u2705 \u7ec6\u7c92\u5ea6\u63a7\u5236 \u26a0\ufe0f \u4e2d\u7b49\u63a7\u5236 \u5b66\u4e60\u66f2\u7ebf \u8f83\u9661\u5ced \u8f83\u5e73\u7f13 \u4ee3\u7801\u590d\u6742\u5ea6 \u8f83\u9ad8 \u8f83\u4f4e \u9002\u7528\u573a\u666f \u590d\u6742\u5de5\u4f5c\u6d41 \u7b80\u5355\u5230\u4e2d\u7b49\u590d\u6742\u5ea6"},{"location":"llmapps/langgraph/streaming/","title":"LangGraph \u6d41\u5f0f\u4f20\u8f93\u5b8c\u6574\u6559\u7a0b","text":""},{"location":"llmapps/langgraph/streaming/#_1","title":"\u6982\u8ff0","text":"<p>LangGraph \u5b9e\u73b0\u4e86\u6d41\u5f0f\u4f20\u8f93\u7cfb\u7edf\uff0c\u80fd\u591f\u5b9e\u65f6\u5c55\u793a\u66f4\u65b0\u3002\u6d41\u5f0f\u4f20\u8f93\u5bf9\u4e8e\u63d0\u5347\u57fa\u4e8e LLM \u7684\u5e94\u7528\u7a0b\u5e8f\u7684\u54cd\u5e94\u80fd\u529b\u81f3\u5173\u91cd\u8981\u3002\u901a\u8fc7\u9010\u6b65\u663e\u793a\u8f93\u51fa\uff08\u5373\u4f7f\u5728\u5b8c\u6574\u54cd\u5e94\u51c6\u5907\u597d\u4e4b\u524d\uff09\uff0c\u6d41\u5f0f\u4f20\u8f93\u663e\u8457\u6539\u5584\u4e86\u7528\u6237\u4f53\u9a8c\uff0c\u7279\u522b\u662f\u5728\u5904\u7406 LLM \u5ef6\u8fdf\u65f6\u3002</p>"},{"location":"llmapps/langgraph/streaming/#_2","title":"\u652f\u6301\u7684\u6d41\u6a21\u5f0f","text":"\u6a21\u5f0f \u8f93\u51fa\u5185\u5bb9 \u6027\u80fd \u573a\u666f <code>values</code> \u6bcf\u6b65\u5b8c\u6574\u72b6\u6001 \u8f83\u6162 \u8c03\u8bd5\u6216\u72b6\u6001\u8ddf\u8e2a <code>updates</code> \u589e\u91cf\u66f4\u65b0 \u5feb \u5b9e\u65f6\u72b6\u6001\u66f4\u65b0 <code>messages</code> LLM token\u6d41 \u4e2d \u804a\u5929 UI \u5b9e\u65f6\u751f\u6210 <code>custom</code> \u81ea\u5b9a\u4e49\u6570\u636e \u53ef\u63a7 \u8fdb\u5ea6\u65e5\u5fd7\u3001\u81ea\u5b9a\u4e49\u4e8b\u4ef6 <code>debug</code> \u5168\u90e8\u7ec6\u8282 \u6700\u6162 \u6df1\u5ea6\u8c03\u8bd5\u5206\u6790"},{"location":"llmapps/langgraph/streaming/#_3","title":"\u57fa\u7840\u7528\u6cd5","text":""},{"location":"llmapps/langgraph/streaming/#_4","title":"\u57fa\u672c\u6d41\u5f0f\u4f20\u8f93\u793a\u4f8b","text":"<pre><code># \u540c\u6b65\u6d41\u5f0f\u4f20\u8f93\nfor chunk in graph.stream(inputs, stream_mode=\"updates\"):\n    print(chunk)\n\n# \u5f02\u6b65\u6d41\u5f0f\u4f20\u8f93\nasync for chunk in graph.astream(inputs, stream_mode=\"updates\"):\n    print(chunk)\n</code></pre>"},{"location":"llmapps/langgraph/streaming/#_5","title":"\u5b8c\u6574\u793a\u4f8b","text":"<pre><code>from typing import TypedDict\nfrom langgraph.graph import StateGraph, START, END\n\nclass State(TypedDict):\n    topic: str\n    joke: str\n\ndef refine_topic(state: State):\n    return {\"topic\": state[\"topic\"] + \" and cats\"}\n\ndef generate_joke(state: State):\n    return {\"joke\": f\"This is a joke about {state['topic']}\"}\n\n# \u6784\u5efa\u56fe\ngraph = (\n    StateGraph(State)\n    .add_node(refine_topic)\n    .add_node(generate_joke)\n    .add_edge(START, \"refine_topic\")\n    .add_edge(\"refine_topic\", \"generate_joke\")\n    .add_edge(\"generate_joke\", END)\n    .compile()\n)\n\n# \u6d41\u5f0f\u4f20\u8f93\u66f4\u65b0\nfor chunk in graph.stream(\n    {\"topic\": \"ice cream\"},\n    stream_mode=\"updates\",\n):\n    print(chunk)\n</code></pre> <p>\u8f93\u51fa\uff1a</p> <pre><code>{'refine_topic': {'topic': 'ice cream and cats'}}\n{'generate_joke': {'joke': 'This is a joke about ice cream and cats'}}\n</code></pre>"},{"location":"llmapps/langgraph/streaming/#_6","title":"\u591a\u6a21\u5f0f\u6d41\u5f0f\u4f20\u8f93","text":"<p>\u53ef\u4ee5\u540c\u65f6\u6d41\u5f0f\u4f20\u8f93\u591a\u79cd\u6a21\u5f0f\uff1a</p> <pre><code>for mode, chunk in graph.stream(\n    inputs, \n    stream_mode=[\"updates\", \"custom\"]\n):\n    print(f\"{mode}: {chunk}\")\n</code></pre>"},{"location":"llmapps/langgraph/streaming/#_7","title":"\u6d41\u5f0f\u4f20\u8f93\u56fe\u72b6\u6001","text":""},{"location":"llmapps/langgraph/streaming/#updates","title":"\u4f7f\u7528 updates \u6a21\u5f0f","text":"<p>\u6d41\u5f0f\u4f20\u8f93\u72b6\u6001\u66f4\u65b0\uff08\u4ec5\u663e\u793a\u53d8\u5316\u7684\u90e8\u5206\uff09\uff1a</p> <pre><code>for chunk in graph.stream(\n    {\"topic\": \"ice cream\"},\n    stream_mode=\"updates\",\n):\n    print(chunk)\n</code></pre>"},{"location":"llmapps/langgraph/streaming/#values","title":"\u4f7f\u7528 values \u6a21\u5f0f","text":"<p>\u6d41\u5f0f\u4f20\u8f93\u5b8c\u6574\u72b6\u6001\u503c\uff1a</p> <pre><code>for chunk in graph.stream(\n    {\"topic\": \"ice cream\"},\n    stream_mode=\"values\",\n):\n    print(chunk)\n</code></pre>"},{"location":"llmapps/langgraph/streaming/#_8","title":"\u6d41\u5f0f\u4f20\u8f93\u5b50\u56fe\u8f93\u51fa","text":"<p>\u5305\u542b\u5b50\u56fe\u8f93\u51fa\u7684\u6d41\u5f0f\u4f20\u8f93\uff1a</p> <pre><code>for chunk in graph.stream(\n    {\"foo\": \"foo\"},\n    subgraphs=True,  # \u542f\u7528\u5b50\u56fe\u6d41\u5f0f\u4f20\u8f93\n    stream_mode=\"updates\",\n):\n    print(chunk)\n</code></pre>"},{"location":"llmapps/langgraph/streaming/#llm-token","title":"\u6d41\u5f0f\u4f20\u8f93 LLM Token","text":""},{"location":"llmapps/langgraph/streaming/#llm-token_1","title":"\u57fa\u7840 LLM Token \u6d41\u5f0f\u4f20\u8f93","text":"<pre><code>from langchain.chat_models import init_chat_model\nfrom langgraph.graph import StateGraph, START\n\nmodel = init_chat_model(model=\"openai:gpt-4o-mini\")\n\ndef call_model(state):\n    \"\"\"\u8c03\u7528 LLM \u751f\u6210\u5173\u4e8e\u4e3b\u9898\u7684\u7b11\u8bdd\"\"\"\n    model_response = model.invoke([\n        {\"role\": \"user\", \"content\": f\"Generate a joke about {state['topic']}\"}\n    ])\n    return {\"joke\": model_response.content}\n\ngraph = (\n    StateGraph(State)\n    .add_node(call_model)\n    .add_edge(START, \"call_model\")\n    .compile()\n)\n\n# \u6d41\u5f0f\u4f20\u8f93 LLM token\nfor message_chunk, metadata in graph.stream(\n    {\"topic\": \"ice cream\"},\n    stream_mode=\"messages\",\n):\n    if message_chunk.content:\n        print(message_chunk.content, end=\"|\", flush=True)\n</code></pre>"},{"location":"llmapps/langgraph/streaming/#llm","title":"\u6309\u6807\u7b7e\u8fc7\u6ee4 LLM \u8c03\u7528","text":"<pre><code># \u4e3a\u4e0d\u540c\u6a21\u578b\u8bbe\u7f6e\u6807\u7b7e\njoke_model = init_chat_model(model=\"openai:gpt-4o-mini\", tags=['joke'])\npoem_model = init_chat_model(model=\"openai:gpt-4o-mini\", tags=['poem'])\n\n# \u6d41\u5f0f\u4f20\u8f93\u65f6\u6309\u6807\u7b7e\u8fc7\u6ee4\nasync for msg, metadata in graph.astream(\n    {\"topic\": \"cats\"},\n    stream_mode=\"messages\",\n):\n    if metadata[\"tags\"] == [\"joke\"]:\n        print(msg.content, end=\"|\", flush=True)\n</code></pre>"},{"location":"llmapps/langgraph/streaming/#_9","title":"\u6309\u8282\u70b9\u8fc7\u6ee4","text":"<pre><code>for msg, metadata in graph.stream(\n    inputs,\n    stream_mode=\"messages\",\n):\n    # \u53ea\u6d41\u5f0f\u4f20\u8f93\u7279\u5b9a\u8282\u70b9\u7684 token\n    if msg.content and metadata[\"langgraph_node\"] == \"write_poem\":\n        print(msg.content, end=\"|\", flush=True)\n</code></pre>"},{"location":"llmapps/langgraph/streaming/#_10","title":"\u6d41\u5f0f\u4f20\u8f93\u81ea\u5b9a\u4e49\u6570\u636e","text":""},{"location":"llmapps/langgraph/streaming/#_11","title":"\u4ece\u8282\u70b9\u6d41\u5f0f\u4f20\u8f93\u81ea\u5b9a\u4e49\u6570\u636e","text":"<pre><code>from typing import TypedDict\nfrom langgraph.config import get_stream_writer\nfrom langgraph.graph import StateGraph, START\n\nclass State(TypedDict):\n    query: str\n    answer: str\n\ndef node(state: State):\n    # \u83b7\u53d6\u6d41\u5199\u5165\u5668\u53d1\u9001\u81ea\u5b9a\u4e49\u6570\u636e\n    writer = get_stream_writer()\n    # \u53d1\u9001\u81ea\u5b9a\u4e49\u6570\u636e\n    writer({\"custom_key\": \"Generating custom data inside node\"})\n    return {\"answer\": \"some data\"}\n\ngraph = (\n    StateGraph(State)\n    .add_node(node)\n    .add_edge(START, \"node\")\n    .compile()\n)\n\n# \u63a5\u6536\u81ea\u5b9a\u4e49\u6570\u636e\nfor chunk in graph.stream(inputs, stream_mode=\"custom\"):\n    print(chunk)\n</code></pre>"},{"location":"llmapps/langgraph/streaming/#_12","title":"\u4ece\u5de5\u5177\u6d41\u5f0f\u4f20\u8f93\u81ea\u5b9a\u4e49\u6570\u636e","text":"<pre><code>from langchain.tools import tool\nfrom langgraph.config import get_stream_writer\n\n@tool\ndef query_database(query: str) -&gt; str:\n    \"\"\"\u67e5\u8be2\u6570\u636e\u5e93\"\"\"\n    writer = get_stream_writer()\n    # \u53d1\u9001\u8fdb\u5ea6\u66f4\u65b0\n    writer({\"data\": \"Retrieved 0/100 records\", \"type\": \"progress\"})\n    # \u6267\u884c\u67e5\u8be2\n    writer({\"data\": \"Retrieved 100/100 records\", \"type\": \"progress\"})\n    return \"some-answer\"\n</code></pre>"},{"location":"llmapps/langgraph/streaming/#llm_1","title":"\u4e0e\u4efb\u610f LLM \u4e00\u8d77\u4f7f\u7528","text":"<p>\u5373\u4f7f LLM API \u6ca1\u6709\u5b9e\u73b0 LangChain \u804a\u5929\u6a21\u578b\u63a5\u53e3\uff0c\u4e5f\u53ef\u4ee5\u4f7f\u7528\u81ea\u5b9a\u4e49\u6a21\u5f0f\u8fdb\u884c\u6d41\u5f0f\u4f20\u8f93\uff1a</p> <pre><code>from langgraph.config import get_stream_writer\n\ndef call_arbitrary_model(state):\n    \"\"\"\u8c03\u7528\u4efb\u610f\u6a21\u578b\u5e76\u6d41\u5f0f\u4f20\u8f93\u8f93\u51fa\"\"\"\n    writer = get_stream_writer()\n\n    # \u4f7f\u7528\u81ea\u5b9a\u4e49\u6d41\u5f0f\u5ba2\u6237\u7aef\n    for chunk in your_custom_streaming_client(state[\"topic\"]):\n        # \u5c06\u81ea\u5b9a\u4e49\u6570\u636e\u53d1\u9001\u5230\u6d41\n        writer({\"custom_llm_chunk\": chunk})\n\n    return {\"result\": \"completed\"}\n\n# \u63a5\u6536\u81ea\u5b9a\u4e49\u6570\u636e\nfor chunk in graph.stream(\n    {\"topic\": \"cats\"},\n    stream_mode=\"custom\",\n):\n    print(chunk)\n</code></pre>"},{"location":"llmapps/langgraph/streaming/#_13","title":"\u8c03\u8bd5\u6a21\u5f0f","text":"<p>\u4f7f\u7528\u8c03\u8bd5\u6a21\u5f0f\u83b7\u53d6\u8be6\u7ec6\u4fe1\u606f\uff1a</p> <pre><code>for chunk in graph.stream(\n    {\"topic\": \"ice cream\"},\n    stream_mode=\"debug\",\n):\n    print(chunk)\n</code></pre>"},{"location":"llmapps/langgraph/streaming/#_14","title":"\u7981\u7528\u7279\u5b9a\u804a\u5929\u6a21\u578b\u7684\u6d41\u5f0f\u4f20\u8f93","text":"<p>\u5bf9\u4e8e\u4e0d\u652f\u6301\u6d41\u5f0f\u4f20\u8f93\u7684\u6a21\u578b\uff1a</p> <pre><code>from langchain.chat_models import init_chat_model\n\nmodel = init_chat_model(\n    \"anthropic:claude-sonnet-4-5\",\n    disable_streaming=True  # \u7981\u7528\u6d41\u5f0f\u4f20\u8f93\n)\n</code></pre>"},{"location":"llmapps/langgraph/streaming/#python-311","title":"Python &lt; 3.11 \u7684\u5f02\u6b65\u5904\u7406","text":""},{"location":"llmapps/langgraph/streaming/#_15","title":"\u624b\u52a8\u4f20\u9012\u914d\u7f6e","text":"<pre><code>async def call_model(state, config):\n    topic = state[\"topic\"]\n    # \u5fc5\u987b\u663e\u5f0f\u4f20\u9012 config\n    joke_response = await model.ainvoke(\n        [{\"role\": \"user\", \"content\": f\"Write a joke about {topic}\"}],\n        config,  # \u663e\u5f0f\u4f20\u9012\u914d\u7f6e\n    )\n    return {\"joke\": joke_response.content}\n</code></pre>"},{"location":"llmapps/langgraph/streaming/#_16","title":"\u5f02\u6b65\u81ea\u5b9a\u4e49\u6d41\u5f0f\u4f20\u8f93","text":"<pre><code>from langgraph.types import StreamWriter\n\nasync def generate_joke(state: State, writer: StreamWriter):\n    # \u5728\u5f02\u6b65\u51fd\u6570\u4e2d\u76f4\u63a5\u4f7f\u7528 writer \u53c2\u6570\n    writer({\"custom_key\": \"Streaming custom data\"})\n    return {\"joke\": f\"This is a joke about {state['topic']}\"}\n</code></pre>"},{"location":"llmapps/langgraph/streaming/#_17","title":"\u6700\u4f73\u5b9e\u8df5","text":"<ol> <li>\u9009\u62e9\u5408\u9002\u7684\u6d41\u6a21\u5f0f\uff1a\u6839\u636e\u9700\u6c42\u9009\u62e9 <code>updates</code>\u3001<code>values</code>\u3001<code>messages</code> \u6216 <code>custom</code> \u6a21\u5f0f</li> <li>\u5408\u7406\u4f7f\u7528\u8fc7\u6ee4\uff1a\u4f7f\u7528\u6807\u7b7e\u6216\u8282\u70b9\u540d\u79f0\u8fc7\u6ee4\u6d41\u5f0f\u8f93\u51fa</li> <li>\u5904\u7406\u5f02\u6b65\u573a\u666f\uff1a\u5728 Python &lt; 3.11 \u4e2d\u6ce8\u610f\u624b\u52a8\u4f20\u9012\u914d\u7f6e</li> <li>\u9519\u8bef\u5904\u7406\uff1a\u5728\u6d41\u5f0f\u4f20\u8f93\u8fc7\u7a0b\u4e2d\u6dfb\u52a0\u9002\u5f53\u7684\u9519\u8bef\u5904\u7406\u673a\u5236</li> <li>\u6027\u80fd\u8003\u8651\uff1a\u907f\u514d\u5728\u6d41\u5f0f\u4f20\u8f93\u4e2d\u6267\u884c\u963b\u585e\u64cd\u4f5c</li> </ol> <p>\u901a\u8fc7\u672c\u6559\u7a0b\uff0c\u60a8\u53ef\u4ee5\u5145\u5206\u5229\u7528 LangGraph \u7684\u6d41\u5f0f\u4f20\u8f93\u529f\u80fd\uff0c\u6784\u5efa\u54cd\u5e94\u8fc5\u901f\u3001\u7528\u6237\u4f53\u9a8c\u826f\u597d\u7684 LLM \u5e94\u7528\u7a0b\u5e8f\u3002</p>"},{"location":"llmapps/langgraph/thinking%20in%20Langgraph/","title":"LangGraph \u601d\u7ef4\u6a21\u5f0f\u5b8c\u5168\u6307\u5357","text":"<p>\u901a\u8fc7\u5c06\u5ba2\u6237\u652f\u6301\u90ae\u4ef6\u667a\u80fd\u4f53\u5206\u89e3\u4e3a\u79bb\u6563\u6b65\u9aa4\uff0c\u5b66\u4e60\u5982\u4f55\u7528 LangGraph \u6784\u5efa\u667a\u80fd\u4f53</p> <p>LangGraph \u53ef\u4ee5\u6539\u53d8\u4f60\u6784\u5efa\u667a\u80fd\u4f53\u7684\u601d\u7ef4\u65b9\u5f0f\u3002\u4f7f\u7528 LangGraph \u6784\u5efa\u667a\u80fd\u4f53\u65f6\uff0c\u4f60\u9996\u5148\u9700\u8981\u5c06\u5176\u5206\u89e3\u4e3a\u79f0\u4e3a\u8282\u70b9\u7684\u79bb\u6563\u6b65\u9aa4\u3002\u7136\u540e\uff0c\u63cf\u8ff0\u6bcf\u4e2a\u8282\u70b9\u7684\u4e0d\u540c\u51b3\u7b56\u548c\u8f6c\u6362\u3002\u6700\u540e\uff0c\u901a\u8fc7\u5171\u4eab\u7684\u72b6\u6001\u5c06\u8282\u70b9\u8fde\u63a5\u8d77\u6765\uff0c\u6bcf\u4e2a\u8282\u70b9\u90fd\u53ef\u4ee5\u8bfb\u53d6\u548c\u5199\u5165\u8fd9\u4e2a\u72b6\u6001\u3002\u672c\u6559\u7a0b\u5c06\u6307\u5bfc\u4f60\u5b8c\u6210\u6784\u5efa\u5ba2\u6237\u652f\u6301\u90ae\u4ef6\u667a\u80fd\u4f53\u7684\u601d\u7ef4\u8fc7\u7a0b\u3002</p>"},{"location":"llmapps/langgraph/thinking%20in%20Langgraph/#_1","title":"\u4ece\u8981\u81ea\u52a8\u5316\u7684\u6d41\u7a0b\u5f00\u59cb","text":"<p>\u5047\u8bbe\u4f60\u9700\u8981\u6784\u5efa\u4e00\u4e2a\u5904\u7406\u5ba2\u6237\u652f\u6301\u90ae\u4ef6\u7684 AI \u667a\u80fd\u4f53\u3002\u4ea7\u54c1\u56e2\u961f\u7ed9\u4e86\u4f60\u4ee5\u4e0b\u8981\u6c42\uff1a</p> <p>\u667a\u80fd\u4f53\u5e94\u8be5\u80fd\u591f\uff1a</p> <ul> <li>\u8bfb\u53d6\u4f20\u5165\u7684\u5ba2\u6237\u90ae\u4ef6</li> <li>\u6309\u7d27\u6025\u7a0b\u5ea6\u548c\u4e3b\u9898\u8fdb\u884c\u5206\u7c7b</li> <li>\u641c\u7d22\u76f8\u5173\u6587\u6863\u6765\u56de\u7b54\u95ee\u9898</li> <li>\u8d77\u8349\u9002\u5f53\u7684\u56de\u590d</li> <li>\u5c06\u590d\u6742\u95ee\u9898\u8f6c\u4ea4\u7ed9\u4eba\u5de5\u4ee3\u7406</li> <li>\u9700\u8981\u65f6\u5b89\u6392\u8ddf\u8fdb</li> </ul> <p>\u9700\u8981\u5904\u7406\u7684\u793a\u4f8b\u573a\u666f\uff1a</p> <ol> <li>\u7b80\u5355\u4ea7\u54c1\u95ee\u9898\uff1a\"\u5982\u4f55\u91cd\u7f6e\u5bc6\u7801\uff1f\"</li> <li>\u9519\u8bef\u62a5\u544a\uff1a\"\u9009\u62e9 PDF \u683c\u5f0f\u65f6\u5bfc\u51fa\u529f\u80fd\u5d29\u6e83\"</li> <li>\u7d27\u6025\u8d26\u5355\u95ee\u9898\uff1a\"\u6211\u7684\u8ba2\u9605\u88ab\u91cd\u590d\u6536\u8d39\u4e86\uff01\"</li> <li>\u529f\u80fd\u8bf7\u6c42\uff1a\"\u80fd\u5426\u4e3a\u79fb\u52a8\u5e94\u7528\u6dfb\u52a0\u6df1\u8272\u6a21\u5f0f\uff1f\"</li> <li>\u590d\u6742\u6280\u672f\u95ee\u9898\uff1a\"\u6211\u4eec\u7684 API \u96c6\u6210\u95f4\u6b47\u6027\u5931\u8d25\uff0c\u51fa\u73b0 504 \u9519\u8bef\"</li> </ol> <p>\u8981\u5728 LangGraph \u4e2d\u5b9e\u73b0\u667a\u80fd\u4f53\uff0c\u4f60\u901a\u5e38\u9700\u8981\u9075\u5faa\u76f8\u540c\u7684\u4e94\u4e2a\u6b65\u9aa4\u3002</p>"},{"location":"llmapps/langgraph/thinking%20in%20Langgraph/#1","title":"\u6b65\u9aa4 1\uff1a\u5c06\u5de5\u4f5c\u6d41\u7a0b\u6620\u5c04\u4e3a\u79bb\u6563\u6b65\u9aa4","text":"<p>\u9996\u5148\u8bc6\u522b\u6d41\u7a0b\u4e2d\u7684\u4e0d\u540c\u6b65\u9aa4\u3002\u6bcf\u4e2a\u6b65\u9aa4\u5c06\u6210\u4e3a\u4e00\u4e2a\u8282\u70b9\uff08\u6267\u884c\u7279\u5b9a\u64cd\u4f5c\u7684\u51fd\u6570\uff09\u3002\u7136\u540e\u52fe\u753b\u8fd9\u4e9b\u6b65\u9aa4\u5982\u4f55\u76f8\u4e92\u8fde\u63a5\u3002</p> <p></p> <p>\u7bad\u5934\u663e\u793a\u53ef\u80fd\u7684\u8def\u5f84\uff0c\u4f46\u5b9e\u9645\u9009\u62e9\u54ea\u6761\u8def\u5f84\u7684\u51b3\u7b56\u53d1\u751f\u5728\u6bcf\u4e2a\u8282\u70b9\u5185\u90e8\u3002</p> <p>\u73b0\u5728\u4f60\u5df2\u7ecf\u8bc6\u522b\u4e86\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u7684\u7ec4\u4ef6\uff0c\u8ba9\u6211\u4eec\u7406\u89e3\u6bcf\u4e2a\u8282\u70b9\u9700\u8981\u505a\u4ec0\u4e48\uff1a</p> <ul> <li>\u8bfb\u53d6\u90ae\u4ef6\uff1a\u63d0\u53d6\u548c\u89e3\u6790\u90ae\u4ef6\u5185\u5bb9</li> <li>\u5206\u7c7b\u610f\u56fe\uff1a\u4f7f\u7528 LLM \u5206\u7c7b\u7d27\u6025\u7a0b\u5ea6\u548c\u4e3b\u9898\uff0c\u7136\u540e\u8def\u7531\u5230\u9002\u5f53\u7684\u64cd\u4f5c</li> <li>\u6587\u6863\u641c\u7d22\uff1a\u67e5\u8be2\u77e5\u8bc6\u5e93\u83b7\u53d6\u76f8\u5173\u4fe1\u606f</li> <li>\u9519\u8bef\u8ddf\u8e2a\uff1a\u5728\u8ddf\u8e2a\u7cfb\u7edf\u4e2d\u521b\u5efa\u6216\u66f4\u65b0\u95ee\u9898</li> <li>\u8d77\u8349\u56de\u590d\uff1a\u751f\u6210\u9002\u5f53\u7684\u54cd\u5e94</li> <li>\u4eba\u5de5\u5ba1\u6838\uff1a\u8f6c\u4ea4\u7ed9\u4eba\u5de5\u4ee3\u7406\u8fdb\u884c\u6279\u51c6\u6216\u5904\u7406</li> <li>\u53d1\u9001\u56de\u590d\uff1a\u53d1\u9001\u90ae\u4ef6\u56de\u590d</li> </ul> <p>\u63d0\u793a\uff1a\u6ce8\u610f\u6709\u4e9b\u8282\u70b9\u51b3\u5b9a\u4e0b\u4e00\u6b65\u53bb\u54ea\u91cc\uff08\u5206\u7c7b\u610f\u56fe\u3001\u8d77\u8349\u56de\u590d\u3001\u4eba\u5de5\u5ba1\u6838\uff09\uff0c\u800c\u5176\u4ed6\u8282\u70b9\u603b\u662f\u8fdb\u5165\u76f8\u540c\u7684\u4e0b\u4e00\u6b65\uff08\u8bfb\u53d6\u90ae\u4ef6\u603b\u662f\u5230\u5206\u7c7b\u610f\u56fe\uff0c\u6587\u6863\u641c\u7d22\u603b\u662f\u5230\u8d77\u8349\u56de\u590d\uff09\u3002</p>"},{"location":"llmapps/langgraph/thinking%20in%20Langgraph/#2","title":"\u6b65\u9aa4 2\uff1a\u8bc6\u522b\u6bcf\u4e2a\u6b65\u9aa4\u9700\u8981\u505a\u4ec0\u4e48","text":"<p>\u5bf9\u4e8e\u56fe\u4e2d\u7684\u6bcf\u4e2a\u8282\u70b9\uff0c\u786e\u5b9a\u5b83\u4ee3\u8868\u4ec0\u4e48\u7c7b\u578b\u7684\u64cd\u4f5c\u4ee5\u53ca\u9700\u8981\u4ec0\u4e48\u4e0a\u4e0b\u6587\u624d\u80fd\u6b63\u5e38\u5de5\u4f5c\u3002</p>"},{"location":"llmapps/langgraph/thinking%20in%20Langgraph/#llm","title":"LLM \u6b65\u9aa4","text":"<p>\u5f53\u6b65\u9aa4\u9700\u8981\u7406\u89e3\u3001\u5206\u6790\u3001\u751f\u6210\u6587\u672c\u6216\u505a\u51fa\u63a8\u7406\u51b3\u7b56\u65f6\u4f7f\u7528\uff1a</p> <p>\u5206\u7c7b\u610f\u56fe\u8282\u70b9</p> <ul> <li>\u9759\u6001\u4e0a\u4e0b\u6587\uff08\u63d0\u793a\uff09\uff1a\u5206\u7c7b\u7c7b\u522b\u3001\u7d27\u6025\u7a0b\u5ea6\u5b9a\u4e49\u3001\u54cd\u5e94\u683c\u5f0f</li> <li>\u52a8\u6001\u4e0a\u4e0b\u6587\uff08\u6765\u81ea\u72b6\u6001\uff09\uff1a\u90ae\u4ef6\u5185\u5bb9\u3001\u53d1\u4ef6\u4eba\u4fe1\u606f</li> <li>\u671f\u671b\u7ed3\u679c\uff1a\u786e\u5b9a\u8def\u7531\u7684\u7ed3\u6784\u5316\u5206\u7c7b</li> </ul> <p>\u8d77\u8349\u56de\u590d\u8282\u70b9</p> <ul> <li>\u9759\u6001\u4e0a\u4e0b\u6587\uff08\u63d0\u793a\uff09\uff1a\u8bed\u6c14\u6307\u5357\u3001\u516c\u53f8\u653f\u7b56\u3001\u54cd\u5e94\u6a21\u677f</li> <li>\u52a8\u6001\u4e0a\u4e0b\u6587\uff08\u6765\u81ea\u72b6\u6001\uff09\uff1a\u5206\u7c7b\u7ed3\u679c\u3001\u641c\u7d22\u7ed3\u679c\u3001\u5ba2\u6237\u5386\u53f2</li> <li>\u671f\u671b\u7ed3\u679c\uff1a\u51c6\u5907\u5ba1\u6838\u7684\u4e13\u4e1a\u90ae\u4ef6\u56de\u590d</li> </ul>"},{"location":"llmapps/langgraph/thinking%20in%20Langgraph/#_2","title":"\u6570\u636e\u6b65\u9aa4","text":"<p>\u5f53\u6b65\u9aa4\u9700\u8981\u4ece\u5916\u90e8\u6e90\u68c0\u7d22\u4fe1\u606f\u65f6\u4f7f\u7528\uff1a</p> <p>\u6587\u6863\u641c\u7d22\u8282\u70b9</p> <ul> <li>\u53c2\u6570\uff1a\u6839\u636e\u610f\u56fe\u548c\u4e3b\u9898\u6784\u5efa\u7684\u67e5\u8be2</li> <li>\u91cd\u8bd5\u7b56\u7565\uff1a\u662f\uff0c\u5bf9\u6682\u65f6\u6027\u6545\u969c\u4f7f\u7528\u6307\u6570\u9000\u907f</li> <li>\u7f13\u5b58\uff1a\u53ef\u4ee5\u7f13\u5b58\u5e38\u89c1\u67e5\u8be2\u4ee5\u51cf\u5c11 API \u8c03\u7528</li> </ul> <p>\u5ba2\u6237\u5386\u53f2\u67e5\u8be2</p> <ul> <li>\u53c2\u6570\uff1a\u6765\u81ea\u72b6\u6001\u7684\u5ba2\u6237\u90ae\u4ef6\u6216 ID</li> <li>\u91cd\u8bd5\u7b56\u7565\uff1a\u662f\uff0c\u4f46\u5982\u679c\u4e0d\u53ef\u7528\u5219\u56de\u9000\u5230\u57fa\u672c\u4fe1\u606f</li> <li>\u7f13\u5b58\uff1a\u662f\uff0c\u4f7f\u7528\u751f\u5b58\u65f6\u95f4\u6765\u5e73\u8861\u65b0\u9c9c\u5ea6\u548c\u6027\u80fd</li> </ul>"},{"location":"llmapps/langgraph/thinking%20in%20Langgraph/#_3","title":"\u64cd\u4f5c\u6b65\u9aa4","text":"<p>\u5f53\u6b65\u9aa4\u9700\u8981\u6267\u884c\u5916\u90e8\u64cd\u4f5c\u65f6\u4f7f\u7528\uff1a</p> <p>\u53d1\u9001\u56de\u590d\u8282\u70b9</p> <ul> <li>\u6267\u884c\u65f6\u673a\uff1a\u6279\u51c6\u540e\uff08\u4eba\u5de5\u6216\u81ea\u52a8\uff09</li> <li>\u91cd\u8bd5\u7b56\u7565\uff1a\u662f\uff0c\u5bf9\u7f51\u7edc\u95ee\u9898\u4f7f\u7528\u6307\u6570\u9000\u907f</li> <li>\u4e0d\u5e94\u7f13\u5b58\uff1a\u6bcf\u6b21\u53d1\u9001\u90fd\u662f\u552f\u4e00\u64cd\u4f5c</li> </ul> <p>\u9519\u8bef\u8ddf\u8e2a\u8282\u70b9</p> <ul> <li>\u6267\u884c\u65f6\u673a\uff1a\u610f\u56fe\u4e3a\"\u9519\u8bef\"\u65f6\u603b\u662f\u6267\u884c</li> <li>\u91cd\u8bd5\u7b56\u7565\uff1a\u662f\uff0c\u5173\u952e\u662f\u4e0d\u80fd\u4e22\u5931\u9519\u8bef\u62a5\u544a</li> <li>\u8fd4\u56de\uff1a\u8981\u5728\u54cd\u5e94\u4e2d\u5305\u542b\u7684\u5de5\u5355 ID</li> </ul>"},{"location":"llmapps/langgraph/thinking%20in%20Langgraph/#_4","title":"\u7528\u6237\u8f93\u5165\u6b65\u9aa4","text":"<p>\u5f53\u6b65\u9aa4\u9700\u8981\u4eba\u5de5\u5e72\u9884\u65f6\u4f7f\u7528\uff1a</p> <p>\u4eba\u5de5\u5ba1\u6838\u8282\u70b9</p> <ul> <li>\u51b3\u7b56\u4e0a\u4e0b\u6587\uff1a\u539f\u59cb\u90ae\u4ef6\u3001\u8349\u7a3f\u56de\u590d\u3001\u7d27\u6025\u7a0b\u5ea6\u3001\u5206\u7c7b</li> <li>\u671f\u671b\u8f93\u5165\u683c\u5f0f\uff1a\u6279\u51c6\u5e03\u5c14\u503c\u52a0\u4e0a\u53ef\u9009\u7684\u7f16\u8f91\u54cd\u5e94</li> <li>\u89e6\u53d1\u65f6\u673a\uff1a\u9ad8\u7d27\u6025\u7a0b\u5ea6\u3001\u590d\u6742\u95ee\u9898\u6216\u8d28\u91cf\u62c5\u5fe7</li> </ul>"},{"location":"llmapps/langgraph/thinking%20in%20Langgraph/#3","title":"\u6b65\u9aa4 3\uff1a\u8bbe\u8ba1\u4f60\u7684\u72b6\u6001","text":"<p>\u72b6\u6001\u662f\u4f60\u7684\u667a\u80fd\u4f53\u4e2d\u6240\u6709\u8282\u70b9\u90fd\u53ef\u4ee5\u8bbf\u95ee\u7684\u5171\u4eab[\u5185\u5b58]\u3002\u53ef\u4ee5\u628a\u5b83\u770b\u4f5c\u4f60\u7684\u667a\u80fd\u4f53\u5728\u5904\u7406\u8fc7\u7a0b\u4e2d\u7528\u6765\u8ddf\u8e2a\u4e00\u5207\u5b66\u4e60\u548c\u51b3\u7b56\u7684\u7b14\u8bb0\u672c\u3002</p>"},{"location":"llmapps/langgraph/thinking%20in%20Langgraph/#_5","title":"\u4ec0\u4e48\u5e94\u8be5\u653e\u5728\u72b6\u6001\u4e2d\uff1f","text":"<p>\u5bf9\u6bcf\u4e2a\u6570\u636e\u7247\u6bb5\u95ee\u81ea\u5df1\u8fd9\u4e9b\u95ee\u9898\uff1a</p> <p>\u5305\u542b\u5728\u72b6\u6001\u4e2d</p> <ul> <li>\u662f\u5426\u9700\u8981\u8de8\u6b65\u9aa4\u6301\u4e45\u5316\uff1f\u5982\u679c\u662f\uff0c\u5c31\u653e\u5728\u72b6\u6001\u4e2d</li> </ul> <p>\u4e0d\u8981\u5b58\u50a8</p> <ul> <li>\u80fd\u5426\u4ece\u5176\u4ed6\u6570\u636e\u63a8\u5bfc\u51fa\u6765\uff1f\u5982\u679c\u662f\uff0c\u5728\u9700\u8981\u65f6\u8ba1\u7b97\u800c\u4e0d\u662f\u5b58\u50a8\u5728\u72b6\u6001\u4e2d</li> </ul> <p>\u5bf9\u4e8e\u6211\u4eec\u7684\u90ae\u4ef6\u667a\u80fd\u4f53\uff0c\u6211\u4eec\u9700\u8981\u8ddf\u8e2a\uff1a</p> <ul> <li>\u539f\u59cb\u90ae\u4ef6\u548c\u53d1\u4ef6\u4eba\u4fe1\u606f\uff08\u65e0\u6cd5\u91cd\u5efa\u8fd9\u4e9b\uff09</li> <li>\u5206\u7c7b\u7ed3\u679c\uff08\u591a\u4e2a\u4e0b\u6e38\u8282\u70b9\u9700\u8981\uff09</li> <li>\u641c\u7d22\u7ed3\u679c\u548c\u5ba2\u6237\u6570\u636e\uff08\u91cd\u65b0\u83b7\u53d6\u6210\u672c\u9ad8\uff09</li> <li>\u8349\u7a3f\u56de\u590d\uff08\u9700\u8981\u901a\u8fc7\u5ba1\u6838\u6301\u4e45\u5316\uff09</li> <li>\u6267\u884c\u5143\u6570\u636e\uff08\u7528\u4e8e\u8c03\u8bd5\u548c\u6062\u590d\uff09</li> </ul>"},{"location":"llmapps/langgraph/thinking%20in%20Langgraph/#_6","title":"\u4fdd\u6301\u72b6\u6001\u539f\u59cb\uff0c\u6309\u9700\u683c\u5f0f\u5316\u63d0\u793a","text":"<p>\u5173\u952e\u539f\u5219\uff1a\u4f60\u7684\u72b6\u6001\u5e94\u8be5\u5b58\u50a8\u539f\u59cb\u6570\u636e\uff0c\u800c\u4e0d\u662f\u683c\u5f0f\u5316\u6587\u672c\u3002\u5728\u9700\u8981\u65f6\u5728\u8282\u70b9\u5185\u90e8\u683c\u5f0f\u5316\u63d0\u793a\u3002</p> <p>\u8fd9\u79cd\u5206\u79bb\u610f\u5473\u7740\uff1a</p> <ul> <li>\u4e0d\u540c\u8282\u70b9\u53ef\u4ee5\u4e3a\u4e86\u5404\u81ea\u7684\u9700\u8981\u4ee5\u4e0d\u540c\u65b9\u5f0f\u683c\u5f0f\u5316\u76f8\u540c\u7684\u6570\u636e</li> <li>\u4f60\u53ef\u4ee5\u66f4\u6539\u63d0\u793a\u6a21\u677f\u800c\u4e0d\u4fee\u6539\u72b6\u6001\u6a21\u5f0f</li> <li>\u8c03\u8bd5\u66f4\u6e05\u6670 - \u4f60\u53ef\u4ee5\u770b\u5230\u6bcf\u4e2a\u8282\u70b9\u63a5\u6536\u5230\u7684\u786e\u5207\u6570\u636e</li> <li>\u4f60\u7684\u667a\u80fd\u4f53\u53ef\u4ee5\u6f14\u8fdb\u800c\u4e0d\u7834\u574f\u73b0\u6709\u72b6\u6001</li> </ul> <p>\u8ba9\u6211\u4eec\u5b9a\u4e49\u6211\u4eec\u7684\u72b6\u6001\uff1a</p> <pre><code>from typing import TypedDict, Literal\n\n# \u5b9a\u4e49\u90ae\u4ef6\u5206\u7c7b\u7ed3\u6784\nclass EmailClassification(TypedDict):\n    intent: Literal[\"question\", \"bug\", \"billing\", \"feature\", \"complex\"]\n    urgency: Literal[\"low\", \"medium\", \"high\", \"critical\"]\n    topic: str\n    summary: str\n\nclass EmailAgentState(TypedDict):\n    # \u539f\u59cb\u90ae\u4ef6\u6570\u636e\n    email_content: str\n    sender_email: str\n    email_id: str\n\n    # \u5206\u7c7b\u7ed3\u679c\n    classification: EmailClassification | None\n\n    # \u539f\u59cb\u641c\u7d22/API \u7ed3\u679c\n    search_results: list[str] | None  # \u539f\u59cb\u6587\u6863\u5757\u5217\u8868\n    customer_history: dict | None  # \u6765\u81ea CRM \u7684\u539f\u59cb\u5ba2\u6237\u6570\u636e\n\n    # \u751f\u6210\u7684\u5185\u5bb9\n    draft_response: str | None\n</code></pre> <p>\u6ce8\u610f\u72b6\u6001\u53ea\u5305\u542b\u539f\u59cb\u6570\u636e - \u6ca1\u6709\u63d0\u793a\u6a21\u677f\uff0c\u6ca1\u6709\u683c\u5f0f\u5316\u5b57\u7b26\u4e32\uff0c\u6ca1\u6709\u6307\u4ee4\u3002\u5206\u7c7b\u8f93\u51fa\u4f5c\u4e3a\u5355\u4e2a\u5b57\u5178\u5b58\u50a8\uff0c\u76f4\u63a5\u6765\u81ea LLM\u3002</p>"},{"location":"llmapps/langgraph/thinking%20in%20Langgraph/#4","title":"\u6b65\u9aa4 4\uff1a\u6784\u5efa\u4f60\u7684\u8282\u70b9","text":"<p>\u73b0\u5728\u6211\u4eec\u5b9e\u73b0\u6bcf\u4e2a\u6b65\u9aa4\u4f5c\u4e3a\u4e00\u4e2a\u51fd\u6570\u3002LangGraph \u4e2d\u7684\u8282\u70b9\u53ea\u662f\u4e00\u4e2a Python \u51fd\u6570\uff0c\u5b83\u63a5\u53d7\u5f53\u524d\u72b6\u6001\u5e76\u8fd4\u56de\u5bf9\u5176\u7684\u66f4\u65b0\u3002</p>"},{"location":"llmapps/langgraph/thinking%20in%20Langgraph/#_7","title":"\u9002\u5f53\u5904\u7406\u9519\u8bef","text":"<p>\u4e0d\u540c\u7c7b\u578b\u7684\u9519\u8bef\u9700\u8981\u4e0d\u540c\u7684\u5904\u7406\u7b56\u7565\uff1a</p> \u9519\u8bef\u7c7b\u578b \u8c01\u4fee\u590d \u7b56\u7565 \u4f7f\u7528\u65f6\u673a \u6682\u65f6\u6027\u9519\u8bef\uff08\u7f51\u7edc\u95ee\u9898\u3001\u901f\u7387\u9650\u5236\uff09 \u7cfb\u7edf\uff08\u81ea\u52a8\uff09 \u91cd\u8bd5\u7b56\u7565 \u901a\u5e38\u91cd\u8bd5\u80fd\u89e3\u51b3\u7684\u4e34\u65f6\u6545\u969c LLM \u53ef\u6062\u590d\u9519\u8bef\uff08\u5de5\u5177\u6545\u969c\u3001\u89e3\u6790\u95ee\u9898\uff09 LLM \u5c06\u9519\u8bef\u5b58\u50a8\u5728\u72b6\u6001\u4e2d\u5e76\u5faa\u73af\u56de\u53bb LLM \u53ef\u4ee5\u770b\u5230\u9519\u8bef\u5e76\u8c03\u6574\u65b9\u6cd5 \u7528\u6237\u53ef\u4fee\u590d\u9519\u8bef\uff08\u7f3a\u5c11\u4fe1\u606f\u3001\u6307\u4ee4\u4e0d\u6e05\uff09 \u4eba\u5de5 \u4f7f\u7528 <code>interrupt()</code> \u6682\u505c \u9700\u8981\u7528\u6237\u8f93\u5165\u624d\u80fd\u7ee7\u7eed \u610f\u5916\u9519\u8bef \u5f00\u53d1\u8005 \u8ba9\u5b83\u4eec\u5192\u6ce1 \u9700\u8981\u8c03\u8bd5\u7684\u672a\u77e5\u95ee\u9898 <p>\u6682\u65f6\u6027\u9519\u8bef\u5904\u7406</p> <pre><code>from langgraph.types import RetryPolicy\n\nworkflow.add_node(\n    \"search_documentation\",\n    search_documentation,\n    retry_policy=RetryPolicy(max_attempts=3, initial_interval=1.0)\n)\n</code></pre> <p>LLM \u53ef\u6062\u590d\u9519\u8bef\u5904\u7406</p> <pre><code>from langgraph.types import Command\n\ndef execute_tool(state: State) -&gt; Command[Literal[\"agent\", \"execute_tool\"]]:\n    try:\n        result = run_tool(state['tool_call'])\n        return Command(update={\"tool_result\": result}, goto=\"agent\")\n    except ToolError as e:\n        # \u8ba9 LLM \u770b\u5230\u95ee\u9898\u5e76\u91cd\u8bd5\n        return Command(\n            update={\"tool_result\": f\"\u5de5\u5177\u9519\u8bef: {str(e)}\"},\n            goto=\"agent\"\n        )\n</code></pre> <p>\u7528\u6237\u53ef\u4fee\u590d\u9519\u8bef\u5904\u7406</p> <pre><code>from langgraph.types import Command\n\ndef lookup_customer_history(state: State) -&gt; Command[Literal[\"draft_response\"]]:\n    if not state.get('customer_id'):\n        user_input = interrupt({\n            \"message\": \"\u9700\u8981\u5ba2\u6237 ID\",\n            \"request\": \"\u8bf7\u63d0\u4f9b\u5ba2\u6237\u8d26\u6237 ID \u4ee5\u67e5\u8be2\u8ba2\u9605\u5386\u53f2\"\n        })\n        return Command(\n            update={\"customer_id\": user_input['customer_id']},\n            goto=\"lookup_customer_history\"\n        )\n    # \u73b0\u5728\u7ee7\u7eed\u67e5\u8be2\n    customer_data = fetch_customer_history(state['customer_id'])\n    return Command(update={\"customer_history\": customer_data}, goto=\"draft_response\")\n</code></pre> <p>\u610f\u5916\u9519\u8bef\u5904\u7406</p> <pre><code>def send_reply(state: EmailAgentState):\n    try:\n        email_service.send(state[\"draft_response\"])\n    except Exception:\n        raise  # \u629b\u51fa\u610f\u5916\u9519\u8bef\n</code></pre>"},{"location":"llmapps/langgraph/thinking%20in%20Langgraph/#_8","title":"\u5b9e\u73b0\u6211\u4eec\u7684\u90ae\u4ef6\u667a\u80fd\u4f53\u8282\u70b9","text":"<p>\u6211\u4eec\u5c06\u6bcf\u4e2a\u8282\u70b9\u5b9e\u73b0\u4e3a\u4e00\u4e2a\u7b80\u5355\u7684\u51fd\u6570\u3002\u8bb0\u4f4f\uff1a\u8282\u70b9\u63a5\u53d7\u72b6\u6001\uff0c\u6267\u884c\u5de5\u4f5c\uff0c\u5e76\u8fd4\u56de\u66f4\u65b0\u3002</p> <p>\u8bfb\u53d6\u548c\u5206\u7c7b\u8282\u70b9</p> <pre><code>from typing import Literal\nfrom langgraph.graph import StateGraph, START, END\nfrom langgraph.types import interrupt, Command, RetryPolicy\nfrom langchain_openai import ChatOpenAI\nfrom langchain_core.messages import HumanMessage\n\nllm = ChatOpenAI(model=\"gpt-4\")\n\ndef read_email(state: EmailAgentState) -&gt; dict:\n    \"\"\"\u63d0\u53d6\u548c\u89e3\u6790\u90ae\u4ef6\u5185\u5bb9\"\"\"\n    # \u5728\u751f\u4ea7\u73af\u5883\u4e2d\uff0c\u8fd9\u5c06\u8fde\u63a5\u5230\u4f60\u7684\u90ae\u4ef6\u670d\u52a1\n    return {\n        \"messages\": [HumanMessage(content=f\"\u5904\u7406\u90ae\u4ef6: {state['email_content']}\")]\n    }\n\ndef classify_intent(state: EmailAgentState) -&gt; Command[Literal[\"search_documentation\", \"human_review\", \"draft_response\", \"bug_tracking\"]]:\n    \"\"\"\u4f7f\u7528 LLM \u5206\u7c7b\u90ae\u4ef6\u610f\u56fe\u548c\u7d27\u6025\u7a0b\u5ea6\uff0c\u7136\u540e\u76f8\u5e94\u8def\u7531\"\"\"\n\n    # \u521b\u5efa\u8fd4\u56de EmailClassification \u5b57\u5178\u7684\u7ed3\u6784\u5316 LLM\n    structured_llm = llm.with_structured_output(EmailClassification)\n\n    # \u6309\u9700\u683c\u5f0f\u5316\u63d0\u793a\uff0c\u4e0d\u5b58\u50a8\u5728\u72b6\u6001\u4e2d\n    classification_prompt = f\"\"\"\n    \u5206\u6790\u6b64\u5ba2\u6237\u90ae\u4ef6\u5e76\u5206\u7c7b\uff1a\n\n    \u90ae\u4ef6: {state['email_content']}\n    \u53d1\u4ef6\u4eba: {state['sender_email']}\n\n    \u63d0\u4f9b\u5206\u7c7b\uff0c\u5305\u62ec\u610f\u56fe\u3001\u7d27\u6025\u7a0b\u5ea6\u3001\u4e3b\u9898\u548c\u6458\u8981\u3002\n    \"\"\"\n\n    # \u76f4\u63a5\u83b7\u53d6\u7ed3\u6784\u5316\u54cd\u5e94\u4f5c\u4e3a\u5b57\u5178\n    classification = structured_llm.invoke(classification_prompt)\n\n    # \u6839\u636e\u5206\u7c7b\u786e\u5b9a\u4e0b\u4e00\u4e2a\u8282\u70b9\n    if classification['intent'] == 'billing' or classification['urgency'] == 'critical':\n        goto = \"human_review\"\n    elif classification['intent'] in ['question', 'feature']:\n        goto = \"search_documentation\"\n    elif classification['intent'] == 'bug':\n        goto = \"bug_tracking\"\n    else:\n        goto = \"draft_response\"\n\n    # \u5c06\u5206\u7c7b\u4f5c\u4e3a\u5355\u4e2a\u5b57\u5178\u5b58\u50a8\u5728\u72b6\u6001\u4e2d\n    return Command(\n        update={\"classification\": classification},\n        goto=goto\n    )\n</code></pre> <p>\u641c\u7d22\u548c\u8ddf\u8e2a\u8282\u70b9</p> <pre><code>def search_documentation(state: EmailAgentState) -&gt; Command[Literal[\"draft_response\"]]:\n    \"\"\"\u641c\u7d22\u77e5\u8bc6\u5e93\u83b7\u53d6\u76f8\u5173\u4fe1\u606f\"\"\"\n\n    # \u4ece\u5206\u7c7b\u6784\u5efa\u641c\u7d22\u67e5\u8be2\n    classification = state.get('classification', {})\n    query = f\"{classification.get('intent', '')} {classification.get('topic', '')}\"\n\n    try:\n        # \u5728\u6b64\u5b9e\u73b0\u4f60\u7684\u641c\u7d22\u903b\u8f91\n        # \u5b58\u50a8\u539f\u59cb\u641c\u7d22\u7ed3\u679c\uff0c\u4e0d\u662f\u683c\u5f0f\u5316\u6587\u672c\n        search_results = [\n            \"\u901a\u8fc7\u8bbe\u7f6e &gt; \u5b89\u5168 &gt; \u66f4\u6539\u5bc6\u7801\u91cd\u7f6e\u5bc6\u7801\",\n            \"\u5bc6\u7801\u5fc5\u987b\u81f3\u5c1112\u4e2a\u5b57\u7b26\",\n            \"\u5305\u542b\u5927\u5199\u5b57\u6bcd\u3001\u5c0f\u5199\u5b57\u6bcd\u3001\u6570\u5b57\u548c\u7b26\u53f7\"\n        ]\n    except SearchAPIError as e:\n        # \u5bf9\u4e8e\u53ef\u6062\u590d\u7684\u641c\u7d22\u9519\u8bef\uff0c\u5b58\u50a8\u9519\u8bef\u5e76\u7ee7\u7eed\n        search_results = [f\"\u641c\u7d22\u6682\u65f6\u4e0d\u53ef\u7528: {str(e)}\"]\n\n    return Command(\n        update={\"search_results\": search_results},  # \u5b58\u50a8\u539f\u59cb\u7ed3\u679c\u6216\u9519\u8bef\n        goto=\"draft_response\"\n    )\n\ndef bug_tracking(state: EmailAgentState) -&gt; Command[Literal[\"draft_response\"]]:\n    \"\"\"\u5728\u9519\u8bef\u8ddf\u8e2a\u7cfb\u7edf\u4e2d\u521b\u5efa\u6216\u66f4\u65b0\u5de5\u5355\"\"\"\n\n    # \u901a\u8fc7 API \u5728\u4f60\u7684\u9519\u8bef\u8ddf\u8e2a\u7cfb\u7edf\u4e2d\u521b\u5efa\u5de5\u5355\n    ticket_id = \"BUG-12345\"  # \u5c06\u901a\u8fc7 API \u521b\u5efa\n\n    return Command(\n        update={\n            \"search_results\": [f\"\u9519\u8bef\u5de5\u5355 {ticket_id} \u5df2\u521b\u5efa\"],\n            \"current_step\": \"bug_tracked\"\n        },\n        goto=\"draft_response\"\n    )\n</code></pre> <p>\u54cd\u5e94\u8282\u70b9</p> <pre><code>def draft_response(state: EmailAgentState) -&gt; Command[Literal[\"human_review\", \"send_reply\"]]:\n    \"\"\"\u4f7f\u7528\u4e0a\u4e0b\u6587\u751f\u6210\u54cd\u5e94\u5e76\u6839\u636e\u8d28\u91cf\u8def\u7531\"\"\"\n\n    classification = state.get('classification', {})\n\n    # \u6309\u9700\u4ece\u539f\u59cb\u72b6\u6001\u6570\u636e\u683c\u5f0f\u5316\u4e0a\u4e0b\u6587\n    context_sections = []\n\n    if state.get('search_results'):\n        # \u4e3a\u63d0\u793a\u683c\u5f0f\u5316\u641c\u7d22\u7ed3\u679c\n        formatted_docs = \"\\n\".join([f\"- {doc}\" for doc in state['search_results']])\n        context_sections.append(f\"\u76f8\u5173\u6587\u6863:\\n{formatted_docs}\")\n\n    if state.get('customer_history'):\n        # \u4e3a\u63d0\u793a\u683c\u5f0f\u5316\u5ba2\u6237\u6570\u636e\n        context_sections.append(f\"\u5ba2\u6237\u5c42\u7ea7: {state['customer_history'].get('tier', 'standard')}\")\n\n    # \u4f7f\u7528\u683c\u5f0f\u5316\u4e0a\u4e0b\u6587\u6784\u5efa\u63d0\u793a\n    draft_prompt = f\"\"\"\n    \u8d77\u8349\u5bf9\u6b64\u5ba2\u6237\u90ae\u4ef6\u7684\u56de\u590d\uff1a\n    {state['email_content']}\n\n    \u90ae\u4ef6\u610f\u56fe: {classification.get('intent', 'unknown')}\n    \u7d27\u6025\u7a0b\u5ea6: {classification.get('urgency', 'medium')}\n\n    {chr(10).join(context_sections)}\n\n    \u6307\u5357\uff1a\n    - \u4e13\u4e1a\u4e14\u4e50\u4e8e\u52a9\u4eba\n    - \u89e3\u51b3\u4ed6\u4eec\u7684\u5177\u4f53\u95ee\u9898\n    - \u76f8\u5173\u65f6\u4f7f\u7528\u63d0\u4f9b\u7684\u6587\u6863\n    \"\"\"\n\n    response = llm.invoke(draft_prompt)\n\n    # \u6839\u636e\u7d27\u6025\u7a0b\u5ea6\u548c\u610f\u56fe\u786e\u5b9a\u662f\u5426\u9700\u8981\u4eba\u5de5\u5ba1\u6838\n    needs_review = (\n        classification.get('urgency') in ['high', 'critical'] or\n        classification.get('intent') == 'complex'\n    )\n\n    # \u8def\u7531\u5230\u9002\u5f53\u7684\u4e0b\u4e00\u8282\u70b9\n    goto = \"human_review\" if needs_review else \"send_reply\"\n\n    return Command(\n        update={\"draft_response\": response.content},  # \u53ea\u5b58\u50a8\u539f\u59cb\u54cd\u5e94\n        goto=goto\n    )\n\ndef human_review(state: EmailAgentState) -&gt; Command[Literal[\"send_reply\", END]]:\n    \"\"\"\u4f7f\u7528 interrupt \u6682\u505c\u4eba\u5de5\u5ba1\u6838\u5e76\u6839\u636e\u51b3\u7b56\u8def\u7531\"\"\"\n\n    classification = state.get('classification', {})\n\n    # interrupt() \u5fc5\u987b\u9996\u5148\u51fa\u73b0 - \u5b83\u4e4b\u524d\u7684\u4efb\u4f55\u4ee3\u7801\u90fd\u5c06\u5728\u6062\u590d\u65f6\u91cd\u65b0\u8fd0\u884c\n    human_decision = interrupt({\n        \"email_id\": state['email_id'],\n        \"original_email\": state['email_content'],\n        \"draft_response\": state['draft_response'],\n        \"urgency\": classification.get('urgency'),\n        \"intent\": classification.get('intent'),\n        \"action\": \"\u8bf7\u5ba1\u6838\u5e76\u6279\u51c6/\u7f16\u8f91\u6b64\u54cd\u5e94\"\n    })\n\n    # \u73b0\u5728\u5904\u7406\u4eba\u5de5\u51b3\u7b56\n    if human_decision.get(\"approved\"):\n        return Command(\n            update={\"draft_response\": human_decision.get(\"edited_response\", state['draft_response'])},\n            goto=\"send_reply\"\n        )\n    else:\n        # \u62d2\u7edd\u610f\u5473\u7740\u4eba\u5de5\u5c06\u76f4\u63a5\u5904\u7406\n        return Command(update={}, goto=END)\n\ndef send_reply(state: EmailAgentState) -&gt; dict:\n    \"\"\"\u53d1\u9001\u90ae\u4ef6\u56de\u590d\"\"\"\n    # \u4e0e\u90ae\u4ef6\u670d\u52a1\u96c6\u6210\n    print(f\"\u53d1\u9001\u56de\u590d: {state['draft_response'][:100]}...\")\n    return {}\n</code></pre>"},{"location":"llmapps/langgraph/thinking%20in%20Langgraph/#5","title":"\u6b65\u9aa4 5\uff1a\u5c06\u5b83\u4eec\u8fde\u63a5\u8d77\u6765","text":"<p>\u73b0\u5728\u6211\u4eec\u5c06\u8282\u70b9\u8fde\u63a5\u6210\u4e00\u4e2a\u5de5\u4f5c\u56fe\u3002\u7531\u4e8e\u6211\u4eec\u7684\u8282\u70b9\u5904\u7406\u81ea\u5df1\u7684\u8def\u7531\u51b3\u7b56\uff0c\u6211\u4eec\u53ea\u9700\u8981\u4e00\u4e9b\u57fa\u672c\u7684\u8fb9\u3002</p> <p>\u8981\u4f7f\u7528 <code>interrupt()</code> \u542f\u7528[\u4eba\u5de5\u5e72\u9884]\uff0c\u6211\u4eec\u9700\u8981\u4f7f\u7528[\u68c0\u67e5\u70b9]\u8fdb\u884c\u7f16\u8bd1\u4ee5\u5728\u8fd0\u884c\u4e4b\u95f4\u4fdd\u5b58\u72b6\u6001\uff1a</p> <pre><code>from langgraph.checkpoint.memory import MemorySaver\nfrom langgraph.types import RetryPolicy\n\n# \u521b\u5efa\u56fe\nworkflow = StateGraph(EmailAgentState)\n\n# \u6dfb\u52a0\u5e26\u6709\u9002\u5f53\u9519\u8bef\u5904\u7406\u7684\u8282\u70b9\nworkflow.add_node(\"read_email\", read_email)\nworkflow.add_node(\"classify_intent\", classify_intent)\n\n# \u4e3a\u53ef\u80fd\u6709\u6682\u65f6\u6027\u6545\u969c\u7684\u8282\u70b9\u6dfb\u52a0\u91cd\u8bd5\u7b56\u7565\nworkflow.add_node(\n    \"search_documentation\",\n    search_documentation,\n    retry_policy=RetryPolicy(max_attempts=3)\n)\nworkflow.add_node(\"bug_tracking\", bug_tracking)\nworkflow.add_node(\"draft_response\", draft_response)\nworkflow.add_node(\"human_review\", human_review)\nworkflow.add_node(\"send_reply\", send_reply)\n\n# \u53ea\u6dfb\u52a0\u57fa\u672c\u8fb9\nworkflow.add_edge(START, \"read_email\")\nworkflow.add_edge(\"read_email\", \"classify_intent\")\nworkflow.add_edge(\"send_reply\", END)\n\n# \u4f7f\u7528\u68c0\u67e5\u70b9\u8fdb\u884c\u6301\u4e45\u5316\u7f16\u8bd1\nmemory = MemorySaver()\napp = workflow.compile(checkpointer=memory)\n</code></pre> <p>\u56fe\u7ed3\u6784\u662f\u6700\u5c0f\u7684\uff0c\u56e0\u4e3a\u8def\u7531\u901a\u8fc7 <code>Command</code> \u5bf9\u8c61\u5728\u8282\u70b9\u5185\u90e8\u53d1\u751f\u3002\u6bcf\u4e2a\u8282\u70b9\u4f7f\u7528\u7c7b\u578b\u63d0\u793a\u5982 <code>Command[Literal[\"node1\", \"node2\"]]</code> \u58f0\u660e\u5b83\u53ef\u4ee5\u53bb\u54ea\u91cc\uff0c\u4f7f\u6d41\u7a0b\u660e\u786e\u4e14\u53ef\u8ffd\u8e2a\u3002</p>"},{"location":"llmapps/langgraph/thinking%20in%20Langgraph/#_9","title":"\u6d4b\u8bd5\u4f60\u7684\u667a\u80fd\u4f53","text":"<p>\u8ba9\u6211\u4eec\u7528\u4e00\u4e2a\u9700\u8981\u4eba\u5de5\u5ba1\u6838\u7684\u7d27\u6025\u8d26\u5355\u95ee\u9898\u6765\u8fd0\u884c\u6211\u4eec\u7684\u667a\u80fd\u4f53\uff1a</p> <pre><code># \u6d4b\u8bd5\u7d27\u6025\u8d26\u5355\u95ee\u9898\ninitial_state = {\n    \"email_content\": \"\u6211\u7684\u8ba2\u9605\u88ab\u91cd\u590d\u6536\u8d39\u4e86\uff01\u8fd9\u5f88\u7d27\u6025\uff01\",\n    \"sender_email\": \"customer@example.com\",\n    \"email_id\": \"email_123\",\n    \"messages\": []\n}\n\n# \u4f7f\u7528 thread_id \u8fdb\u884c\u6301\u4e45\u5316\u8fd0\u884c\nconfig = {\"configurable\": {\"thread_id\": \"customer_123\"}}\nresult = app.invoke(initial_state, config)\n# \u56fe\u5c06\u5728 human_review \u5904\u6682\u505c\nprint(f\"\u51c6\u5907\u5ba1\u6838\u7684\u8349\u7a3f: {result['draft_response'][:100]}...\")\n\n# \u51c6\u5907\u5c31\u7eea\u65f6\uff0c\u63d0\u4f9b\u4eba\u5de5\u8f93\u5165\u4ee5\u6062\u590d\nfrom langgraph.types import Command\n\nhuman_response = Command(\n    resume={\n        \"approved\": True,\n        \"edited_response\": \"\u6211\u4eec\u4e3a\u91cd\u590d\u6536\u8d39\u8bda\u631a\u9053\u6b49\u3002\u6211\u5df2\u7acb\u5373\u542f\u52a8\u9000\u6b3e...\"\n    }\n)\n\n# \u6062\u590d\u6267\u884c\nfinal_result = app.invoke(human_response, config)\nprint(f\"\u90ae\u4ef6\u53d1\u9001\u6210\u529f\uff01\")\n</code></pre> <p>\u5f53\u56fe\u9047\u5230 <code>interrupt()</code> \u65f6\u6682\u505c\uff0c\u5c06\u6240\u6709\u5185\u5bb9\u4fdd\u5b58\u5230\u68c0\u67e5\u70b9\uff0c\u5e76\u7b49\u5f85\u3002\u5b83\u53ef\u4ee5\u5728\u51e0\u5929\u540e\u6062\u590d\uff0c\u4ece\u505c\u6b62\u7684\u5730\u65b9\u51c6\u786e\u7ee7\u7eed\u3002<code>thread_id</code> \u786e\u4fdd\u6b64\u5bf9\u8bdd\u7684\u6240\u6709\u72b6\u6001\u90fd\u4e00\u8d77\u4fdd\u5b58\u3002</p>"},{"location":"llmapps/langgraph/thinking%20in%20Langgraph/#_10","title":"\u603b\u7ed3\u548c\u4e0b\u4e00\u6b65","text":""},{"location":"llmapps/langgraph/thinking%20in%20Langgraph/#_11","title":"\u5173\u952e\u89c1\u89e3","text":"<p>\u6784\u5efa\u8fd9\u4e2a\u90ae\u4ef6\u667a\u80fd\u4f53\u5411\u6211\u4eec\u5c55\u793a\u4e86 LangGraph \u7684\u601d\u7ef4\u65b9\u5f0f\uff1a</p> <p>\u5206\u89e3\u4e3a\u79bb\u6563\u6b65\u9aa4 * \u6bcf\u4e2a\u8282\u70b9\u505a\u597d\u4e00\u4ef6\u4e8b\u3002\u8fd9\u79cd\u5206\u89e3\u652f\u6301\u6d41\u5f0f\u8fdb\u5ea6\u66f4\u65b0\u3001\u53ef\u4ee5\u6682\u505c\u548c\u6062\u590d\u7684\u6301\u4e45\u6267\u884c\uff0c\u4ee5\u53ca\u6e05\u6670\u7684\u8c03\u8bd5\uff0c\u56e0\u4e3a\u4f60\u53ef\u4ee5\u5728\u6b65\u9aa4\u4e4b\u95f4\u68c0\u67e5\u72b6\u6001\u3002</p> <p>\u72b6\u6001\u662f\u5171\u4eab\u5185\u5b58 * \u5b58\u50a8\u539f\u59cb\u6570\u636e\uff0c\u800c\u4e0d\u662f\u683c\u5f0f\u5316\u6587\u672c\u3002\u8fd9\u8ba9\u4e0d\u540c\u8282\u70b9\u4ee5\u4e0d\u540c\u65b9\u5f0f\u4f7f\u7528\u76f8\u540c\u7684\u4fe1\u606f\u3002</p> <p>\u8282\u70b9\u662f\u51fd\u6570 * \u5b83\u4eec\u63a5\u53d7\u72b6\u6001\uff0c\u6267\u884c\u5de5\u4f5c\uff0c\u5e76\u8fd4\u56de\u66f4\u65b0\u3002\u5f53\u9700\u8981\u505a\u51fa\u8def\u7531\u51b3\u7b56\u65f6\uff0c\u5b83\u4eec\u6307\u5b9a\u72b6\u6001\u66f4\u65b0\u548c\u4e0b\u4e00\u4e2a\u76ee\u7684\u5730\u3002</p> <p>\u9519\u8bef\u662f\u6d41\u7a0b\u7684\u4e00\u90e8\u5206 * \u6682\u65f6\u6027\u6545\u969c\u91cd\u8bd5\uff0cLLM \u53ef\u6062\u590d\u9519\u8bef\u5faa\u73af\u56de\u53bb\u5e76\u63d0\u4f9b\u4e0a\u4e0b\u6587\uff0c\u7528\u6237\u53ef\u4fee\u590d\u95ee\u9898\u6682\u505c\u7b49\u5f85\u8f93\u5165\uff0c\u610f\u5916\u9519\u8bef\u5192\u6ce1\u7528\u4e8e\u8c03\u8bd5\u3002</p> <p>\u4eba\u5de5\u8f93\u5165\u662f\u4e00\u7b49\u516c\u6c11 * <code>interrupt()</code> \u51fd\u6570\u65e0\u9650\u671f\u6682\u505c\u6267\u884c\uff0c\u4fdd\u5b58\u6240\u6709\u72b6\u6001\uff0c\u5e76\u5728\u4f60\u63d0\u4f9b\u8f93\u5165\u65f6\u4ece\u505c\u6b62\u7684\u5730\u65b9\u51c6\u786e\u6062\u590d\u3002\u5f53\u4e0e\u8282\u70b9\u4e2d\u7684\u5176\u4ed6\u64cd\u4f5c\u7ed3\u5408\u65f6\uff0c\u5b83\u5fc5\u987b\u9996\u5148\u51fa\u73b0\u3002</p> <p>\u56fe\u7ed3\u6784\u81ea\u7136\u51fa\u73b0 * \u4f60\u5b9a\u4e49\u57fa\u672c\u8fde\u63a5\uff0c\u4f60\u7684\u8282\u70b9\u5904\u7406\u81ea\u5df1\u7684\u8def\u7531\u903b\u8f91\u3002\u8fd9\u4f7f\u63a7\u5236\u6d41\u660e\u786e\u4e14\u53ef\u8ffd\u8e2a - \u4f60\u603b\u662f\u53ef\u4ee5\u901a\u8fc7\u67e5\u770b\u5f53\u524d\u8282\u70b9\u6765\u7406\u89e3\u4f60\u7684\u667a\u80fd\u4f53\u4e0b\u4e00\u6b65\u5c06\u505a\u4ec0\u4e48\u3002</p>"},{"location":"llmapps/langgraph/thinking%20in%20Langgraph/#_12","title":"\u9ad8\u7ea7\u8003\u8651","text":"<p>\u8282\u70b9\u7c92\u5ea6\u6743\u8861 \u4f60\u53ef\u80fd\u4f1a\u60f3\uff1a\u4e3a\u4ec0\u4e48\u4e0d\u5c06\"\u8bfb\u53d6\u90ae\u4ef6\"\u548c\"\u5206\u7c7b\u610f\u56fe\"\u5408\u5e76\u4e3a\u4e00\u4e2a\u8282\u70b9\uff1f\u6216\u8005\u4e3a\u4ec0\u4e48\u5c06\u6587\u6863\u641c\u7d22\u4e0e\u8d77\u8349\u56de\u590d\u5206\u5f00\uff1f</p> <p>\u7b54\u6848\u6d89\u53ca\u5f39\u6027\u4e0e\u53ef\u89c2\u5bdf\u6027\u4e4b\u95f4\u7684\u6743\u8861\u3002</p> <p>\u5f39\u6027\u8003\u8651\uff1a LangGraph \u7684[\u6301\u4e45\u6267\u884c]\u5728\u8282\u70b9\u8fb9\u754c\u521b\u5efa\u68c0\u67e5\u70b9\u3002\u5f53\u5de5\u4f5c\u6d41\u7a0b\u5728\u4e2d\u65ad\u6216\u6545\u969c\u540e\u6062\u590d\u65f6\uff0c\u5b83\u4ece\u6267\u884c\u505c\u6b62\u7684\u8282\u70b9\u5f00\u59cb\u3002\u8f83\u5c0f\u7684\u8282\u70b9\u610f\u5473\u7740\u66f4\u9891\u7e41\u7684\u68c0\u67e5\u70b9\uff0c\u8fd9\u610f\u5473\u7740\u5982\u679c\u51fa\u73b0\u95ee\u9898\uff0c\u91cd\u590d\u7684\u5de5\u4f5c\u66f4\u5c11\u3002\u5982\u679c\u4f60\u5c06\u591a\u4e2a\u64cd\u4f5c\u5408\u5e76\u5230\u4e00\u4e2a\u5927\u8282\u70b9\u4e2d\uff0c\u63a5\u8fd1\u672b\u5c3e\u7684\u5931\u8d25\u610f\u5473\u7740\u4ece\u8be5\u8282\u70b9\u5f00\u59cb\u91cd\u65b0\u6267\u884c\u4e00\u5207\u3002</p> <p>\u6211\u4eec\u4e3a\u90ae\u4ef6\u667a\u80fd\u4f53\u9009\u62e9\u8fd9\u79cd\u5206\u89e3\u7684\u539f\u56e0\uff1a</p> <ul> <li> <p>\u5916\u90e8\u670d\u52a1\u9694\u79bb\uff1a \u6587\u6863\u641c\u7d22\u548c\u9519\u8bef\u8ddf\u8e2a\u662f\u5355\u72ec\u7684\u8282\u70b9\uff0c\u56e0\u4e3a\u5b83\u4eec\u8c03\u7528\u5916\u90e8 API\u3002\u5982\u679c\u641c\u7d22\u670d\u52a1\u7f13\u6162\u6216\u5931\u8d25\uff0c\u6211\u4eec\u5e0c\u671b\u5c06\u5176\u4e0e LLM \u8c03\u7528\u9694\u79bb\u3002\u6211\u4eec\u53ef\u4ee5\u4e3a\u8fd9\u4e9b\u7279\u5b9a\u8282\u70b9\u6dfb\u52a0\u91cd\u8bd5\u7b56\u7565\u800c\u4e0d\u5f71\u54cd\u5176\u4ed6\u8282\u70b9\u3002</p> </li> <li> <p>\u4e2d\u95f4\u53ef\u89c1\u6027\uff1a \u5c06\"\u5206\u7c7b\u610f\u56fe\"\u4f5c\u4e3a\u81ea\u5df1\u7684\u8282\u70b9\u8ba9\u6211\u4eec\u53ef\u4ee5\u5728\u91c7\u53d6\u884c\u52a8\u4e4b\u524d\u68c0\u67e5 LLM \u7684\u51b3\u5b9a\u3002\u8fd9\u5bf9\u4e8e\u8c03\u8bd5\u548c\u76d1\u63a7\u5f88\u6709\u4ef7\u503c - \u4f60\u53ef\u4ee5\u51c6\u786e\u770b\u5230\u667a\u80fd\u4f53\u4f55\u65f6\u4ee5\u53ca\u4e3a\u4f55\u8def\u7531\u5230\u4eba\u5de5\u5ba1\u6838\u3002</p> </li> <li> <p>\u4e0d\u540c\u7684\u6545\u969c\u6a21\u5f0f\uff1a LLM \u8c03\u7528\u3001\u6570\u636e\u5e93\u67e5\u8be2\u548c\u90ae\u4ef6\u53d1\u9001\u6709\u4e0d\u540c\u7684\u91cd\u8bd5\u7b56\u7565\u3002\u5355\u72ec\u7684\u8282\u70b9\u8ba9\u4f60\u53ef\u4ee5\u72ec\u7acb\u914d\u7f6e\u8fd9\u4e9b\u3002</p> </li> <li> <p>\u53ef\u91cd\u7528\u6027\u548c\u6d4b\u8bd5\uff1a \u8f83\u5c0f\u7684\u8282\u70b9\u66f4\u5bb9\u6613\u5355\u72ec\u6d4b\u8bd5\u5e76\u5728\u5176\u4ed6\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u91cd\u7528\u3002</p> </li> </ul> <p>\u4e0d\u540c\u7684\u6709\u6548\u65b9\u6cd5\uff1a\u4f60\u53ef\u4ee5\u5c06\"\u8bfb\u53d6\u90ae\u4ef6\"\u548c\"\u5206\u7c7b\u610f\u56fe\"\u5408\u5e76\u4e3a\u5355\u4e2a\u8282\u70b9\u3002\u4f60\u5c06\u5931\u53bb\u5728\u5206\u7c7b\u4e4b\u524d\u68c0\u67e5\u539f\u59cb\u90ae\u4ef6\u7684\u80fd\u529b\uff0c\u5e76\u4e14\u5728\u8be5\u8282\u70b9\u51fa\u73b0\u4efb\u4f55\u6545\u969c\u65f6\u4f1a\u91cd\u590d\u8fd9\u4e24\u4e2a\u64cd\u4f5c\u3002\u5bf9\u4e8e\u5927\u591a\u6570\u5e94\u7528\uff0c\u5355\u72ec\u8282\u70b9\u7684\u53ef\u89c2\u5bdf\u6027\u548c\u8c03\u8bd5\u597d\u5904\u662f\u503c\u5f97\u7684\u6743\u8861\u3002</p> <p>\u63a7\u5236\u68c0\u67e5\u70b9\u884c\u4e3a\uff1a \u4f60\u53ef\u4ee5\u4f7f\u7528[\u6301\u4e45\u6027\u6a21\u5f0f]\u8c03\u6574\u68c0\u67e5\u70b9\u7684\u5199\u5165\u65f6\u95f4\u3002\u9ed8\u8ba4\u7684 <code>\"async\"</code> \u6a21\u5f0f\u5728\u540e\u53f0\u5199\u5165\u68c0\u67e5\u70b9\u4ee5\u83b7\u5f97\u826f\u597d\u7684\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u6301\u4e45\u6027\u3002\u4f7f\u7528 <code>\"exit\"</code> \u6a21\u5f0f\u4ec5\u5728\u5b8c\u6210\u65f6\u68c0\u67e5\u70b9\uff08\u5bf9\u4e8e\u4e0d\u9700\u8981\u4e2d\u95f4\u6267\u884c\u6062\u590d\u7684\u957f\u65f6\u95f4\u8fd0\u884c\u56fe\u66f4\u5feb\uff09\uff0c\u6216\u4f7f\u7528 <code>\"sync\"</code> \u6a21\u5f0f\u4fdd\u8bc1\u5728\u7ee7\u7eed\u4e0b\u4e00\u6b65\u4e4b\u524d\u5199\u5165\u68c0\u67e5\u70b9\uff08\u5f53\u4f60\u9700\u8981\u786e\u4fdd\u72b6\u6001\u5728\u7ee7\u7eed\u6267\u884c\u4e4b\u524d\u6301\u4e45\u5316\u65f6\u5f88\u6709\u7528\uff09\u3002</p>"},{"location":"llmapps/langgraph/thinking%20in%20Langgraph/#_13","title":"\u4ece\u8fd9\u91cc\u53bb\u54ea\u91cc","text":"<p>\u8fd9\u662f\u5173\u4e8e\u4f7f\u7528 LangGraph \u6784\u5efa\u667a\u80fd\u4f53\u7684\u601d\u7ef4\u65b9\u5f0f\u7684\u4ecb\u7ecd\u3002\u4f60\u53ef\u4ee5\u7528\u4ee5\u4e0b\u5185\u5bb9\u6269\u5c55\u8fd9\u4e2a\u57fa\u7840\uff1a</p> <p>\u4eba\u5de5\u5e72\u9884\u6a21\u5f0f * \u5b66\u4e60\u5982\u4f55\u5728\u6267\u884c\u524d\u6dfb\u52a0\u5de5\u5177\u6279\u51c6\u3001\u6279\u91cf\u6279\u51c6\u548c\u5176\u4ed6\u6a21\u5f0f</p> <p>\u5b50\u56fe * \u4e3a\u590d\u6742\u7684\u591a\u6b65\u9aa4\u64cd\u4f5c\u521b\u5efa\u5b50\u56fe</p> <p>\u6d41\u5f0f\u4f20\u8f93 * \u6dfb\u52a0\u6d41\u5f0f\u4f20\u8f93\u4ee5\u5411\u7528\u6237\u663e\u793a\u5b9e\u65f6\u8fdb\u5ea6</p> <p>\u53ef\u89c2\u5bdf\u6027 * \u4f7f\u7528 LangSmith \u6dfb\u52a0\u53ef\u89c2\u5bdf\u6027\u4ee5\u8fdb\u884c\u8c03\u8bd5\u548c\u76d1\u63a7</p> <p>\u5de5\u5177\u96c6\u6210 * \u96c6\u6210\u66f4\u591a\u5de5\u5177\u4ee5\u8fdb\u884c\u7f51\u7edc\u641c\u7d22\u3001\u6570\u636e\u5e93\u67e5\u8be2\u548c API \u8c03\u7528</p> <p>\u91cd\u8bd5\u903b\u8f91 * \u4e3a\u5931\u8d25\u7684\u64cd\u4f5c\u5b9e\u73b0\u6307\u6570\u9000\u907f\u7684\u91cd\u8bd5\u903b\u8f91</p> <p>\u901a\u8fc7\u638c\u63e1\u8fd9\u4e9b\u6838\u5fc3\u6982\u5ff5\uff0c\u4f60\u73b0\u5728\u53ef\u4ee5\u6784\u5efa\u590d\u6742\u3001\u6709\u72b6\u6001\u3001\u751f\u4ea7\u5c31\u7eea\u7684\u667a\u80fd\u4f53\uff0c\u80fd\u591f\u5904\u7406\u73b0\u5b9e\u4e16\u754c\u7684\u4e1a\u52a1\u6d41\u7a0b\uff0c\u540c\u65f6\u4fdd\u6301\u5bf9\u6267\u884c\u6d41\u7a0b\u7684\u5b8c\u5168\u63a7\u5236\u548c\u53ef\u89c1\u6027\u3002</p>"},{"location":"llmapps/langgraph/time%20travel/","title":"LangGraph \u65f6\u95f4\u65c5\u884c\u4f7f\u7528\u6559\u7a0b","text":""},{"location":"llmapps/langgraph/time%20travel/#_1","title":"\u4ec0\u4e48\u662f\u65f6\u95f4\u65c5\u884c\uff1f","text":"<p>\u5728\u57fa\u4e8e\u6a21\u578b\u51b3\u7b56\u7684\u975e\u786e\u5b9a\u6027\u7cfb\u7edf\uff08\u5982LLM\u9a71\u52a8\u7684\u667a\u80fd\u4f53\uff09\u4e2d\uff0c\u65f6\u95f4\u65c5\u884c\u529f\u80fd\u8ba9\u60a8\u80fd\u591f\u8be6\u7ec6\u68c0\u67e5\u51b3\u7b56\u8fc7\u7a0b\uff1a</p> <ul> <li>\ud83d\udd0d \u7406\u89e3\u63a8\u7406\u903b\u8f91\uff1a\u5206\u6790\u5bfc\u81f4\u6210\u529f\u7ed3\u679c\u7684\u5404\u4e2a\u6b65\u9aa4</li> <li>\ud83d\udc1b \u8c03\u8bd5\u9519\u8bef\uff1a\u8bc6\u522b\u9519\u8bef\u53d1\u751f\u7684\u4f4d\u7f6e\u548c\u539f\u56e0  </li> <li>\ud83d\udd04 \u63a2\u7d22\u66ff\u4ee3\u65b9\u6848\uff1a\u6d4b\u8bd5\u4e0d\u540c\u8def\u5f84\u4ee5\u53d1\u73b0\u66f4\u597d\u7684\u89e3\u51b3\u65b9\u6848</li> </ul>"},{"location":"llmapps/langgraph/time%20travel/#_2","title":"\u65f6\u95f4\u65c5\u884c\u6838\u5fc3\u6982\u5ff5","text":"<p>LangGraph\u7684\u65f6\u95f4\u65c5\u884c\u529f\u80fd\u5141\u8bb8\u60a8\u4ece\u4e4b\u524d\u7684\u68c0\u67e5\u70b9\u6062\u590d\u6267\u884c\u2014\u2014\u53ef\u4ee5\u91cd\u653e\u76f8\u540c\u72b6\u6001\uff0c\u4e5f\u53ef\u4ee5\u4fee\u6539\u72b6\u6001\u6765\u63a2\u7d22\u66ff\u4ee3\u65b9\u6848\u3002\u65e0\u8bba\u54ea\u79cd\u60c5\u51b5\uff0c\u6062\u590d\u8fc7\u53bb\u7684\u6267\u884c\u90fd\u4f1a\u5728\u5386\u53f2\u4e2d\u521b\u5efa\u4e00\u4e2a\u65b0\u7684\u5206\u652f\u3002</p>"},{"location":"llmapps/langgraph/time%20travel/#_3","title":"\u4f7f\u7528\u6b65\u9aa4","text":""},{"location":"llmapps/langgraph/time%20travel/#1","title":"1. \u8fd0\u884c\u56fe","text":"<p>\u9996\u5148\u4f7f\u7528\u521d\u59cb\u8f93\u5165\u8fd0\u884c\u56fe\uff1a</p> <pre><code>config = {\n    \"configurable\": {\n        \"thread_id\": uuid.uuid4(),\n    }\n}\nstate = graph.invoke({}, config)\n</code></pre>"},{"location":"llmapps/langgraph/time%20travel/#2","title":"2. \u8bc6\u522b\u68c0\u67e5\u70b9","text":"<p>\u83b7\u53d6\u6267\u884c\u5386\u53f2\u5e76\u5b9a\u4f4d\u6240\u9700\u7684\u68c0\u67e5\u70b9\uff1a</p> <pre><code># \u72b6\u6001\u6309\u65f6\u95f4\u5012\u5e8f\u8fd4\u56de\nstates = list(graph.get_state_history(config))\n\nfor state in states:\n    print(f\"\u4e0b\u4e00\u6b65\u8282\u70b9: {state.next}\")\n    print(f\"\u68c0\u67e5\u70b9ID: {state.config['configurable']['checkpoint_id']}\")\n    print()\n</code></pre> <p>\u6216\u8005\uff0c\u5728\u76ee\u6807\u8282\u70b9\u524d\u8bbe\u7f6e[\u4e2d\u65ad]\uff0c\u7136\u540e\u5728\u4e2d\u65ad\u5904\u627e\u5230\u6700\u8fd1\u7684\u68c0\u67e5\u70b9\u3002</p>"},{"location":"llmapps/langgraph/time%20travel/#3","title":"3. \u66f4\u65b0\u72b6\u6001\uff08\u53ef\u9009\uff09","text":"<p>\u5728\u68c0\u67e5\u70b9\u4fee\u6539\u56fe\u72b6\u6001\uff1a</p> <pre><code>new_config = graph.update_state(\n    selected_state.config, \n    values={\"topic\": \"\u65b0\u7684\u4e3b\u9898\"}\n)\n</code></pre> <p><code>update_state</code>\u4f1a\u521b\u5efa\u4e00\u4e2a\u4e0e\u540c\u4e00\u7ebf\u7a0b\u5173\u8054\u4f46\u5177\u6709\u65b0\u68c0\u67e5\u70b9ID\u7684\u65b0\u68c0\u67e5\u70b9\u3002</p>"},{"location":"llmapps/langgraph/time%20travel/#4","title":"4. \u4ece\u68c0\u67e5\u70b9\u6062\u590d\u6267\u884c","text":"<p>\u4f7f\u7528\u9002\u5f53\u7684<code>thread_id</code>\u548c<code>checkpoint_id</code>\u6062\u590d\u6267\u884c\uff1a</p> <pre><code>graph.invoke(None, new_config)\n</code></pre>"},{"location":"llmapps/langgraph/time%20travel/#_4","title":"\u5b8c\u6574\u5de5\u4f5c\u6d41\u7a0b\u793a\u4f8b","text":""},{"location":"llmapps/langgraph/time%20travel/#_5","title":"\u73af\u5883\u8bbe\u7f6e","text":"<pre><code>%%capture --no-stderr\npip install --quiet -U langgraph langchain_anthropic\n\nimport getpass\nimport os\n\ndef _set_env(var: str):\n    if not os.environ.get(var):\n        os.environ[var] = getpass.getpass(f\"{var}: \")\n\n_set_env(\"ANTHROPIC_API_KEY\")\n</code></pre>"},{"location":"llmapps/langgraph/time%20travel/#_6","title":"\u6784\u5efa\u5de5\u4f5c\u6d41","text":"<pre><code>import uuid\nfrom typing_extensions import TypedDict, NotRequired\nfrom langgraph.graph import StateGraph, START, END\nfrom langchain.chat_models import init_chat_model\nfrom langgraph.checkpoint.memory import InMemorySaver\n\n# \u5b9a\u4e49\u72b6\u6001\u7ed3\u6784\nclass State(TypedDict):\n    topic: NotRequired[str]\n    joke: NotRequired[str]\n\n# \u521d\u59cb\u5316\u6a21\u578b\nmodel = init_chat_model(\"anthropic:claude-sonnet-4-5\", temperature=0)\n\ndef generate_topic(state: State):\n    \"\"\"\u751f\u6210\u7b11\u8bdd\u4e3b\u9898\u7684LLM\u8c03\u7528\"\"\"\n    msg = model.invoke(\"\u7ed9\u6211\u4e00\u4e2a\u6709\u8da3\u7684\u7b11\u8bdd\u4e3b\u9898\")\n    return {\"topic\": msg.content}\n\ndef write_joke(state: State):\n    \"\"\"\u57fa\u4e8e\u4e3b\u9898\u5199\u7b11\u8bdd\u7684LLM\u8c03\u7528\"\"\"\n    msg = model.invoke(f\"\u5199\u4e00\u4e2a\u5173\u4e8e{state['topic']}\u7684\u77ed\u7b11\u8bdd\")\n    return {\"joke\": msg.content}\n\n# \u6784\u5efa\u5de5\u4f5c\u6d41\nworkflow = StateGraph(State)\nworkflow.add_node(\"generate_topic\", generate_topic)\nworkflow.add_node(\"write_joke\", write_joke)\nworkflow.add_edge(START, \"generate_topic\")\nworkflow.add_edge(\"generate_topic\", \"write_joke\")\nworkflow.add_edge(\"write_joke\", END)\n\n# \u7f16\u8bd1\u56fe\ncheckpointer = InMemorySaver()\ngraph = workflow.compile(checkpointer=checkpointer)\n</code></pre>"},{"location":"llmapps/langgraph/time%20travel/#_7","title":"\u6267\u884c\u65f6\u95f4\u65c5\u884c","text":"<pre><code># 1. \u9996\u6b21\u8fd0\u884c\nconfig = {\"configurable\": {\"thread_id\": uuid.uuid4()}}\nstate = graph.invoke({}, config)\nprint(\"\u539f\u59cb\u7ed3\u679c:\", state[\"joke\"])\n\n# 2. \u8bc6\u522b\u68c0\u67e5\u70b9\nstates = list(graph.get_state_history(config))\nselected_state = states[1]  # \u9009\u62e9write_joke\u4e4b\u524d\u7684\u68c0\u67e5\u70b9\n\n# 3. \u4fee\u6539\u72b6\u6001\nnew_config = graph.update_state(\n    selected_state.config, \n    values={\"topic\": \"\u7a0b\u5e8f\u5458\u7684\u751f\u6d3b\"}\n)\n\n# 4. \u6062\u590d\u6267\u884c\nnew_state = graph.invoke(None, new_config)\nprint(\"\u4fee\u6539\u540e\u7684\u7ed3\u679c:\", new_state[\"joke\"])\n</code></pre>"},{"location":"llmapps/langgraph/time%20travel/#_8","title":"\u4f7f\u7528\u573a\u666f","text":""},{"location":"llmapps/langgraph/time%20travel/#_9","title":"\u8c03\u8bd5\u5206\u6790","text":"<p>\u5f53\u667a\u80fd\u4f53\u4ea7\u751f\u610f\u5916\u7ed3\u679c\u65f6\uff0c\u4f7f\u7528\u65f6\u95f4\u65c5\u884c\u56de\u6eaf\u5230\u5173\u952e\u51b3\u7b56\u70b9\uff0c\u5206\u6790\u63a8\u7406\u8fc7\u7a0b\u3002</p>"},{"location":"llmapps/langgraph/time%20travel/#_10","title":"\u65b9\u6848\u5bf9\u6bd4","text":"<p>\u4ece\u540c\u4e00\u68c0\u67e5\u70b9\u51fa\u53d1\uff0c\u5c1d\u8bd5\u4e0d\u540c\u7684\u72b6\u6001\u4fee\u6539\uff0c\u6bd4\u8f83\u591a\u79cd\u89e3\u51b3\u65b9\u6848\u7684\u6548\u679c\u3002</p>"},{"location":"llmapps/langgraph/time%20travel/#_11","title":"\u6027\u80fd\u4f18\u5316","text":"<p>\u8bc6\u522b\u6267\u884c\u74f6\u9888\uff0c\u901a\u8fc7\u4fee\u6539\u72b6\u6001\u6d4b\u8bd5\u66f4\u9ad8\u6548\u7684\u6267\u884c\u8def\u5f84\u3002</p>"},{"location":"llmapps/langgraph/time%20travel/#_12","title":"\u6ce8\u610f\u4e8b\u9879","text":"<ul> <li>\u65f6\u95f4\u65c5\u884c\u4f1a\u521b\u5efa\u65b0\u7684\u6267\u884c\u5206\u652f\uff0c\u4e0d\u5f71\u54cd\u539f\u59cb\u6267\u884c\u5386\u53f2</li> <li>\u786e\u4fdd\u68c0\u67e5\u70b9ID\u6b63\u786e\uff0c\u907f\u514d\u4ece\u9519\u8bef\u7684\u72b6\u6001\u6062\u590d</li> <li>\u72b6\u6001\u4fee\u6539\u5e94\u7b26\u5408\u56fe\u7684\u9884\u671f\u8f93\u5165\u683c\u5f0f</li> <li>\u5185\u5b58\u68c0\u67e5\u70b9\u9002\u7528\u4e8e\u5f00\u53d1\u73af\u5883\uff0c\u751f\u4ea7\u73af\u5883\u5efa\u8bae\u4f7f\u7528\u6301\u4e45\u5316\u5b58\u50a8</li> </ul> <p>\u901a\u8fc7\u65f6\u95f4\u65c5\u884c\u529f\u80fd\uff0c\u60a8\u53ef\u4ee5\u66f4\u6df1\u5165\u5730\u7406\u89e3\u548c\u4f18\u5316\u57fa\u4e8eLLM\u7684\u667a\u80fd\u4f53\u884c\u4e3a\uff0c\u63d0\u9ad8\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u548c\u6027\u80fd\u3002</p>"},{"location":"llmapps/langgraph/use%20the%20graph%20api/","title":"LangGraph Graph API \u6559\u7a0b","text":"<p>\u672c\u6559\u7a0b\u5c06\u6f14\u793a LangGraph Graph API \u7684\u57fa\u7840\u77e5\u8bc6\uff0c\u5305\u62ec\u72b6\u6001\u7ba1\u7406\u3001\u5e38\u89c1\u56fe\u7ed3\u6784\uff08\u5e8f\u5217\u3001\u5206\u652f\u3001\u5faa\u73af\uff09\u7684\u6784\u5efa\uff0c\u4ee5\u53ca LangGraph \u7684\u63a7\u5236\u7279\u6027\u3002</p>"},{"location":"llmapps/langgraph/use%20the%20graph%20api/#_1","title":"\u5b89\u88c5\u4e0e\u8bbe\u7f6e","text":"<p>\u9996\u5148\u5b89\u88c5 <code>langgraph</code>\uff1a</p> <pre><code>pip install -U langgraph\n</code></pre> <p>\u6216\u4f7f\u7528 uv\uff1a</p> <pre><code>uv add langgraph\n</code></pre> <p>\u63d0\u793a\uff1a\u8bbe\u7f6e LangSmith \u4ee5\u83b7\u5f97\u66f4\u597d\u7684\u8c03\u8bd5\u4f53\u9a8c\uff0c\u53ef\u4ee5\u5feb\u901f\u53d1\u73b0\u5e76\u6539\u8fdb LangGraph \u9879\u76ee\u7684\u6027\u80fd\u95ee\u9898\u3002</p>"},{"location":"llmapps/langgraph/use%20the%20graph%20api/#_2","title":"\u5b9a\u4e49\u548c\u66f4\u65b0\u72b6\u6001","text":""},{"location":"llmapps/langgraph/use%20the%20graph%20api/#_3","title":"\u5b9a\u4e49\u72b6\u6001","text":"<p>\u5728 LangGraph \u4e2d\uff0c\u72b6\u6001\u53ef\u4ee5\u662f <code>TypedDict</code>\u3001<code>Pydantic</code> \u6a21\u578b\u6216\u6570\u636e\u7c7b\u3002\u4ee5\u4e0b\u4f7f\u7528 <code>TypedDict</code>\uff1a</p> <pre><code>from langchain.messages import AnyMessage\nfrom typing_extensions import TypedDict\n\nclass State(TypedDict):\n    messages: list[AnyMessage]\n    extra_field: int\n</code></pre>"},{"location":"llmapps/langgraph/use%20the%20graph%20api/#_4","title":"\u66f4\u65b0\u72b6\u6001","text":"<p>\u8282\u70b9\u662f\u8bfb\u53d6\u548c\u66f4\u65b0\u72b6\u6001\u7684 Python \u51fd\u6570\uff1a</p> <pre><code>from langchain.messages import AIMessage\n\ndef node(state: State):\n    messages = state[\"messages\"]\n    new_message = AIMessage(\"Hello!\")\n    return {\"messages\": messages + [new_message], \"extra_field\": 10}\n</code></pre> <p>\u8b66\u544a\uff1a\u8282\u70b9\u5e94\u76f4\u63a5\u8fd4\u56de\u72b6\u6001\u66f4\u65b0\uff0c\u800c\u4e0d\u662f\u6539\u53d8\u72b6\u6001\u3002</p> <p>\u6784\u5efa\u56fe\uff1a</p> <pre><code>from langgraph.graph import StateGraph\n\nbuilder = StateGraph(State)\nbuilder.add_node(node)\nbuilder.set_entry_point(\"node\")\ngraph = builder.compile()\n</code></pre> <p>\u53ef\u89c6\u5316\u56fe\uff1a</p> <pre><code>from IPython.display import Image, display\n\ndisplay(Image(graph.get_graph().draw_mermaid_png()))\n</code></pre> <p>\u8c03\u7528\u56fe\uff1a</p> <pre><code>from langchain.messages import HumanMessage\n\nresult = graph.invoke({\"messages\": [HumanMessage(\"Hi\")]})\n</code></pre>"},{"location":"llmapps/langgraph/use%20the%20graph%20api/#reducers","title":"\u4f7f\u7528 Reducers \u5904\u7406\u72b6\u6001\u66f4\u65b0","text":"<p>\u6bcf\u4e2a\u72b6\u6001\u952e\u53ef\u4ee5\u6709\u72ec\u7acb\u7684 reducer \u51fd\u6570\u6765\u63a7\u5236\u66f4\u65b0\u5904\u7406\u65b9\u5f0f\uff1a</p> <pre><code>from typing_extensions import Annotated\n\ndef add(left, right):\n    return left + right\n\nclass State(TypedDict):\n    messages: Annotated[list[AnyMessage], add]\n    extra_field: int\n</code></pre> <p>\u73b0\u5728\u8282\u70b9\u53ef\u4ee5\u7b80\u5316\uff1a</p> <pre><code>def node(state: State):\n    new_message = AIMessage(\"Hello!\")\n    return {\"messages\": [new_message], \"extra_field\": 10}\n</code></pre>"},{"location":"llmapps/langgraph/use%20the%20graph%20api/#messagesstate","title":"MessagesState","text":"<p>LangGraph \u5305\u542b\u5185\u7f6e\u7684 <code>add_messages</code> reducer\uff1a</p> <pre><code>from langgraph.graph.message import add_messages\n\nclass State(TypedDict):\n    messages: Annotated[list[AnyMessage], add_messages]\n    extra_field: int\n</code></pre> <p>\u4e5f\u53ef\u4ee5\u4f7f\u7528\u9884\u6784\u5efa\u7684 <code>MessagesState</code>\uff1a</p> <pre><code>from langgraph.graph import MessagesState\n\nclass State(MessagesState):\n    extra_field: int\n</code></pre>"},{"location":"llmapps/langgraph/use%20the%20graph%20api/#_5","title":"\u8fd0\u884c\u65f6\u914d\u7f6e","text":"<p>\u6dfb\u52a0\u8fd0\u884c\u65f6\u914d\u7f6e\uff1a</p> <ol> <li>\u6307\u5b9a\u914d\u7f6e\u6a21\u5f0f</li> <li>\u5728\u8282\u70b9\u6216\u6761\u4ef6\u8fb9\u51fd\u6570\u7b7e\u540d\u4e2d\u6dfb\u52a0\u914d\u7f6e</li> <li>\u5c06\u914d\u7f6e\u4f20\u9012\u5230\u56fe\u4e2d</li> </ol> <pre><code>from langgraph.graph import END, StateGraph, START\nfrom langgraph.runtime import Runtime\nfrom typing_extensions import TypedDict\n\n# 1. \u6307\u5b9a\u914d\u7f6e\u6a21\u5f0f\nclass ContextSchema(TypedDict):\n    my_runtime_value: str\n\n# 2. \u5b9a\u4e49\u8bbf\u95ee\u914d\u7f6e\u7684\u56fe\nclass State(TypedDict):\n    my_state_value: str\n\ndef node(state: State, runtime: Runtime[ContextSchema]):\n    if runtime.context[\"my_runtime_value\"] == \"a\":\n        return {\"my_state_value\": 1}\n    elif runtime.context[\"my_runtime_value\"] == \"b\":\n        return {\"my_state_value\": 2}\n    else:\n        raise ValueError(\"Unknown values.\")\n\nbuilder = StateGraph(State, context_schema=ContextSchema)\nbuilder.add_node(node)\nbuilder.add_edge(START, \"node\")\nbuilder.add_edge(\"node\", END)\n\ngraph = builder.compile()\n\n# 3. \u5728\u8fd0\u884c\u65f6\u4f20\u5165\u914d\u7f6e\nprint(graph.invoke({}, context={\"my_runtime_value\": \"a\"}))\n</code></pre>"},{"location":"llmapps/langgraph/use%20the%20graph%20api/#_6","title":"\u91cd\u8bd5\u7b56\u7565","text":"<p>\u4e3a\u8282\u70b9\u6dfb\u52a0\u91cd\u8bd5\u7b56\u7565\uff1a</p> <pre><code>from langgraph.types import RetryPolicy\n\nbuilder.add_node(\n    \"node_name\",\n    node_function,\n    retry_policy=RetryPolicy(),\n)\n</code></pre>"},{"location":"llmapps/langgraph/use%20the%20graph%20api/#_7","title":"\u8282\u70b9\u7f13\u5b58","text":"<p>\u914d\u7f6e\u8282\u70b9\u7f13\u5b58\u7b56\u7565\uff1a</p> <pre><code>from langgraph.types import CachePolicy\nfrom langgraph.cache.memory import InMemoryCache\n\nbuilder.add_node(\n    \"node_name\",\n    node_function,\n    cache_policy=CachePolicy(ttl=120),\n)\n\ngraph = builder.compile(cache=InMemoryCache())\n</code></pre>"},{"location":"llmapps/langgraph/use%20the%20graph%20api/#_8","title":"\u521b\u5efa\u6b65\u9aa4\u5e8f\u5217","text":""},{"location":"llmapps/langgraph/use%20the%20graph%20api/#_9","title":"\u57fa\u672c\u5e8f\u5217","text":"<pre><code>from langgraph.graph import START, StateGraph\n\nbuilder = StateGraph(State)\n\n# \u6dfb\u52a0\u8282\u70b9\nbuilder.add_node(step_1)\nbuilder.add_node(step_2)\nbuilder.add_node(step_3)\n\n# \u6dfb\u52a0\u8fb9\nbuilder.add_edge(START, \"step_1\")\nbuilder.add_edge(\"step_1\", \"step_2\")\nbuilder.add_edge(\"step_2\", \"step_3\")\n</code></pre>"},{"location":"llmapps/langgraph/use%20the%20graph%20api/#_10","title":"\u4f7f\u7528\u5185\u7f6e\u7b80\u5199","text":"<pre><code>builder = StateGraph(State).add_sequence([step_1, step_2, step_3])\nbuilder.add_edge(START, \"step_1\")\n</code></pre>"},{"location":"llmapps/langgraph/use%20the%20graph%20api/#_11","title":"\u521b\u5efa\u5206\u652f","text":""},{"location":"llmapps/langgraph/use%20the%20graph%20api/#_12","title":"\u5e76\u884c\u6267\u884c\u8282\u70b9","text":"<pre><code>import operator\nfrom typing import Annotated\nfrom typing_extensions import TypedDict\nfrom langgraph.graph import StateGraph, START, END\n\nclass State(TypedDict):\n    aggregate: Annotated[list, operator.add]\n\ndef a(state: State):\n    print(f'Adding \"A\" to {state[\"aggregate\"]}')\n    return {\"aggregate\": [\"A\"]}\n\ndef b(state: State):\n    print(f'Adding \"B\" to {state[\"aggregate\"]}')\n    return {\"aggregate\": [\"B\"]}\n\ndef c(state: State):\n    print(f'Adding \"C\" to {state[\"aggregate\"]}')\n    return {\"aggregate\": [\"C\"]}\n\ndef d(state: State):\n    print(f'Adding \"D\" to {state[\"aggregate\"]}')\n    return {\"aggregate\": [\"D\"]}\n\nbuilder = StateGraph(State)\nbuilder.add_node(a)\nbuilder.add_node(b)\nbuilder.add_node(c)\nbuilder.add_node(d)\nbuilder.add_edge(START, \"a\")\nbuilder.add_edge(\"a\", \"b\")\nbuilder.add_edge(\"a\", \"c\")\nbuilder.add_edge(\"b\", \"d\")\nbuilder.add_edge(\"c\", \"d\")\nbuilder.add_edge(\"d\", END)\ngraph = builder.compile()\n</code></pre>"},{"location":"llmapps/langgraph/use%20the%20graph%20api/#_13","title":"\u6761\u4ef6\u5206\u652f","text":"<pre><code>from typing import Literal\n\ndef conditional_edge(state: State) -&gt; Literal[\"b\", \"c\"]:\n    return state[\"which\"]\n\nbuilder.add_conditional_edges(\"a\", conditional_edge)\n</code></pre>"},{"location":"llmapps/langgraph/use%20the%20graph%20api/#map-reduce-send-api","title":"Map-Reduce \u548c Send API","text":"<p>\u4f7f\u7528 Send API \u5b9e\u73b0 map-reduce \u6a21\u5f0f\uff1a</p> <pre><code>from langgraph.graph import StateGraph, START, END\nfrom langgraph.types import Send\nfrom typing_extensions import TypedDict, Annotated\nimport operator\n\nclass OverallState(TypedDict):\n    topic: str\n    subjects: list[str]\n    jokes: Annotated[list[str], operator.add]\n    best_selected_joke: str\n\ndef generate_topics(state: OverallState):\n    return {\"subjects\": [\"lions\", \"elephants\", \"penguins\"]}\n\ndef generate_joke(state: OverallState):\n    joke_map = {\n        \"lions\": \"Why don't lions like fast food? Because they can't catch it!\",\n        \"elephants\": \"Why don't elephants use computers? They're afraid of the mouse!\",\n        \"penguins\": \"Why don't penguins like talking to strangers at parties? Because they find it hard to break the ice.\"\n    }\n    return {\"jokes\": [joke_map[state[\"subject\"]]]}\n\ndef continue_to_jokes(state: OverallState):\n    return [Send(\"generate_joke\", {\"subject\": s}) for s in state[\"subjects\"]]\n\nbuilder = StateGraph(OverallState)\nbuilder.add_node(\"generate_topics\", generate_topics)\nbuilder.add_node(\"generate_joke\", generate_joke)\nbuilder.add_edge(START, \"generate_topics\")\nbuilder.add_conditional_edges(\"generate_topics\", continue_to_jokes, [\"generate_joke\"])\n</code></pre>"},{"location":"llmapps/langgraph/use%20the%20graph%20api/#_14","title":"\u521b\u5efa\u548c\u63a7\u5236\u5faa\u73af","text":""},{"location":"llmapps/langgraph/use%20the%20graph%20api/#_15","title":"\u57fa\u672c\u5faa\u73af","text":"<pre><code>import operator\nfrom typing import Annotated, Literal\nfrom typing_extensions import TypedDict\nfrom langgraph.graph import StateGraph, START, END\n\nclass State(TypedDict):\n    aggregate: Annotated[list, operator.add]\n\ndef a(state: State):\n    print(f'Node A sees {state[\"aggregate\"]}')\n    return {\"aggregate\": [\"A\"]}\n\ndef b(state: State):\n    print(f'Node B sees {state[\"aggregate\"]}')\n    return {\"aggregate\": [\"B\"]}\n\n# \u5b9a\u4e49\u8282\u70b9\nbuilder = StateGraph(State)\nbuilder.add_node(a)\nbuilder.add_node(b)\n\n# \u5b9a\u4e49\u8fb9\ndef route(state: State) -&gt; Literal[\"b\", END]:\n    if len(state[\"aggregate\"]) &lt; 7:\n        return \"b\"\n    else:\n        return END\n\nbuilder.add_edge(START, \"a\")\nbuilder.add_conditional_edges(\"a\", route)\nbuilder.add_edge(\"b\", \"a\")\ngraph = builder.compile()\n</code></pre>"},{"location":"llmapps/langgraph/use%20the%20graph%20api/#_16","title":"\u8bbe\u7f6e\u9012\u5f52\u9650\u5236","text":"<pre><code>from langgraph.errors import GraphRecursionError\n\ntry:\n    graph.invoke({\"aggregate\": []}, {\"recursion_limit\": 4})\nexcept GraphRecursionError:\n    print(\"Recursion Error\")\n</code></pre>"},{"location":"llmapps/langgraph/use%20the%20graph%20api/#_17","title":"\u5f02\u6b65\u652f\u6301","text":"<p>\u5c06\u540c\u6b65\u5b9e\u73b0\u8f6c\u6362\u4e3a\u5f02\u6b65\u5b9e\u73b0\uff1a</p> <pre><code>from langchain.chat_models import init_chat_model\nfrom langgraph.graph import MessagesState, StateGraph\n\nasync def node(state: MessagesState):\n    new_message = await llm.ainvoke(state[\"messages\"])\n    return {\"messages\": [new_message]}\n\nbuilder = StateGraph(MessagesState).add_node(node).set_entry_point(\"node\")\ngraph = builder.compile()\n\ninput_message = {\"role\": \"user\", \"content\": \"Hello\"}\nresult = await graph.ainvoke({\"messages\": [input_message]})\n</code></pre>"},{"location":"llmapps/langgraph/use%20the%20graph%20api/#command","title":"\u4f7f\u7528 Command \u7ed3\u5408\u63a7\u5236\u6d41\u548c\u72b6\u6001\u66f4\u65b0","text":"<p>\u4f7f\u7528 <code>Command</code> \u5bf9\u8c61\u5728\u540c\u4e00\u8282\u70b9\u4e2d\u6267\u884c\u72b6\u6001\u66f4\u65b0\u548c\u51b3\u5b9a\u4e0b\u4e00\u4e2a\u8282\u70b9\uff1a</p> <pre><code>import random\nfrom typing_extensions import TypedDict, Literal\nfrom langgraph.graph import StateGraph, START\nfrom langgraph.types import Command\n\nclass State(TypedDict):\n    foo: str\n\ndef node_a(state: State) -&gt; Command[Literal[\"node_b\", \"node_c\"]]:\n    print(\"Called A\")\n    value = random.choice([\"b\", \"c\"])\n    if value == \"b\":\n        goto = \"node_b\"\n    else:\n        goto = \"node_c\"\n\n    return Command(\n        update={\"foo\": value},\n        goto=goto,\n    )\n\ndef node_b(state: State):\n    print(\"Called B\")\n    return {\"foo\": state[\"foo\"] + \"b\"}\n\ndef node_c(state: State):\n    print(\"Called C\")\n    return {\"foo\": state[\"foo\"] + \"c\"}\n\nbuilder = StateGraph(State)\nbuilder.add_edge(START, \"node_a\")\nbuilder.add_node(node_a)\nbuilder.add_node(node_b)\nbuilder.add_node(node_c)\n\ngraph = builder.compile()\n</code></pre>"},{"location":"llmapps/langgraph/use%20the%20graph%20api/#_18","title":"\u53ef\u89c6\u5316\u56fe","text":""},{"location":"llmapps/langgraph/use%20the%20graph%20api/#mermaid","title":"Mermaid \u8bed\u6cd5","text":"<pre><code>print(app.get_graph().draw_mermaid())\n</code></pre>"},{"location":"llmapps/langgraph/use%20the%20graph%20api/#png","title":"PNG \u56fe\u50cf","text":"<pre><code>from IPython.display import Image, display\n\ndisplay(Image(app.get_graph().draw_mermaid_png()))\n</code></pre> <p>\u672c\u6559\u7a0b\u6db5\u76d6\u4e86 LangGraph Graph API \u7684\u6838\u5fc3\u6982\u5ff5\uff0c\u5305\u62ec\u72b6\u6001\u7ba1\u7406\u3001\u5e8f\u5217\u3001\u5206\u652f\u3001\u5faa\u73af\u3001\u5f02\u6b65\u652f\u6301\u548c\u53ef\u89c6\u5316\u3002\u8fd9\u4e9b\u57fa\u7840\u5c06\u5e2e\u52a9\u60a8\u6784\u5efa\u590d\u6742\u7684 AI \u5e94\u7528\u7a0b\u5e8f\u5de5\u4f5c\u6d41\u3002</p>"},{"location":"llmapps/langgraph/workflows%2Bagents/","title":"LangGraph \u5de5\u4f5c\u6d41\u4e0e\u667a\u80fd\u4f53\u6559\u7a0b","text":"<p>\u672c\u6559\u7a0b\u5c06\u4ecb\u7ecd\u5982\u4f55\u4f7f\u7528 LangGraph \u6784\u5efa\u5de5\u4f5c\u6d41\u548c\u667a\u80fd\u4ee3\u7406\u7cfb\u7edf\u3002</p>"},{"location":"llmapps/langgraph/workflows%2Bagents/#_1","title":"\u6982\u8ff0","text":""},{"location":"llmapps/langgraph/workflows%2Bagents/#vs","title":"\u5de5\u4f5c\u6d41 vs \u667a\u80fd\u4f53","text":"<ul> <li>\u5de5\u4f5c\u6d41\uff1a\u5177\u6709\u9884\u5b9a\u4e49\u7684\u4ee3\u7801\u8def\u5f84\uff0c\u6309\u7279\u5b9a\u987a\u5e8f\u6267\u884c</li> <li>\u667a\u80fd\u4f53\uff1a\u52a8\u6001\u7684\uff0c\u80fd\u591f\u5b9a\u4e49\u81ea\u5df1\u7684\u6d41\u7a0b\u548c\u5de5\u5177\u4f7f\u7528\u65b9\u5f0f</li> </ul> <p>LangGraph \u5728\u6784\u5efa\u667a\u80fd\u4f53\u548c\u5de5\u4f5c\u6d41\u65f6\u63d0\u4f9b\u4e86\u591a\u79cd\u4f18\u52bf\uff0c\u5305\u62ec\u6301\u4e45\u5316\u3001\u6d41\u5f0f\u5904\u7406\u548c\u8c03\u8bd5\u652f\u6301\u3002</p> <p></p>"},{"location":"llmapps/langgraph/workflows%2Bagents/#_2","title":"\u73af\u5883\u8bbe\u7f6e","text":""},{"location":"llmapps/langgraph/workflows%2Bagents/#1","title":"1. \u5b89\u88c5\u4f9d\u8d56","text":"<pre><code>pip install langchain_core langchain-anthropic langgraph\n</code></pre>"},{"location":"llmapps/langgraph/workflows%2Bagents/#2-llm","title":"2. \u521d\u59cb\u5316 LLM","text":"<pre><code>import os\nimport getpass\nfrom langchain_anthropic import ChatAnthropic\n\ndef _set_env(var: str):\n    if not os.environ.get(var):\n        os.environ[var] = getpass.getpass(f\"{var}: \")\n\n_set_env(\"ANTHROPIC_API_KEY\")\n\nllm = ChatAnthropic(model=\"claude-sonnet-4-5\")\n</code></pre>"},{"location":"llmapps/langgraph/workflows%2Bagents/#llm","title":"LLM \u589e\u5f3a\u529f\u80fd","text":"<p>\u5de5\u4f5c\u6d41\u548c\u667a\u80fd\u4f53\u7cfb\u7edf\u57fa\u4e8e LLM \u53ca\u5176\u5404\u79cd\u589e\u5f3a\u529f\u80fd\uff1a</p> <ul> <li>\u5de5\u5177\u8c03\u7528\uff1a\u8ba9 LLM \u80fd\u591f\u4f7f\u7528\u5916\u90e8\u5de5\u5177</li> <li>\u7ed3\u6784\u5316\u8f93\u51fa\uff1a\u786e\u4fdd\u8f93\u51fa\u7b26\u5408\u9884\u5b9a\u4e49\u683c\u5f0f</li> <li>\u77ed\u671f\u8bb0\u5fc6\uff1a\u4e3a LLM \u63d0\u4f9b\u4e0a\u4e0b\u6587\u8bb0\u5fc6</li> </ul> <p></p>"},{"location":"llmapps/langgraph/workflows%2Bagents/#_3","title":"\u7ed3\u6784\u5316\u8f93\u51fa\u793a\u4f8b","text":"<pre><code>from pydantic import BaseModel, Field\n\nclass SearchQuery(BaseModel):\n    search_query: str = Field(None, description=\"\u4f18\u5316\u7684\u7f51\u7edc\u641c\u7d22\u67e5\u8be2\")\n    justification: str = Field(None, description=\"\u4e3a\u4ec0\u4e48\u6b64\u67e5\u8be2\u4e0e\u7528\u6237\u8bf7\u6c42\u76f8\u5173\")\n\n# \u589e\u5f3a LLM \u4ee5\u652f\u6301\u7ed3\u6784\u5316\u8f93\u51fa\nstructured_llm = llm.with_structured_output(SearchQuery)\n\n# \u8c03\u7528\u589e\u5f3a\u540e\u7684 LLM\noutput = structured_llm.invoke(\"\u9499 CT \u8bc4\u5206\u4e0e\u9ad8\u80c6\u56fa\u9187\u6709\u4ec0\u4e48\u5173\u7cfb\uff1f\")\n</code></pre>"},{"location":"llmapps/langgraph/workflows%2Bagents/#_4","title":"\u5de5\u5177\u8c03\u7528\u793a\u4f8b","text":"<pre><code># \u5b9a\u4e49\u5de5\u5177\ndef multiply(a: int, b: int) -&gt; int:\n    return a * b\n\n# \u4e3a LLM \u7ed1\u5b9a\u5de5\u5177\nllm_with_tools = llm.bind_tools([multiply])\n\n# \u8c03\u7528 LLM\nmsg = llm_with_tools.invoke(\"2 \u4e58\u4ee5 3 \u7b49\u4e8e\u591a\u5c11\uff1f\")\n\n# \u83b7\u53d6\u5de5\u5177\u8c03\u7528\nprint(msg.tool_calls)\n</code></pre>"},{"location":"llmapps/langgraph/workflows%2Bagents/#_5","title":"\u5de5\u4f5c\u6d41\u6a21\u5f0f","text":""},{"location":"llmapps/langgraph/workflows%2Bagents/#1-prompt-chaining","title":"1. \u63d0\u793a\u94fe (Prompt Chaining)","text":"<p>\u63d0\u793a\u94fe\u662f\u6307\u6bcf\u4e2a LLM \u8c03\u7528\u5904\u7406\u524d\u4e00\u4e2a\u8c03\u7528\u7684\u8f93\u51fa\uff0c\u9002\u7528\u4e8e\u53ef\u4ee5\u5206\u89e3\u4e3a\u8f83\u5c0f\u3001\u53ef\u9a8c\u8bc1\u6b65\u9aa4\u7684\u4efb\u52a1\u3002</p> <p>\u5e94\u7528\u573a\u666f\uff1a - \u5c06\u6587\u6863\u7ffb\u8bd1\u6210\u4e0d\u540c\u8bed\u8a00 - \u9a8c\u8bc1\u751f\u6210\u5185\u5bb9\u7684\u4e00\u81f4\u6027</p> <p></p>"},{"location":"llmapps/langgraph/workflows%2Bagents/#graph-api","title":"Graph API \u5b9e\u73b0","text":"<pre><code>from typing_extensions import TypedDict\nfrom langgraph.graph import StateGraph, START, END\n\n# \u56fe\u72b6\u6001\u5b9a\u4e49\nclass State(TypedDict):\n    topic: str\n    joke: str\n    improved_joke: str\n    final_joke: str\n\n# \u8282\u70b9\u51fd\u6570\ndef generate_joke(state: State):\n    \"\"\"\u751f\u6210\u521d\u59cb\u7b11\u8bdd\"\"\"\n    msg = llm.invoke(f\"\u5199\u4e00\u4e2a\u5173\u4e8e {state['topic']} \u7684\u77ed\u7b11\u8bdd\")\n    return {\"joke\": msg.content}\n\ndef check_punchline(state: State):\n    \"\"\"\u68c0\u67e5\u7b11\u8bdd\u662f\u5426\u6709\u7b11\u70b9\"\"\"\n    if \"?\" in state[\"joke\"] or \"!\" in state[\"joke\"]:\n        return \"Pass\"\n    return \"Fail\"\n\ndef improve_joke(state: State):\n    \"\"\"\u6539\u8fdb\u7b11\u8bdd\"\"\"\n    msg = llm.invoke(f\"\u901a\u8fc7\u6dfb\u52a0\u6587\u5b57\u6e38\u620f\u8ba9\u8fd9\u4e2a\u7b11\u8bdd\u66f4\u6709\u8da3\uff1a{state['joke']}\")\n    return {\"improved_joke\": msg.content}\n\ndef polish_joke(state: State):\n    \"\"\"\u6700\u7ec8\u6da6\u8272\"\"\"\n    msg = llm.invoke(f\"\u4e3a\u8fd9\u4e2a\u7b11\u8bdd\u6dfb\u52a0\u4e00\u4e2a\u610f\u60f3\u4e0d\u5230\u7684\u8f6c\u6298\uff1a{state['improved_joke']}\")\n    return {\"final_joke\": msg.content}\n\n# \u6784\u5efa\u5de5\u4f5c\u6d41\nworkflow = StateGraph(State)\nworkflow.add_node(\"generate_joke\", generate_joke)\nworkflow.add_node(\"improve_joke\", improve_joke)\nworkflow.add_node(\"polish_joke\", polish_joke)\n\n# \u6dfb\u52a0\u8fb9\u8fde\u63a5\u8282\u70b9\nworkflow.add_edge(START, \"generate_joke\")\nworkflow.add_conditional_edges(\n    \"generate_joke\", check_punchline, {\"Fail\": \"improve_joke\", \"Pass\": END}\n)\nworkflow.add_edge(\"improve_joke\", \"polish_joke\")\nworkflow.add_edge(\"polish_joke\", END)\n\n# \u7f16\u8bd1\u5e76\u6267\u884c\nchain = workflow.compile()\nstate = chain.invoke({\"topic\": \"\u732b\"})\n</code></pre>"},{"location":"llmapps/langgraph/workflows%2Bagents/#2-parallelization","title":"2. \u5e76\u884c\u5316 (Parallelization)","text":"<p>\u5e76\u884c\u5316\u8ba9 LLM \u540c\u65f6\u5904\u7406\u4efb\u52a1\uff0c\u53ef\u4ee5\u63d0\u9ad8\u901f\u5ea6\u6216\u589e\u52a0\u8f93\u51fa\u7f6e\u4fe1\u5ea6\u3002</p> <p>\u5e94\u7528\u573a\u666f\uff1a - \u540c\u65f6\u5904\u7406\u591a\u4e2a\u72ec\u7acb\u5b50\u4efb\u52a1 - \u591a\u6b21\u8fd0\u884c\u540c\u4e00\u4efb\u52a1\u4ee5\u68c0\u67e5\u4e0d\u540c\u8f93\u51fa</p> <p></p>"},{"location":"llmapps/langgraph/workflows%2Bagents/#graph-api_1","title":"Graph API \u5b9e\u73b0","text":"<pre><code>class State(TypedDict):\n    topic: str\n    joke: str\n    story: str\n    poem: str\n    combined_output: str\n\ndef call_llm_1(state: State):\n    msg = llm.invoke(f\"\u5199\u4e00\u4e2a\u5173\u4e8e {state['topic']} \u7684\u7b11\u8bdd\")\n    return {\"joke\": msg.content}\n\ndef call_llm_2(state: State):\n    msg = llm.invoke(f\"\u5199\u4e00\u4e2a\u5173\u4e8e {state['topic']} \u7684\u6545\u4e8b\")\n    return {\"story\": msg.content}\n\ndef call_llm_3(state: State):\n    msg = llm.invoke(f\"\u5199\u4e00\u9996\u5173\u4e8e {state['topic']} \u7684\u8bd7\")\n    return {\"poem\": msg.content}\n\ndef aggregator(state: State):\n    combined = f\"\u8fd9\u662f\u5173\u4e8e {state['topic']} \u7684\u6545\u4e8b\u3001\u7b11\u8bdd\u548c\u8bd7\u6b4c\uff01\\n\\n\"\n    combined += f\"\u6545\u4e8b\uff1a\\n{state['story']}\\n\\n\"\n    combined += f\"\u7b11\u8bdd\uff1a\\n{state['joke']}\\n\\n\"\n    combined += f\"\u8bd7\u6b4c\uff1a\\n{state['poem']}\"\n    return {\"combined_output\": combined}\n\n# \u6784\u5efa\u5e76\u884c\u5de5\u4f5c\u6d41\nparallel_builder = StateGraph(State)\nparallel_builder.add_node(\"call_llm_1\", call_llm_1)\nparallel_builder.add_node(\"call_llm_2\", call_llm_2)\nparallel_builder.add_node(\"call_llm_3\", call_llm_3)\nparallel_builder.add_node(\"aggregator\", aggregator)\n\n# \u8bbe\u7f6e\u5e76\u884c\u6267\u884c\u8def\u5f84\nparallel_builder.add_edge(START, \"call_llm_1\")\nparallel_builder.add_edge(START, \"call_llm_2\")\nparallel_builder.add_edge(START, \"call_llm_3\")\nparallel_builder.add_edge(\"call_llm_1\", \"aggregator\")\nparallel_builder.add_edge(\"call_llm_2\", \"aggregator\")\nparallel_builder.add_edge(\"call_llm_3\", \"aggregator\")\nparallel_builder.add_edge(\"aggregator\", END)\n\nparallel_workflow = parallel_builder.compile()\n</code></pre>"},{"location":"llmapps/langgraph/workflows%2Bagents/#3-routing","title":"3. \u8def\u7531 (Routing)","text":"<p>\u8def\u7531\u5de5\u4f5c\u6d41\u5904\u7406\u8f93\u5165\u5e76\u5c06\u5176\u5b9a\u5411\u5230\u7279\u5b9a\u4efb\u52a1\uff0c\u9002\u7528\u4e8e\u590d\u6742\u4efb\u52a1\u7684\u4e13\u95e8\u6d41\u7a0b\u3002</p> <p></p>"},{"location":"llmapps/langgraph/workflows%2Bagents/#graph-api_2","title":"Graph API \u5b9e\u73b0","text":"<pre><code>from typing_extensions import Literal\nfrom pydantic import BaseModel, Field\nfrom langchain.messages import HumanMessage, SystemMessage\n\nclass Route(BaseModel):\n    step: Literal[\"poem\", \"story\", \"joke\"] = Field(\n        None, description=\"\u8def\u7531\u8fc7\u7a0b\u4e2d\u7684\u4e0b\u4e00\u6b65\"\n    )\n\n# \u589e\u5f3a LLM \u4ee5\u652f\u6301\u8def\u7531\u51b3\u7b56\nrouter = llm.with_structured_output(Route)\n\nclass State(TypedDict):\n    input: str\n    decision: str\n    output: str\n\ndef llm_call_router(state: State):\n    \"\"\"\u8def\u7531\u8f93\u5165\u5230\u9002\u5f53\u7684\u8282\u70b9\"\"\"\n    decision = router.invoke([\n        SystemMessage(content=\"\u6839\u636e\u7528\u6237\u8bf7\u6c42\u5c06\u8f93\u5165\u8def\u7531\u5230\u6545\u4e8b\u3001\u7b11\u8bdd\u6216\u8bd7\u6b4c\u3002\"),\n        HumanMessage(content=state[\"input\"])\n    ])\n    return {\"decision\": decision.step}\n\ndef route_decision(state: State):\n    if state[\"decision\"] == \"story\":\n        return \"llm_call_1\"\n    elif state[\"decision\"] == \"joke\":\n        return \"llm_call_2\"\n    elif state[\"decision\"] == \"poem\":\n        return \"llm_call_3\"\n</code></pre>"},{"location":"llmapps/langgraph/workflows%2Bagents/#4-orchestrator-worker","title":"4. \u7f16\u6392\u5668-\u5de5\u4f5c\u8005 (Orchestrator-Worker)","text":"<p>\u5728\u8fd9\u79cd\u914d\u7f6e\u4e2d\uff0c\u7f16\u6392\u5668\u5206\u89e3\u4efb\u52a1\u3001\u59d4\u6d3e\u5b50\u4efb\u52a1\u7ed9\u5de5\u4f5c\u8005\uff0c\u5e76\u5c06\u5de5\u4f5c\u8005\u8f93\u51fa\u5408\u6210\u4e3a\u6700\u7ec8\u7ed3\u679c\u3002</p> <p></p>"},{"location":"llmapps/langgraph/workflows%2Bagents/#send-api","title":"\u4f7f\u7528 Send API \u5b9e\u73b0","text":"<pre><code>from langgraph.types import Send\nfrom typing import Annotated, List\nimport operator\n\nclass Section(BaseModel):\n    name: str = Field(description=\"\u62a5\u544a\u90e8\u5206\u7684\u540d\u79f0\")\n    description: str = Field(description=\"\u672c\u8282\u8981\u6db5\u76d6\u7684\u4e3b\u8981\u4e3b\u9898\u548c\u6982\u5ff5\u7684\u7b80\u8981\u6982\u8ff0\")\n\nclass Sections(BaseModel):\n    sections: List[Section] = Field(description=\"\u62a5\u544a\u7684\u5404\u90e8\u5206\")\n\nplanner = llm.with_structured_output(Sections)\n\nclass State(TypedDict):\n    topic: str\n    sections: list[Section]\n    completed_sections: Annotated[list, operator.add]\n    final_report: str\n\nclass WorkerState(TypedDict):\n    section: Section\n    completed_sections: Annotated[list, operator.add]\n\ndef orchestrator(state: State):\n    \"\"\"\u7f16\u6392\u5668\u751f\u6210\u62a5\u544a\u8ba1\u5212\"\"\"\n    report_sections = planner.invoke([\n        SystemMessage(content=\"\u751f\u6210\u62a5\u544a\u8ba1\u5212\u3002\"),\n        HumanMessage(content=f\"\u8fd9\u662f\u62a5\u544a\u4e3b\u9898\uff1a{state['topic']}\")\n    ])\n    return {\"sections\": report_sections.sections}\n\ndef llm_call(state: WorkerState):\n    \"\"\"\u5de5\u4f5c\u8005\u7f16\u5199\u62a5\u544a\u90e8\u5206\"\"\"\n    section = llm.invoke([\n        SystemMessage(content=\"\u6309\u7167\u63d0\u4f9b\u7684\u540d\u79f0\u548c\u63cf\u8ff0\u7f16\u5199\u62a5\u544a\u90e8\u5206\u3002\"),\n        HumanMessage(content=f\"\u8fd9\u662f\u90e8\u5206\u540d\u79f0\uff1a{state['section'].name} \u548c\u63cf\u8ff0\uff1a{state['section'].description}\")\n    ])\n    return {\"completed_sections\": [section.content]}\n\ndef assign_workers(state: State):\n    \"\"\"\u4e3a\u8ba1\u5212\u4e2d\u7684\u6bcf\u4e2a\u90e8\u5206\u5206\u914d\u5de5\u4f5c\u8005\"\"\"\n    return [Send(\"llm_call\", {\"section\": s}) for s in state[\"sections\"]]\n</code></pre>"},{"location":"llmapps/langgraph/workflows%2Bagents/#5-evaluator-optimizer","title":"5. \u8bc4\u4f30\u5668-\u4f18\u5316\u5668 (Evaluator-Optimizer)","text":"<p>\u5728\u8fd9\u79cd\u5de5\u4f5c\u6d41\u4e2d\uff0c\u4e00\u4e2a LLM \u8c03\u7528\u521b\u5efa\u54cd\u5e94\uff0c\u53e6\u4e00\u4e2a\u8bc4\u4f30\u8be5\u54cd\u5e94\u3002\u5982\u679c\u9700\u8981\u6539\u8fdb\uff0c\u63d0\u4f9b\u53cd\u9988\u5e76\u91cd\u65b0\u521b\u5efa\u54cd\u5e94\u3002</p> <p></p>"},{"location":"llmapps/langgraph/workflows%2Bagents/#graph-api_3","title":"Graph API \u5b9e\u73b0","text":"<pre><code>class Feedback(BaseModel):\n    grade: Literal[\"funny\", \"not funny\"] = Field(description=\"\u51b3\u5b9a\u7b11\u8bdd\u662f\u5426\u6709\u8da3\")\n    feedback: str = Field(description=\"\u5982\u679c\u7b11\u8bdd\u4e0d\u597d\u7b11\uff0c\u63d0\u4f9b\u6539\u8fdb\u53cd\u9988\")\n\nevaluator = llm.with_structured_output(Feedback)\n\nclass State(TypedDict):\n    joke: str\n    topic: str\n    feedback: str\n    funny_or_not: str\n\ndef llm_call_generator(state: State):\n    \"\"\"LLM \u751f\u6210\u7b11\u8bdd\"\"\"\n    if state.get(\"feedback\"):\n        msg = llm.invoke(f\"\u5199\u4e00\u4e2a\u5173\u4e8e {state['topic']} \u7684\u7b11\u8bdd\uff0c\u4f46\u8981\u8003\u8651\u53cd\u9988\uff1a{state['feedback']}\")\n    else:\n        msg = llm.invoke(f\"\u5199\u4e00\u4e2a\u5173\u4e8e {state['topic']} \u7684\u7b11\u8bdd\")\n    return {\"joke\": msg.content}\n\ndef llm_call_evaluator(state: State):\n    \"\"\"LLM \u8bc4\u4f30\u7b11\u8bdd\"\"\"\n    grade = evaluator.invoke(f\"\u8bc4\u4ef7\u8fd9\u4e2a\u7b11\u8bdd\uff1a{state['joke']}\")\n    return {\"funny_or_not\": grade.grade, \"feedback\": grade.feedback}\n\ndef route_joke(state: State):\n    \"\"\"\u6839\u636e\u8bc4\u4f30\u5668\u53cd\u9988\u8def\u7531\u56de\u7b11\u8bdd\u751f\u6210\u5668\u6216\u7ed3\u675f\"\"\"\n    if state[\"funny_or_not\"] == \"funny\":\n        return \"Accepted\"\n    elif state[\"funny_or_not\"] == \"not funny\":\n        return \"Rejected + Feedback\"\n</code></pre>"},{"location":"llmapps/langgraph/workflows%2Bagents/#agents","title":"\u667a\u80fd\u4f53 (Agents)","text":"<p>\u667a\u80fd\u4f53\u901a\u5e38\u662f\u4f7f\u7528\u5de5\u5177\u6267\u884c\u64cd\u4f5c\u7684 LLM\uff0c\u5728\u8fde\u7eed\u53cd\u9988\u5faa\u73af\u4e2d\u8fd0\u884c\uff0c\u7528\u4e8e\u95ee\u9898\u548c\u89e3\u51b3\u65b9\u6848\u4e0d\u53ef\u9884\u6d4b\u7684\u60c5\u51b5\u3002</p> <p></p>"},{"location":"llmapps/langgraph/workflows%2Bagents/#_6","title":"\u5de5\u5177\u5b9a\u4e49","text":"<pre><code>from langchain.tools import tool\n\n@tool\ndef multiply(a: int, b: int) -&gt; int:\n    \"\"\"\u5c06 `a` \u548c `b` \u76f8\u4e58\"\"\"\n    return a * b\n\n@tool\ndef add(a: int, b: int) -&gt; int:\n    \"\"\"\u5c06 `a` \u548c `b` \u76f8\u52a0\"\"\"\n    return a + b\n\n@tool\ndef divide(a: int, b: int) -&gt; float:\n    \"\"\"\u5c06 `a` \u9664\u4ee5 `b`\"\"\"\n    return a / b\n\n# \u4e3a LLM \u7ed1\u5b9a\u5de5\u5177\ntools = [add, multiply, divide]\ntools_by_name = {tool.name: tool for tool in tools}\nllm_with_tools = llm.bind_tools(tools)\n</code></pre>"},{"location":"llmapps/langgraph/workflows%2Bagents/#graph-api_4","title":"Graph API \u5b9e\u73b0\u667a\u80fd\u4f53","text":"<pre><code>from langgraph.graph import MessagesState\nfrom langchain.messages import SystemMessage, HumanMessage, ToolMessage\n\ndef llm_call(state: MessagesState):\n    \"\"\"LLM \u51b3\u5b9a\u662f\u5426\u8c03\u7528\u5de5\u5177\"\"\"\n    return {\n        \"messages\": [\n            llm_with_tools.invoke([\n                SystemMessage(content=\"\u4f60\u662f\u4e00\u4e2a\u6709\u5e2e\u52a9\u7684\u52a9\u624b\uff0c\u8d1f\u8d23\u5bf9\u4e00\u7ec4\u8f93\u5165\u6267\u884c\u7b97\u672f\u8fd0\u7b97\u3002\")\n            ] + state[\"messages\"])\n        ]\n    }\n\ndef tool_node(state: dict):\n    \"\"\"\u6267\u884c\u5de5\u5177\u8c03\u7528\"\"\"\n    result = []\n    for tool_call in state[\"messages\"][-1].tool_calls:\n        tool = tools_by_name[tool_call[\"name\"]]\n        observation = tool.invoke(tool_call[\"args\"])\n        result.append(ToolMessage(content=observation, tool_call_id=tool_call[\"id\"]))\n    return {\"messages\": result}\n\ndef should_continue(state: MessagesState) -&gt; Literal[\"tool_node\", END]:\n    \"\"\"\u6839\u636e LLM \u662f\u5426\u8fdb\u884c\u5de5\u5177\u8c03\u7528\u6765\u51b3\u5b9a\u662f\u5426\u7ee7\u7eed\u5faa\u73af\"\"\"\n    messages = state[\"messages\"]\n    last_message = messages[-1]\n\n    if last_message.tool_calls:\n        return \"tool_node\"\n    return END\n\n# \u6784\u5efa\u667a\u80fd\u4f53\nagent_builder = StateGraph(MessagesState)\nagent_builder.add_node(\"llm_call\", llm_call)\nagent_builder.add_node(\"tool_node\", tool_node)\n\nagent_builder.add_edge(START, \"llm_call\")\nagent_builder.add_conditional_edges(\"llm_call\", should_continue, [\"tool_node\", END])\nagent_builder.add_edge(\"tool_node\", \"llm_call\")\n\nagent = agent_builder.compile()\n</code></pre>"},{"location":"llmapps/langgraph/workflows%2Bagents/#_7","title":"\u603b\u7ed3","text":"<p>\u672c\u6559\u7a0b\u4ecb\u7ecd\u4e86 LangGraph \u4e2d\u7684\u4e3b\u8981\u5de5\u4f5c\u6d41\u548c\u667a\u80fd\u4f53\u6a21\u5f0f\uff1a</p> <ol> <li>\u63d0\u793a\u94fe\uff1a\u987a\u5e8f\u6267\u884c\uff0c\u9002\u7528\u4e8e\u53ef\u5206\u89e3\u4efb\u52a1</li> <li>\u5e76\u884c\u5316\uff1a\u540c\u65f6\u6267\u884c\uff0c\u63d0\u9ad8\u6548\u7387</li> <li>\u8def\u7531\uff1a\u6839\u636e\u8f93\u5165\u5b9a\u5411\u5230\u7279\u5b9a\u4efb\u52a1</li> <li>\u7f16\u6392\u5668-\u5de5\u4f5c\u8005\uff1a\u52a8\u6001\u4efb\u52a1\u5206\u89e3\u548c\u5206\u914d</li> <li>\u8bc4\u4f30\u5668-\u4f18\u5316\u5668\uff1a\u8fed\u4ee3\u6539\u8fdb\u8f93\u51fa\u8d28\u91cf</li> <li>\u667a\u80fd\u4f53\uff1a\u81ea\u4e3b\u51b3\u7b56\u548c\u5de5\u5177\u4f7f\u7528</li> </ol> <p>\u6bcf\u79cd\u6a21\u5f0f\u90fd\u6709\u5176\u9002\u7528\u573a\u666f\uff0c\u9009\u62e9\u5408\u9002\u7684\u6a21\u5f0f\u53d6\u51b3\u4e8e\u5177\u4f53\u4efb\u52a1\u7684\u9700\u6c42\u548c\u590d\u6742\u6027\u3002LangGraph \u63d0\u4f9b\u4e86\u7075\u6d3b\u7684 API \u6765\u6784\u5efa\u8fd9\u4e9b\u6a21\u5f0f\uff0c\u65e0\u8bba\u662f\u4f7f\u7528 Graph API \u8fd8\u662f Functional API\u3002</p>"},{"location":"machine/interview/","title":"\u673a\u5668\u5b66\u4e60\u9762\u8bd5\u9898","text":""},{"location":"machine/interview/#_2","title":"\u4e00\u3001\u673a\u5668\u5b66\u4e60\u6a21\u578b","text":""},{"location":"machine/interview/#11","title":"1.1 \u6709\u76d1\u7763\u5b66\u4e60\u6a21\u578b","text":"<p>\u6709\u76d1\u7763\u5b66\u4e60\u6a21\u578b\u662f\u4e00\u79cd\u5229\u7528\u5df2\u77e5\u6807\u7b7e\u7684\u8bad\u7ec3\u6570\u636e\u6765\u5b66\u4e60\u8f93\u5165\u4e0e\u8f93\u51fa\u4e4b\u95f4\u6620\u5c04\u5173\u7cfb\u7684\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u5176\u6838\u5fc3\u5728\u4e8e\u901a\u8fc7\u8bad\u7ec3\u96c6\u4e2d\u7684\u8f93\u5165\u7279\u5f81\u548c\u5bf9\u5e94\u6807\u7b7e\u6765\u8c03\u6574\u6a21\u578b\u53c2\u6570\uff0c\u4ece\u800c\u5b9e\u73b0\u5bf9\u65b0\u6570\u636e\u7684\u51c6\u786e\u9884\u6d4b\u3002\u8be5\u6a21\u578b\u4e3b\u8981\u5e94\u7528\u4e8e\u5206\u7c7b\u548c\u56de\u5f52\u4efb\u52a1\uff0c\u5176\u4e2d\u5206\u7c7b\u7528\u4e8e\u5c06\u6570\u636e\u5206\u914d\u5230\u9884\u5b9a\u4e49\u7c7b\u522b\uff0c\u56de\u5f52\u5219\u7528\u4e8e\u9884\u6d4b\u8fde\u7eed\u6570\u503c\u3002</p> <p>\u4e3b\u8981\u7b97\u6cd5\u53ca\u7279\u70b9</p> \u7b97\u6cd5 \u6838\u5fc3\u539f\u7406 \u4f18\u70b9 \u7f3a\u70b9 \u652f\u6301\u5411\u91cf\u673a(SVM) \u5bfb\u627e\u6700\u4f18\u51b3\u7b56\u8fb9\u754c\u4ee5\u6700\u5927\u5316\u7c7b\u522b\u95f4\u9694 \u5728\u9ad8\u7ef4\u7a7a\u95f4\u8868\u73b0\u826f\u597d\uff0c\u9002\u5408\u5c0f\u6837\u672c\u6570\u636e \u5bf9\u5927\u89c4\u6a21\u6570\u636e\u8bad\u7ec3\u65f6\u95f4\u957f\uff0c\u5bf9\u7f3a\u5931\u6570\u636e\u654f\u611f \u4eba\u5de5\u795e\u7ecf\u7f51\u7edc(ANN) \u6a21\u62df\u4eba\u8111\u795e\u7ecf\u5143\u5de5\u4f5c\u65b9\u5f0f\uff0c\u901a\u8fc7\u591a\u5c42\u7ed3\u6784\u5904\u7406\u975e\u7ebf\u6027\u5173\u7cfb \u5f3a\u5927\u7684\u975e\u7ebf\u6027\u5efa\u6a21\u80fd\u529b\uff0c\u9002\u7528\u4e8e\u590d\u6742\u95ee\u9898 \u8bad\u7ec3\u65f6\u95f4\u957f\uff0c\u6613\u8fc7\u62df\u5408\uff0c\u5bf9\u53c2\u6570\u654f\u611f \u51b3\u7b56\u6811(DT) \u901a\u8fc7\u6811\u5f62\u7ed3\u6784\u8fdb\u884c\u7279\u5f81\u5212\u5206 \u6613\u4e8e\u7406\u89e3\u548c\u89e3\u91ca\uff0c\u53ef\u5904\u7406\u6570\u503c\u548c\u7c7b\u522b\u6570\u636e \u6613\u8fc7\u62df\u5408\uff0c\u5bf9\u6570\u636e\u53d8\u5316\u654f\u611f \u6734\u7d20\u8d1d\u53f6\u65af(NB) \u57fa\u4e8e\u8d1d\u53f6\u65af\u5b9a\u7406\u7684\u7c7b\u6761\u4ef6\u72ec\u7acb\u6027\u5047\u8bbe \u8ba1\u7b97\u6548\u7387\u9ad8\uff0c\u9002\u5408\u9ad8\u7ef4\u6570\u636e \u7279\u5f81\u72ec\u7acb\u6027\u5047\u8bbe\u5728\u73b0\u5b9e\u4e2d\u5f80\u5f80\u4e0d\u6210\u7acb K\u8fd1\u90bb(KNN) \u57fa\u4e8e\u8ddd\u79bb\u5ea6\u91cf\u627e\u5230\u6700\u8fd1\u7684K\u4e2a\u8bad\u7ec3\u6837\u672c\u8fdb\u884c\u5206\u7c7b \u7b80\u5355\u6613\u61c2\uff0c\u65e0\u9700\u8bad\u7ec3\u8fc7\u7a0b \u5bf9K\u503c\u9009\u62e9\u654f\u611f\uff0c\u8ba1\u7b97\u91cf\u5927 <p></p>"},{"location":"machine/interview/#12","title":"1.2 \u65e0\u76d1\u7763\u5b66\u4e60\u6a21\u578b","text":"<p>\u65e0\u76d1\u7763\u5b66\u4e60\u6a21\u578b\u662f\u673a\u5668\u5b66\u4e60\u7684\u91cd\u8981\u5206\u652f\uff0c\u5176\u6838\u5fc3\u5728\u4e8e\u76f4\u63a5\u4ece\u672a\u6807\u8bb0\u7684\u6570\u636e\u4e2d\u6316\u6398\u6f5c\u5728\u7ed3\u6784\u4e0e\u5185\u5728\u89c4\u5f8b\uff0c\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\u6807\u7b7e\u3002 \u8be5\u6a21\u578b\u4e3b\u8981\u4efb\u52a1\u5305\u62ec\u805a\u7c7b\u5206\u6790\u3001\u964d\u7ef4\u5904\u7406\u3001\u5f02\u5e38\u68c0\u6d4b\u548c\u5173\u8054\u89c4\u5219\u5b66\u4e60\u7b49\uff0c\u5e7f\u6cdb\u5e94\u7528\u4e8e\u5ba2\u6237\u7ec6\u5206\u3001\u5546\u54c1\u63a8\u8350\u3001\u5f02\u5e38\u68c0\u6d4b\u7b49\u9886\u57df\u3002</p> <p></p>"},{"location":"machine/interview/#13","title":"1.3 \u6982\u7387\u6a21\u578b","text":"<p>\u6982\u7387\u6a21\u578b\u662f\u4e00\u7c7b\u5229\u7528\u6982\u7387\u8bba\u4e0e\u7edf\u8ba1\u5b66\u63cf\u8ff0\u6570\u636e\u751f\u6210\u673a\u5236\u4e0e\u53d8\u91cf\u5173\u7cfb\u7684\u6570\u5b66\u6a21\u578b\u3002\u5b83\u901a\u8fc7\u8054\u5408\u6982\u7387\u5206\u5e03 \\(P(X, Y)\\) \u5efa\u6a21\u8f93\u5165 \\(X\\) \u4e0e\u8f93\u51fa \\(Y\\) \u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u652f\u6301\u63a8\u7406\u3001\u9884\u6d4b\u4e0e\u51b3\u7b56\u3002</p> <p>\u2705 \u6838\u5fc3\u601d\u60f3\uff1a\u5c06\u590d\u6742\u7cfb\u7edf\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u663e\u5f0f\u5efa\u6a21\uff0c\u5b9e\u73b0\u201c\u5728\u4e0d\u786e\u5b9a\u4e2d\u6c42\u786e\u5b9a\u201d\u3002</p> <p></p>"},{"location":"machine/interview/#_3","title":"\u6838\u5fc3\u6982\u7387\u6a21\u578b\u7c7b\u578b","text":"<p>1. \u8d1d\u53f6\u65af\u7f51\u7edc\uff08Bayesian Network\uff09</p> <ul> <li>\u7c7b\u578b\uff1a\u6709\u5411\u56fe\u6a21\u578b\uff08DAG\uff09</li> <li>\u7ed3\u6784\uff1a\u8282\u70b9 = \u968f\u673a\u53d8\u91cf\uff0c\u8fb9 = \u56e0\u679c\u4f9d\u8d56</li> <li>\u5e94\u7528\uff1a\u533b\u7597\u8bca\u65ad\u3001\u63a8\u8350\u7cfb\u7edf\u3001\u8bed\u97f3\u8bc6\u522b</li> </ul> <p>\ud83c\udf30 \u793a\u4f8b\uff1a \u8282\u70b9\uff1a<code>Rain</code>\uff08\u662f\u5426\u4e0b\u96e8\uff09\u3001<code>Sprinkler</code>\uff08\u6d12\u6c34\u5668\u662f\u5426\u5f00\u542f\uff09\u3001<code>Wet Grass</code>\uff08\u8349\u5730\u662f\u5426\u6e7f\uff09 \u8fb9\uff1a<code>Rain \u2192 Wet Grass</code>\uff0c<code>Sprinkler \u2192 Wet Grass</code> \u53ef\u8ba1\u7b97\u201c\u5df2\u77e5\u8349\u5730\u6e7f\uff0c\u4e0b\u96e8\u7684\u6982\u7387\u201d\u2014\u2014\u5373\u540e\u9a8c\u6982\u7387\u63a8\u7406\u3002</p> <p>2. \u9690\u9a6c\u5c14\u53ef\u592b\u6a21\u578b\uff08HMM\uff09</p> <ul> <li>\u672c\u8d28\uff1a\u7ed3\u6784\u6700\u7b80\u5355\u7684\u52a8\u6001\u8d1d\u53f6\u65af\u7f51\u7edc</li> <li>\u9002\u7528\uff1a\u65f6\u5e8f\u6570\u636e\u5efa\u6a21\uff08\u5982\u8bed\u97f3\u3001\u6587\u672c\uff09</li> <li>\u4e24\u5927\u53d8\u91cf\uff1a<ul> <li>\u9690\u72b6\u6001\u5e8f\u5217 \\(y_1, y_2, ..., y_n\\)\uff08\u4e0d\u53ef\u89c2\u6d4b\uff09</li> <li>\u89c2\u6d4b\u5e8f\u5217 \\(x_1, x_2, ..., x_n\\)\uff08\u53ef\u89c2\u6d4b\uff09</li> </ul> </li> </ul> <p>\ud83d\udccc \u8054\u5408\u6982\u7387\u5206\u89e3\u4e3a\uff1a $$ P(x_1,y_1,...,x_n,y_n) = P(y_1)P(x_1|y_1)\\prod_{i=2}^n P(y_i|y_{i-1})P(x_i|y_i) $$</p> <p>3. \u9a6c\u5c14\u53ef\u592b\u968f\u673a\u573a\uff08MRF\uff09\u4e0e\u6761\u4ef6\u968f\u673a\u573a\uff08CRF\uff09</p> \u6a21\u578b \u7c7b\u578b \u7279\u70b9 \u5e94\u7528 MRF \u65e0\u5411\u56fe\u6a21\u578b \u5efa\u6a21\u53d8\u91cf\u95f4\u5bf9\u79f0\u4f9d\u8d56\uff08\u5982\u56fe\u50cf\u50cf\u7d20\uff09 \u56fe\u50cf\u5904\u7406\u3001\u57fa\u56e0\u5206\u6790 CRF \u5224\u522b\u5f0f\u65e0\u5411\u6a21\u578b \u76f4\u63a5\u5efa\u6a21 $P(Y X)$\uff0c\u5e38\u7528\u4e8e\u5e8f\u5217\u6807\u6ce8"},{"location":"machine/interview/#_4","title":"\u6982\u7387\u6a21\u578b\u7684\u6838\u5fc3\u5b66\u4e60\u65b9\u6cd5","text":"<p>1. \u6781\u5927\u4f3c\u7136\u4f30\u8ba1\uff08MLE\uff09</p> <ul> <li>\u76ee\u6807\uff1a\u627e\u5230\u4f7f\u89c2\u6d4b\u6570\u636e\u51fa\u73b0\u6982\u7387\u6700\u5927\u7684\u53c2\u6570 \\(\\theta\\)</li> <li>\u516c\u5f0f\uff1a  </li> <li> \\[   \\hat{\\theta}_{MLE} = \\arg\\max_\\theta P(D|\\theta) \\] </li> <li> <p>\u5b9e\u4f8b\uff1a\u629b\u786c\u5e0110\u6b21\u5f977\u6b21\u6b63\u9762 \u2192 \u4f30\u8ba1\u6b63\u9762\u6982\u7387\u4e3a0.7</p> <p>\ud83d\udd0d \u5b9e\u8df5\u6280\u5de7\uff1a\u5e38\u5bf9\u4f3c\u7136\u53d6\u5bf9\u6570\uff08\u5bf9\u6570\u4f3c\u7136\uff09\uff0c\u4fbf\u4e8e\u4f18\u5316\u3002</p> </li> </ul> <p>2. \u8d1d\u53f6\u65af\u5b66\u4e60\uff08Bayesian Learning\uff09</p> <ul> <li>\u6838\u5fc3\u7406\u5ff5\uff1a\u53c2\u6570 \\(\\theta\\) \u662f\u4e00\u4e2a\u968f\u673a\u53d8\u91cf\uff0c\u5177\u6709\u5148\u9a8c\u5206\u5e03 \\(P(\\theta)\\)</li> <li>\u66f4\u65b0\u8fc7\u7a0b\uff1a\u5229\u7528\u8d1d\u53f6\u65af\u516c\u5f0f\u5f97\u5230\u540e\u9a8c \\(P(\\theta|D)\\)   $$   P(\\theta|D) = \\frac{P(D|\\theta)P(\\theta)}{P(D)}   $$</li> <li>\u4f18\u52bf\uff1a\u53ef\u878d\u5408\u5148\u9a8c\u77e5\u8bc6\uff0c\u9002\u5408\u5c0f\u6837\u672c\u573a\u666f</li> </ul> <p>\ud83e\udde0 \u5173\u952e\u6982\u5ff5\uff1a</p> <ul> <li>\u5148\u9a8c\u6982\u7387\uff1a\u5efa\u6a21\u524d\u7684\u77e5\u8bc6\uff08\u5982\u201c\u67d0\u75c5\u53d1\u75c5\u7387\u4f4e\u201d\uff09</li> <li>\u540e\u9a8c\u6982\u7387\uff1a\u89c2\u6d4b\u6570\u636e\u540e\u7684\u66f4\u65b0\u4fe1\u5ff5</li> <li>\u5965\u5361\u59c6\u5243\u5200\u539f\u7406\uff1a\u7b80\u5355\u6a21\u578b\u4f18\u5148\uff0c\u9632\u6b62\u8fc7\u62df\u5408</li> </ul>"},{"location":"machine/interview/#14-vs","title":"1.4 \u751f\u6210\u6a21\u578b VS \u5224\u522b\u6a21\u578b","text":""},{"location":"machine/interview/#1-discriminative-model","title":"1\ufe0f\u20e3 \u5224\u522b\u6a21\u578b\uff08Discriminative Model\uff09","text":"<p>\u6838\u5fc3\u601d\u60f3\uff1a\u76f4\u63a5\u5b66\u4e60 \u6761\u4ef6\u6982\u7387 ( P(y|x) )\uff0c\u5373\u7ed9\u5b9a\u8f93\u5165 (x)\uff0c\u9884\u6d4b\u8f93\u51fa (y) \u7684\u6982\u7387\u3002</p> <ul> <li>\u76ee\u6807\uff1a\u533a\u5206\u4e0d\u540c\u7c7b\u522b</li> <li>\u91cd\u70b9\uff1a\u8fb9\u754c/\u5206\u7c7b</li> <li>\u5e38\u89c1\u65b9\u6cd5\uff1a<ul> <li>\u903b\u8f91\u56de\u5f52\uff08Logistic Regression\uff09</li> <li>\u652f\u6301\u5411\u91cf\u673a\uff08SVM\uff09</li> <li>\u6761\u4ef6\u968f\u673a\u573a\uff08CRF\uff09</li> <li>\u795e\u7ecf\u7f51\u7edc\u5206\u7c7b\u5668</li> </ul> </li> </ul> <p>\u6570\u5b66\u8868\u8fbe\uff1a</p> \\[ \\hat{y} = \\arg\\max_y P(y|x) \\] <p>\u8bad\u7ec3\u65f6\u76f4\u63a5\u4f18\u5316\u635f\u5931\u51fd\u6570\uff08\u6bd4\u5982\u4ea4\u53c9\u71b5\uff09\uff1a</p> \\[ \\mathcal{L} = - \\sum_i y_i \\log P(y_i|x_i) \\] <p>\u76f4\u89c2\u7406\u89e3\uff1a</p> <p>\u5224\u522b\u6a21\u578b\u50cf\u4e00\u4e2a\u6cd5\u5b98\uff0c\u4e13\u6ce8\u4e8e \u5224\u65ad A \u548c B \u54ea\u4e2a\u53ef\u80fd\u6027\u66f4\u5927\uff0c\u4e0d\u5173\u5fc3\u8f93\u5165\u662f\u600e\u4e48\u751f\u6210\u7684\u3002</p>"},{"location":"machine/interview/#2-generative-model","title":"2\ufe0f\u20e3 \u751f\u6210\u6a21\u578b\uff08Generative Model\uff09","text":"<p>\u6838\u5fc3\u601d\u60f3\uff1a\u5b66\u4e60 \u8054\u5408\u6982\u7387 ( P(x, y) ) \u6216\u8005\u6570\u636e\u5206\u5e03 ( P(x) )\uff0c\u4ece\u800c\u80fd\u751f\u6210\u6570\u636e\u3002</p> <ul> <li>\u76ee\u6807\uff1a\u5efa\u6a21\u6570\u636e\u5206\u5e03\uff0c\u751f\u6210\u65b0\u6837\u672c</li> <li>\u91cd\u70b9\uff1a\u6570\u636e\u672c\u8eab</li> <li> <p>\u5e38\u89c1\u65b9\u6cd5\uff1a</p> <ul> <li>\u9ad8\u65af\u6df7\u5408\u6a21\u578b\uff08GMM\uff09</li> <li>\u6734\u7d20\u8d1d\u53f6\u65af\uff08Naive Bayes\uff09</li> <li>\u9690\u9a6c\u5c14\u53ef\u592b\u6a21\u578b\uff08HMM\uff09</li> <li>\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08VAE\uff09</li> <li>\u751f\u6210\u5bf9\u6297\u7f51\u7edc\uff08GAN\uff09</li> <li>\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff0c\u5982 GPT \u7cfb\u5217\uff09</li> </ul> </li> </ul> <p>\u6570\u5b66\u8868\u8fbe\uff1a</p> <ol> <li> <p>\u5bf9\u4e8e\u5206\u7c7b\u4efb\u52a1\uff1a $$    P(y|x) = \\frac{P(x|y)P(y)}{P(x)} $$</p> </li> <li> <p>\u5bf9\u4e8e\u751f\u6210\u4efb\u52a1\uff08\u65e0\u6807\u7b7e\uff09\uff1a $$    P(x) \\quad \\text{\u6216\u8005} \\quad P(x|z) \\text{\uff0c\u5176\u4e2d z \u662f\u6f5c\u53d8\u91cf} $$</p> </li> </ol> <p>\u76f4\u89c2\u7406\u89e3\uff1a</p> <p>\u751f\u6210\u6a21\u578b\u50cf\u4e00\u4e2a\u753b\u5bb6\uff0c\u4e0d\u4ec5\u80fd\u8bf4\u201c\u8fd9\u662f\u732b\u8fd8\u662f\u72d7\u201d\uff0c\u8fd8\u80fd \u753b\u51fa\u4e00\u53ea\u65b0\u7684\u732b\u6216\u72d7\u3002</p> \u7279\u6027 \u5224\u522b\u6a21\u578b \u751f\u6210\u6a21\u578b \u5b66\u4e60\u76ee\u6807 \u6761\u4ef6\u6982\u7387 (P(y x)) \u8054\u5408\u6982\u7387 (P(x, y)) \u6216 (P(x)) \u9884\u6d4b\u80fd\u529b \u5206\u7c7b\u3001\u56de\u5f52 \u751f\u6210\u3001\u5206\u7c7b \u6570\u636e\u5efa\u6a21 \u4e0d\u5173\u5fc3\u6570\u636e\u5206\u5e03 \u5b66\u4e60\u6570\u636e\u5206\u5e03 \u4f18\u52bf \u8fb9\u754c\u6e05\u6670\uff0c\u5206\u7c7b\u7cbe\u5ea6\u9ad8 \u53ef\u4ee5\u751f\u6210\u65b0\u6837\u672c\uff0c\u9002\u5e94\u534a\u76d1\u7763\u5b66\u4e60 \u52a3\u52bf \u4e0d\u80fd\u751f\u6210\u6837\u672c \u5206\u7c7b\u7cbe\u5ea6\u53ef\u80fd\u4f4e\u4e8e\u5224\u522b\u6a21\u578b \u793a\u4f8b Logistic Regression, SVM, DNN \u5206\u7c7b\u5668 Naive Bayes, GMM, HMM, VAE, GAN, GPT"},{"location":"machine/interview/#15","title":"1.5 \u6a21\u578b\u8bad\u7ec3\u6d41\u7a0b","text":"<p>\u673a\u5668\u5b66\u4e60\u6a21\u578b\u8bad\u7ec3\u53ef\u4ee5\u62bd\u8c61\u4e3a \u4e00\u4e2a\u8fed\u4ee3\u4f18\u5316\u8fc7\u7a0b\uff0c\u5927\u81f4\u6d41\u7a0b\u5982\u4e0b\uff1a</p> <ol> <li>\u660e\u786e\u95ee\u9898\u4e0e\u76ee\u6807</li> <li>\u6536\u96c6\u6570\u636e</li> <li>\u6570\u636e\u9884\u5904\u7406\u4e0e\u7279\u5f81\u5de5\u7a0b</li> <li>\u9009\u62e9\u6a21\u578b</li> <li>\u5b9a\u4e49\u635f\u5931\u51fd\u6570\u548c\u4f18\u5316\u5668</li> <li>\u8bad\u7ec3\u6a21\u578b\uff08\u6a21\u578b\u62df\u5408\uff09</li> <li>\u6a21\u578b\u8bc4\u4f30\u4e0e\u8c03\u53c2</li> <li>\u6a21\u578b\u90e8\u7f72\u4e0e\u76d1\u63a7</li> </ol>"},{"location":"machine/interview/#1","title":"1\ufe0f\u20e3 \u660e\u786e\u95ee\u9898\u4e0e\u76ee\u6807","text":"<ul> <li> <p>\u4efb\u52a1\u7c7b\u578b\uff1a</p> <ul> <li>\u5206\u7c7b\uff08Classification\uff09\uff1a\u9884\u6d4b\u7c7b\u522b \\((y \\in {0,1,...,K})\\)</li> <li>\u56de\u5f52\uff08Regression\uff09\uff1a\u9884\u6d4b\u8fde\u7eed\u503c \\((y \\in \\mathbb{R})\\)</li> <li>\u6392\u5e8f/\u63a8\u8350\u3001\u805a\u7c7b\u3001\u751f\u6210\u7b49</li> </ul> </li> <li> <p>\u76ee\u6807\u6307\u6807\uff1a</p> <ul> <li>\u5206\u7c7b\uff1a\u51c6\u786e\u7387\uff08Accuracy\uff09\u3001F1\u3001ROC-AUC</li> <li>\u56de\u5f52\uff1aMSE\u3001MAE\u3001R\u00b2</li> </ul> </li> <li> <p>\u7ea6\u675f\u6761\u4ef6\uff1a</p> <ul> <li>\u8bad\u7ec3\u65f6\u95f4\u3001\u6a21\u578b\u5927\u5c0f\u3001\u53ef\u89e3\u91ca\u6027\u7b49</li> </ul> </li> </ul> <p>\ud83d\udd39 \u5c0f\u8d34\u58eb\uff1a\u95ee\u9898\u5b9a\u4e49\u76f4\u63a5\u51b3\u5b9a\u540e\u7eed\u6570\u636e\u6536\u96c6\u3001\u6a21\u578b\u9009\u62e9\u548c\u8bc4\u4f30\u65b9\u6cd5\u3002</p>"},{"location":"machine/interview/#2","title":"2\ufe0f\u20e3 \u6570\u636e\u6536\u96c6","text":"<ul> <li>\u6570\u636e\u662f ML \u7684\u6838\u5fc3\uff0c\u8d28\u91cf\u51b3\u5b9a\u6a21\u578b\u4e0a\u9650</li> <li> <p>\u6765\u6e90\uff1a</p> <ul> <li>\u516c\u5f00\u6570\u636e\u96c6\uff08Kaggle\u3001UCI\uff09</li> <li>\u4f01\u4e1a\u4e1a\u52a1\u6570\u636e\uff08\u6570\u636e\u5e93\u3001\u65e5\u5fd7\uff09</li> <li>\u4f20\u611f\u5668\u6216\u722c\u866b\u91c7\u96c6</li> </ul> </li> <li> <p>\u6ce8\u610f\uff1a</p> <ul> <li>\u6570\u636e\u91cf\u662f\u5426\u8db3\u591f</li> <li>\u6807\u7b7e\u662f\u5426\u51c6\u786e\uff08\u76d1\u7763\u5b66\u4e60\uff09</li> </ul> </li> </ul>"},{"location":"machine/interview/#3","title":"3\ufe0f\u20e3 \u6570\u636e\u9884\u5904\u7406\u4e0e\u7279\u5f81\u5de5\u7a0b","text":""},{"location":"machine/interview/#_5","title":"\u6570\u636e\u6e05\u6d17\uff1a","text":"<ul> <li>\u7f3a\u5931\u503c\u5904\u7406\uff1a\u586b\u5145\u3001\u5220\u9664\u6216\u6807\u8bb0</li> <li>\u5f02\u5e38\u503c\u5904\u7406\uff1a\u53bb\u9664\u6216\u4fee\u6b63</li> <li>\u6570\u636e\u7c7b\u578b\u8f6c\u6362</li> </ul>"},{"location":"machine/interview/#_6","title":"\u7279\u5f81\u5904\u7406\uff1a","text":"<ul> <li>\u6570\u503c\u5f52\u4e00\u5316/\u6807\u51c6\u5316</li> <li>\u7c7b\u522b\u53d8\u91cf\u7f16\u7801\uff08One-hot\u3001Label Encoding\uff09</li> <li>\u7279\u5f81\u7ec4\u5408\u6216\u964d\u7ef4\uff08PCA\u3001SVD\uff09</li> </ul>"},{"location":"machine/interview/#_7","title":"\u7279\u5f81\u9009\u62e9\uff1a","text":"<ul> <li>\u76f8\u5173\u6027\u5206\u6790\u3001\u65b9\u5dee\u9009\u62e9\u3001\u6811\u6a21\u578b\u7279\u5f81\u91cd\u8981\u6027</li> <li>\u907f\u514d\u9ad8\u7ef4\u7a00\u758f\u6216\u566a\u58f0\u7279\u5f81</li> </ul> <p>\ud83d\udd39 \u5c0f\u8d34\u58eb\uff1a\u597d\u7684\u7279\u5f81\u6bd4\u590d\u6742\u6a21\u578b\u66f4\u91cd\u8981\u3002</p>"},{"location":"machine/interview/#4","title":"4\ufe0f\u20e3 \u9009\u62e9\u6a21\u578b","text":"<p>\u6839\u636e\u95ee\u9898\u7c7b\u578b\u548c\u6570\u636e\u7279\u6027\u9009\u62e9\u5408\u9002\u7684\u7b97\u6cd5\uff1a</p> \u95ee\u9898\u7c7b\u578b \u7ecf\u5178\u7b97\u6cd5 \u6df1\u5ea6\u5b66\u4e60\u7b97\u6cd5 \u5206\u7c7b \u903b\u8f91\u56de\u5f52\u3001SVM\u3001\u51b3\u7b56\u6811\u3001\u968f\u673a\u68ee\u6797 MLP\u3001CNN\u3001Transformer \u56de\u5f52 \u7ebf\u6027\u56de\u5f52\u3001\u5cad\u56de\u5f52\u3001\u6811\u56de\u5f52 MLP\u3001LSTM \u805a\u7c7b K-Means\u3001GMM \u81ea\u7f16\u7801\u5668 + \u805a\u7c7b \u751f\u6210 Naive Bayes\u3001GMM GAN\u3001VAE\u3001Diffusion Model"},{"location":"machine/interview/#5","title":"5\ufe0f\u20e3 \u5b9a\u4e49\u635f\u5931\u51fd\u6570\u4e0e\u4f18\u5316\u5668","text":""},{"location":"machine/interview/#loss-function","title":"\u635f\u5931\u51fd\u6570\uff08Loss Function\uff09\uff1a","text":"<ul> <li>\u5206\u7c7b\uff1a\u4ea4\u53c9\u71b5\u635f\u5931 $$   \\mathcal{L} = - \\sum_i y_i \\log \\hat{y}_i $$</li> <li>\u56de\u5f52\uff1a\u5747\u65b9\u8bef\u5dee\uff08MSE\uff09 $$   \\mathcal{L} = \\frac{1}{n}\\sum_i (\\hat{y}_i - y_i)^2 $$</li> </ul>"},{"location":"machine/interview/#optimizer","title":"\u4f18\u5316\u5668\uff08Optimizer\uff09\uff1a","text":"<ul> <li>\u901a\u8fc7\u68af\u5ea6\u4e0b\u964d\u4f18\u5316\u6a21\u578b\u53c2\u6570 (\\theta)</li> <li> <p>\u5e38\u7528\uff1a</p> <ul> <li>SGD\u3001Momentum\u3001Adam\u3001RMSProp</li> </ul> </li> </ul>"},{"location":"machine/interview/#_8","title":"\u6570\u5b66\u672c\u8d28\uff1a","text":"<ul> <li>\u627e\u5230\u6700\u4f18\u53c2\u6570 (\\theta^*)\uff1a</li> </ul> \\[   \\theta^* = \\arg\\min_\\theta \\mathcal{L}(\\theta) \\]"},{"location":"machine/interview/#6","title":"6\ufe0f\u20e3 \u6a21\u578b\u8bad\u7ec3\uff08\u62df\u5408\uff09","text":"<ul> <li>\u5c06\u8bad\u7ec3\u6570\u636e\u8f93\u5165\u6a21\u578b</li> <li>\u8ba1\u7b97\u9884\u6d4b\u503c (\\hat{y})</li> <li>\u6839\u636e\u635f\u5931\u51fd\u6570\u8ba1\u7b97\u68af\u5ea6</li> <li>\u66f4\u65b0\u53c2\u6570\uff08\u68af\u5ea6\u4e0b\u964d\uff09</li> <li>\u8fed\u4ee3\u591a\u6b21\uff08epoch\uff09\uff0c\u76f4\u5230\u6536\u655b\u6216\u8fbe\u5230\u6307\u5b9a\u8f6e\u6570</li> </ul> <p>\ud83d\udca1 \u6ce8\u610f\uff1a</p> <ul> <li>\u6279\u91cf\u8bad\u7ec3\uff08Batch\uff09 vs \u968f\u673a\u68af\u5ea6\u4e0b\u964d\uff08SGD\uff09</li> <li> <p>\u9632\u6b62\u8fc7\u62df\u5408\uff1a</p> <ul> <li>\u6b63\u5219\u5316\uff08L1\u3001L2\uff09</li> <li>Dropout\uff08\u6df1\u5ea6\u5b66\u4e60\uff09</li> <li>\u63d0\u524d\u505c\u6b62\uff08Early Stopping\uff09</li> </ul> </li> </ul>"},{"location":"machine/interview/#7","title":"7\ufe0f\u20e3 \u6a21\u578b\u8bc4\u4f30\u4e0e\u8c03\u53c2","text":""},{"location":"machine/interview/#_9","title":"\u8bc4\u4f30\u65b9\u6cd5\uff1a","text":"<ul> <li> <p>\u62c6\u5206\u6570\u636e\u96c6\uff1a</p> <ul> <li>\u8bad\u7ec3\u96c6 / \u9a8c\u8bc1\u96c6 / \u6d4b\u8bd5\u96c6</li> </ul> </li> <li> <p>\u4ea4\u53c9\u9a8c\u8bc1\uff08K-Fold CV\uff09</p> </li> <li> <p>\u6307\u6807\u9009\u62e9\uff1a</p> <ul> <li>\u5206\u7c7b\uff1aAccuracy\u3001Precision\u3001Recall\u3001F1</li> <li>\u56de\u5f52\uff1aMSE\u3001MAE\u3001R\u00b2</li> </ul> </li> </ul>"},{"location":"machine/interview/#_10","title":"\u8d85\u53c2\u6570\u8c03\u4f18\uff1a","text":"<ul> <li>\u7f51\u683c\u641c\u7d22\uff08Grid Search\uff09</li> <li>\u968f\u673a\u641c\u7d22\uff08Random Search\uff09</li> <li>\u8d1d\u53f6\u65af\u4f18\u5316</li> <li>AutoML \u5de5\u5177</li> </ul> <p>\ud83d\udd39 \u5c0f\u8d34\u58eb\uff1a\u4e0d\u8981\u5728\u6d4b\u8bd5\u96c6\u4e0a\u8c03\u53c2\uff0c\u53ea\u5728\u9a8c\u8bc1\u96c6\u4e0a\u4f18\u5316\u6a21\u578b\u3002</p>"},{"location":"machine/interview/#8","title":"8\ufe0f\u20e3 \u6a21\u578b\u90e8\u7f72\u4e0e\u76d1\u63a7","text":"<ul> <li> <p>\u90e8\u7f72\u65b9\u5f0f\uff1a</p> <ul> <li>\u672c\u5730\u670d\u52a1\uff08Flask/FastAPI\uff09</li> <li>\u4e91\u670d\u52a1\uff08AWS Sagemaker, Azure ML\uff09</li> </ul> </li> <li> <p>\u6a21\u578b\u76d1\u63a7\uff1a</p> <ul> <li>\u7cbe\u5ea6\u968f\u65f6\u95f4\u4e0b\u964d\uff08\u6982\u5ff5\u6f02\u79fb\uff09</li> <li>\u8f93\u5165\u5206\u5e03\u53d8\u5316</li> </ul> </li> <li> <p>\u5b9a\u671f\u66f4\u65b0\u6a21\u578b\uff0c\u4fdd\u6301\u6027\u80fd</p> </li> </ul> <pre><code>\u95ee\u9898\u5b9a\u4e49 \u2192 \u6570\u636e\u6536\u96c6 \u2192 \u6570\u636e\u6e05\u6d17/\u7279\u5f81\u5de5\u7a0b \u2192 \u6a21\u578b\u9009\u62e9 \u2192 \u635f\u5931\u51fd\u6570+\u4f18\u5316\u5668\n\u2192 \u8bad\u7ec3\u6a21\u578b \u2192 \u6a21\u578b\u8bc4\u4f30\u4e0e\u8c03\u53c2 \u2192 \u90e8\u7f72\u4e0e\u76d1\u63a7\n</code></pre>"},{"location":"machine/interview/#_11","title":"\u4e8c\u3001\u6570\u636e\u9884\u5904\u7406","text":""},{"location":"machine/interview/#21","title":"2.1 \u6570\u636e\u6e05\u6d17","text":""},{"location":"machine/interview/#_12","title":"\u7f3a\u5931\u503c\u5904\u7406\uff1a\u5220\u9664\u3001\u586b\u5145\uff08\u5747\u503c\u3001\u4e2d\u4f4d\u6570\u3001\u4f17\u6570\uff09\u3001\u63d2\u503c\u6cd5\u7b49","text":"<p>\u5728\u5b9e\u9645\u6570\u636e\u4e2d\uff0c\u7ecf\u5e38\u4f1a\u9047\u5230 \u90e8\u5206\u6570\u636e\u7f3a\u5931 \u7684\u60c5\u51b5\uff0c\u4f8b\u5982\uff1a</p> \u59d3\u540d \u5e74\u9f84 \u5de5\u8d44 \u5f20\u4e09 25 5000 \u674e\u56db NaN 6000 \u738b\u4e94 30 NaN <p>\u8fd9\u91cc\u7684 <code>NaN</code> \u5c31\u8868\u793a\u7f3a\u5931\u503c\uff08Not a Number\uff09\u3002</p> <p>\u7f3a\u5931\u503c\u4f1a\u5bfc\u81f4\uff1a</p> <ul> <li>\u7edf\u8ba1\u6307\u6807\u504f\u5dee\uff08\u5747\u503c\u3001\u65b9\u5dee\u4e0d\u51c6\u786e\uff09</li> <li>\u673a\u5668\u5b66\u4e60\u6a21\u578b\u62a5\u9519\u6216\u6027\u80fd\u4e0b\u964d</li> </ul> <p>\u6240\u4ee5\u9700\u8981 \u5408\u7406\u5904\u7406\u7f3a\u5931\u503c\u3002</p> <p>\u5148\u5206\u6790\u7f3a\u5931\u60c5\u51b5\uff1a</p> <pre><code>df.isna().sum()\ndf.isna().mean()  # \u7f3a\u5931\u6bd4\u4f8b\n</code></pre>"},{"location":"machine/interview/#1-deletion","title":"1\ufe0f\u20e3 \u5220\u9664\u6cd5\uff08Deletion\uff09","text":"<p>\u601d\u8def\uff1a\u76f4\u63a5\u5220\u9664\u7f3a\u5931\u503c\u6240\u5728\u7684\u884c\u6216\u5217\u3002</p> <ul> <li> <p>\u5220\u9664\u884c\uff08Row-wise deletion\uff09</p> <ul> <li>\u65b9\u6cd5\uff1a<code>dropna(axis=0)</code></li> <li>\u9002\u7528\u573a\u666f\uff1a\u7f3a\u5931\u503c\u8f83\u5c11\uff0c\u5220\u9664\u4e0d\u4f1a\u4e22\u5931\u592a\u591a\u4fe1\u606f</li> <li>\u7f3a\u70b9\uff1a\u4e22\u5931\u4fe1\u606f\uff0c\u5982\u679c\u7f3a\u5931\u503c\u5f88\u591a\uff0c\u4f1a\u5bfc\u81f4\u6570\u636e\u91cf\u4e25\u91cd\u4e0d\u8db3</li> </ul> </li> <li> <p>\u5220\u9664\u5217\uff08Column-wise deletion\uff09</p> <ul> <li>\u65b9\u6cd5\uff1a<code>dropna(axis=1)</code></li> <li>\u9002\u7528\u573a\u666f\uff1a\u67d0\u5217\u7f3a\u5931\u503c\u8fc7\u591a\u4e14\u4e0d\u91cd\u8981</li> <li>\u7f3a\u70b9\uff1a\u53ef\u80fd\u4e22\u5931\u6709\u4ef7\u503c\u7279\u5f81</li> </ul> </li> </ul> <p>\u793a\u4f8b\uff08Pandas\uff09\uff1a</p> <pre><code>import pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame({\n    '\u59d3\u540d': ['\u5f20\u4e09','\u674e\u56db','\u738b\u4e94'],\n    '\u5e74\u9f84': [25, np.nan, 30],\n    '\u5de5\u8d44': [5000, 6000, np.nan]\n})\n\n# \u5220\u9664\u542b\u6709\u7f3a\u5931\u503c\u7684\u884c\ndf.dropna(axis=0, inplace=True)\n\n# \u5220\u9664\u542b\u6709\u7f3a\u5931\u503c\u7684\u5217\ndf.dropna(axis=1, inplace=True)\n</code></pre>"},{"location":"machine/interview/#2-imputation","title":"2\ufe0f\u20e3 \u586b\u5145\u6cd5\uff08Imputation\uff09","text":"<p>\u601d\u8def\uff1a\u7528\u67d0\u4e2a\u5408\u7406\u7684\u503c\u4ee3\u66ff\u7f3a\u5931\u503c\u3002</p>"},{"location":"machine/interview/#21-mean-imputation","title":"2.1 \u5747\u503c\u586b\u5145\uff08Mean Imputation\uff09","text":"<ul> <li>\u5c06\u7f3a\u5931\u503c\u7528\u8be5\u5217\u7684\u5e73\u5747\u503c\u586b\u5145</li> <li>\u9002\u5408\u8fde\u7eed\u578b\u6570\u636e</li> <li>\u4f18\u70b9\uff1a\u7b80\u5355\uff0c\u6613\u5b9e\u73b0</li> <li>\u7f3a\u70b9\uff1a\u4f1a\u964d\u4f4e\u6570\u636e\u65b9\u5dee\uff0c\u53ef\u80fd\u5f71\u54cd\u6a21\u578b</li> </ul> <pre><code>df['\u5e74\u9f84'].fillna(df['\u5e74\u9f84'].mean(), inplace=True)\n</code></pre>"},{"location":"machine/interview/#22-median-imputation","title":"2.2 \u4e2d\u4f4d\u6570\u586b\u5145\uff08Median Imputation\uff09","text":"<ul> <li>\u5c06\u7f3a\u5931\u503c\u7528\u8be5\u5217\u7684\u4e2d\u4f4d\u6570\u586b\u5145</li> <li>\u9002\u5408\u6709\u5f02\u5e38\u503c\u7684\u8fde\u7eed\u578b\u6570\u636e</li> <li>\u4f18\u70b9\uff1a\u4e0d\u53d7\u6781\u7aef\u503c\u5f71\u54cd</li> </ul> <pre><code>df['\u5e74\u9f84'].fillna(df['\u5e74\u9f84'].median(), inplace=True)\n</code></pre>"},{"location":"machine/interview/#23-mode-imputation","title":"2.3 \u4f17\u6570\u586b\u5145\uff08Mode Imputation\uff09","text":"<ul> <li>\u5c06\u7f3a\u5931\u503c\u7528\u8be5\u5217\u6700\u5e38\u51fa\u73b0\u7684\u503c\u586b\u5145</li> <li>\u9002\u5408\u7c7b\u522b\u578b\u6570\u636e</li> <li>\u4f18\u70b9\uff1a\u4fdd\u7559\u7c7b\u522b\u7279\u5f81\u5206\u5e03</li> </ul> <pre><code>df['\u6027\u522b'].fillna(df['\u6027\u522b'].mode()[0], inplace=True)\n</code></pre>"},{"location":"machine/interview/#24-constant-imputation","title":"2.4 \u56fa\u5b9a\u503c\u586b\u5145\uff08Constant Imputation\uff09","text":"<ul> <li>\u7528\u56fa\u5b9a\u503c\u586b\u5145\uff0c\u4f8b\u5982 0\u3001-1\u3001\"\u672a\u77e5\"</li> <li>\u9002\u5408\u7f3a\u5931\u672c\u8eab\u6709\u542b\u4e49\u7684\u60c5\u51b5</li> </ul> <pre><code>df['\u5de5\u8d44'].fillna(0, inplace=True)\n</code></pre>"},{"location":"machine/interview/#3-interpolation","title":"3\ufe0f\u20e3 \u63d2\u503c\u6cd5\uff08Interpolation\uff09","text":"<p>\u601d\u8def\uff1a\u5229\u7528\u5df2\u6709\u6570\u636e\u7684\u8d8b\u52bf\u6216\u6a21\u5f0f\u6765\u9884\u6d4b\u7f3a\u5931\u503c</p> <ul> <li>\u9002\u5408\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u6216\u8fde\u7eed\u6570\u636e</li> <li> <p>\u5e38\u89c1\u65b9\u6cd5\uff1a</p> <ul> <li>\u7ebf\u6027\u63d2\u503c\uff08Linear\uff09</li> <li>\u591a\u9879\u5f0f\u63d2\u503c\uff08Polynomial\uff09</li> <li>\u65f6\u95f4\u5e8f\u5217\u63d2\u503c\uff08Time\uff09</li> </ul> </li> </ul> <pre><code>df['\u5de5\u8d44'] = df['\u5de5\u8d44'].interpolate(method='linear')\n</code></pre> <ul> <li>\u4f18\u70b9\uff1a\u4fdd\u7559\u6570\u636e\u8d8b\u52bf\uff0c\u9002\u5408\u8fde\u7eed\u578b\u548c\u65f6\u95f4\u5e8f\u5217</li> <li>\u7f3a\u70b9\uff1a\u4e0d\u9002\u5408\u7c7b\u522b\u578b\u6570\u636e\uff1b\u53ef\u80fd\u5f15\u5165\u504f\u5dee</li> </ul>"},{"location":"machine/interview/#4_1","title":"4\ufe0f\u20e3 \u9ad8\u7ea7\u586b\u5145\u65b9\u6cd5","text":"<ul> <li>KNN \u586b\u5145\uff1a\u7528\u76f8\u4f3c\u6837\u672c\u7684\u5e73\u5747\u503c\u586b\u5145</li> <li>\u56de\u5f52\u586b\u5145\uff1a\u7528\u5176\u4ed6\u7279\u5f81\u9884\u6d4b\u7f3a\u5931\u503c</li> <li>\u591a\u91cd\u63d2\u8865\uff08MICE\uff09\uff1a\u7528\u591a\u6b21\u9884\u6d4b\u586b\u5145\uff0c\u4fdd\u7559\u6570\u636e\u5206\u5e03</li> </ul> <p>\u8fd9\u4e9b\u65b9\u6cd5\u53ef\u4ee5\u63d0\u9ad8\u9884\u6d4b\u7cbe\u5ea6\uff0c\u4f46\u8ba1\u7b97\u590d\u6742\u5ea6\u66f4\u9ad8\u3002</p> <p>\u7f3a\u5931\u503c\u5904\u7406\u9009\u62e9\u6307\u5357</p> \u65b9\u6cd5 \u9002\u7528\u573a\u666f \u4f18\u70b9 \u7f3a\u70b9 \u5220\u9664 \u7f3a\u5931\u503c\u5c11\u3001\u6570\u636e\u91cf\u5927 \u7b80\u5355 \u4e22\u5931\u4fe1\u606f\u3001\u53ef\u80fd\u5f15\u5165\u504f\u5dee \u5747\u503c/\u4e2d\u4f4d\u6570 \u8fde\u7eed\u578b\u7279\u5f81 \u7b80\u5355\u3001\u6613\u5b9e\u73b0 \u65b9\u5dee\u964d\u4f4e\u3001\u53ef\u80fd\u5f15\u5165\u504f\u5dee \u4f17\u6570 \u7c7b\u522b\u578b\u7279\u5f81 \u4fdd\u7559\u7c7b\u522b\u5206\u5e03 \u65e0\u6cd5\u5904\u7406\u8fde\u7eed\u578b \u63d2\u503c \u65f6\u95f4\u5e8f\u5217\u3001\u8fde\u7eed\u578b\u6570\u636e \u4fdd\u7559\u8d8b\u52bf \u4e0d\u9002\u5408\u7c7b\u522b\u578b\u6570\u636e \u9ad8\u7ea7\u65b9\u6cd5 \u5bf9\u7cbe\u5ea6\u8981\u6c42\u9ad8\u3001\u7f3a\u5931\u6a21\u5f0f\u590d\u6742 \u66f4\u5408\u7406\u3001\u4fdd\u7559\u6570\u636e\u5206\u5e03 \u8ba1\u7b97\u590d\u6742\u3001\u5b9e\u73b0\u590d\u6742"},{"location":"machine/interview/#_13","title":"\u5f02\u5e38\u503c\u5904\u7406\uff1a\u5220\u9664\u3001\u89c6\u4e3a\u7f3a\u5931\u503c\u3001\u4fee\u6b63\u6216\u4fdd\u7559\uff08\u6839\u636e\u4e1a\u52a1\u903b\u8f91\uff09","text":"<p>\u5f02\u5e38\u503c\uff08Outlier\uff09 \u662f\u6307\u5728\u6570\u636e\u96c6\u4e2d \u663e\u8457\u504f\u79bb\u5176\u4ed6\u89c2\u6d4b\u503c\u7684\u6570\u636e\u70b9\u3002</p> <ul> <li>\u4f8b\u5b50\uff1a\u5de5\u8d44\u4e3a 10 \u4e07\u5143\uff0c\u800c\u5927\u591a\u6570\u5458\u5de5\u5de5\u8d44\u5728 3-5 \u5343\u5143\u4e4b\u95f4\u3002</li> <li> <p>\u5f02\u5e38\u503c\u53ef\u80fd\u6765\u6e90\uff1a</p> <ul> <li>\u6570\u636e\u5f55\u5165\u9519\u8bef</li> <li>\u4eea\u5668\u6d4b\u91cf\u9519\u8bef</li> <li>\u771f\u5b9e\u7684\u6781\u7aef\u503c\uff08\u7f55\u89c1\u4e8b\u4ef6\uff09</li> </ul> </li> </ul> <p>\u5f02\u5e38\u503c\u5982\u679c\u4e0d\u5904\u7406\uff0c\u53ef\u80fd\u5bfc\u81f4\u7edf\u8ba1\u6307\u6807\u5931\u771f\u6216\u6a21\u578b\u6027\u80fd\u4e0b\u964d\u3002</p> <p>\u5148\u68c0\u6d4b\uff0c\u518d\u5904\u7406\uff1a</p> <pre><code>df.describe()\ndf.boxplot()\n</code></pre>"},{"location":"machine/interview/#_14","title":"\u68c0\u6d4b\u5f02\u5e38\u503c\u7684\u65b9\u6cd5","text":""},{"location":"machine/interview/#1_1","title":"1\ufe0f\u20e3 \u57fa\u4e8e\u7edf\u8ba1\u91cf","text":"<ul> <li>\u6807\u51c6\u5dee\u6cd5\uff1a $$   x \\text{ \u662f\u5f02\u5e38\u503c if } |x-\\bar{x}| &gt; k\\sigma $$   \u5e38\u7528 (k=3)</li> <li>IQR\u6cd5\uff08\u56db\u5206\u4f4d\u8ddd\uff09\uff1a $$   \\text{IQR} = Q_3 - Q_1 $$ $$   x \\text{ \u662f\u5f02\u5e38\u503c if } x &lt; Q_1 - 1.5 \\cdot IQR \\text{ \u6216 } x &gt; Q_3 + 1.5 \\cdot IQR $$</li> </ul>"},{"location":"machine/interview/#2_1","title":"2\ufe0f\u20e3 \u57fa\u4e8e\u6a21\u578b","text":"<ul> <li>Z-score</li> <li>Isolation Forest</li> <li>Local Outlier Factor (LOF)</li> </ul>"},{"location":"machine/interview/#_15","title":"\u5f02\u5e38\u503c\u5904\u7406\u65b9\u6cd5","text":""},{"location":"machine/interview/#1_2","title":"1\ufe0f\u20e3 \u5220\u9664\u6cd5","text":"<p>\u601d\u8def\uff1a\u76f4\u63a5\u5220\u9664\u5f02\u5e38\u503c\u5bf9\u5e94\u7684\u884c\u3002</p> <ul> <li> <p>\u4f18\u70b9\uff1a</p> <ul> <li>\u7b80\u5355\u3001\u5feb\u901f</li> <li>\u9002\u5408\u5f02\u5e38\u503c\u5f88\u5c11\u7684\u60c5\u51b5</li> </ul> </li> <li> <p>\u7f3a\u70b9\uff1a</p> <ul> <li>\u4e22\u5931\u4fe1\u606f</li> <li>\u4e0d\u9002\u5408\u5f02\u5e38\u503c\u53ef\u80fd\u6709\u5b9e\u9645\u610f\u4e49\u7684\u60c5\u51b5</li> </ul> </li> </ul> <p>Pandas \u793a\u4f8b\uff1a</p> <pre><code>import pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame({'\u5de5\u8d44':[5000,6000,7000,100000]})\nQ1 = df['\u5de5\u8d44'].quantile(0.25)\nQ3 = df['\u5de5\u8d44'].quantile(0.75)\nIQR = Q3 - Q1\ndf_clean = df[(df['\u5de5\u8d44'] &gt;= Q1 - 1.5*IQR) &amp; (df['\u5de5\u8d44'] &lt;= Q3 + 1.5*IQR)]\n</code></pre>"},{"location":"machine/interview/#2-nan","title":"2\ufe0f\u20e3 \u89c6\u4e3a\u7f3a\u5931\u503c\uff08NaN\uff09","text":"<p>\u601d\u8def\uff1a\u628a\u5f02\u5e38\u503c\u6807\u8bb0\u4e3a\u7f3a\u5931\u503c\uff0c\u518d\u7528\u7f3a\u5931\u503c\u5904\u7406\u65b9\u6cd5\u586b\u5145\u3002</p> <ul> <li> <p>\u4f18\u70b9\uff1a</p> <ul> <li>\u53ef\u4ee5\u7ed3\u5408\u5747\u503c/\u4e2d\u4f4d\u6570/\u63d2\u503c\u7b49\u65b9\u6cd5</li> <li>\u4fdd\u7559\u6570\u636e\u91cf</li> </ul> </li> <li> <p>\u7f3a\u70b9\uff1a</p> <ul> <li>\u586b\u5145\u503c\u53ef\u80fd\u4e0d\u51c6\u786e</li> <li>\u9700\u8981\u5408\u7406\u9009\u62e9\u586b\u5145\u503c</li> </ul> </li> </ul> <p>Pandas \u793a\u4f8b\uff1a</p> <pre><code>df.loc[(df['\u5de5\u8d44'] &gt; Q3 + 1.5*IQR), '\u5de5\u8d44'] = np.nan\ndf['\u5de5\u8d44'].fillna(df['\u5de5\u8d44'].median(), inplace=True)\n</code></pre>"},{"location":"machine/interview/#3-capping-winsorization","title":"3\ufe0f\u20e3 \u4fee\u6b63\u6cd5\uff08Capping \u6216 Winsorization\uff09","text":"<p>\u601d\u8def\uff1a\u628a\u5f02\u5e38\u503c\u66ff\u6362\u4e3a\u4e0a\u9650\u6216\u4e0b\u9650\u503c\u3002</p> <ul> <li> <p>\u4f18\u70b9\uff1a</p> <ul> <li>\u4fdd\u7559\u6570\u636e\u91cf</li> <li>\u51cf\u5c11\u5f02\u5e38\u503c\u5bf9\u6a21\u578b\u7684\u5f71\u54cd</li> </ul> </li> <li> <p>\u7f3a\u70b9\uff1a</p> <ul> <li>\u53ef\u80fd\u626d\u66f2\u6570\u636e\u5206\u5e03</li> </ul> </li> </ul> <p>Pandas \u793a\u4f8b\uff1a</p> <pre><code>lower_bound = Q1 - 1.5*IQR\nupper_bound = Q3 + 1.5*IQR\ndf['\u5de5\u8d44'] = df['\u5de5\u8d44'].clip(lower_bound, upper_bound)\n</code></pre>"},{"location":"machine/interview/#4_2","title":"4\ufe0f\u20e3 \u4fdd\u7559\u6cd5","text":"<p>\u601d\u8def\uff1a\u5bf9\u5f02\u5e38\u503c\u4e0d\u505a\u5904\u7406\uff0c\u76f4\u63a5\u4fdd\u7559</p> <ul> <li> <p>\u9002\u7528\u573a\u666f\uff1a</p> <ul> <li>\u5f02\u5e38\u503c\u662f \u771f\u5b9e\u7684\u6781\u7aef\u4e8b\u4ef6\uff0c\u5bf9\u4e1a\u52a1\u6709\u610f\u4e49</li> <li>\u5982\u91d1\u878d\u98ce\u63a7\u4e2d\u7684\u6b3a\u8bc8\u4ea4\u6613</li> </ul> </li> <li> <p>\u4f18\u70b9\uff1a</p> <ul> <li>\u4fdd\u7559\u5b8c\u6574\u4fe1\u606f</li> </ul> </li> <li> <p>\u7f3a\u70b9\uff1a</p> <ul> <li>\u53ef\u80fd\u5f71\u54cd\u6a21\u578b\u8bad\u7ec3\u548c\u7edf\u8ba1\u6307\u6807</li> </ul> </li> </ul> \u65b9\u6cd5 \u9002\u7528\u573a\u666f \u4f18\u70b9 \u7f3a\u70b9 \u5220\u9664 \u5f02\u5e38\u503c\u5c11\uff0c\u53ef\u80fd\u662f\u9519\u8bef\u6570\u636e \u7b80\u5355\u5feb\u901f \u4e22\u5931\u4fe1\u606f \u89c6\u4e3a\u7f3a\u5931\u503c \u5f02\u5e38\u503c\u53ef\u7528\u586b\u5145\u66ff\u4ee3 \u53ef\u7ed3\u5408\u7f3a\u5931\u503c\u5904\u7406\u65b9\u6cd5 \u586b\u5145\u503c\u53ef\u80fd\u4e0d\u51c6\u786e \u4fee\u6b63\uff08Capping\uff09 \u5f02\u5e38\u503c\u5bf9\u6a21\u578b\u5f71\u54cd\u5927\uff0c\u4f46\u6570\u636e\u91cf\u4e0d\u80fd\u4e22 \u4fdd\u7559\u6570\u636e\u91cf\uff0c\u51cf\u5c11\u5f71\u54cd \u53ef\u80fd\u6539\u53d8\u5206\u5e03 \u4fdd\u7559 \u5f02\u5e38\u503c\u662f\u771f\u5b9e\u6709\u6548\u4e8b\u4ef6 \u4fdd\u7559\u4fe1\u606f \u53ef\u80fd\u5f71\u54cd\u6a21\u578b"},{"location":"machine/interview/#_16","title":"\u91cd\u590d\u6570\u636e\u5904\u7406\uff1a\u8bc6\u522b\u5e76\u5220\u9664\u5b8c\u5168\u91cd\u590d\u7684\u6837\u672c","text":"<p>\u91cd\u590d\u6570\u636e \u662f\u6307\u5728\u6570\u636e\u96c6\u4e2d \u5b8c\u5168\u76f8\u540c\u6216\u90e8\u5206\u5b57\u6bb5\u76f8\u540c\u7684\u6837\u672c\u884c\u3002 \u4f8b\u5982\uff1a</p> \u59d3\u540d \u5e74\u9f84 \u57ce\u5e02 \u5f20\u4e09 25 \u5317\u4eac \u5f20\u4e09 25 \u5317\u4eac \u2190 \u91cd\u590d\u884c \u674e\u56db 30 \u4e0a\u6d77 <p>\u91cd\u590d\u6570\u636e\u53ef\u80fd\u6765\u6e90\uff1a</p> <ul> <li>\u6570\u636e\u591a\u6b21\u5bfc\u5165</li> <li>\u91c7\u96c6\u7cfb\u7edf\u9519\u8bef</li> <li>\u6570\u636e\u5408\u5e76\uff08merge/concat\uff09\u65f6\u672a\u53bb\u91cd</li> </ul>"},{"location":"machine/interview/#_17","title":"\u91cd\u590d\u6570\u636e\u7684\u8bc6\u522b","text":"<p>\u5728 Pandas \u4e2d\u5e38\u7528\u65b9\u6cd5\u662f <code>duplicated()</code>\uff1a</p> <pre><code>import pandas as pd\n\ndf = pd.DataFrame({\n    '\u59d3\u540d': ['\u5f20\u4e09', '\u5f20\u4e09', '\u674e\u56db', '\u738b\u4e94', '\u674e\u56db'],\n    '\u5e74\u9f84': [25, 25, 30, 22, 30],\n    '\u57ce\u5e02': ['\u5317\u4eac', '\u5317\u4eac', '\u4e0a\u6d77', '\u5e7f\u5dde', '\u4e0a\u6d77']\n})\n\n# \u5224\u65ad\u662f\u5426\u91cd\u590d\uff08\u8fd4\u56de\u5e03\u5c14\u503c\uff09\nprint(df.duplicated())\n\n# \u67e5\u770b\u91cd\u590d\u7684\u6837\u672c\nprint(df[df.duplicated()])\n</code></pre> <p>\u8f93\u51fa\uff1a</p> <pre><code>0    False\n1     True\n2    False\n3    False\n4     True\ndtype: bool\n</code></pre>"},{"location":"machine/interview/#1_3","title":"1\ufe0f\u20e3 \u5220\u9664\u5b8c\u5168\u91cd\u590d\u7684\u884c","text":"<pre><code>df_clean = df.drop_duplicates()\n</code></pre> <p>\u9ed8\u8ba4\u6839\u636e\u6240\u6709\u5217\u53bb\u91cd\uff0c\u4ec5\u4fdd\u7559\u7b2c\u4e00\u6b21\u51fa\u73b0\u7684\u8bb0\u5f55\u3002</p>"},{"location":"machine/interview/#2_2","title":"2\ufe0f\u20e3 \u6307\u5b9a\u5217\u8fdb\u884c\u53bb\u91cd","text":"<p>\u6709\u65f6\u53ea\u60f3\u6839\u636e\u67d0\u51e0\u5217\u5224\u65ad\u662f\u5426\u91cd\u590d\uff0c\u6bd4\u5982 \u201c\u59d3\u540d + \u57ce\u5e02\u201d\uff1a</p> <pre><code>df_clean = df.drop_duplicates(subset=['\u59d3\u540d', '\u57ce\u5e02'])\n</code></pre>"},{"location":"machine/interview/#3_1","title":"3\ufe0f\u20e3 \u4fdd\u7559\u6700\u540e\u4e00\u6b21\u51fa\u73b0\u7684\u8bb0\u5f55","text":"<pre><code>df_clean = df.drop_duplicates(keep='last')\n</code></pre> <ul> <li><code>keep='first'</code>\uff08\u9ed8\u8ba4\uff09\uff1a\u4fdd\u7559\u7b2c\u4e00\u6b21\u51fa\u73b0\u7684\u8bb0\u5f55</li> <li><code>keep='last'</code>\uff1a\u4fdd\u7559\u6700\u540e\u4e00\u6b21\u51fa\u73b0\u7684\u8bb0\u5f55</li> <li><code>keep=False</code>\uff1a\u5220\u9664\u6240\u6709\u91cd\u590d\u9879</li> </ul>"},{"location":"machine/interview/#4_3","title":"4\ufe0f\u20e3 \u67e5\u770b\u91cd\u590d\u7684\u6570\u91cf","text":"<pre><code>duplicate_count = df.duplicated().sum()\nprint(f\"\u5171\u6709 {duplicate_count} \u6761\u91cd\u590d\u6837\u672c\")\n</code></pre> \u65b9\u6cd5 \u4ee3\u7801\u793a\u4f8b \u529f\u80fd \u68c0\u67e5\u91cd\u590d <code>df.duplicated()</code> \u8fd4\u56de\u5e03\u5c14Series \u67e5\u770b\u91cd\u590d\u884c <code>df[df.duplicated()]</code> \u663e\u793a\u6240\u6709\u91cd\u590d\u8bb0\u5f55 \u5220\u9664\u91cd\u590d <code>df.drop_duplicates()</code> \u5220\u9664\u91cd\u590d\u8bb0\u5f55 \u6307\u5b9a\u5217\u53bb\u91cd <code>df.drop_duplicates(subset=['\u5217\u540d'])</code> \u6309\u6307\u5b9a\u5217\u5224\u65ad\u91cd\u590d \u4fdd\u7559\u6700\u540e <code>keep='last'</code> \u4fdd\u7559\u6700\u540e\u4e00\u6761\u91cd\u590d\u8bb0\u5f55 \u5220\u9664\u6240\u6709\u91cd\u590d <code>keep=False</code> \u6240\u6709\u91cd\u590d\u7684\u90fd\u5220\u9664"},{"location":"machine/interview/#22","title":"2.2 \u6570\u636e\u8f6c\u6362","text":""},{"location":"machine/interview/#z-scoremin-max-scaling","title":"\u7279\u5f81\u7f29\u653e\uff1a\u6807\u51c6\u5316\uff08Z-score\uff09\u3001\u5f52\u4e00\u5316\uff08Min-Max Scaling\uff09\u7b49\uff0c\u6d88\u9664\u91cf\u7eb2\u5f71\u54cd","text":"<p>\u4e0d\u540c\u7279\u5f81\u5f80\u5f80\u5177\u6709 \u4e0d\u540c\u7684\u91cf\u7eb2\uff08\u5355\u4f4d\uff09\u548c\u53d6\u503c\u8303\u56f4\uff1a</p> \u7279\u5f81 \u542b\u4e49 \u53d6\u503c\u8303\u56f4 \u8eab\u9ad8 \u5355\u4f4d\uff1acm 150 ~ 190 \u4f53\u91cd \u5355\u4f4d\uff1akg 40 ~ 90 \u6536\u5165 \u5355\u4f4d\uff1a\u5143 3,000 ~ 30,000 <p>\ud83d\udc49 \u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff1a</p> <ul> <li>\u8ddd\u79bb\u5ea6\u91cf\u7c7b\u7b97\u6cd5\uff08\u5982 KNN\u3001K-Means\uff09\u4f1a\u88ab\u6570\u503c\u5927\u7684\u7279\u5f81\u4e3b\u5bfc\u3002</li> <li>\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\uff08\u5982\u7ebf\u6027\u56de\u5f52\u3001\u795e\u7ecf\u7f51\u7edc\uff09\u4f1a\u56e0\u4e0d\u540c\u7279\u5f81\u5c3a\u5ea6\u4e0d\u540c\u5bfc\u81f4\u6536\u655b\u7f13\u6162\u6216\u9707\u8361\u3002</li> </ul> <p>\u2705 \u901a\u8fc7\u7279\u5f81\u7f29\u653e\uff0c\u4f7f\u6240\u6709\u7279\u5f81\u5904\u4e8e\u76f8\u4f3c\u7684\u6570\u503c\u8303\u56f4\uff0c\u4ece\u800c\uff1a</p> <ul> <li>\u63d0\u9ad8\u6a21\u578b\u6536\u655b\u901f\u5ea6</li> <li>\u907f\u514d\u7279\u5f81\u201c\u4e3b\u5bfc\u6548\u5e94\u201d</li> <li>\u63d0\u9ad8\u8bad\u7ec3\u7a33\u5b9a\u6027</li> </ul>"},{"location":"machine/interview/#_18","title":"\ud83e\uddee \u5e38\u89c1\u7279\u5f81\u7f29\u653e\u65b9\u6cd5","text":""},{"location":"machine/interview/#1-standardization-z-score-normalization","title":"1\ufe0f\u20e3 \u6807\u51c6\u5316\uff08Standardization / Z-score Normalization\uff09","text":"<p>\u516c\u5f0f\uff1a $$ x' = \\frac{x - \\mu}{\\sigma} $$</p> <ul> <li>\\(\\mu\\)\uff1a\u5747\u503c\uff08mean\uff09</li> <li>\\(\\sigma\\)\uff1a\u6807\u51c6\u5dee\uff08standard deviation\uff09</li> </ul> <p>\ud83d\udc49 \u7f29\u653e\u540e\u6570\u636e\u670d\u4ece \u5747\u503c\u4e3a0\u3001\u6807\u51c6\u5dee\u4e3a1 \u7684\u5206\u5e03\u3002</p> <p>\u9002\u7528\u573a\u666f\uff1a</p> <ul> <li>\u6570\u636e\u8fd1\u4f3c\u7b26\u5408\u6b63\u6001\u5206\u5e03</li> <li>\u7ebf\u6027\u6a21\u578b\uff08Logistic Regression, SVM, PCA\uff09</li> <li>\u795e\u7ecf\u7f51\u7edc\u8f93\u5165\u5c42</li> </ul> <p>Python \u5b9e\u73b0\uff1a</p> <pre><code>from sklearn.preprocessing import StandardScaler\nimport pandas as pd\n\ndata = pd.DataFrame({\n    '\u8eab\u9ad8': [160, 170, 180],\n    '\u4f53\u91cd': [50, 65, 80]\n})\n\nscaler = StandardScaler()\nscaled = scaler.fit_transform(data)\n\nprint(pd.DataFrame(scaled, columns=data.columns))\n</code></pre> <p>\u8f93\u51fa\uff1a</p> \u8eab\u9ad8 \u4f53\u91cd -1.22 -1.22 0.00 0.00 1.22 1.22"},{"location":"machine/interview/#2-min-max-scaling","title":"2\ufe0f\u20e3 \u5f52\u4e00\u5316\uff08Min-Max Scaling\uff09","text":"<p>\u516c\u5f0f\uff1a $$ x' = \\frac{x - x_{\\min}}{x_{\\max} - x_{\\min}} $$</p> <ul> <li>\u5c06\u6570\u636e\u7f29\u653e\u81f3 <code>[0, 1]</code> \u6216\u81ea\u5b9a\u4e49\u533a\u95f4 <code>[a, b]</code>\u3002</li> </ul> <p>\u9002\u7528\u573a\u666f\uff1a</p> <ul> <li>\u6570\u636e\u6ca1\u6709\u660e\u663e\u7684\u6b63\u6001\u5206\u5e03</li> <li>\u795e\u7ecf\u7f51\u7edc\u8f93\u5165\u5c42\uff08\u5c24\u5176\u662f Sigmoid / Tanh\uff09</li> <li>\u9700\u8981\u56fa\u5b9a\u533a\u95f4\u7684\u7b97\u6cd5</li> </ul> <p>Python \u5b9e\u73b0\uff1a</p> <pre><code>from sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler(feature_range=(0, 1))\nscaled = scaler.fit_transform(data)\n\nprint(pd.DataFrame(scaled, columns=data.columns))\n</code></pre> <p>\u8f93\u51fa\uff1a</p> \u8eab\u9ad8 \u4f53\u91cd 0.0 0.0 0.5 0.5 1.0 1.0"},{"location":"machine/interview/#3-robust-scaling","title":"3\ufe0f\u20e3 \u7a33\u5065\u7f29\u653e\uff08Robust Scaling\uff09","text":"<p>\u516c\u5f0f\uff1a $$ x' = \\frac{x - \\text{Median}(x)}{IQR} $$ \u5176\u4e2d (IQR = Q3 - Q1)\uff08\u56db\u5206\u4f4d\u8ddd\uff09\u3002</p> <p>\u9002\u7528\u573a\u666f\uff1a</p> <ul> <li>\u6570\u636e\u4e2d\u5b58\u5728\u5f02\u5e38\u503c\uff08outliers\uff09</li> <li>\u5bf9\u5f02\u5e38\u503c\u4e0d\u654f\u611f\u7684\u6a21\u578b</li> </ul> <p>Python \u5b9e\u73b0\uff1a</p> <pre><code>from sklearn.preprocessing import RobustScaler\n\nscaler = RobustScaler()\nscaled = scaler.fit_transform(data)\nprint(pd.DataFrame(scaled, columns=data.columns))\n</code></pre>"},{"location":"machine/interview/#4-l2-normalization","title":"4\ufe0f\u20e3 \u5355\u4f4d\u5411\u91cf\u5316\uff08L2 Normalization\uff09","text":"<p>\u516c\u5f0f\uff1a $$ x' = \\frac{x}{|x|} $$ \u5c06\u6bcf\u4e2a\u6837\u672c\u7f29\u653e\u4e3a\u5355\u4f4d\u957f\u5ea6\uff08\u5373\u5411\u91cf\u957f\u5ea6\u4e3a1\uff09\u3002</p> <p>\u9002\u7528\u573a\u666f\uff1a</p> <ul> <li>\u6587\u672c\u5411\u91cf\uff08TF-IDF\u3001\u8bcd\u5d4c\u5165\uff09</li> <li>\u4f59\u5f26\u76f8\u4f3c\u5ea6\u5ea6\u91cf\u4efb\u52a1</li> </ul> <p>Python \u5b9e\u73b0\uff1a</p> <pre><code>from sklearn.preprocessing import Normalizer\n\nscaler = Normalizer(norm='l2')\nscaled = scaler.fit_transform(data)\nprint(pd.DataFrame(scaled, columns=data.columns))\n</code></pre> \u65b9\u6cd5 \u516c\u5f0f \u7ed3\u679c\u8303\u56f4 \u662f\u5426\u6297\u5f02\u5e38\u503c \u5178\u578b\u5e94\u7528 \u6807\u51c6\u5316 ((x - \u03bc)/\u03c3) \u65e0\u754c\uff08\u5747\u503c0\uff0c\u65b9\u5dee1\uff09 \u274c SVM, PCA, LR \u5f52\u4e00\u5316 ((x - min)/(max - min)) [0, 1] \u274c \u795e\u7ecf\u7f51\u7edc \u7a33\u5065\u7f29\u653e ((x - Median)/IQR) \u65e0\u754c \u2705 \u542b\u5f02\u5e38\u503c\u6570\u636e \u5355\u4f4d\u5411\u91cf\u5316 (x/\u2016x\u2016) \u5411\u91cf\u957f\u5ea6=1 \u2705 \u6587\u672c\u76f8\u4f3c\u5ea6"},{"location":"machine/interview/#one-hot-encoding","title":"\u7f16\u7801\u5206\u7c7b\u53d8\u91cf\uff1a\u72ec\u70ed\u7f16\u7801\uff08One-Hot Encoding\uff09\u3001\u6807\u7b7e\u7f16\u7801\u7b49\uff0c\u5c06\u7c7b\u522b\u6570\u636e\u8f6c\u4e3a\u6570\u503c\u6570\u636e","text":"<p>\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\uff08\u5c24\u5176\u662f\u7ebf\u6027\u6a21\u578b\u3001\u795e\u7ecf\u7f51\u7edc\uff09\u53ea\u80fd\u5904\u7406\u6570\u503c\u578b\u7279\u5f81\uff0c \u800c\u73b0\u5b9e\u6570\u636e\u5e38\u5305\u542b\u5927\u91cf\u7c7b\u522b\u7279\u5f81\uff08categorical features\uff09\uff0c\u4f8b\u5982\uff1a</p> \u6027\u522b \u57ce\u5e02 \u6559\u80b2\u6c34\u5e73 \u7537 \u5317\u4eac \u672c\u79d1 \u5973 \u4e0a\u6d77 \u7855\u58eb \u5973 \u5e7f\u5dde \u535a\u58eb <p>\ud83d\udc49 \u6a21\u578b\u65e0\u6cd5\u76f4\u63a5\u7406\u89e3\u201c\u5317\u4eac\u201d\u201c\u7855\u58eb\u201d\uff0c \u5fc5\u987b\u628a\u8fd9\u4e9b\u6587\u5b57\u8f6c\u4e3a\u6570\u503c\uff0c\u4e14\u8981\u907f\u514d\u5f15\u5165\u4eba\u4e3a\u7684\u5927\u5c0f\u5173\u7cfb\u3002</p>"},{"location":"machine/interview/#_19","title":"\ud83e\uddee \u5e38\u89c1\u7f16\u7801\u65b9\u6cd5","text":""},{"location":"machine/interview/#1-label-encoding","title":"1\ufe0f\u20e3 \u6807\u7b7e\u7f16\u7801\uff08Label Encoding\uff09","text":"<p>\u5c06\u6bcf\u4e2a\u7c7b\u522b\u6620\u5c04\u4e3a\u4e00\u4e2a\u6574\u6570\u6807\u7b7e\u3002</p> \u57ce\u5e02 \u7f16\u7801 \u5317\u4eac 0 \u4e0a\u6d77 1 \u5e7f\u5dde 2 <p>\u5b9e\u73b0\uff1a</p> <pre><code>from sklearn.preprocessing import LabelEncoder\nimport pandas as pd\n\ndf = pd.DataFrame({'\u57ce\u5e02': ['\u5317\u4eac', '\u4e0a\u6d77', '\u5e7f\u5dde', '\u5317\u4eac']})\n\nencoder = LabelEncoder()\ndf['\u57ce\u5e02_\u7f16\u7801'] = encoder.fit_transform(df['\u57ce\u5e02'])\n\nprint(df)\n</code></pre> <p>\u8f93\u51fa\uff1a</p> \u57ce\u5e02 \u57ce\u5e02_\u7f16\u7801 \u5317\u4eac 0 \u4e0a\u6d77 2 \u5e7f\u5dde 1 \u5317\u4eac 0 <p>\u2705 \u4f18\u70b9\uff1a</p> <ul> <li>\u7b80\u5355\u9ad8\u6548</li> <li>\u4e0d\u589e\u52a0\u7ef4\u5ea6</li> </ul> <p>\u26a0\ufe0f \u7f3a\u70b9\uff1a</p> <ul> <li>\u5f15\u5165\u4e86\u201c\u5927\u5c0f\u201d\u5173\u7cfb\uff080 &lt; 1 &lt; 2\uff09\uff0c   \u5bf9\u7ebf\u6027\u6a21\u578b\u6216\u8ddd\u79bb\u6a21\u578b\uff08\u5982 KNN\u3001SVM\uff09\u4f1a\u9020\u6210\u8bef\u5bfc\u3002</li> </ul> <p>\u9002\u7528\u573a\u666f\uff1a</p> <ul> <li>\u6811\u6a21\u578b\uff08\u5982\u51b3\u7b56\u6811\u3001\u968f\u673a\u68ee\u6797\u3001XGBoost\uff09   \u6811\u6a21\u578b\u53ea\u5173\u6ce8\u662f\u5426\u76f8\u7b49\uff0c\u4e0d\u53d7\u6570\u503c\u5927\u5c0f\u5f71\u54cd\u3002</li> </ul>"},{"location":"machine/interview/#2-one-hot-encoding","title":"2\ufe0f\u20e3 \u72ec\u70ed\u7f16\u7801\uff08One-Hot Encoding\uff09","text":"<p>\u5c06\u6bcf\u4e2a\u7c7b\u522b\u8f6c\u6362\u4e3a\u4e00\u4e2a\u201c0/1 \u5411\u91cf\u201d\uff0c \u6bcf\u4e2a\u4f4d\u7f6e\u4ee3\u8868\u4e00\u4e2a\u7c7b\u522b\u662f\u5426\u5b58\u5728\u3002</p> \u57ce\u5e02 \u5317\u4eac \u4e0a\u6d77 \u5e7f\u5dde \u5317\u4eac 1 0 0 \u4e0a\u6d77 0 1 0 \u5e7f\u5dde 0 0 1 <p>\u5b9e\u73b0\uff1a</p>"},{"location":"machine/interview/#1pandas-get_dummies","title":"\u2705 \u65b9\u6cd5 1\uff1aPandas \u81ea\u5e26 <code>get_dummies()</code>","text":"<pre><code>df = pd.DataFrame({'\u57ce\u5e02': ['\u5317\u4eac', '\u4e0a\u6d77', '\u5e7f\u5dde', '\u5317\u4eac']})\ndf_encoded = pd.get_dummies(df, columns=['\u57ce\u5e02'])\nprint(df_encoded)\n</code></pre> <p>\u8f93\u51fa\uff1a</p> \u57ce\u5e02_\u5317\u4eac \u57ce\u5e02_\u4e0a\u6d77 \u57ce\u5e02_\u5e7f\u5dde 1 0 0 0 1 0 0 0 1 1 0 0"},{"location":"machine/interview/#2scikit-learn-onehotencoder","title":"\u2705 \u65b9\u6cd5 2\uff1aScikit-Learn <code>OneHotEncoder</code>","text":"<pre><code>from sklearn.preprocessing import OneHotEncoder\n\nencoder = OneHotEncoder(sparse_output=False)\nencoded = encoder.fit_transform(df[['\u57ce\u5e02']])\n\nprint(pd.DataFrame(encoded, columns=encoder.get_feature_names_out(['\u57ce\u5e02'])))\n</code></pre> <p>\u2705 \u4f18\u70b9\uff1a</p> <ul> <li>\u4e0d\u5f15\u5165\u7c7b\u522b\u987a\u5e8f</li> <li>\u9002\u7528\u4e8e\u51e0\u4e4e\u6240\u6709\u673a\u5668\u5b66\u4e60\u7b97\u6cd5</li> </ul> <p>\u26a0\ufe0f \u7f3a\u70b9\uff1a</p> <ul> <li>\u7ef4\u5ea6\u7206\u70b8\uff08\u7c7b\u522b\u591a\u65f6\u4f1a\u4ea7\u751f\u5927\u91cf\u7279\u5f81\uff09</li> <li>\u7a00\u758f\u77e9\u9635\u5360\u7528\u5185\u5b58</li> </ul> <p>\u9002\u7528\u573a\u666f\uff1a</p> <ul> <li>\u7ebf\u6027\u6a21\u578b\uff08\u5982 Logistic Regression\uff09</li> <li>\u795e\u7ecf\u7f51\u7edc</li> <li>KNN\u3001SVM\u3001KMeans</li> </ul>"},{"location":"machine/interview/#3-binary-encoding","title":"3\ufe0f\u20e3 \u4e8c\u503c\u7f16\u7801\uff08Binary Encoding\uff09","text":"<p>\u6bcf\u4e2a\u7c7b\u522b\u5148\u6620\u5c04\u4e3a\u6574\u6570\uff0c\u518d\u8f6c\u4e3a\u4e8c\u8fdb\u5236\u4f4d\u3002</p> <p>\u4f8b\u5982\u6709 6 \u4e2a\u7c7b\u522b\uff1a</p> \u7c7b\u522b \u6574\u6570 \u4e8c\u8fdb\u5236 \u5206\u5217 A 1 001 0,0,1 B 2 010 0,1,0 C 3 011 0,1,1 <p>\u2705 \u4f18\u70b9\uff1a</p> <ul> <li>\u538b\u7f29\u7ef4\u5ea6\uff08\u6bd4\u72ec\u70ed\u7f16\u7801\u5c0f\uff09</li> <li>\u4e0d\u5f15\u5165\u5e8f\u5173\u7cfb   \u26a0\ufe0f \u7f3a\u70b9\uff1a</li> <li>\u4e0d\u76f4\u89c2</li> </ul> <p>\u5b9e\u73b0\u4f9d\u8d56\u5e93\uff1a<code>category_encoders</code></p> <pre><code>!pip install category_encoders\nimport category_encoders as ce\n\nencoder = ce.BinaryEncoder(cols=['\u57ce\u5e02'])\ndf_encoded = encoder.fit_transform(df)\nprint(df_encoded)\n</code></pre>"},{"location":"machine/interview/#4-frequency-encoding","title":"4\ufe0f\u20e3 \u9891\u6570\u7f16\u7801\uff08Frequency Encoding\uff09","text":"<p>\u7528\u6bcf\u4e2a\u7c7b\u522b\u51fa\u73b0\u7684\u9891\u7387\u6216\u6b21\u6570\u66ff\u6362\u7c7b\u522b\u503c\u3002</p> \u57ce\u5e02 \u9891\u6570\u7f16\u7801 \u5317\u4eac 2 \u4e0a\u6d77 1 \u5e7f\u5dde 1 <p>\u5b9e\u73b0\uff1a</p> <pre><code>freq = df['\u57ce\u5e02'].value_counts()\ndf['\u57ce\u5e02_\u9891\u6570\u7f16\u7801'] = df['\u57ce\u5e02'].map(freq)\n</code></pre> <p>\u2705 \u4f18\u70b9\uff1a</p> <ul> <li>\u7b80\u5355\uff0c\u4e0d\u589e\u52a0\u7ef4\u5ea6</li> <li>\u53ef\u6355\u6349\u7c7b\u522b\u5206\u5e03\u4fe1\u606f</li> </ul> <p>\u26a0\ufe0f \u7f3a\u70b9\uff1a</p> <ul> <li>\u4ecd\u53ef\u80fd\u9690\u542b\u201c\u5927\u5c0f\u201d\u5173\u7cfb</li> <li>\u4e0d\u9002\u5408\u8ddd\u79bb\u5ea6\u91cf\u6a21\u578b</li> </ul>"},{"location":"machine/interview/#5-target-encoding","title":"5\ufe0f\u20e3 \u76ee\u6807\u7f16\u7801\uff08Target Encoding\uff09","text":"<p>\u7528\u6bcf\u4e2a\u7c7b\u522b\u5bf9\u5e94\u76ee\u6807\u53d8\u91cf ( y ) \u7684\u5e73\u5747\u503c\u7f16\u7801\u3002 \u5e38\u7528\u4e8e\u5206\u7c7b\u95ee\u9898\uff08\u5c24\u5176\u662f\u9ad8\u57fa\u6570\u7c7b\u522b\uff09\u3002</p> \u57ce\u5e02 \u5e73\u5747\u8d2d\u4e70\u7387 \u5317\u4eac 0.8 \u4e0a\u6d77 0.3 \u5e7f\u5dde 0.6 <p>\u5b9e\u73b0\uff1a</p> <pre><code>target_mean = df.groupby('\u57ce\u5e02')['\u662f\u5426\u8d2d\u4e70'].mean()\ndf['\u57ce\u5e02_\u76ee\u6807\u7f16\u7801'] = df['\u57ce\u5e02'].map(target_mean)\n</code></pre> <p>\u2705 \u4f18\u70b9\uff1a</p> <ul> <li>\u5bf9\u9ad8\u57fa\u6570\u7c7b\u522b\u6709\u5f88\u5f3a\u8868\u73b0\u529b   \u26a0\ufe0f \u7f3a\u70b9\uff1a</li> <li>\u5bb9\u6613\u8fc7\u62df\u5408\uff08\u5c24\u5176\u5728\u6837\u672c\u5c11\u65f6\uff09   \u2192 \u5e94\u5728\u4ea4\u53c9\u9a8c\u8bc1\u4e2d\u8c28\u614e\u4f7f\u7528\u3002</li> </ul> \u7f16\u7801\u65b9\u5f0f \u662f\u5426\u4fdd\u5e8f \u662f\u5426\u6269\u7ef4 \u662f\u5426\u6297\u9ad8\u57fa\u6570 \u5178\u578b\u6a21\u578b \u5907\u6ce8 \u6807\u7b7e\u7f16\u7801 \u2705 \u274c \u2705 \u6811\u6a21\u578b \u7b80\u5355\u5feb\u901f \u72ec\u70ed\u7f16\u7801 \u274c \u2705 \u274c \u7ebf\u6027\u3001NN \u65e0\u5e8f\u7c7b\u522b\u63a8\u8350 \u4e8c\u503c\u7f16\u7801 \u274c \u2705\uff08\u5c11\uff09 \u2705 \u901a\u7528 \u5e73\u8861\u7ef4\u5ea6\u4e0e\u65e0\u5e8f\u6027 \u9891\u6570\u7f16\u7801 \u274c \u274c \u2705 \u6811\u6a21\u578b \u6355\u6349\u5168\u5c40\u7edf\u8ba1 \u76ee\u6807\u7f16\u7801 \u274c \u274c \u2705 \u9ad8\u57fa\u6570\u5206\u7c7b \u9632\u6b62\u8fc7\u62df\u5408\u9700\u6b63\u5219"},{"location":"machine/interview/#_20","title":"\u6570\u636e\u7c7b\u578b\u8f6c\u6362\uff1a\u5982\u5c06\u6587\u672c\u3001\u65f6\u95f4\u7b49\u8f6c\u4e3a\u6570\u503c\u578b","text":"<p>\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u5927\u591a\u6570\u53ea\u80fd\u5904\u7406\u6570\u503c\uff08float\u3001int\uff09\u7c7b\u578b\u6570\u636e\uff0c\u4f8b\u5982\uff1a</p> <ul> <li>\u56de\u5f52\u6a21\u578b\u3001SVM\u3001KNN\u3001\u795e\u7ecf\u7f51\u7edc\u7b49\uff1b</li> <li>\u51b3\u7b56\u6811\u7c7b\u6a21\u578b\uff08\u5982 RandomForest\uff09\u867d\u53ef\u5904\u7406\u90e8\u5206\u7c7b\u522b\u6570\u636e\uff0c\u4f46\u901a\u5e38\u4ecd\u5efa\u8bae\u6570\u503c\u5316\u3002</li> </ul> <p>\ud83d\udc49 \u76ee\u6807\uff1a \u5c06\u6587\u672c\u3001\u65e5\u671f\u3001\u5e03\u5c14\u3001\u7c7b\u522b\u7b49\u5b57\u6bb5\uff0c\u8f6c\u6362\u4e3a\u6a21\u578b\u53ef\u7406\u89e3\u7684\u6570\u503c\u7279\u5f81\u3002</p>"},{"location":"machine/interview/#_21","title":"\ud83d\udcda \u5e38\u89c1\u7684\u6570\u636e\u7c7b\u578b\u53ca\u8f6c\u6362\u65b9\u5f0f","text":"\u6570\u636e\u7c7b\u578b \u8f6c\u6362\u65b9\u5f0f \u4e3e\u4f8b\u8bf4\u660e \u6587\u672c\u578b\uff08string/object\uff09 \u7f16\u7801\uff08\u5982LabelEncoder\u3001OneHotEncoder\uff09 \u201c\u57ce\u5e02\u201d\u5217\uff1a<code>[\"\u5317\u4eac\",\"\u4e0a\u6d77\",\"\u5e7f\u5dde\"] \u2192 [0,1,2]</code>\uff08LabelEncoder\uff09\u6216 <code>[1,0,0],[0,1,0],[0,0,1]</code>\uff08OneHot\uff09 \u7c7b\u522b\u578b\uff08categorical\uff09 \u7f16\u7801\uff08\u4e0e\u6587\u672c\u578b\u76f8\u540c\uff09 \u201c\u6027\u522b\u201d\u5217\uff1a<code>[\"\u7537\",\"\u5973\"] \u2192 [0,1]</code> \u65f6\u95f4\u578b\uff08datetime\uff09 \u63d0\u53d6\u65f6\u95f4\u7279\u5f81\u6216\u8f6c\u6362\u4e3a\u65f6\u95f4\u6233 \u201c2024-05-10\u201d \u2192 \u63d0\u53d6\u51fa<code>\u5e74=2024, \u6708=5, \u65e5=10, \u661f\u671f=5</code>\uff0c\u6216\u8f6c\u6362\u4e3a <code>timestamp=1715299200</code> \u5e03\u5c14\u578b\uff08bool\uff09 \u8f6c\u6362\u4e3a0\u548c1 <code>True \u2192 1, False \u2192 0</code> \u6df7\u5408\u578b\uff08\u6570\u503c+\u6587\u672c\uff09 \u5148\u6e05\u6d17\u518d\u8f6c\u6362 <code>\"12kg\" \u2192 12</code> \u6216 <code>\"\u5426\"\u21920</code>\u3001<code>\"\u662f\"\u21921</code> \u6587\u672c\u63cf\u8ff0\u578b\uff08\u81ea\u7136\u8bed\u8a00\uff09 \u6587\u672c\u5411\u91cf\u5316\uff08TF-IDF\u3001Word2Vec\u3001BERT Embedding\uff09 <code>\"\u6211\u559c\u6b22\u673a\u5668\u5b66\u4e60\"</code> \u2192 \u5411\u91cf <code>[0.25, 0.11, 0.83, ...]</code>"},{"location":"machine/interview/#_22","title":"\ud83e\udde0 \u65f6\u95f4\u7c7b\u578b\u8f6c\u6362\u8be6\u89e3","text":"<p>\u65f6\u95f4\u6570\u636e\u662f\u6700\u5e38\u89c1\u7684\u201c\u975e\u6570\u503c\u578b\u201d\u6570\u636e\u4e4b\u4e00\u3002 \u901a\u5e38\u6709\u4e09\u79cd\u5904\u7406\u65b9\u5f0f\uff1a</p>"},{"location":"machine/interview/#1_4","title":"\u2705 \u65b9\u6cd51\uff1a\u63d0\u53d6\u65f6\u95f4\u7279\u5f81","text":"<p>\u9002\u5408\u6709\u5468\u671f\u89c4\u5f8b\u7684\u6570\u636e\uff08\u5982\u9500\u91cf\u3001\u6e29\u5ea6\u3001\u4ea4\u901a\u6d41\u91cf\u7b49\uff09</p> <pre><code>import pandas as pd\n\ndf = pd.DataFrame({\n    \"date\": pd.to_datetime([\"2023-05-01\", \"2023-06-15\", \"2023-07-20\"])\n})\ndf[\"year\"] = df[\"date\"].dt.year\ndf[\"month\"] = df[\"date\"].dt.month\ndf[\"day\"] = df[\"date\"].dt.day\ndf[\"weekday\"] = df[\"date\"].dt.weekday\nprint(df)\n</code></pre> <p>\u8f93\u51fa\uff1a</p> <pre><code>        date  year  month  day  weekday\n0 2023-05-01  2023      5    1        0\n1 2023-06-15  2023      6   15        3\n2 2023-07-20  2023      7   20        3\n</code></pre>"},{"location":"machine/interview/#2_3","title":"\u2705 \u65b9\u6cd52\uff1a\u8f6c\u6362\u4e3a\u65f6\u95f4\u6233\uff08\u6570\u503c\u578b\uff09","text":"<pre><code>df[\"timestamp\"] = df[\"date\"].astype(\"int64\") // 1e9  # \u79d2\u7ea7\u65f6\u95f4\u6233\n</code></pre> <p>\u4f8b\u5982\uff1a</p> <pre><code>2023-05-01 \u2192 1682899200\n</code></pre>"},{"location":"machine/interview/#3sincos","title":"\u2705 \u65b9\u6cd53\uff1a\u5468\u671f\u6027\u7279\u5f81\u7f16\u7801\uff08sin\u3001cos\uff09","text":"<p>\u5468\u671f\u6027\u65f6\u95f4\u7279\u5f81\uff08\u5982\u201c\u6708\u4efd\u201d\u3001\u201c\u5c0f\u65f6\u201d\uff09\u53ef\u7528\u6b63\u4f59\u5f26\u51fd\u6570\u7f16\u7801\uff0c\u4ee5\u4fdd\u7559\u8fde\u7eed\u6027\u3002</p> <pre><code>import numpy as np\n\ndf[\"month_sin\"] = np.sin(2 * np.pi * df[\"month\"] / 12)\ndf[\"month_cos\"] = np.cos(2 * np.pi * df[\"month\"] / 12)\n</code></pre> <p>\ud83d\udc49 \u4f18\u70b9\uff1a\u6a21\u578b\u53ef\u4ee5\u5b66\u4e60\u5230\u201c12\u6708\u548c1\u6708\u201d\u76f8\u90bb\uff0c\u800c\u4e0d\u662f\u8ddd\u79bb\u4e3a11\u3002</p>"},{"location":"machine/interview/#_23","title":"\ud83e\uddee \u6587\u672c\u7c7b\u578b\u8f6c\u6362\u8be6\u89e3","text":""},{"location":"machine/interview/#1label-encoding","title":"\u2705 \u65b9\u6cd51\uff1aLabel Encoding\uff08\u6807\u7b7e\u7f16\u7801\uff09","text":"<p>\u9002\u5408\u6709\u5927\u5c0f\u6216\u987a\u5e8f\u5173\u7cfb\u7684\u7c7b\u522b\uff08\u5982\uff1a\u4f4e\u3001\u4e2d\u3001\u9ad8\uff09</p> <pre><code>from sklearn.preprocessing import LabelEncoder\n\nencoder = LabelEncoder()\ndf[\"label_encoded\"] = encoder.fit_transform([\"\u5317\u4eac\",\"\u4e0a\u6d77\",\"\u5e7f\u5dde\"])\nprint(df)\n</code></pre> <p>\u8f93\u51fa\uff1a</p> <pre><code>\u539f\u59cb\u503c\uff1a[\"\u5317\u4eac\",\"\u4e0a\u6d77\",\"\u5e7f\u5dde\"]\n\u7f16\u7801\u540e\uff1a[0, 2, 1]\n</code></pre>"},{"location":"machine/interview/#2one-hot-encoding","title":"\u2705 \u65b9\u6cd52\uff1aOne-Hot Encoding\uff08\u72ec\u70ed\u7f16\u7801\uff09","text":"<p>\u9002\u5408\u65e0\u5e8f\u7c7b\u522b</p> <pre><code>import pandas as pd\n\ndf = pd.DataFrame({\"city\": [\"\u5317\u4eac\", \"\u4e0a\u6d77\", \"\u5e7f\u5dde\"]})\ndf = pd.get_dummies(df, columns=[\"city\"])\nprint(df)\n</code></pre> <p>\u8f93\u51fa\uff1a</p> <pre><code>   city_\u5317\u4eac  city_\u4e0a\u6d77  city_\u5e7f\u5dde\n0        1        0        0\n1        0        1        0\n2        0        0        1\n</code></pre>"},{"location":"machine/interview/#3tf-idf-word2vec-bert","title":"\u2705 \u65b9\u6cd53\uff1a\u6587\u672c\u5411\u91cf\u5316\uff08TF-IDF / Word2Vec / BERT\uff09","text":"<p>\u7528\u4e8e\u5904\u7406\u81ea\u7136\u8bed\u8a00\u6587\u672c\u3002</p> <pre><code>from sklearn.feature_extraction.text import TfidfVectorizer\n\ntexts = [\"\u6211\u559c\u6b22\u673a\u5668\u5b66\u4e60\", \"\u673a\u5668\u5b66\u4e60\u5f88\u597d\u73a9\"]\ntfidf = TfidfVectorizer()\nfeatures = tfidf.fit_transform(texts)\nprint(features.toarray())\n</code></pre> \u6b65\u9aa4 \u8f6c\u6362\u5bf9\u8c61 \u5de5\u5177/\u65b9\u6cd5 \u8f6c\u6362\u540e\u7c7b\u578b 1 \u5e03\u5c14\u578b <code>.astype(int)</code> int 2 \u6587\u672c/\u7c7b\u522b\u578b <code>LabelEncoder</code> / <code>OneHotEncoder</code> / <code>get_dummies()</code> \u6570\u503c 3 \u65f6\u95f4\u578b <code>pd.to_datetime()</code> + <code>.dt</code>\u63d0\u53d6 \u6570\u503c 4 \u6df7\u5408\u5b57\u7b26\u4e32 <code>str.replace()</code> + <code>.astype()</code> \u6570\u503c 5 \u81ea\u7136\u8bed\u8a00\u6587\u672c TF-IDF / Word2Vec / Embedding \u5411\u91cf"},{"location":"machine/interview/#23","title":"2.3 \u6570\u636e\u5206\u5272","text":""},{"location":"machine/interview/#_24","title":"\u5212\u5206\u8bad\u7ec3\u96c6\u3001\u9a8c\u8bc1\u96c6\u548c\u6d4b\u8bd5\u96c6\uff0c\u5408\u7406\u5206\u914d\u6570\u636e\uff0c\u907f\u514d\u8fc7\u62df\u5408","text":"<p>\u5728\u673a\u5668\u5b66\u4e60\u4e2d\uff0c\u6211\u4eec\u5e0c\u671b\u6a21\u578b\u4e0d\u4ec5\u5728\u8bad\u7ec3\u6570\u636e\u4e0a\u8868\u73b0\u597d\uff0c\u8fd8\u8981\u5728\u672a\u77e5\u6570\u636e\u4e0a\u8868\u73b0\u4f18\u5f02\u3002 \u5982\u679c\u53ea\u7528\u540c\u4e00\u4efd\u6570\u636e\u6765\u8bad\u7ec3\u548c\u8bc4\u4f30\u6a21\u578b\uff0c\u5c31\u4f1a\u5bfc\u81f4\u6a21\u578b\u201c\u80cc\u9898\u201d\u2014\u2014\u5373 \u8fc7\u62df\u5408\uff08Overfitting\uff09\u3002</p> <p>\ud83d\udc49 \u89e3\u51b3\u65b9\u6cd5\uff1a \u5c06\u539f\u59cb\u6570\u636e\u5212\u5206\u4e3a\u4e0d\u540c\u7684\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u4e0d\u540c\u76ee\u7684\uff1a</p> \u6570\u636e\u96c6 \u7528\u9014 \u4f5c\u7528 \u8bad\u7ec3\u96c6\uff08Training Set\uff09 \u8bad\u7ec3\u6a21\u578b \u5b66\u4e60\u6570\u636e\u7279\u5f81\u548c\u89c4\u5f8b \u9a8c\u8bc1\u96c6\uff08Validation Set\uff09 \u8c03\u53c2\u548c\u6a21\u578b\u9009\u62e9 \u5224\u65ad\u6a21\u578b\u5728\u672a\u89c1\u6570\u636e\u4e0a\u7684\u8868\u73b0\uff0c\u9632\u6b62\u8fc7\u62df\u5408 \u6d4b\u8bd5\u96c6\uff08Test Set\uff09 \u6700\u7ec8\u8bc4\u4f30 \u6a21\u62df\u771f\u5b9e\u73af\u5883\u4e0b\u7684\u6a21\u578b\u8868\u73b0"},{"location":"machine/interview/#_25","title":"\ud83d\udcda \u5e38\u89c1\u5212\u5206\u6bd4\u4f8b","text":"\u6570\u636e\u96c6 \u5e38\u89c1\u6bd4\u4f8b \u8bad\u7ec3\u96c6 60%\uff5e80% \u9a8c\u8bc1\u96c6 10%\uff5e20% \u6d4b\u8bd5\u96c6 10%\uff5e20% <p>\u4f8b\u5982\uff1a</p> <pre><code>80% \u8bad\u7ec3\u96c6 + 10% \u9a8c\u8bc1\u96c6 + 10% \u6d4b\u8bd5\u96c6\n</code></pre> <p>\u2705 \u7ecf\u9a8c\u6cd5\u5219\uff1a</p> <ul> <li>\u6570\u636e\u91cf\u8f83\u5927 \u2192 \u53ef\u4ee5 70% / 15% / 15%</li> <li>\u6570\u636e\u91cf\u8f83\u5c0f \u2192 \u91c7\u7528 \u4ea4\u53c9\u9a8c\u8bc1\uff08K-Fold Cross Validation\uff09 \u6765\u66ff\u4ee3\u9a8c\u8bc1\u96c6</li> </ul>"},{"location":"machine/interview/#python","title":"\ud83e\udde0 \u6570\u636e\u5212\u5206\u7684\u57fa\u672c\u65b9\u6cd5\uff08Python \u5b9e\u4f8b\uff09","text":""},{"location":"machine/interview/#1-sklearn-train_test_split","title":"\u2705 \u65b9\u6cd51\uff1a\u4f7f\u7528 sklearn \u7684 <code>train_test_split</code>","text":"<pre><code>from sklearn.model_selection import train_test_split\nimport pandas as pd\n\n# \u6784\u9020\u793a\u4f8b\u6570\u636e\ndata = pd.DataFrame({\n    \"feature1\": range(1, 11),\n    \"feature2\": range(11, 21),\n    \"label\": [0, 1, 0, 1, 0, 1, 0, 1, 0, 1]\n})\n\n# \u5148\u5212\u5206\u8bad\u7ec3\u96c6 + \u4e34\u65f6\u96c6\ntrain_set, temp_set = train_test_split(data, test_size=0.3, random_state=42)\n\n# \u518d\u5212\u5206\u9a8c\u8bc1\u96c6\u548c\u6d4b\u8bd5\u96c6\nval_set, test_set = train_test_split(temp_set, test_size=0.5, random_state=42)\n\nprint(f\"\u8bad\u7ec3\u96c6: {train_set.shape}\")\nprint(f\"\u9a8c\u8bc1\u96c6: {val_set.shape}\")\nprint(f\"\u6d4b\u8bd5\u96c6: {test_set.shape}\")\n</code></pre> <p>\u8f93\u51fa\uff1a</p> <pre><code>\u8bad\u7ec3\u96c6: (7, 3)\n\u9a8c\u8bc1\u96c6: (1, 3)\n\u6d4b\u8bd5\u96c6: (2, 3)\n</code></pre>"},{"location":"machine/interview/#2stratified-split","title":"\u2705 \u65b9\u6cd52\uff1a\u5206\u5c42\u62bd\u6837\uff08Stratified Split\uff09","text":"<p>\u7528\u4e8e\u5206\u7c7b\u4efb\u52a1\uff0c\u4fdd\u8bc1\u6bcf\u4e2a\u6570\u636e\u96c6\u4e2d\u7c7b\u522b\u6bd4\u4f8b\u4e00\u81f4\u3002</p> <pre><code>from sklearn.model_selection import train_test_split\n\nX = data[[\"feature1\", \"feature2\"]]\ny = data[\"label\"]\n\nX_train, X_temp, y_train, y_temp = train_test_split(\n    X, y, test_size=0.3, stratify=y, random_state=42\n)\nX_val, X_test, y_val, y_test = train_test_split(\n    X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42\n)\n</code></pre> <p>\ud83d\udc49 \u4f18\u70b9\uff1a \u907f\u514d\u5212\u5206\u540e\u67d0\u4e00\u7c7b\u6837\u672c\u8fc7\u5c11\u6216\u7f3a\u5931\u3002</p>"},{"location":"machine/interview/#cross-validation","title":"\ud83e\uddea \u4ea4\u53c9\u9a8c\u8bc1\uff08Cross Validation\uff09","text":"<p>\u5f53\u6570\u636e\u91cf\u8f83\u5c0f\u65f6\uff0c\u5355\u6b21\u5212\u5206\u4e0d\u591f\u7a33\u5b9a\uff0c\u8fd9\u65f6\u7528\u4ea4\u53c9\u9a8c\u8bc1\u3002 \u5e38\u7528\u65b9\u5f0f\u662f K \u6298\u4ea4\u53c9\u9a8c\u8bc1\uff08K-Fold CV\uff09\uff1a</p>"},{"location":"machine/interview/#_26","title":"\ud83d\udcd8 \u539f\u7406\uff1a","text":"<ul> <li>\u5c06\u6570\u636e\u5206\u6210 K \u4efd\uff1b</li> <li>\u6bcf\u6b21\u53d6 1 \u4efd\u4f5c\u4e3a\u9a8c\u8bc1\u96c6\uff0c\u5176\u4f59 K\u22121 \u4efd\u4f5c\u4e3a\u8bad\u7ec3\u96c6\uff1b</li> <li>\u91cd\u590d K \u6b21\uff1b</li> <li>\u6700\u540e\u5bf9 K \u6b21\u9a8c\u8bc1\u7ed3\u679c\u53d6\u5e73\u5747\u3002</li> </ul> <pre><code>from sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.datasets import load_iris\n\nX, y = load_iris(return_X_y=True)\nmodel = LogisticRegression(max_iter=1000)\n\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\nscores = cross_val_score(model, X, y, cv=kf)\n\nprint(\"\u6bcf\u6298\u5f97\u5206:\", scores)\nprint(\"\u5e73\u5747\u51c6\u786e\u7387:\", scores.mean())\n</code></pre> <p>\u8f93\u51fa\uff1a</p> <pre><code>\u6bcf\u6298\u5f97\u5206: [0.96 0.93 0.96 0.90 0.96]\n\u5e73\u5747\u51c6\u786e\u7387: 0.942\n</code></pre> <p>\u2705 \u4f18\u70b9\uff1a</p> <ul> <li>\u66f4\u7a33\u5b9a\u7684\u6a21\u578b\u8bc4\u4f30\uff1b</li> <li>\u6570\u636e\u5145\u5206\u5229\u7528\uff1b</li> <li>\u7279\u522b\u9002\u5408\u6837\u672c\u8f83\u5c11\u7684\u60c5\u51b5\u3002</li> </ul> \u95ee\u9898 \u539f\u56e0 \u89e3\u51b3\u529e\u6cd5 \u6570\u636e\u6cc4\u6f0f\uff08Data Leakage\uff09 \u6d4b\u8bd5\u6570\u636e\u5728\u8bad\u7ec3\u9636\u6bb5\u88ab\u201c\u5077\u770b\u201d \u5212\u5206\u524d\u8981\u5148\u5206\u5272\u6570\u636e\uff0c\u518d\u505a\u6807\u51c6\u5316\u3001\u7279\u5f81\u5de5\u7a0b \u65f6\u95f4\u5e8f\u5217\u6570\u636e\u4e0d\u80fd\u968f\u673a\u5212\u5206 \u65f6\u95f4\u6709\u987a\u5e8f \u5e94\u4f7f\u7528\u65f6\u95f4\u987a\u5e8f\u5212\u5206\uff0c\u5982\u524d 80% \u8bad\u7ec3\uff0c\u540e 20% \u6d4b\u8bd5 \u7c7b\u522b\u5206\u5e03\u4e0d\u5747\u8861 \u67d0\u7c7b\u6837\u672c\u6bd4\u4f8b\u592a\u4f4e \u4f7f\u7528\u5206\u5c42\u62bd\u6837\uff08stratify\uff09\u4fdd\u6301\u6bd4\u4f8b \u968f\u673a\u6027\u95ee\u9898 \u6bcf\u6b21\u5212\u5206\u7ed3\u679c\u4e0d\u540c \u8bbe\u7f6e <code>random_state</code> \u4fdd\u8bc1\u7ed3\u679c\u53ef\u590d\u73b0"},{"location":"machine/interview/#_27","title":"\u5b8c\u6574\u793a\u4f8b","text":"<pre><code>from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nimport pandas as pd\n\n# 1\ufe0f\u20e3 \u52a0\u8f7d\u6570\u636e\ndf = pd.read_csv(\"data.csv\")\n\n# 2\ufe0f\u20e3 \u5212\u5206\u7279\u5f81\u4e0e\u6807\u7b7e\nX = df.drop(\"label\", axis=1)\ny = df[\"label\"]\n\n# 3\ufe0f\u20e3 \u5212\u5206\u8bad\u7ec3\u3001\u9a8c\u8bc1\u3001\u6d4b\u8bd5\u96c6\nX_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\nX_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n\n# 4\ufe0f\u20e3 \u4ec5\u7528\u8bad\u7ec3\u96c6\u62df\u5408\u6807\u51c6\u5316\u5668\uff0c\u9632\u6b62\u6570\u636e\u6cc4\u6f0f\nscaler = StandardScaler().fit(X_train)\n\n# 5\ufe0f\u20e3 \u5bf9\u5168\u90e8\u96c6\u505a\u53d8\u6362\nX_train = scaler.transform(X_train)\nX_val = scaler.transform(X_val)\nX_test = scaler.transform(X_test)\n</code></pre>"},{"location":"machine/interview/#24","title":"2.4 \u5176\u4ed6\u5904\u7406","text":""},{"location":"machine/interview/#smote","title":"\u5904\u7406\u4e0d\u5e73\u8861\u6570\u636e\uff1a\u8fc7\u91c7\u6837\u3001\u6b20\u91c7\u6837\u3001SMOTE\u7b49","text":"<p>\u5728\u5206\u7c7b\u95ee\u9898\u4e2d\uff0c\u5982\u679c\u5404\u7c7b\u522b\u6837\u672c\u6570\u91cf\u5dee\u5f02\u5f88\u5927\uff0c\u5c31\u53eb\u505a\u7c7b\u522b\u4e0d\u5e73\u8861\u3002 \u4f8b\u5982\uff1a</p> \u7c7b\u522b \u6837\u672c\u6570\u91cf \u6b63\u6837\u672c\uff081\uff09 100 \u8d1f\u6837\u672c\uff080\uff09 5000 <p>\u6b64\u65f6\uff1a</p> <ul> <li>\u6a21\u578b\u82e5\u53ea\u9884\u6d4b\u201c0\u201d\uff0c\u51c6\u786e\u7387\u4e5f\u80fd\u8fbe 98%\uff1b</li> <li>\u4f46\u6a21\u578b\u51e0\u4e4e\u6ca1\u5b66\u5230\u5c11\u6570\u7c7b\uff081\uff09\u7684\u7279\u5f81\u3002</li> </ul> <p>\ud83d\udc49 \u7ed3\u679c\uff1a\u9ad8\u51c6\u786e\u7387\u4f46\u4f4e\u53ec\u56de\u7387\uff0c\u6a21\u578b\u201c\u770b\u4f3c\u806a\u660e\uff0c\u5b9e\u5219\u65e0\u7528\u201d\u3002</p>"},{"location":"machine/interview/#_28","title":"\ud83e\udde0 \u4e3a\u4ec0\u4e48\u8981\u5904\u7406\u4e0d\u5e73\u8861\u6570\u636e\uff1f","text":"<p>\u82e5\u4e0d\u5904\u7406\uff0c\u6a21\u578b\u4f1a\uff1a</p> <ul> <li>\u503e\u5411\u4e8e\u9884\u6d4b\u591a\u6570\u7c7b\uff1b</li> <li>\u5ffd\u7565\u7a00\u6709\u4e8b\u4ef6\uff08\u5982\u6b3a\u8bc8\u68c0\u6d4b\u3001\u75be\u75c5\u8bca\u65ad\u3001\u5f02\u5e38\u68c0\u6d4b\uff09\uff1b</li> <li>\u6027\u80fd\u6307\u6807\uff08\u51c6\u786e\u7387\uff09\u5931\u771f\u3002</li> </ul> <p>\u56e0\u6b64\uff0c\u6211\u4eec\u9700\u8981 \u91cd\u65b0\u5e73\u8861\u6570\u636e\u5206\u5e03\uff0c\u8ba9\u6a21\u578b\u516c\u5e73\u5b66\u4e60\u6bcf\u4e00\u7c7b\u3002</p>"},{"location":"machine/interview/#_29","title":"\u2699\ufe0f \u5e38\u89c1\u7684\u5904\u7406\u65b9\u6cd5","text":"\u65b9\u6cd5\u7c7b\u522b \u4ee3\u8868\u65b9\u6cd5 \u601d\u60f3 \u6570\u636e\u5c42\u9762 \u6b20\u91c7\u6837\u3001\u8fc7\u91c7\u6837\u3001SMOTE \u6539\u53d8\u6570\u636e\u5206\u5e03 \u7b97\u6cd5\u5c42\u9762 \u52a0\u6743\u6a21\u578b\u3001\u4ee3\u4ef7\u654f\u611f\u5b66\u4e60 \u4fee\u6539\u8bad\u7ec3\u6743\u91cd \u8bc4\u4f30\u5c42\u9762 \u4f7f\u7528 F1-score\u3001AUC \u7b49\u6307\u6807 \u6539\u53d8\u8bc4\u4f30\u65b9\u5f0f"},{"location":"machine/interview/#_30","title":"\ud83e\udde9 \u6570\u636e\u5c42\u9762\u65b9\u6cd5\u8be6\u89e3","text":""},{"location":"machine/interview/#1-under-sampling","title":"1\ufe0f\u20e3 \u6b20\u91c7\u6837\uff08Under-Sampling\uff09","text":"<p>\ud83d\udc49 \u601d\u60f3\uff1a \u4ece\u591a\u6570\u7c7b\u4e2d\u968f\u673a\u5220\u9664\u90e8\u5206\u6837\u672c\uff0c\u4f7f\u5404\u7c7b\u6837\u672c\u6570\u91cf\u63a5\u8fd1\u3002</p> <p>\u2705 \u4f18\u70b9\uff1a</p> <ul> <li>\u7b80\u5355\u76f4\u89c2</li> <li>\u964d\u4f4e\u8ba1\u7b97\u91cf</li> </ul> <p>\u26a0\ufe0f \u7f3a\u70b9\uff1a</p> <ul> <li>\u4e22\u5931\u591a\u6570\u7c7b\u4fe1\u606f\uff0c\u53ef\u80fd\u5f71\u54cd\u6a21\u578b\u8868\u73b0</li> </ul> <p>\ud83d\udcd8 \u793a\u4f8b\uff1a</p> <pre><code>from imblearn.under_sampling import RandomUnderSampler\nimport pandas as pd\n\nX = pd.DataFrame({'x1': [1,2,3,4,5,6,7,8], 'x2':[2,3,4,5,6,7,8,9]})\ny = [0,0,0,0,1,1,1,1]\n\nrus = RandomUnderSampler(random_state=42)\nX_res, y_res = rus.fit_resample(X, y)\n\nprint(\"\u91c7\u6837\u524d:\", pd.Series(y).value_counts())\nprint(\"\u91c7\u6837\u540e:\", pd.Series(y_res).value_counts())\n</code></pre> <p>\u8f93\u51fa\uff1a</p> <pre><code>\u91c7\u6837\u524d:\n0    4\n1    4\n\u91c7\u6837\u540e:\n0    4\n1    4\n</code></pre>"},{"location":"machine/interview/#2-over-sampling","title":"2\ufe0f\u20e3 \u8fc7\u91c7\u6837\uff08Over-Sampling\uff09","text":"<p>\ud83d\udc49 \u601d\u60f3\uff1a \u901a\u8fc7\u590d\u5236\u6216\u5408\u6210\u65b0\u7684\u5c11\u6570\u7c7b\u6837\u672c\uff0c\u4f7f\u5176\u6570\u91cf\u4e0e\u591a\u6570\u7c7b\u63a5\u8fd1\u3002</p> <p>\u2705 \u4f18\u70b9\uff1a</p> <ul> <li>\u4e0d\u4e22\u5931\u4fe1\u606f</li> <li>\u6709\u52a9\u4e8e\u6a21\u578b\u5b66\u4e60\u5c11\u6570\u7c7b\u7279\u5f81</li> </ul> <p>\u26a0\ufe0f \u7f3a\u70b9\uff1a</p> <ul> <li>\u5bb9\u6613\u8fc7\u62df\u5408\uff08\u5c24\u5176\u662f\u7b80\u5355\u590d\u5236\u6837\u672c\uff09</li> </ul> <p>\ud83d\udcd8 \u793a\u4f8b\uff1a</p> <pre><code>from imblearn.over_sampling import RandomOverSampler\n\nros = RandomOverSampler(random_state=42)\nX_res, y_res = ros.fit_resample(X, y)\n\nprint(\"\u91c7\u6837\u540e:\", pd.Series(y_res).value_counts())\n</code></pre>"},{"location":"machine/interview/#3-smotesynthetic-minority-over-sampling-technique","title":"3\ufe0f\u20e3 SMOTE\uff08Synthetic Minority Over-sampling Technique\uff09","text":"<p>\ud83d\udc49 \u601d\u60f3\uff1a \u901a\u8fc7\u63d2\u503c\u7b97\u6cd5\u751f\u6210\u65b0\u7684\u5c11\u6570\u7c7b\u6837\u672c\uff0c\u800c\u4e0d\u662f\u7b80\u5355\u590d\u5236\u3002</p> <ul> <li>\u5bf9\u4e8e\u5c11\u6570\u7c7b\u6837\u672c \\(x_i\\)\uff0c\u5728\u5176 K \u4e2a\u8fd1\u90bb\u4e2d\u968f\u673a\u9009\u53d6\u4e00\u4e2a\u6837\u672c \\(x_j\\)</li> <li>\u6309\u6bd4\u4f8b\u751f\u6210\u65b0\u6837\u672c\uff1a $$   x_{new} = x_i + \\lambda (x_j - x_i), \\quad \\lambda \\in [0,1] $$</li> </ul> <p>\u2705 \u4f18\u70b9\uff1a</p> <ul> <li>\u6bd4\u968f\u673a\u8fc7\u91c7\u6837\u66f4\u5408\u7406</li> <li>\u51cf\u5c11\u8fc7\u62df\u5408</li> </ul> <p>\u26a0\ufe0f \u7f3a\u70b9\uff1a</p> <ul> <li>\u53ef\u80fd\u751f\u6210\u566a\u58f0\u70b9\uff08\u8fb9\u754c\u6a21\u7cca\uff09</li> </ul> <p>\ud83d\udcd8 \u793a\u4f8b\uff1a</p> <pre><code>from imblearn.over_sampling import SMOTE\n\nsm = SMOTE(random_state=42)\nX_res, y_res = sm.fit_resample(X, y)\n\nprint(\"\u91c7\u6837\u540e:\", pd.Series(y_res).value_counts())\n</code></pre>"},{"location":"machine/interview/#_31","title":"\ud83e\uddee \u7b97\u6cd5\u5c42\u9762\u65b9\u6cd5","text":"<p>\u6709\u65f6\u4e0d\u6539\u6570\u636e\uff0c\u800c\u662f\u5728\u6a21\u578b\u8bad\u7ec3\u65f6\u8c03\u6574\u6743\u91cd\u3002</p>"},{"location":"machine/interview/#1-class-weight","title":"\u2705 1. \u7c7b\u522b\u6743\u91cd\uff08Class Weight\uff09","text":"<p>\u4f8b\u5982\u5728 Logistic Regression\u3001SVM\u3001RandomForest \u4e2d\uff1a</p> <pre><code>from sklearn.linear_model import LogisticRegression\n\nmodel = LogisticRegression(class_weight='balanced')\nmodel.fit(X_res, y_res)\n</code></pre> <p>\u4f5c\u7528\uff1a</p> <ul> <li>\u81ea\u52a8\u6839\u636e\u7c7b\u522b\u6570\u91cf\u5206\u914d\u6743\u91cd\uff1a</li> </ul> \\[   w_i = \\frac{N}{2 \\times N_i} \\] <p>\u5373\u7c7b\u522b\u6837\u672c\u8d8a\u5c11\uff0c\u6743\u91cd\u8d8a\u5927\u3002</p>"},{"location":"machine/interview/#2-cost-sensitive-learning","title":"\u2705 2. \u4ee3\u4ef7\u654f\u611f\u5b66\u4e60\uff08Cost-sensitive Learning\uff09","text":"<p>\u901a\u8fc7\u8bbe\u7f6e \u8bef\u5206\u7c7b\u4ee3\u4ef7\u77e9\u9635\uff0c\u8ba9\u6a21\u578b\u201c\u66f4\u6015\u201d\u5c11\u6570\u7c7b\u9884\u6d4b\u9519\u8bef\u3002</p> <p>\u4f8b\u5982\u5728\u51b3\u7b56\u6811\u4e2d\uff1a</p> <pre><code>from sklearn.tree import DecisionTreeClassifier\nmodel = DecisionTreeClassifier(class_weight={0:1, 1:5})\n</code></pre>"},{"location":"machine/interview/#_32","title":"\ud83d\udcca \u8bc4\u4f30\u5c42\u9762\u65b9\u6cd5","text":"<p>\u5f53\u7c7b\u522b\u4e0d\u5e73\u8861\u65f6\uff0c\u51c6\u786e\u7387\uff08Accuracy\uff09 \u4e0d\u80fd\u771f\u5b9e\u53cd\u6620\u6027\u80fd\u3002 \u63a8\u8350\u4f7f\u7528\u4ee5\u4e0b\u6307\u6807\uff1a</p> \u6307\u6807 \u542b\u4e49 \u9002\u7528\u573a\u666f \u7cbe\u786e\u7387\uff08Precision\uff09 \u9884\u6d4b\u4e3a\u6b63\u7684\u6837\u672c\u4e2d\uff0c\u5b9e\u9645\u4e3a\u6b63\u7684\u6bd4\u4f8b \u5c11\u6570\u7c7b\u9519\u8bef\u4ee3\u4ef7\u9ad8\u65f6\uff08\u5982\u8bc8\u9a97\u68c0\u6d4b\uff09 \u53ec\u56de\u7387\uff08Recall\uff09 \u5b9e\u9645\u4e3a\u6b63\u7684\u6837\u672c\u4e2d\uff0c\u88ab\u6a21\u578b\u627e\u51fa\u7684\u6bd4\u4f8b \u5c11\u6570\u7c7b\u6f0f\u68c0\u4ee3\u4ef7\u9ad8\u65f6\uff08\u5982\u764c\u75c7\u68c0\u6d4b\uff09 F1-score \u7cbe\u786e\u7387\u4e0e\u53ec\u56de\u7387\u7684\u8c03\u548c\u5e73\u5747 \u7efc\u5408\u8bc4\u4f30 ROC-AUC \u6a21\u578b\u533a\u5206\u7c7b\u522b\u80fd\u529b \u7efc\u5408\u6027\u80fd\u6307\u6807"},{"location":"machine/interview/#_33","title":"\u6570\u636e\u589e\u5f3a\uff1a\u5728\u56fe\u50cf\u3001\u6587\u672c\u7b49\u9886\u57df\u6269\u5145\u8bad\u7ec3\u6837\u672c","text":"<p>\u6570\u636e\u589e\u5f3a\uff08Data Augmentation\uff09 \u662f\u6307\u901a\u8fc7\u5bf9\u5df2\u6709\u6570\u636e\u8fdb\u884c\u53d8\u6362\u3001\u6270\u52a8\u6216\u751f\u6210\u65b0\u6837\u672c\uff0c\u6765\u6269\u5145\u8bad\u7ec3\u6570\u636e\u96c6\uff0c \u4ee5\u63d0\u5347\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\uff08Generalization\uff09\u3001\u9632\u6b62\u8fc7\u62df\u5408\uff08Overfitting\uff09\u3002</p>"},{"location":"machine/interview/#_34","title":"\ud83e\udde0 \u4e3a\u4ec0\u4e48\u8981\u505a\u6570\u636e\u589e\u5f3a\uff1f","text":"<p>\u5728\u5b9e\u9645\u4e2d\uff0c\u6570\u636e\u5f80\u5f80\uff1a</p> <ul> <li>\u6837\u672c\u91cf\u5c11\uff1b</li> <li>\u5206\u5e03\u4e0d\u5747\uff1b</li> <li>\u566a\u58f0\u5927\uff1b</li> <li>\u96be\u4ee5\u91c7\u96c6\u3002</li> </ul> <p>\ud83d\udc49 \u6570\u636e\u589e\u5f3a\u53ef\u4ee5\uff1a</p> <ul> <li>\u589e\u52a0\u6837\u672c\u591a\u6837\u6027\uff1b</li> <li>\u8ba9\u6a21\u578b\u5b66\u4e60\u201c\u672c\u8d28\u7279\u5f81\u201d\uff1b</li> <li>\u51cf\u5c11\u8fc7\u62df\u5408\u3001\u63d0\u5347\u9c81\u68d2\u6027\uff1b</li> <li>\u8282\u7ea6\u6807\u6ce8\u6210\u672c\u3002</li> </ul>"},{"location":"machine/interview/#_35","title":"\ud83d\udcca \u6570\u636e\u589e\u5f3a\u7684\u7c7b\u578b\u603b\u89c8","text":"\u7c7b\u578b \u9002\u7528\u9886\u57df \u4e3e\u4f8b \u56fe\u50cf\u589e\u5f3a CV\uff08\u8ba1\u7b97\u673a\u89c6\u89c9\uff09 \u7ffb\u8f6c\u3001\u65cb\u8f6c\u3001\u88c1\u526a\u3001\u4eae\u5ea6\u8c03\u6574\u3001\u566a\u58f0\u6dfb\u52a0 \u6587\u672c\u589e\u5f3a NLP\uff08\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff09 \u540c\u4e49\u8bcd\u66ff\u6362\u3001\u968f\u673a\u63d2\u5165\u3001\u56de\u8bd1\u3001\u6df7\u5408\u751f\u6210 \u97f3\u9891\u589e\u5f3a \u8bed\u97f3\u8bc6\u522b\u3001\u97f3\u9891\u5206\u7c7b \u52a0\u566a\u3001\u53d8\u901f\u3001\u53d8\u8c03\u3001\u65f6\u95f4\u88c1\u526a \u6570\u503c\u7279\u5f81\u589e\u5f3a \u7ed3\u6784\u5316\u6570\u636e \u968f\u673a\u6270\u52a8\u3001SMOTE\u3001\u566a\u58f0\u6ce8\u5165"},{"location":"machine/interview/#_36","title":"\ud83d\uddbc\ufe0f \u56fe\u50cf\u6570\u636e\u589e\u5f3a\u8be6\u89e3","text":"<p>\u56fe\u50cf\u589e\u5f3a\uff08Image Augmentation\uff09\u662f\u6700\u5e38\u7528\u7684\u65b9\u5f0f\u4e4b\u4e00\u3002</p>"},{"location":"machine/interview/#1_5","title":"\u2705 1\ufe0f\u20e3 \u57fa\u672c\u53d8\u6362","text":"\u65b9\u6cd5 \u8bf4\u660e \u7ffb\u8f6c\uff08Flip\uff09 \u6c34\u5e73\u6216\u5782\u76f4\u7ffb\u8f6c \u65cb\u8f6c\uff08Rotation\uff09 \u968f\u673a\u89d2\u5ea6\u65cb\u8f6c \u5e73\u79fb\uff08Shift\uff09 \u56fe\u50cf\u5728\u5e73\u9762\u5185\u79fb\u52a8 \u7f29\u653e\uff08Zoom\uff09 \u6539\u53d8\u5927\u5c0f \u88c1\u526a\uff08Crop\uff09 \u968f\u673a\u6216\u4e2d\u5fc3\u88c1\u526a \u989c\u8272\u6270\u52a8 \u6539\u53d8\u4eae\u5ea6\u3001\u5bf9\u6bd4\u5ea6\u3001\u9971\u548c\u5ea6 \u52a0\u566a\u58f0 \u6a21\u62df\u566a\u58f0\u73af\u5883 <p>\ud83d\udcd8 \u793a\u4f8b\uff08\u4f7f\u7528 PyTorch\uff09</p> <pre><code>from torchvision import transforms\nfrom PIL import Image\n\n# \u5b9a\u4e49\u6570\u636e\u589e\u5f3a\u7ba1\u9053\ntransform = transforms.Compose([\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomRotation(15),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n    transforms.ToTensor()\n])\n\nimg = Image.open(\"cat.jpg\")\naug_img = transform(img)\n</code></pre> <p>\u2705 \u8fd9\u4e9b\u64cd\u4f5c\u80fd\u5728\u8bad\u7ec3\u65f6\u52a8\u6001\u5e94\u7528\uff0c\u6bcf\u4e2a epoch \u751f\u6210\u4e0d\u540c\u7248\u672c\u7684\u56fe\u7247\u3002</p>"},{"location":"machine/interview/#2_4","title":"\u2705 2\ufe0f\u20e3 \u9ad8\u7ea7\u56fe\u50cf\u589e\u5f3a","text":"\u6280\u672f \u539f\u7406 \u5e94\u7528 Cutout \u5728\u56fe\u7247\u4e0a\u968f\u673a\u906e\u76d6\u4e00\u90e8\u5206\u533a\u57df \u589e\u5f3a\u6a21\u578b\u6297\u906e\u6321\u6027 Mixup \u5c06\u4e24\u5f20\u56fe\u7ebf\u6027\u6df7\u5408 \u6539\u5584\u8fb9\u754c\u6cdb\u5316\u80fd\u529b CutMix \u5c06\u4e00\u5f20\u56fe\u7684\u4e00\u90e8\u5206\u8d34\u5230\u53e6\u4e00\u5f20\u56fe \u63d0\u5347\u9c81\u68d2\u6027 AutoAugment / RandAugment \u81ea\u52a8\u641c\u7d22\u6700\u4f73\u589e\u5f3a\u7b56\u7565 \u63d0\u5347\u6a21\u578b\u6027\u80fd"},{"location":"machine/interview/#nlp","title":"\u270d\ufe0f \u6587\u672c\u6570\u636e\u589e\u5f3a\u8be6\u89e3\uff08NLP\uff09","text":"<p>\u6587\u672c\u589e\u5f3a\u76f8\u5bf9\u66f4\u590d\u6742\uff0c\u56e0\u4e3a\u8bed\u8a00\u7ed3\u6784\u8981\u4fdd\u6301\u8bed\u4e49\u5408\u7406\u3002</p>"},{"location":"machine/interview/#1_6","title":"\u2705 1\ufe0f\u20e3 \u57fa\u672c\u7b56\u7565","text":"\u65b9\u6cd5 \u793a\u4f8b \u8bf4\u660e \u540c\u4e49\u8bcd\u66ff\u6362 \u201c\u6211\u5f88\u9ad8\u5174\u201d \u2192 \u201c\u6211\u975e\u5e38\u5f00\u5fc3\u201d \u66ff\u6362\u90e8\u5206\u8bcd\u6c47 \u968f\u673a\u63d2\u5165 \u201c\u6211\u53bb\u5403\u996d\u201d \u2192 \u201c\u6211\u9a6c\u4e0a\u53bb\u5403\u996d\u201d \u968f\u673a\u63d2\u5165\u76f8\u8fd1\u8bcd \u968f\u673a\u5220\u9664 \u201c\u6211\u4eca\u5929\u53bb\u4e0a\u5b66\u201d \u2192 \u201c\u6211\u53bb\u4e0a\u5b66\u201d \u5220\u9664\u4e0d\u5f71\u54cd\u8bed\u4e49\u7684\u8bcd \u968f\u673a\u4ea4\u6362 \u201c\u4ed6\u53bb\u4e86\u5317\u4eac\u201d \u2192 \u201c\u5317\u4eac\u4ed6\u53bb\u4e86\u201d \u6253\u4e71\u5c40\u90e8\u987a\u5e8f \u56de\u8bd1\uff08Back Translation\uff09 \u4e2d\u6587 \u2192 \u82f1\u6587 \u2192 \u4e2d\u6587 \u5229\u7528\u7ffb\u8bd1\u6a21\u578b\u751f\u6210\u65b0\u53e5\u5f0f EDA\uff08Easy Data Augmentation\uff09 \u7efc\u5408\u4ee5\u4e0a\u64cd\u4f5c \u7b80\u5355\u5b9e\u7528\u7684\u589e\u5f3a\u65b9\u6cd5 <p>\ud83d\udcd8 \u793a\u4f8b\uff08\u4f7f\u7528 nlpaug\uff09</p> <pre><code>import nlpaug.augmenter.word as naw\n\ntext = \"\u673a\u5668\u5b66\u4e60\u53ef\u4ee5\u8ba9\u8ba1\u7b97\u673a\u81ea\u5df1\u5b66\u4e60\u89c4\u5f8b\u3002\"\n\n# \u540c\u4e49\u8bcd\u66ff\u6362\u589e\u5f3a\naug = naw.SynonymAug(aug_src='wordnet')\naug_text = aug.augment(text)\n\nprint(\"\u539f\u53e5\uff1a\", text)\nprint(\"\u589e\u5f3a\u540e\uff1a\", aug_text)\n</code></pre> <p>\u8f93\u51fa\uff1a</p> <pre><code>\u539f\u53e5\uff1a \u673a\u5668\u5b66\u4e60\u53ef\u4ee5\u8ba9\u8ba1\u7b97\u673a\u81ea\u5df1\u5b66\u4e60\u89c4\u5f8b\u3002\n\u589e\u5f3a\u540e\uff1a \u673a\u5668\u5b66\u4e60\u80fd\u4f7f\u8ba1\u7b97\u673a\u81ea\u5df1\u5b66\u4e60\u89c4\u5f8b\u3002\n</code></pre>"},{"location":"machine/interview/#_37","title":"\u4e09\u3001\u7ebf\u6027\u6a21\u578b","text":""},{"location":"machine/interview/#31","title":"3.1 \u7ebf\u6027\u56de\u5f52","text":"<p>\u7ebf\u6027\u56de\u5f52\uff08Linear Regression\uff09 \u662f\u673a\u5668\u5b66\u4e60\u4e2d\u6700\u57fa\u7840\u7684\u76d1\u7763\u5b66\u4e60\u6a21\u578b\u4e4b\u4e00\uff0c\u7528\u4e8e \u9884\u6d4b\u4e00\u4e2a\u8fde\u7eed\u6570\u503c\u3002</p> <p>\u5176\u6838\u5fc3\u601d\u60f3\u662f\uff1a</p> <p>\u5bfb\u627e\u4e00\u4e2a\u6700\u4f18\u7684\u7ebf\u6027\u51fd\u6570\uff0c\u4f7f\u9884\u6d4b\u503c \\(\\hat{y}\\) \u4e0e\u771f\u5b9e\u503c \\(y\\) \u4e4b\u95f4\u7684\u8bef\u5dee\u6700\u5c0f\u3002</p>"},{"location":"machine/interview/#1_7","title":"1\ufe0f\u20e3 \u539f\u7406","text":""},{"location":"machine/interview/#_38","title":"\u4e00\u5143\u7ebf\u6027\u56de\u5f52","text":"<p>\u5047\u8bbe\u8f93\u5165\u7279\u5f81\u53ea\u6709\u4e00\u4e2a ( x )\uff0c\u8f93\u51fa\u4e3a ( y )\uff1a</p> \\[ \\hat{y} = w x + b \\] <p>\u5176\u4e2d\uff1a</p> <ul> <li>$ \\hat{y} $\uff1a\u9884\u6d4b\u503c</li> <li>$ w $\uff1a\u6743\u91cd\uff08\u659c\u7387\uff09</li> <li>$b $\uff1a\u504f\u7f6e\uff08\u622a\u8ddd\uff09</li> </ul> <p>\u76ee\u6807\u662f\uff1a\u627e\u5230\u6700\u4f73\u7684 \\(w\\)\u3001\\(b\\)\uff0c\u4f7f\u5f97\u9884\u6d4b\u7ed3\u679c\u6700\u63a5\u8fd1\u771f\u5b9e\u503c\u3002</p>"},{"location":"machine/interview/#_39","title":"\u591a\u5143\u7ebf\u6027\u56de\u5f52","text":"<p>\u5f53\u7279\u5f81\u6709\u591a\u4e2a $x_1, x_2, ..., x_n $ \u65f6\uff1a</p> \\[ \\hat{y} = w_1 x_1 + w_2 x_2 + \\dots + w_n x_n + b \\] <p>\u6216\u8005\u7528\u5411\u91cf\u5f62\u5f0f\u8868\u793a\u4e3a\uff1a</p> \\[ \\hat{y} = \\mathbf{w}^\\top \\mathbf{x} + b \\]"},{"location":"machine/interview/#_40","title":"\u5cad\u56de\u5f52","text":"<p>\u5cad\u56de\u5f52\u662f \u7ebf\u6027\u56de\u5f52\u7684\u4e00\u79cd\u6539\u8fdb\uff0c\u4e3b\u8981\u7528\u4e8e\u89e3\u51b3 \u591a\u91cd\u5171\u7ebf\u6027\uff08\u7279\u5f81\u9ad8\u5ea6\u76f8\u5173\uff09 \u6216 \u8fc7\u62df\u5408 \u95ee\u9898\u3002</p> <p>\u6838\u5fc3\u601d\u60f3\uff1a</p> <p>\u5728\u6700\u5c0f\u5316\u9884\u6d4b\u8bef\u5dee\u7684\u57fa\u7840\u4e0a\uff0c\u589e\u52a0\u5bf9\u6743\u91cd\u7684 L2 \u6b63\u5219\u5316\u7ea6\u675f\uff0c\u4f7f\u6a21\u578b\u6743\u91cd\u4e0d\u81f3\u4e8e\u8fc7\u5927\u3002</p> <p>\u7ebf\u6027\u56de\u5f52\u7684\u635f\u5931\u51fd\u6570\uff08\u5747\u65b9\u8bef\u5dee\uff09\u4e3a\uff1a</p> \\[ J(\\mathbf{w}) = \\frac{1}{2m} \\sum_{i=1}^{m} (\\hat{y}^{(i)} - y^{(i)})^2 \\] <p>\u5cad\u56de\u5f52\u5728\u6b64\u57fa\u7840\u4e0a\u589e\u52a0 L2 \u6b63\u5219\u5316\u9879\uff1a</p> \\[ J_{\\text{ridge}}(\\mathbf{w}) = \\frac{1}{2m} \\sum_{i=1}^{m} (\\hat{y}^{(i)} - y^{(i)})^2 + \\frac{\\lambda}{2} \\sum_{j=1}^{n} w_j^2 \\] <p>\u5176\u4e2d\uff1a</p> <ul> <li>\\(\\lambda \\ge 0\\) \u662f \u6b63\u5219\u5316\u7cfb\u6570</li> <li>\\(w_j\\) \u662f\u6a21\u578b\u7684\u6743\u91cd</li> <li>\u5f53 \\(\\lambda = 0\\) \u65f6\uff0c\u9000\u5316\u4e3a\u666e\u901a\u7ebf\u6027\u56de\u5f52</li> <li>\u5f53 \\(\\lambda\\) \u589e\u5927\u65f6\uff0c\u6a21\u578b\u6743\u91cd\u88ab\u538b\u7f29\uff0c\u51cf\u5c11\u8fc7\u62df\u5408</li> </ul>"},{"location":"machine/interview/#_41","title":"\u89e3\u6790\u89e3\uff08\u6b63\u89c4\u65b9\u7a0b\uff09","text":"<p>\u52a0\u5165 L2 \u6b63\u5219\u5316\u540e\u7684\u89e3\u6790\u89e3\u4e3a\uff1a</p> \\[ \\mathbf{w} = (\\mathbf{X}^\\top \\mathbf{X} + \\lambda \\mathbf{I})^{-1} \\mathbf{X}^\\top \\mathbf{y} \\] <p>\u5176\u4e2d\uff1a</p> <ul> <li>\\(\\mathbf{I}\\) \u662f \\(n \\times n\\) \u5355\u4f4d\u77e9\u9635</li> <li>\u6b63\u5219\u5316\u9879\u4fdd\u8bc1\u77e9\u9635 \u53ef\u9006\uff0c\u89e3\u51b3\u591a\u91cd\u5171\u7ebf\u6027\u95ee\u9898</li> </ul> <p>\u6ce8\u610f\uff1a\u504f\u7f6e \\(b\\) \u901a\u5e38\u4e0d\u6b63\u5219\u5316\u3002</p>"},{"location":"machine/interview/#_42","title":"\u68af\u5ea6\u4e0b\u964d\u6cd5","text":"<p>\u5cad\u56de\u5f52\u68af\u5ea6\u66f4\u65b0\u516c\u5f0f\uff1a</p> \\[ \\frac{\\partial J_{\\text{ridge}}}{\\partial w_j} = \\frac{1}{m} \\sum_{i=1}^{m} (\\hat{y}^{(i)} - y^{(i)}) x_j^{(i)} + \\lambda w_j \\] <p>\u66f4\u65b0\u89c4\u5219\uff1a</p> \\[ w_j := w_j - \\alpha \\left( \\frac{1}{m} \\sum_{i=1}^{m} (\\hat{y}^{(i)} - y^{(i)}) x_j^{(i)} + \\lambda w_j \\right) \\] <p>\u5176\u4e2d \\(\\alpha\\) \u4e3a\u5b66\u4e60\u7387\u3002</p> <pre><code>import numpy as np\nfrom sklearn.linear_model import Ridge\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# \u6784\u9020\u793a\u4f8b\u6570\u636e\nnp.random.seed(42)\nX = np.random.rand(100, 5)\ny = X @ np.array([1.5, -2.0, 0.5, 3.0, -1.0]) + np.random.randn(100) * 0.5\n\n# \u5212\u5206\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# \u8bad\u7ec3\u5cad\u56de\u5f52\u6a21\u578b\nridge = Ridge(alpha=1.0)  # alpha = \u03bb\nridge.fit(X_train, y_train)\n\n# \u9884\u6d4b\ny_pred = ridge.predict(X_test)\n\n# \u6a21\u578b\u8bc4\u4f30\nprint(\"\u7cfb\u6570 w:\", ridge.coef_)\nprint(\"\u622a\u8ddd b:\", ridge.intercept_)\nprint(\"MSE:\", mean_squared_error(y_test, y_pred))\nprint(\"R\u00b2:\", r2_score(y_test, y_pred))\n</code></pre>"},{"location":"machine/interview/#lasso","title":"Lasso\u56de\u5f52","text":"<p>Lasso \u56de\u5f52\uff08Least Absolute Shrinkage and Selection Operator\uff09 \u662f\u5728\u7ebf\u6027\u56de\u5f52\u7684\u57fa\u7840\u4e0a\u52a0\u5165 L1 \u6b63\u5219\u5316\u9879 \u7684\u6a21\u578b\u3002 \u5b83\u4e0d\u4ec5\u80fd\u9632\u6b62\u8fc7\u62df\u5408\uff0c\u8fd8\u80fd\u5b9e\u73b0 \u7279\u5f81\u9009\u62e9\uff08Feature Selection\uff09\uff0c\u56e0\u4e3a\u5b83\u4f1a\u4f7f\u90e8\u5206\u7279\u5f81\u7cfb\u6570\u53d8\u4e3a 0\u3002</p>"},{"location":"machine/interview/#_43","title":"\u2699\ufe0f \u6a21\u578b\u539f\u7406","text":"<p>\u5728\u666e\u901a\u7ebf\u6027\u56de\u5f52\u4e2d\uff0c\u6211\u4eec\u5e0c\u671b\u6700\u5c0f\u5316\u6b8b\u5dee\u5e73\u65b9\u548c\uff1a</p> \\[ J(\\mathbf{w}) = \\frac{1}{2m} \\sum_{i=1}^{m} (y_i - \\hat{y}*i)^2 = \\frac{1}{2m} \\sum*{i=1}^{m} (y_i - \\mathbf{w}^T \\mathbf{x}_i)^2 \\] <p>\u800c\u5728 Lasso \u56de\u5f52 \u4e2d\uff0c\u6211\u4eec\u5728\u635f\u5931\u51fd\u6570\u4e2d\u52a0\u5165\u4e00\u4e2a L1 \u6b63\u5219\u5316\u9879\uff1a</p> \\[ J(\\mathbf{w}) = \\frac{1}{2m} \\sum_{i=1}^{m} (y_i - \\mathbf{w}^T \\mathbf{x}*i)^2 + \\lambda \\sum*{j=1}^{n} |w_j| \\] <p>\u5176\u4e2d\uff1a</p> <ul> <li>\\(\\lambda\\) \u4e3a\u6b63\u5219\u5316\u5f3a\u5ea6\uff08\u8d85\u53c2\u6570\uff09\uff0c\u63a7\u5236\u6a21\u578b\u590d\u6742\u5ea6\uff1b</li> <li>\\(|w_j|\\) \u662f\u6743\u91cd\u7684\u7edd\u5bf9\u503c\uff1b</li> <li>L1 \u6b63\u5219\u5316\u9f13\u52b1\u6743\u91cd\u7a00\u758f\uff08\u90e8\u5206\u6743\u91cd\u4e3a 0\uff09\u3002</li> </ul>"},{"location":"machine/interview/#_44","title":"\ud83e\uddee \u6570\u5b66\u63a8\u5bfc","text":"<p>1. \u635f\u5931\u51fd\u6570</p> <p>\u6211\u4eec\u6700\u5c0f\u5316\u5982\u4e0b\u76ee\u6807\uff1a $$ \\min_{\\mathbf{w}} \\frac{1}{2m} |\\mathbf{y} - X\\mathbf{w}|_2^2 + \\lambda |\\mathbf{w}|_1 $$</p> <p>\u5176\u4e2d\uff1a</p> <ul> <li>\\(|\\mathbf{w}|_1 = \\sum_j |w_j|\\)</li> <li>\\(|\\cdot|_2^2\\) \u8868\u793a\u5e73\u65b9\u548c\u3002</li> </ul> <p>2. L1 \u7684\u4e0d\u53ef\u5bfc\u6027</p> <p>\u7531\u4e8e \\(|w_j|\\) \u5728 \\(w_j=0\\) \u5904\u4e0d\u53ef\u5bfc\uff0c\u68af\u5ea6\u4e0b\u964d\u4e0d\u80fd\u76f4\u63a5\u4f7f\u7528\u3002 \u56e0\u6b64\uff0cLasso \u56de\u5f52\u7684\u6c42\u89e3\u901a\u5e38\u91c7\u7528 \u5750\u6807\u4e0b\u964d\u6cd5\uff08Coordinate Descent\uff09 \u6216 \u6b21\u68af\u5ea6\u6cd5\uff08Subgradient Method\uff09\u3002</p> <p>3. \u5750\u6807\u4e0b\u964d\u6cd5\uff08Coordinate Descent\uff09</p> <p>\u5728\u6bcf\u4e2a\u7279\u5f81\u7ef4\u5ea6\u4e0a\u5355\u72ec\u4f18\u5316\uff1a</p> \\[ w_j \\leftarrow S\\left( \\frac{1}{m} \\sum_{i=1}^{m} x_{ij}(y_i - \\hat{y}_{i, -j}), \\frac{\\lambda}{m} \\right) \\] <p>\u5176\u4e2d \\(S\\) \u662f \u8f6f\u9608\u503c\u51fd\u6570\uff08Soft Thresholding Function\uff09\uff1a</p> \\[ S(z, \\gamma) = \\begin{cases} z - \\gamma, &amp; \\text{if } z &gt; \\gamma \\ 0, &amp; \\text{if } |z| \\le \\gamma \\ z + \\gamma, &amp; \\text{if } z &lt; -\\gamma \\end{cases} \\] <p>\u8be5\u51fd\u6570\u80fd\u81ea\u52a8\u628a\u5c0f\u4e8e\u9608\u503c\u7684\u6743\u91cd\u538b\u7f29\u4e3a 0\uff0c\u4ece\u800c\u5b9e\u73b0 \u7279\u5f81\u9009\u62e9\u3002</p> <pre><code>from sklearn.linear_model import Lasso\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.datasets import load_boston\nimport numpy as np\n\n# \u52a0\u8f7d\u6570\u636e\nX, y = load_boston(return_X_y=True)\n\n# \u5212\u5206\u6570\u636e\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# \u521b\u5efa\u5e76\u8bad\u7ec3 Lasso \u56de\u5f52\u6a21\u578b\nlasso = Lasso(alpha=0.1)\nlasso.fit(X_train, y_train)\n\n# \u9884\u6d4b\ny_pred = lasso.predict(X_test)\n\n# \u8bc4\u4f30\nprint(\"MSE:\", mean_squared_error(y_test, y_pred))\nprint(\"R\u00b2:\", r2_score(y_test, y_pred))\nprint(\"\u7cfb\u6570:\", lasso.coef_)\n</code></pre>"},{"location":"machine/interview/#_45","title":"\u26a0\ufe0f \u6ce8\u610f\u4e8b\u9879","text":"<ol> <li> <p>\u7279\u5f81\u6807\u51c6\u5316</p> <ul> <li>\u5728\u4f7f\u7528 Lasso \u524d\u5fc5\u987b\u5bf9\u7279\u5f81\u8fdb\u884c \u6807\u51c6\u5316\uff08StandardScaler\uff09\uff0c\u5426\u5219\u4e0d\u540c\u91cf\u7eb2\u7684\u7279\u5f81\u4f1a\u53d7\u5230\u4e0d\u540c\u60e9\u7f5a\u3002</li> </ul> </li> <li> <p>\u8d85\u53c2\u6570 \u03bb \u7684\u9009\u62e9</p> <ul> <li>\\(\\lambda\\) \u8fc7\u5927 \u2192 \u7cfb\u6570\u5168\u90e8\u8d8b\u8fd1\u4e8e 0\uff1b</li> <li>\\(\\lambda\\) \u8fc7\u5c0f \u2192 \u9000\u5316\u4e3a\u666e\u901a\u7ebf\u6027\u56de\u5f52\uff1b</li> <li>\u53ef\u901a\u8fc7\u4ea4\u53c9\u9a8c\u8bc1\uff08\u5982 <code>LassoCV</code>\uff09\u81ea\u52a8\u9009\u62e9\u6700\u4f73\u53c2\u6570\u3002</li> </ul> </li> <li> <p>\u591a\u91cd\u5171\u7ebf\u6027\u95ee\u9898</p> <ul> <li>Lasso \u80fd\u81ea\u52a8\u201c\u5254\u9664\u201d\u5197\u4f59\u7279\u5f81\uff0c\u56e0\u6b64\u5728\u591a\u91cd\u5171\u7ebf\u6027\u95ee\u9898\u4e2d\u8868\u73b0\u8f83\u597d\u3002</li> </ul> </li> </ol>"},{"location":"machine/interview/#_46","title":"\u5f39\u6027\u7f51\u7edc\u56de\u5f52","text":"<p>\u5f39\u6027\u7f51\u7edc\uff08Elastic Net\uff09 \u662f\u4e00\u79cd\u5728 Lasso \u7684\u57fa\u7840\u4e0a\u52a0\u5165 L2 \u6b63\u5219\u5316 \u7684\u7ebf\u6027\u6a21\u578b\u3002 \u5b83\u5728\u4fdd\u8bc1\u7279\u5f81\u9009\u62e9\u80fd\u529b\u7684\u540c\u65f6\uff0c\u7f13\u89e3\u4e86 Lasso \u5728\u7279\u5f81\u9ad8\u5ea6\u76f8\u5173\u65f6\u7684\u4e0d\u7a33\u5b9a\u6027\u95ee\u9898\u3002</p>"},{"location":"machine/interview/#_47","title":"\u2699\ufe0f \u6a21\u578b\u539f\u7406","text":"<p>\u666e\u901a\u7ebf\u6027\u56de\u5f52\u7684\u76ee\u6807\u51fd\u6570\u4e3a\uff1a</p> \\[ J(\\mathbf{w}) = \\frac{1}{2m} \\sum_{i=1}^{m} (y_i - \\mathbf{w}^T \\mathbf{x}_i)^2 \\] <p>\u800c\u5f39\u6027\u7f51\u7edc\u5728\u6b64\u57fa\u7840\u4e0a\u52a0\u5165\u4e86 L1 + L2 \u6b63\u5219\u9879\uff1a</p> \\[ J(\\mathbf{w}) = \\frac{1}{2m} \\sum_{i=1}^{m} (y_i - \\mathbf{w}^T \\mathbf{x}*i)^2 + \\lambda_1 \\sum*{j=1}^{n} |w_j| + \\frac{\\lambda_2}{2} \\sum_{j=1}^{n} w_j^2 \\] <p>\u4e3a\u4e86\u66f4\u65b9\u4fbf\u8c03\u8282\uff0c\u901a\u5e38\u5c06\u5b83\u6539\u5199\u4e3a\u5e26\u6709\u6df7\u5408\u7cfb\u6570\u7684\u5f62\u5f0f\uff1a</p> \\[ J(\\mathbf{w}) = \\frac{1}{2m} |\\mathbf{y} - X\\mathbf{w}|_2^2 + \\lambda \\left( \\alpha |\\mathbf{w}|_1 + \\frac{1 - \\alpha}{2} |\\mathbf{w}|_2^2 \\right) \\] <p>\u5176\u4e2d\uff1a</p> <ul> <li>\\(\\lambda\\) \u63a7\u5236\u6574\u4f53\u6b63\u5219\u5316\u5f3a\u5ea6\uff1b</li> <li> <p>\\(\\alpha \\in [0,1]\\) \u63a7\u5236 L1 \u548c L2 \u7684\u6bd4\u4f8b\uff1a</p> </li> <li> <p>\\(\\alpha = 1\\) \u2192 Lasso \u56de\u5f52\uff1b</p> </li> <li>\\(\\alpha = 0\\) \u2192 \u5cad\u56de\u5f52\uff1b</li> <li>\\(0 &lt; \\alpha &lt; 1\\) \u2192 \u5f39\u6027\u7f51\u7edc\u3002</li> </ul>"},{"location":"machine/interview/#_48","title":"\ud83e\uddee \u6570\u5b66\u63a8\u5bfc\u601d\u8def","text":"<p>\u5f39\u6027\u7f51\u7edc\u7684\u76ee\u6807\u662f\u540c\u65f6\u6700\u5c0f\u5316\uff1a</p> <ul> <li>\u6b8b\u5dee\u5e73\u65b9\u548c\uff1b</li> <li>\u6743\u91cd\u7684 \u7edd\u5bf9\u503c\u4e4b\u548c\uff08\u7a00\u758f\u6027\uff09\uff1b</li> <li>\u6743\u91cd\u7684 \u5e73\u65b9\u548c\uff08\u7a33\u5b9a\u6027\uff09\u3002</li> </ul> <p>\u7531\u4e8e L1 \u9879\u4e0d\u53ef\u5bfc\uff0c\u56e0\u6b64\u4f7f\u7528 \u5750\u6807\u4e0b\u964d\u6cd5\uff08Coordinate Descent\uff09 \u6c42\u89e3\u3002</p> <p>\u5176\u66f4\u65b0\u516c\u5f0f\u7c7b\u4f3c\u4e8e Lasso \u7684\u8f6f\u9608\u503c\u51fd\u6570\uff1a</p> \\[ w_j \\leftarrow \\frac{S\\left(\\frac{1}{m}\\sum_{i=1}^{m} x_{ij}(y_i - \\hat{y}_{i,-j}), \\lambda \\alpha\\right)}{1 + \\lambda (1-\\alpha)} \\] <p>\u5176\u4e2d \\(S(z, \\gamma)\\) \u4e3a\u8f6f\u9608\u503c\u51fd\u6570\uff1a</p> \\[ S(z, \\gamma) = \\begin{cases} z - \\gamma, &amp; z &gt; \\gamma \\ 0, &amp; |z| \\le \\gamma \\ z + \\gamma, &amp; z &lt; -\\gamma \\end{cases} \\] <p>L2 \u9879\u7684\u5b58\u5728\u4f7f\u5f97\u5206\u6bcd\u4e2d\u591a\u4e86 \\(1 + \\lambda(1-\\alpha)\\)\uff0c\u8fd9\u4f1a\u9632\u6b62\u6743\u91cd\u8fc7\u5ea6\u538b\u7f29\uff0c\u7f13\u89e3 Lasso \u7684\u4e0d\u7a33\u5b9a\u6027\u3002</p> \u6a21\u578b \u6b63\u5219\u5316\u51e0\u4f55\u5f62\u72b6 \u7279\u5f81\u9009\u62e9\u80fd\u529b \u7a33\u5b9a\u6027 Ridge \u5706\u5f62\uff08L2\uff09 \u65e0 \u5f3a Lasso \u83f1\u5f62\uff08L1\uff09 \u5f3a \u5f31\uff08\u76f8\u5173\u7279\u5f81\u4e0d\u7a33\u5b9a\uff09 ElasticNet \u5706\u89d2\u83f1\u5f62\uff08L1+L2\uff09 \u4e2d\u7b49 \u4e2d\u7b49\u504f\u5f3a \u6a21\u578b \u6b63\u5219\u9879 \u7a00\u758f\u6027 \u591a\u91cd\u5171\u7ebf\u6027\u5904\u7406 \u9002\u7528\u573a\u666f \u7ebf\u6027\u56de\u5f52 \u65e0 \u65e0 \u5dee \u65e0\u7ea6\u675f\u6570\u636e \u5cad\u56de\u5f52 L2 \u65e0 \u597d \u9632\u6b62\u8fc7\u62df\u5408 Lasso \u56de\u5f52 L1 \u5f3a \u5dee \u7279\u5f81\u9009\u62e9 \u5f39\u6027\u7f51\u7edc L1 + L2 \u4e2d\u7b49 \u597d \u9ad8\u7ef4\u7a00\u758f\u6570\u636e <pre><code>from sklearn.linear_model import ElasticNet\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.datasets import load_diabetes\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.preprocessing import StandardScaler\n\n# \u52a0\u8f7d\u6570\u636e\nX, y = load_diabetes(return_X_y=True)\n\n# \u6807\u51c6\u5316\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\n\n# \u5212\u5206\u8bad\u7ec3\u96c6\u4e0e\u6d4b\u8bd5\u96c6\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# \u8bad\u7ec3\u6a21\u578b\nelastic = ElasticNet(alpha=0.1, l1_ratio=0.5)  # \u03b1\u63a7\u5236L1\u4e0eL2\u6bd4\u4f8b\nelastic.fit(X_train, y_train)\n\n# \u9884\u6d4b\ny_pred = elastic.predict(X_test)\n\n# \u8bc4\u4f30\nprint(\"MSE:\", mean_squared_error(y_test, y_pred))\nprint(\"R\u00b2:\", r2_score(y_test, y_pred))\nprint(\"\u7cfb\u6570:\", elastic.coef_)\n</code></pre>"},{"location":"machine/interview/#2_5","title":"2\ufe0f\u20e3 \u635f\u5931\u51fd\u6570","text":"<p>\u7ebf\u6027\u56de\u5f52\u5e38\u7528\u7684\u635f\u5931\u51fd\u6570\u662f \u5747\u65b9\u8bef\u5dee\uff08MSE\uff09\uff1a</p> \\[ \\text{MSE} = \\frac{1}{m}\\sum_{i=1}^{m} (\\hat{y}^{(i)} - y^{(i)})^2 \\] <p>\u5176\u4ed6\u5e38\u89c1\u7684\u6709\uff1a</p> <ul> <li>MAE\uff08\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\uff09\uff1a $$   \\text{MAE} = \\frac{1}{m}\\sum | \\hat{y} - y | $$</li> <li>RMSE\uff08\u5747\u65b9\u6839\u8bef\u5dee\uff09\uff1a $$   \\text{RMSE} = \\sqrt{\\text{MSE}} $$</li> </ul>"},{"location":"machine/interview/#3_2","title":"3\ufe0f\u20e3 \u6570\u5b66\u63a8\u5bfc\u8fc7\u7a0b","text":"<p>\u6211\u4eec\u6765\u63a8\u5bfc\u51fa\u6700\u4f18\u53c2\u6570 \\(\\mathbf{w}\\) \u7684\u89e3\u6790\u89e3\uff08\u6b63\u89c4\u65b9\u7a0b\u6cd5\uff09\u3002</p>"},{"location":"machine/interview/#1_8","title":"1\ufe0f\u20e3 \u5411\u91cf\u5316\u8868\u793a","text":"<p>\u8bbe\uff1a</p> <ul> <li>\\(\\mathbf{X}\\) \u4e3a\u7279\u5f81\u77e9\u9635\uff08\u7ef4\u5ea6\uff1a\\(m \\times n\\)\uff09</li> <li>\\(\\mathbf{y}\\) \u4e3a\u771f\u5b9e\u6807\u7b7e\uff08\u7ef4\u5ea6\uff1a\\(m \\times 1\\)\uff09</li> <li>\\(\\mathbf{w}\\) \u4e3a\u6743\u91cd\u5411\u91cf\uff08\u7ef4\u5ea6\uff1a\\(n \\times 1\\)\uff09</li> </ul> <p>\u6a21\u578b\u53ef\u5199\u4e3a\uff1a</p> \\[ \\hat{\\mathbf{y}} = \\mathbf{X} \\mathbf{w} \\] <p>\u635f\u5931\u51fd\u6570\u4e3a\uff1a</p> \\[ J(\\mathbf{w}) = \\frac{1}{2m} (\\mathbf{Xw} - \\mathbf{y})^\\top (\\mathbf{Xw} - \\mathbf{y}) \\]"},{"location":"machine/interview/#2_6","title":"2\ufe0f\u20e3 \u5bf9\u53c2\u6570\u6c42\u5bfc","text":"<p>\u6211\u4eec\u5bf9 \\(\\mathbf{w}\\) \u6c42\u504f\u5bfc\uff1a</p> \\[ \\frac{\\partial J}{\\partial \\mathbf{w}} = \\frac{1}{m} \\mathbf{X}^\\top (\\mathbf{Xw} - \\mathbf{y}) \\] <p>\u4ee4\u5bfc\u6570\u4e3a 0\uff0c\u5f97\u5230\u6700\u4f18\u89e3\uff1a</p> \\[ \\mathbf{X}^\\top \\mathbf{Xw} = \\mathbf{X}^\\top \\mathbf{y} \\]"},{"location":"machine/interview/#3_3","title":"3\ufe0f\u20e3 \u89e3\u51fa\u53c2\u6570\uff08\u6b63\u89c4\u65b9\u7a0b\uff09","text":"\\[ \\mathbf{w} = (\\mathbf{X}^\\top \\mathbf{X})^{-1} \\mathbf{X}^\\top \\mathbf{y} \\] <p>\u8fd9\u662f \u7ebf\u6027\u56de\u5f52\u7684\u89e3\u6790\u89e3\uff0c\u524d\u63d0\u662f \\(\\mathbf{X}^\\top \\mathbf{X}\\) \u53ef\u9006\u3002</p>"},{"location":"machine/interview/#4_4","title":"4\ufe0f\u20e3 \u68af\u5ea6\u4e0b\u964d\u6cd5\uff08\u6570\u503c\u89e3\uff09","text":"<p>\u82e5\u7279\u5f81\u8f83\u591a\u6216\u77e9\u9635\u4e0d\u53ef\u9006\uff0c\u53ef\u4f7f\u7528\u68af\u5ea6\u4e0b\u964d\u6cd5\u8fed\u4ee3\u6c42\u89e3\uff1a</p> <p>\u66f4\u65b0\u89c4\u5219\uff1a</p> \\[ \\begin{aligned} w_j &amp;:= w_j - \\alpha \\frac{\\partial J}{\\partial w_j} \\ b &amp;:= b - \\alpha \\frac{\\partial J}{\\partial b} \\end{aligned} \\] <p>\u5176\u4e2d\u5b66\u4e60\u7387 \\(\\alpha\\) \u63a7\u5236\u6bcf\u6b21\u66f4\u65b0\u7684\u6b65\u957f\u3002</p> <p>\u5bfc\u6570\u5c55\u5f00\u4e3a\uff1a</p> \\[ \\frac{\\partial J}{\\partial w_j} = \\frac{1}{m} \\sum_{i=1}^{m} (\\hat{y}^{(i)} - y^{(i)}) x_j^{(i)} \\] \\[ \\frac{\\partial J}{\\partial b} = \\frac{1}{m} \\sum_{i=1}^{m} (\\hat{y}^{(i)} - y^{(i)}) \\]"},{"location":"machine/interview/#4_5","title":"4\ufe0f\u20e3 \u8bc4\u4f30\u6307\u6807","text":"<p>\u7ebf\u6027\u56de\u5f52\u5e38\u7528\u4ee5\u4e0b\u6307\u6807\u8bc4\u4f30\u6a21\u578b\u6027\u80fd\uff1a</p> \u6307\u6807 \u516c\u5f0f \u542b\u4e49 \u7406\u60f3\u503c MSE\uff08\u5747\u65b9\u8bef\u5dee\uff09 \\(\\frac{1}{m}\\sum (\\hat{y} - y)^2\\) \u8861\u91cf\u8bef\u5dee\u5e73\u65b9\u7684\u5e73\u5747\u503c \u8d8a\u5c0f\u8d8a\u597d RMSE\uff08\u5747\u65b9\u6839\u8bef\u5dee\uff09 \\(\\sqrt{\\frac{1}{m}\\sum (\\hat{y} - y)^2}\\) \u4e0e\u539f\u91cf\u7eb2\u4e00\u81f4 \u8d8a\u5c0f\u8d8a\u597d MAE\uff08\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\uff09 $ \\frac{1}{m}\\sum \\lvert  \\hat{y} - y \\rvert$ \u5bf9\u5f02\u5e38\u503c\u66f4\u9c81\u68d2 \u8d8a\u5c0f\u8d8a\u597d R\u00b2\uff08\u51b3\u5b9a\u7cfb\u6570\uff09 \\(R^2 = 1 - \\frac{\\sum (y_i - \\hat{y}_i)^2}{\\sum (y_i - \\bar{y})^2}\\) \u53cd\u6620\u62df\u5408\u7a0b\u5ea6 \u8d8a\u63a5\u8fd1 1 \u8d8a\u597d \\[ R^2 = 1 - \\frac{\\sum (y_i - \\hat{y}_i)^2}{\\sum (y_i - \\bar{y})^2} \\]"},{"location":"machine/interview/#5_1","title":"5\ufe0f\u20e3 \u5b9e\u73b0\u4ee3\u7801","text":"<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.datasets import make_regression\nfrom sklearn.preprocessing import StandardScaler\n\n# \u751f\u6210\u793a\u4f8b\u6570\u636e\nX, y = make_regression(n_samples=100, n_features=1, noise=10, random_state=42)\n\n# \u6570\u636e\u6807\u51c6\u5316\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# \u5212\u5206\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n\n# \u521b\u5efa\u5e76\u8bad\u7ec3\u6a21\u578b\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# \u9884\u6d4b\ny_pred = model.predict(X_test)\n\n# \u8bc4\u4f30\u6a21\u578b\nmse = mean_squared_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n\nprint(f\"\u5747\u65b9\u8bef\u5dee(MSE): {mse:.2f}\")\nprint(f\"R\u00b2\u5206\u6570: {r2:.2f}\")\nprint(f\"\u7cfb\u6570: {model.coef_}\")\nprint(f\"\u622a\u8ddd: {model.intercept_:.2f}\")\n\n# \u53ef\u89c6\u5316\u7ed3\u679c\nplt.figure(figsize=(10, 6))\nplt.scatter(X_test, y_test, color='blue', label='\u5b9e\u9645\u503c')\nplt.plot(X_test, y_pred, color='red', linewidth=2, label='\u9884\u6d4b\u503c')\nplt.xlabel('\u7279\u5f81')\nplt.ylabel('\u76ee\u6807')\nplt.title('\u7ebf\u6027\u56de\u5f52\u7ed3\u679c')\nplt.legend()\nplt.show()\n</code></pre>"},{"location":"machine/interview/#6_1","title":"6\ufe0f\u20e3 \u6a21\u578b\u4f18\u5316\uff08\u53c2\u6570\u8c03\u4f18\uff09","text":"<pre><code>from sklearn.model_selection import GridSearchCV\n\n# \u53c2\u6570\u7f51\u683c\nparam_grid = {\n    'alpha': [0.001, 0.01, 0.1, 1, 10, 100],\n    'l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9]\n}\n\n# \u7f51\u683c\u641c\u7d22\ngrid_search = GridSearchCV(ElasticNet(), param_grid, cv=5, scoring='r2')\ngrid_search.fit(X_train, y_train)\n\nprint(f\"\u6700\u4f73\u53c2\u6570: {grid_search.best_params_}\")\nprint(f\"\u6700\u4f73\u5206\u6570: {grid_search.best_score_:.3f}\")\n</code></pre>"},{"location":"machine/interview/#7_1","title":"7\ufe0f\u20e3 \u6ce8\u610f\u4e8b\u9879","text":"\u95ee\u9898 \u8bf4\u660e \u89e3\u51b3\u65b9\u6cd5 \u591a\u91cd\u5171\u7ebf\u6027 \u7279\u5f81\u9ad8\u5ea6\u76f8\u5173\u5bfc\u81f4\u77e9\u9635\u4e0d\u53ef\u9006 \u4f7f\u7528\u5cad\u56de\u5f52\uff08L2\u6b63\u5219\u5316\uff09 \u5f02\u5e38\u503c\u654f\u611f \u6781\u7aef\u6837\u672c\u4f1a\u4e25\u91cd\u5f71\u54cd\u6a21\u578b \u53bb\u9664\u6216\u9c81\u68d2\u56de\u5f52 \u7ebf\u6027\u5047\u8bbe \u6a21\u578b\u5047\u8bbe\u8f93\u5165\u4e0e\u8f93\u51fa\u7ebf\u6027\u5173\u7cfb \u53ef\u52a0\u5165\u591a\u9879\u5f0f\u7279\u5f81 \u5f02\u65b9\u5dee\u6027 \u6b8b\u5dee\u65b9\u5dee\u4e0d\u4e00\u81f4 \u5bf9\u6570\u53d8\u6362\u6216\u52a0\u6743\u56de\u5f52 \u7279\u5f81\u7f29\u653e \u68af\u5ea6\u4e0b\u964d\u6536\u655b\u901f\u5ea6\u6162 \u6807\u51c6\u5316\u6216\u5f52\u4e00\u5316"},{"location":"machine/interview/#32","title":"3.2 \u903b\u8f91\u56de\u5f52","text":"<p>\u903b\u8f91\u56de\u5f52\u662f\u4e00\u79cd\u7528\u4e8e\u4e8c\u5206\u7c7b\u95ee\u9898\u7684\u7ebf\u6027\u6a21\u578b\u3002 \u4e0e\u7ebf\u6027\u56de\u5f52\u4e0d\u540c\u7684\u662f\uff0c\u5b83\u7684\u8f93\u51fa\u662f\u4e00\u4e2a\u6982\u7387\u503c\uff08\u8303\u56f4 \\([0,1]\\)\uff09\uff0c\u7136\u540e\u901a\u8fc7\u9608\u503c\uff08\u901a\u5e38\u4e3a 0.5\uff09\u5c06\u6837\u672c\u5206\u7c7b\u4e3a\u6b63\u7c7b\u6216\u8d1f\u7c7b\u3002</p>"},{"location":"machine/interview/#1_9","title":"1\ufe0f\u20e3 \u539f\u7406","text":"<p>\u5047\u8bbe\u8f93\u5165\u6837\u672c\u4e3a \\(x = (x_1, x_2, \\dots, x_n)\\)\uff0c\u6a21\u578b\u53c2\u6570\u4e3a \\(\\theta = (\\theta_0, \\theta_1, \\dots, \\theta_n)\\)\uff0c\u903b\u8f91\u56de\u5f52\u5047\u8bbe\uff1a</p> \\[ z = \\theta^T x = \\theta_0 + \\theta_1 x_1 + \\dots + \\theta_n x_n \\] <p>\u7136\u540e\u4f7f\u7528 Sigmoid \u51fd\u6570 \u5c06 \\(z\\) \u6620\u5c04\u5230 \\([0,1]\\)\uff1a</p> \\[ h_\\theta(x) = \\sigma(z) = \\frac{1}{1 + e^{-z}} \\] <p>\u6b64\u65f6 \\(h_\\theta(x)\\) \u8868\u793a\u6837\u672c\u5c5e\u4e8e\u6b63\u7c7b\uff08\\(y=1\\)\uff09\u7684\u6982\u7387\u3002</p>"},{"location":"machine/interview/#_49","title":"\u5206\u7c7b\u89c4\u5219","text":"\\[ \\hat{y} = \\begin{cases} 1, &amp; \\text{if } h_\\theta(x) \\ge 0.5 \\\\ 0, &amp; \\text{if } h_\\theta(x) &lt; 0.5 \\end{cases} \\]"},{"location":"machine/interview/#2_7","title":"2\ufe0f\u20e3 \u635f\u5931\u51fd\u6570","text":"<p>\u903b\u8f91\u56de\u5f52\u4f7f\u7528\u7684\u635f\u5931\u51fd\u6570\u662f\u5bf9\u6570\u635f\u5931\uff08Log Loss\uff09 \u6216 \u4ea4\u53c9\u71b5\u635f\u5931\uff08Cross Entropy Loss\uff09\u3002</p>"},{"location":"machine/interview/#21_1","title":"2.1 \u5355\u6837\u672c\u635f\u5931\u51fd\u6570","text":"<p>\u5bf9\u4e8e\u4e00\u4e2a\u6837\u672c \\((x^{(i)}, y^{(i)})\\)\uff1a</p> \\[ L(\\theta) = -\\left[y^{(i)} \\log h_\\theta(x^{(i)}) + (1 - y^{(i)}) \\log (1 - h_\\theta(x^{(i)}))\\right] \\]"},{"location":"machine/interview/#22_1","title":"2.2 \u603b\u635f\u5931\u51fd\u6570","text":"<p>\u5bf9\u6240\u6709\u6837\u672c\u53d6\u5e73\u5747\uff1a</p> \\[ J(\\theta) = -\\frac{1}{m} \\sum_{i=1}^m \\left[y^{(i)} \\log h_\\theta(x^{(i)}) + (1 - y^{(i)}) \\log (1 - h_\\theta(x^{(i)}))\\right] \\]"},{"location":"machine/interview/#3_4","title":"3\ufe0f\u20e3 \u6570\u5b66\u63a8\u5bfc\u8fc7\u7a0b","text":"<p>\u76ee\u6807\uff1a\u901a\u8fc7\u6700\u5c0f\u5316 \\(J(\\theta)\\) \u6c42\u89e3\u6700\u4f18\u53c2\u6570 \\(\\theta\\)\u3002</p>"},{"location":"machine/interview/#31-gradient","title":"3.1 \u68af\u5ea6\uff08Gradient\uff09","text":"<p>\u5bf9\u53c2\u6570 \\(\\theta_j\\) \u6c42\u504f\u5bfc\uff1a</p> \\[ \\frac{\\partial J(\\theta)}{\\partial \\theta_j} = \\frac{1}{m} \\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)}) x_j^{(i)} \\]"},{"location":"machine/interview/#32_1","title":"3.2 \u68af\u5ea6\u4e0b\u964d\u6cd5\u66f4\u65b0\u89c4\u5219","text":"\\[ \\theta_j := \\theta_j - \\alpha \\frac{\\partial J(\\theta)}{\\partial \\theta_j} \\] <p>\u5176\u4e2d \\(\\alpha\\) \u4e3a\u5b66\u4e60\u7387\uff08learning rate\uff09\u3002</p>"},{"location":"machine/interview/#4_6","title":"4\ufe0f\u20e3 \u8bc4\u4f30\u6307\u6807","text":"<p>\u5e38\u89c1\u7684\u4e8c\u5206\u7c7b\u8bc4\u4f30\u6307\u6807\u6709\uff1a</p> \u6307\u6807 \u542b\u4e49 \u516c\u5f0f \u51c6\u786e\u7387\uff08Accuracy\uff09 \u5206\u7c7b\u6b63\u786e\u7684\u6bd4\u4f8b \\(\\displaystyle \\text{Acc} = \\frac{TP + TN}{TP + TN + FP + FN}\\) \u7cbe\u786e\u7387\uff08Precision\uff09 \u9884\u6d4b\u4e3a\u6b63\u4e2d\u5b9e\u9645\u4e3a\u6b63\u7684\u6bd4\u4f8b \\(\\displaystyle \\text{P} = \\frac{TP}{TP + FP}\\) \u53ec\u56de\u7387\uff08Recall\uff09 \u5b9e\u9645\u4e3a\u6b63\u4e2d\u88ab\u9884\u6d4b\u4e3a\u6b63\u7684\u6bd4\u4f8b \\(\\displaystyle \\text{R} = \\frac{TP}{TP + FN}\\) F1-score \u7cbe\u786e\u7387\u4e0e\u53ec\u56de\u7387\u7684\u8c03\u548c\u5e73\u5747 \\(\\displaystyle F1 = \\frac{2PR}{P + R}\\) AUC\uff08ROC \u66f2\u7ebf\u4e0b\u7684\u9762\u79ef\uff09 \u8861\u91cf\u6574\u4f53\u5206\u7c7b\u80fd\u529b \u6570\u503c\u8d8a\u63a5\u8fd1 1 \u8d8a\u597d"},{"location":"machine/interview/#5_2","title":"5\ufe0f\u20e3 \u5b9e\u73b0\u4ee3\u7801","text":"<pre><code>from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\nfrom sklearn.datasets import load_breast_cancer\n\n# 1. \u52a0\u8f7d\u6570\u636e\ndata = load_breast_cancer()\nX, y = data.data, data.target\n\n# 2. \u5212\u5206\u6570\u636e\u96c6\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# 3. \u8bad\u7ec3\u903b\u8f91\u56de\u5f52\u6a21\u578b\nmodel = LogisticRegression(max_iter=1000)\nmodel.fit(X_train, y_train)\n\n# 4. \u9884\u6d4b\ny_pred = model.predict(X_test)\ny_pred_prob = model.predict_proba(X_test)[:, 1]\n\n# 5. \u8bc4\u4f30\nprint(\"\u51c6\u786e\u7387:\", accuracy_score(y_test, y_pred))\nprint(\"\u7cbe\u786e\u7387:\", precision_score(y_test, y_pred))\nprint(\"\u53ec\u56de\u7387:\", recall_score(y_test, y_pred))\nprint(\"F1 \u503c:\", f1_score(y_test, y_pred))\nprint(\"AUC \u503c:\", roc_auc_score(y_test, y_pred_prob))\n</code></pre>"},{"location":"machine/interview/#6_2","title":"6\ufe0f\u20e3 \u6a21\u578b\u4f18\u5316","text":"\u4f18\u5316\u65b9\u5411 \u65b9\u6cd5 \u8bf4\u660e \u7279\u5f81\u7f29\u653e \u6807\u51c6\u5316 <code>StandardScaler</code> \u6709\u52a9\u4e8e\u68af\u5ea6\u4e0b\u964d\u66f4\u5feb\u6536\u655b \u6b63\u5219\u5316 \\(L_1\\)\uff08Lasso\uff09\u6216 \\(L_2\\)\uff08Ridge\uff09 \u9632\u6b62\u8fc7\u62df\u5408\uff0csklearn \u9ed8\u8ba4\u4f7f\u7528 \\(L_2\\) \u8c03\u6574\u8d85\u53c2\u6570 <code>C</code>\uff08\u6b63\u5219\u5316\u5f3a\u5ea6\uff09 \u8d8a\u5c0f\u4ee3\u8868\u6b63\u5219\u5316\u8d8a\u5f3a \u7279\u5f81\u9009\u62e9 \u53bb\u9664\u5171\u7ebf\u6027\u7279\u5f81 \u63d0\u9ad8\u6a21\u578b\u7a33\u5b9a\u6027 \u7c7b\u522b\u4e0d\u5e73\u8861\u5904\u7406 <code>class_weight='balanced'</code> \u6216\u4e0a\u91c7\u6837 \u89e3\u51b3\u7c7b\u522b\u6837\u672c\u5206\u5e03\u4e0d\u5747\u7684\u95ee\u9898"},{"location":"machine/interview/#7_2","title":"7\ufe0f\u20e3 \u6ce8\u610f\u4e8b\u9879","text":"<ol> <li>\u8f93\u5165\u7279\u5f81\u9700\u6570\u503c\u5316\uff08One-Hot \u7f16\u7801\u7b49\u65b9\u5f0f\u5904\u7406\u5206\u7c7b\u7279\u5f81\uff09</li> <li>\u7279\u5f81\u7f29\u653e\u5f88\u91cd\u8981\uff08\u5c24\u5176\u662f\u4f7f\u7528\u68af\u5ea6\u4e0b\u964d\u8bad\u7ec3\u65f6\uff09</li> <li>\u4e0d\u8981\u5728\u5f3a\u975e\u7ebf\u6027\u95ee\u9898\u4e0a\u76f4\u63a5\u4f7f\u7528\u903b\u8f91\u56de\u5f52\uff08\u5b83\u672c\u8d28\u662f\u7ebf\u6027\u5206\u7c7b\u5668\uff09</li> <li>\u68c0\u67e5\u591a\u91cd\u5171\u7ebf\u6027\uff08\u53ef\u7528 VIF \u68c0\u67e5\uff09</li> <li>\u5408\u7406\u9009\u62e9\u6b63\u5219\u5316\u9879\uff0c\u9632\u6b62\u8fc7\u62df\u5408\u6216\u6b20\u62df\u5408\u3002</li> </ol>"},{"location":"machine/interview/#8_1","title":"8\ufe0f\u20e3 \u4f18\u7f3a\u70b9","text":"<p>\u4f18\u70b9\uff1a</p> <ul> <li>\u7b80\u5355\u3001\u9ad8\u6548\uff0c\u53ef\u89e3\u91ca\u6027\u5f3a\uff1b</li> <li>\u8f93\u51fa\u6982\u7387\uff0c\u6709\u826f\u597d\u7684\u7406\u8bba\u57fa\u7840\uff1b</li> <li>\u53ef\u7528\u4e8e\u5728\u7ebf\u5b66\u4e60\uff08\u589e\u91cf\u66f4\u65b0\uff09\u3002</li> </ul> <p>\u7f3a\u70b9\uff1a</p> <ul> <li>\u4ec5\u80fd\u5904\u7406\u7ebf\u6027\u53ef\u5206\u95ee\u9898\uff1b</li> <li>\u5bf9\u5f02\u5e38\u503c\u654f\u611f\uff1b</li> <li>\u7279\u5f81\u5de5\u7a0b\u5f71\u54cd\u5927\u3002</li> </ul>"},{"location":"machine/interview/#32_2","title":"3.2 \u9762\u8bd5\u9898","text":""},{"location":"machine/interview/#_50","title":"\u4ec0\u4e48\u662f\u68af\u5ea6\u4e0b\u964d\uff1f","text":"<p>\u68af\u5ea6\u4e0b\u964d\u662f\u4e00\u79cd\u4f18\u5316\u7b97\u6cd5\uff0c\u7528\u4e8e\u6700\u5c0f\u5316\u4e00\u4e2a\u76ee\u6807\u51fd\u6570\uff08\u5982\u635f\u5931\u51fd\u6570\uff09\u3002 \u5b83\u7684\u6838\u5fc3\u601d\u60f3\u662f\uff1a</p> <p>\u6cbf\u7740\u51fd\u6570\u68af\u5ea6\u7684\u53cd\u65b9\u5411\u4e0d\u65ad\u8c03\u6574\u53c2\u6570\uff0c\u76f4\u5230\u627e\u5230\u51fd\u6570\u7684\u6700\u5c0f\u503c\u3002</p> <p>\u4f60\u53ef\u4ee5\u628a\u5b83\u60f3\u8c61\u6210\u4e00\u4e2a\u4eba\u7ad9\u5728\u5c71\u9876\uff08\u635f\u5931\u51fd\u6570\u7684\u9ad8\u70b9\uff09\uff0c \u6bcf\u6b21\u671d\u7740\u201c\u6700\u9661\u7684\u4e0b\u5761\u65b9\u5411\u201d\u8d70\u4e00\u6b65\uff0c\u76f4\u5230\u8d70\u5230\u5c71\u8c37\u5e95\uff08\u635f\u5931\u6700\u5c0f\u70b9\uff09\u3002</p> <p>\u6570\u5b66\u5b9a\u4e49</p> <p>\u5047\u8bbe\u6211\u4eec\u6709\u4e00\u4e2a\u9700\u8981\u6700\u5c0f\u5316\u7684\u51fd\u6570\uff1a</p> \\[ J(\\theta) \\] <p>\u5176\u4e2d \\(\\theta\\) \u8868\u793a\u53c2\u6570\u5411\u91cf\uff08\u4f8b\u5982\u6a21\u578b\u6743\u91cd\uff09\u3002 \u76ee\u6807\u662f\u627e\u5230\uff1a</p> \\[ \\theta^* = \\arg\\min_\\theta J(\\theta) \\] <p>\u68af\u5ea6\uff08Gradient\uff09</p> <p>\u68af\u5ea6\u662f\u51fd\u6570\u5728\u67d0\u4e00\u70b9\u7684\u65b9\u5411\u5bfc\u6570\u5411\u91cf\uff0c\u8868\u793a\u51fd\u6570\u589e\u957f\u6700\u5feb\u7684\u65b9\u5411\u3002 \u68af\u5ea6\u5b9a\u4e49\u4e3a\uff1a</p> \\[ \\nabla_\\theta J(\\theta) = \\begin{bmatrix} \\frac{\\partial J}{\\partial \\theta_1} \\ \\frac{\\partial J}{\\partial \\theta_2} \\ \\vdots \\ \\frac{\\partial J}{\\partial \\theta_n} \\end{bmatrix} \\] <p>\u82e5\u6211\u4eec\u60f3\u8ba9\u51fd\u6570 \\(J(\\theta)\\) \u53d8\u5c0f\uff0c\u5c31\u5e94\u5f53\u6cbf\u7740\u68af\u5ea6\u7684\u53cd\u65b9\u5411\u79fb\u52a8\u3002</p> <p>\u68af\u5ea6\u4e0b\u964d\u7684\u66f4\u65b0\u516c\u5f0f</p> <p>\u6bcf\u6b21\u8fed\u4ee3\u65f6\uff0c\u66f4\u65b0\u53c2\u6570\uff1a</p> \\[ \\theta := \\theta - \\alpha \\nabla_\\theta J(\\theta) \\] <p>\u5176\u4e2d\uff1a</p> <ul> <li>\\(\\alpha\\)\uff1a\u5b66\u4e60\u7387\uff08learning rate\uff09\uff0c\u63a7\u5236\u6bcf\u6b21\u66f4\u65b0\u6b65\u957f\uff1b</li> <li>\\(\\nabla_\\theta J(\\theta)\\)\uff1a\u68af\u5ea6\uff1b</li> <li>\u8d1f\u53f7\u8868\u793a\u6cbf\u68af\u5ea6\u53cd\u65b9\u5411\u66f4\u65b0\u3002</li> </ul> <p>\u68af\u5ea6\u4e0b\u964d\u7684\u51e0\u4f55\u76f4\u89c2</p> <ul> <li>\u68af\u5ea6\u65b9\u5411\uff1a\u51fd\u6570\u4e0a\u5347\u6700\u5feb\u7684\u65b9\u5411\uff1b</li> <li>\u8d1f\u68af\u5ea6\u65b9\u5411\uff1a\u51fd\u6570\u4e0b\u964d\u6700\u5feb\u7684\u65b9\u5411\uff1b</li> <li>\u5b66\u4e60\u7387 \\(\\alpha\\) \u592a\u5927 \u2192 \u53ef\u80fd\u8de8\u8fc7\u8c37\u5e95\u3001\u53d1\u6563\uff1b</li> <li>\u5b66\u4e60\u7387 \\(\\alpha\\) \u592a\u5c0f \u2192 \u6536\u655b\u901f\u5ea6\u6162\uff1b</li> <li>\u6070\u5f53\u7684 \\(\\alpha\\) \u2192 \u7a33\u5b9a\u800c\u5feb\u901f\u5730\u6536\u655b\u5230\u6700\u5c0f\u503c\u3002</li> </ul> <p>\u68af\u5ea6\u4e0b\u964d\u7684\u4e09\u79cd\u4e3b\u8981\u5f62\u5f0f</p> \u7c7b\u578b \u8ba1\u7b97\u65b9\u5f0f \u7279\u70b9 \u6279\u91cf\u68af\u5ea6\u4e0b\u964d\uff08BGD\uff09 \u4f7f\u7528\u5168\u90e8\u6837\u672c\u8ba1\u7b97\u68af\u5ea6\uff1a  \\(\\nabla_\\theta J(\\theta) = \\frac{1}{m} \\sum_{i=1}^m \\nabla_\\theta L^{(i)}(\\theta)\\) \u6536\u655b\u7a33\u5b9a\uff0c\u4f46\u8ba1\u7b97\u91cf\u5927 \u968f\u673a\u68af\u5ea6\u4e0b\u964d\uff08SGD\uff09 \u6bcf\u6b21\u4f7f\u7528\u4e00\u4e2a\u6837\u672c\u66f4\u65b0\uff1a  \\(\\theta := \\theta - \\alpha \\nabla_\\theta L^{(i)}(\\theta)\\) \u66f4\u65b0\u5feb\uff0c\u4f46\u6ce2\u52a8\u5927 \u5c0f\u6279\u91cf\u68af\u5ea6\u4e0b\u964d\uff08Mini-batch GD\uff09 \u6bcf\u6b21\u4f7f\u7528\u4e00\u5c0f\u90e8\u5206\u6837\u672c\uff08\u5982 32\u300164 \u4e2a\uff09\u8ba1\u7b97\u68af\u5ea6 \u7efc\u5408\u4e24\u8005\u4f18\u70b9\uff0c\u662f\u6df1\u5ea6\u5b66\u4e60\u7684\u6807\u51c6\u505a\u6cd5 <p>\u68af\u5ea6\u4e0b\u964d\u7684\u6536\u655b\u8fc7\u7a0b</p> <p>\u5047\u8bbe\u76ee\u6807\u51fd\u6570\u662f\uff1a</p> \\[ J(\\theta) = \\theta^2 \\] <p>\u5219\uff1a</p> \\[ \\frac{dJ}{d\\theta} = 2\\theta \\] <p>\u66f4\u65b0\u516c\u5f0f\u4e3a\uff1a</p> \\[ \\theta := \\theta - \\alpha \\cdot 2\\theta \\] <p>\u5982\u679c\u8bbe\u521d\u59cb \\(\\theta_0 = 5, \\alpha = 0.1\\)\uff1a</p> \u8fed\u4ee3\u6b21\u6570 \\(\\theta\\) \\(J(\\theta)\\) 0 5.0 25.0 1 4.0 16.0 2 3.2 10.24 3 2.56 6.55 ... ... ... <p>\u53ef\u4ee5\u770b\u5230\uff0c\\(\\theta\\) \u4e00\u6b65\u6b65\u63a5\u8fd1\u6700\u4f18\u70b9 \\(0\\)\uff0c\\(J(\\theta)\\) \u9010\u6e10\u4e0b\u964d\u3002</p> <p>\u68af\u5ea6\u4e0b\u964d\u7684\u4f18\u7f3a\u70b9</p> <p>\u4f18\u70b9\uff1a</p> <ul> <li>\u7b80\u5355\u6613\u5b9e\u73b0\uff1b</li> <li>\u901a\u7528\u6027\u5f3a\uff0c\u9002\u7528\u4e8e\u5404\u79cd\u53ef\u5fae\u51fd\u6570\uff1b</li> <li>\u53ef\u7528\u4e8e\u5927\u89c4\u6a21\u673a\u5668\u5b66\u4e60\u4efb\u52a1\u3002</li> </ul> <p>\u7f3a\u70b9\uff1a</p> <ul> <li>\u5bf9\u5b66\u4e60\u7387 \\(\\alpha\\) \u654f\u611f\uff1b</li> <li>\u53ef\u80fd\u9677\u5165\u5c40\u90e8\u6700\u5c0f\u503c\uff1b</li> <li>\u6536\u655b\u901f\u5ea6\u53d6\u51b3\u4e8e\u51fd\u6570\u5f62\u72b6\uff08\u978d\u70b9\u3001\u5e73\u7f13\u533a\u57df\u7b49\uff09\u3002</li> </ul> <p>\u6539\u8fdb\u7b97\u6cd5\uff08\u6269\u5c55\uff09</p> <p>\u5728\u73b0\u4ee3\u6df1\u5ea6\u5b66\u4e60\u4e2d\uff0c\u68af\u5ea6\u4e0b\u964d\u884d\u751f\u51fa\u8bb8\u591a\u6539\u8fdb\u7b97\u6cd5\uff0c\u4f8b\u5982\uff1a</p> \u4f18\u5316\u7b97\u6cd5 \u5173\u952e\u601d\u60f3 Momentum \u6a21\u62df\u60ef\u6027\uff0c\u52a0\u5feb\u6536\u655b AdaGrad \u81ea\u9002\u5e94\u5b66\u4e60\u7387 RMSProp \u907f\u514d\u5b66\u4e60\u7387\u8fc7\u5c0f\u95ee\u9898 Adam \u7ed3\u5408 Momentum \u548c RMSProp\uff08\u6700\u5e38\u7528\uff09"},{"location":"machine/interview/#momentumadagradrmspropadam","title":"\u68af\u5ea6\u4e0b\u964d\u6539\u8fdb\u7b97\u6cd5\uff1aMomentum\u3001AdaGrad\u3001RMSProp\u3001Adam","text":""},{"location":"machine/interview/#momentum","title":"Momentum","text":"<p>\u52a0\u5165\u201c\u60ef\u6027\u201d\u7684\u6982\u5ff5\uff0c\u8ba9\u53c2\u6570\u66f4\u65b0\u4e0d\u4ec5\u4f9d\u8d56\u5f53\u524d\u68af\u5ea6\uff0c\u8fd8\u8003\u8651\u8fc7\u53bb\u68af\u5ea6\u7684\u7d2f\u79ef\u8d8b\u52bf\u3002 \u5c31\u50cf\u4e00\u4e2a\u5c0f\u7403\u5728\u5c71\u8c37\u4e2d\u6eda\u52a8\u65f6\uff0c\u4f1a\u6709\u60ef\u6027\uff0c\u4e0d\u4f1a\u7acb\u5373\u505c\u4e0b\u3002</p> <p>\u6570\u5b66\u516c\u5f0f</p> <p>\u5b9a\u4e49\u901f\u5ea6\u9879 \\(v_t\\)\uff1a</p> \\[ v_t = \\beta v_{t-1} + (1 - \\beta) \\nabla_\\theta J(\\theta_t) \\] <p>\u53c2\u6570\u66f4\u65b0\u4e3a\uff1a</p> \\[ \\theta_{t+1} = \\theta_t - \\alpha v_t \\] <p>\u5176\u4e2d\uff1a</p> <ul> <li>\\(\\beta\\) \u662f\u52a8\u91cf\u7cfb\u6570\uff08\u901a\u5e38\u53d6 \\(0.9\\)\uff09\uff1b</li> <li>\\(v_t\\) \u7c7b\u4f3c\u52a8\u91cf\u7684\u7d2f\u79ef\u68af\u5ea6\u3002</li> <li>\\(\\alpha\\) \u662f\u5b66\u4e60\u7387</li> </ul> <p>\u7279\u70b9</p> <p>\u2705 \u52a0\u901f\u6536\u655b\uff08\u5c24\u5176\u5728\u5ce1\u8c37\u5f62\u66f2\u9762\u4e2d\uff09 \u2705 \u6291\u5236\u9707\u8361\uff08\u65b9\u5411\u66f4\u7a33\u5b9a\uff09 \u26a0\ufe0f \u5982\u679c \\(\\beta\\) \u592a\u5927\uff0c\u53ef\u80fd\u201c\u51b2\u8fc7\u8c37\u5e95\u201d\u3002</p>"},{"location":"machine/interview/#adagrad","title":"AdaGrad\uff08\u81ea\u9002\u5e94\u5b66\u4e60\u7387\u7b97\u6cd5\uff09","text":"<p>\u4e0d\u540c\u53c2\u6570\u7684\u68af\u5ea6\u5927\u5c0f\u5dee\u5f02\u53ef\u80fd\u5f88\u5927\u3002 AdaGrad \u901a\u8fc7\u5bf9\u6bcf\u4e2a\u53c2\u6570\u5355\u72ec\u8c03\u6574\u5b66\u4e60\u7387\uff0c\u4f7f\u5f97\u66f4\u65b0\u66f4\u7a33\u5b9a\u3002</p> <p>\u6570\u5b66\u516c\u5f0f</p> <p>\u8bbe\u6bcf\u4e2a\u53c2\u6570\u90fd\u6709\u81ea\u5df1\u7684\u7d2f\u79ef\u5e73\u65b9\u68af\u5ea6 \\(G_t\\)\uff1a</p> \\[ G_t = G_{t-1} + [\\nabla_\\theta J(\\theta_t)]^2 \\] <p>\u53c2\u6570\u66f4\u65b0\uff1a</p> \\[ \\theta_{t+1} = \\theta_t - \\frac{\\alpha}{\\sqrt{G_t + \\varepsilon}} \\nabla_\\theta J(\\theta_t) \\] <p>\u5176\u4e2d \\(\\varepsilon\\) \u662f\u9632\u6b62\u9664\u96f6\u7684\u5c0f\u5e38\u6570\uff08\u5982 \\(10^{-8}\\)\uff09\u3002</p> <p>** \u7279\u70b9**</p> <p>\u2705 \u5bf9\u7a00\u758f\u6570\u636e\u6709\u6548\uff08\u5982 NLP \u4e2d\u7684\u8bcd\u5d4c\u5165\uff09 \u26a0\ufe0f \u7f3a\u70b9\uff1a\u5b66\u4e60\u7387\u4e0d\u65ad\u8870\u51cf\uff0c\u53ef\u80fd\u8fc7\u65e9\u505c\u6ede\u3002</p>"},{"location":"machine/interview/#rmsprop","title":"RMSProp\uff08\u5747\u65b9\u6839\u4f20\u64ad\uff09","text":"<p>RMSProp \u662f\u4e3a\u4e86\u89e3\u51b3 AdaGrad \u5b66\u4e60\u7387\u8870\u51cf\u8fc7\u5feb\u7684\u95ee\u9898\u3002 \u5b83\u4e0d\u662f\u7d2f\u79ef\u6240\u6709\u5386\u53f2\u68af\u5ea6\u5e73\u65b9\uff0c\u800c\u662f\u4f7f\u7528\u6307\u6570\u52a0\u6743\u79fb\u52a8\u5e73\u5747\uff08EWMA\uff09\u3002</p> <p>\u6570\u5b66\u516c\u5f0f</p> \\[ E[g^2]*t = \\beta E[g^2]*{t-1} + (1 - \\beta)(\\nabla_\\theta J(\\theta_t))^2 \\] \\[ \\theta_{t+1} = \\theta_t - \\frac{\\alpha}{\\sqrt{E[g^2]*t + \\varepsilon}} \\nabla*\\theta J(\\theta_t) \\] <p>\u5176\u4e2d\uff1a</p> <ul> <li>\\(\\beta\\) \u4e00\u822c\u53d6 \\(0.9\\)\uff1b</li> <li>\\(E[g^2]_t\\) \u662f\u68af\u5ea6\u5e73\u65b9\u7684\u6307\u6570\u52a0\u6743\u5e73\u5747\u3002</li> </ul> <p>\u7279\u70b9</p> <p>\u2705 \u81ea\u9002\u5e94\u5b66\u4e60\u7387\uff0c\u4e0d\u4f1a\u8fc7\u65e9\u8870\u51cf \u2705 \u5728\u975e\u5e73\u7a33\u95ee\u9898\uff08\u5982 RNN\uff09\u4e0a\u8868\u73b0\u826f\u597d \u26a0\ufe0f \u65e0\u52a8\u91cf\u9879\uff0c\u6536\u655b\u65b9\u5411\u53ef\u80fd\u6296\u52a8</p>"},{"location":"machine/interview/#adamadaptive-moment-estimation","title":"Adam\uff08Adaptive Moment Estimation\uff09","text":"<p>Adam = Momentum + RMSProp \u65e2\u8003\u8651\u68af\u5ea6\u7684\u52a8\u91cf\uff08\u65b9\u5411\uff09\uff0c\u53c8\u8003\u8651\u68af\u5ea6\u7684\u81ea\u9002\u5e94\u5b66\u4e60\u7387\uff08\u5c3a\u5ea6\uff09\u3002</p> <p>\u6570\u5b66\u516c\u5f0f</p> <p>\u5b9a\u4e49\u4e00\u9636\u52a8\u91cf\uff08\u5e73\u5747\u68af\u5ea6\uff09\u548c\u4e8c\u9636\u52a8\u91cf\uff08\u5e73\u5747\u5e73\u65b9\u68af\u5ea6\uff09\uff1a</p> \\[ \\begin{aligned} m_t &amp;= \\beta_1 m_{t-1} + (1 - \\beta_1)\\nabla_\\theta J(\\theta_t) \\ v_t &amp;= \\beta_2 v_{t-1} + (1 - \\beta_2)(\\nabla_\\theta J(\\theta_t))^2 \\end{aligned} \\] <p>\u4e3a\u4fee\u6b63\u504f\u5dee\uff0c\u8fdb\u884c\u504f\u5dee\u6821\u6b63\uff1a</p> \\[ \\begin{aligned} \\hat{m}_t &amp;= \\frac{m_t}{1 - \\beta_1^t} \\ \\hat{v}_t &amp;= \\frac{v_t}{1 - \\beta_2^t} \\end{aligned} \\] <p>\u6700\u7ec8\u53c2\u6570\u66f4\u65b0\uff1a</p> \\[ \\theta_{t+1} = \\theta_t - \\frac{\\alpha}{\\sqrt{\\hat{v}_t} + \\varepsilon} \\hat{m}_t \\] <p>\u53c2\u6570\u53d6\u503c\uff08\u9ed8\u8ba4\u63a8\u8350\uff09</p> <ul> <li>\\(\\beta_1 = 0.9\\)</li> <li>\\(\\beta_2 = 0.999\\)</li> <li>\\(\\varepsilon = 10^{-8}\\)</li> </ul> <p>\u7279\u70b9</p> <p>\u2705 \u6536\u655b\u5feb\u3001\u7a33\u5b9a\u3001\u9c81\u68d2 \u2705 \u5bf9\u8d85\u53c2\u6570\u4e0d\u592a\u654f\u611f \u2705 \u6df1\u5ea6\u5b66\u4e60\u4e2d\u6700\u5e38\u7528\u7684\u4f18\u5316\u7b97\u6cd5\uff08\u51e0\u4e4e\u9ed8\u8ba4\u9009\u62e9\uff09 \u26a0\ufe0f \u6709\u65f6\u4f1a\u9677\u5165\u5c40\u90e8\u6781\u5c0f\u503c\u6216\u978d\u70b9</p> \u7b97\u6cd5 \u5b66\u4e60\u7387\u7c7b\u578b \u662f\u5426\u4f7f\u7528\u52a8\u91cf \u662f\u5426\u9700\u8981\u504f\u5dee\u4fee\u6b63 \u4f18\u70b9 \u7f3a\u70b9 SGD \u56fa\u5b9a \u274c \u274c \u7b80\u5355\u7a33\u5b9a \u6536\u655b\u6162\uff0c\u9707\u8361 Momentum \u56fa\u5b9a \u2705 \u274c \u52a0\u901f\u6536\u655b \u53ef\u80fd\u8d85\u8c03 AdaGrad \u81ea\u9002\u5e94 \u274c \u274c \u7a00\u758f\u6570\u636e\u597d \u5b66\u4e60\u7387\u8fc7\u5feb\u8870\u51cf RMSProp \u81ea\u9002\u5e94 \u274c \u274c \u7a33\u5b9a\u5feb\u901f \u65e0\u52a8\u91cf Adam \u81ea\u9002\u5e94 \u2705 \u2705 \u5feb\u901f\u7a33\u5b9a\u3001\u901a\u7528 \u53ef\u80fd\u6b20\u6536\u655b"},{"location":"machine/interview/#_51","title":"\u68af\u5ea6\u4e0b\u964d\u6cd5\u627e\u5230\u7684\u4e00\u5b9a\u662f\u4e0b\u964d\u6700\u5feb\u7684\u65b9\u5411\u5417\uff1f","text":"<p>\u68af\u5ea6\u4e0b\u964d\u6cd5\u627e\u5230\u7684\u662f\u5f53\u524d\u70b9\u5904\u51fd\u6570\u503c\u4e0b\u964d\u6700\u5feb\u7684\u65b9\u5411\uff0c\u4f46\u4ec5\u9650\u4e8e\u57fa\u4e8e\u4e00\u9636\u5bfc\u6570\u4fe1\u606f\u7684\u201c\u5c40\u90e8\u201d\u6700\u5feb\u4e0b\u964d\u65b9\u5411\u3002\u6362\u53e5\u8bdd\u8bf4\uff0c\u5b83\u662f\u5728\u5f53\u524d\u70b9\u9644\u8fd1\u7528\u7ebf\u6027\u8fd1\u4f3c\u6a21\u578b\u6240\u51b3\u5b9a\u7684\u4e0b\u964d\u6700\u5feb\u65b9\u54119\u3002 <p>\u7406\u8bba\u8bf4\u660e</p> <ul> <li>\u68af\u5ea6\u65b9\u5411\u662f\u591a\u5143\u51fd\u6570\u5728\u67d0\u4e00\u70b9\u5904\u51fd\u6570\u503c\u589e\u957f\u6700\u5feb\u7684\u65b9\u5411\uff0c\u56e0\u6b64\u8d1f\u68af\u5ea6\u65b9\u5411\u5c31\u662f\u4e0b\u964d\u6700\u5feb\u7684\u65b9\u5411\u3002\u68af\u5ea6\u4e0b\u964d\u6cd5\u6b63\u662f\u6cbf\u7740\u8d1f\u68af\u5ea6\u65b9\u5411\u66f4\u65b0\u53c2\u6570\uff0c\u4f7f\u76ee\u6807\u51fd\u6570\u5feb\u901f\u51cf\u5c0f\u3002</li> <li>\u4f46\u662f\uff0c\u68af\u5ea6\u4e0b\u964d\u6cd5\u53ea\u5229\u7528\u4e86\u4e00\u9636\u5bfc\u6570\u4fe1\u606f\uff0c\u6ca1\u6709\u8003\u8651\u66f4\u9ad8\u9636\u7684\u4fe1\u606f\uff08\u5982Hessian\u77e9\u9635\uff0c\u5373\u4e8c\u9636\u5bfc\u6570\uff09\u3002\u56e0\u6b64\uff0c\u5b83\u5bf9\u201c\u5c40\u90e8\u201d\u4e0b\u964d\u65b9\u5411\u7684\u5224\u65ad\u4ec5\u9650\u4e8e\u5f53\u524d\u70b9\u7684\u5207\u5e73\u9762\uff0c\u65e0\u6cd5\u4fdd\u8bc1\u5168\u5c40\u6700\u4f18\u6216\u8005\u5728\u590d\u6742\u5730\u5f62\u4e2d\u627e\u5230\u6700\u5feb\u7684\u4e0b\u964d\u8def\u5f84\u3002</li> </ul> <p>\u4e0e\u725b\u987f\u6cd5\u7684\u5bf9\u6bd4</p> <ul> <li>\u725b\u987f\u6cd5\u5728\u6bcf\u4e00\u6b65\u90fd\u8003\u8651\u4e86\u4e8c\u9636\u5bfc\u6570\u4fe1\u606f\uff0c\u80fd\u66f4\u597d\u5730\u62df\u5408\u5f53\u524d\u70b9\u9644\u8fd1\u7684\u66f2\u9762\uff0c\u7406\u8bba\u4e0a\u6536\u655b\u901f\u5ea6\u66f4\u5feb\uff08\u4e8c\u9636\u6536\u655b\uff09\uff0c\u5c24\u5176\u5728\u63a5\u8fd1\u6700\u4f18\u89e3\u65f6\u8868\u73b0\u4f18\u4e8e\u4ec5\u6709\u4e00\u9636\u6536\u655b\u901f\u5ea6\u7684\u68af\u5ea6\u4e0b\u964d\u6cd5\u3002</li> <li>\u4f46\u7531\u4e8e\u725b\u987f\u6cd5\u8ba1\u7b97\u548c\u5b58\u50a8\u5f00\u9500\u5927\uff0c\u5b9e\u9645\u5927\u89c4\u6a21\u95ee\u9898\u4e2d\u5f80\u5f80\u8fd8\u662f\u9009\u7528\u68af\u5ea6\u4e0b\u964d\u53ca\u5176\u53d8\u79cd\u3002</li> </ul> <p>\u7ed3\u8bba</p> <p>\u68af\u5ea6\u4e0b\u964d\u6cd5\u5728\u5f53\u524d\u70b9\u7684\u8d1f\u68af\u5ea6\u65b9\u5411\u662f\u51fd\u6570\u4e0b\u964d\u6700\u5feb\u7684\u65b9\u5411\uff0c\u4f46\u4ec5\u57fa\u4e8e\u4e00\u9636\u4fe1\u606f\uff0c\u5bf9\u6574\u4f53\u4f18\u5316\u8def\u5f84\u800c\u8a00\u4e0d\u4e00\u5b9a\u80fd\u628a\u63e1\u201c\u5168\u5c40\u6700\u5feb\u201d\u7684\u4e0b\u964d\u65b9\u5411\uff0c\u7279\u522b\u662f\u5728\u6709\u9ad8\u9636\u4fe1\u606f\u53ef\u5229\u7528\u65f6\u3002</p>"},{"location":"machine/interview/#mbgd","title":"MBGD\u9700\u8981\u6ce8\u610f\u4ec0\u4e48\uff1f","text":""},{"location":"machine/interview/#1-mini-batch-batch-size","title":"1. Mini-batch \u5927\u5c0f\uff08batch size\uff09\u9009\u62e9","text":"<ul> <li> <p>\u8fc7\u5927\uff1a</p> <ul> <li>\u68af\u5ea6\u4f30\u8ba1\u975e\u5e38\u51c6\u786e\uff0c\u4f46\u66f4\u65b0\u6b21\u6570\u5c11 \u2192 \u6536\u655b\u6162\u3002</li> <li>\u9700\u8981\u66f4\u591a\u663e\u5b58\u3002</li> <li>\u566a\u58f0\u592a\u5c0f\uff0c\u53ef\u80fd\u9677\u5165\u5c40\u90e8\u6700\u5c0f\u503c\u3002</li> <li> <p>\u8fc7\u5c0f\uff1a</p> </li> <li> <p>\u566a\u58f0\u5927\uff0c\u6536\u655b\u4e0d\u7a33\u5b9a\u3002</p> </li> <li>\u5e76\u884c\u6548\u7387\u4f4e\u3002</li> </ul> </li> </ul> <p>\ud83d\udccf \u4e00\u822c\u7ecf\u9a8c\uff1a</p> <ul> <li>\u5c0f\u6a21\u578b\uff1a<code>batch_size = 32 ~ 128</code></li> <li>\u5927\u6a21\u578b\uff08CNN/RNN\uff09\uff1a<code>batch_size = 256 ~ 1024</code></li> <li>\u6781\u5927\u6a21\u578b\uff08Transformer\uff09\uff1a\u53ef\u80fd\u4f7f\u7528 <code>4096</code> \u6216\u66f4\u591a\uff08\u914d\u5408\u5b66\u4e60\u7387\u8c03\u6574\uff09</li> </ul>"},{"location":"machine/interview/#2-learning-rate","title":"2. \u5b66\u4e60\u7387\uff08Learning Rate, \u03b1\uff09\u8981\u914d\u5408\u8c03\u6574","text":"<p>\u5b66\u4e60\u7387\u548c batch size \u9ad8\u5ea6\u76f8\u5173\u3002 \u5e38\u89c1\u7ecf\u9a8c\u516c\u5f0f\uff1a</p> \\[ \\alpha_{\\text{new}} = \\alpha_{\\text{base}} \\times \\frac{b_{\\text{new}}}{b_{\\text{base}}} \\] <p>\u5373 batch size \u7ffb\u500d\uff0c\u5b66\u4e60\u7387\u4e5f\u53ef\u4ee5\u8fd1\u4f3c\u7ffb\u500d\u3002 \u4f46\u8981\u901a\u8fc7warmup\uff08\u70ed\u8eab\uff09\u7b49\u7b56\u7565\u5e73\u6ed1\u8fc7\u6e21\u3002</p>"},{"location":"machine/interview/#3-shuffling","title":"3. \u6570\u636e\u6253\u4e71\uff08Shuffling\uff09","text":"<p>\u6bcf\u4e2a epoch \u524d\u5fc5\u987b \u968f\u673a\u6253\u4e71\u6570\u636e\uff0c\u5426\u5219\u6bcf\u4e2a batch \u7684\u6570\u636e\u53ef\u80fd\u5206\u5e03\u6709\u504f\u5dee\uff0c\u5bfc\u81f4\u6a21\u578b\u5b66\u4e60\u65b9\u5411\u9519\u8bef\u3002 \u5c24\u5176\u5728\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0c\u5982\u679c\u6837\u672c\u6309\u7c7b\u522b\u987a\u5e8f\u6392\u5217\u800c\u672a\u6253\u4e71\uff0c\u4f1a\u4e25\u91cd\u5f71\u54cd\u8bad\u7ec3\u6548\u679c\u3002</p>"},{"location":"machine/interview/#4_7","title":"4. \u6b63\u5219\u5316\u4e0e\u6279\u5f52\u4e00\u5316\u7684\u5173\u7cfb","text":"<ul> <li>\u5f53 batch \u8f83\u5c0f\u65f6\uff0cBatchNorm \u7684\u5747\u503c\u4e0e\u65b9\u5dee\u4f30\u8ba1\u4e0d\u7a33\u5b9a\u3002   \u2192 \u53ef\u4ee5\u4f7f\u7528 LayerNorm \u6216 GroupNorm \u4ee3\u66ff\u3002</li> <li>\u5f53 batch \u8f83\u5927\u65f6\uff0cBatchNorm \u901a\u5e38\u80fd\u63d0\u5347\u6536\u655b\u901f\u5ea6\u3002</li> </ul>"},{"location":"machine/interview/#5_3","title":"5. \u68af\u5ea6\u566a\u58f0\u4e0e\u6536\u655b\u7a33\u5b9a\u6027","text":"<ul> <li>MBGD \u7684\u68af\u5ea6\u5e26\u6709\u4e00\u5b9a\u968f\u673a\u6027\uff0c\u8fd9\u79cd\u201c\u566a\u58f0\u201d\u5176\u5b9e\u6709\u76ca\u5904\uff08\u9632\u6b62\u9677\u5165\u5c40\u90e8\u6781\u5c0f\u70b9\uff09\u3002</li> <li>\u4f46\u566a\u58f0\u8fc7\u5927\uff08batch \u592a\u5c0f\uff09\u65f6\uff0c\u4f1a\u5bfc\u81f4\u8bad\u7ec3\u8fc7\u7a0b\u9707\u8361\u3002</li> <li>\u53ef\u7ed3\u5408 Momentum \u6216 Adam \u6765\u5e73\u6ed1\u66f4\u65b0\u3002</li> </ul>"},{"location":"machine/interview/#6_3","title":"6. \u663e\u5b58\u4e0e\u8ba1\u7b97\u6548\u7387\u7684\u6743\u8861","text":"<ul> <li>batch \u8d8a\u5927\uff0c\u5360\u7528\u663e\u5b58\u8d8a\u591a\u3002</li> <li> <p>\u82e5\u663e\u5b58\u4e0d\u8db3\uff0c\u53ef\u91c7\u7528\uff1a</p> <ul> <li>Gradient Accumulation\uff08\u68af\u5ea6\u7d2f\u79ef\uff09\uff1b</li> <li>Mixed Precision Training\uff08\u6df7\u5408\u7cbe\u5ea6\u8bad\u7ec3\uff09\uff1b</li> <li>Gradient Checkpointing\uff08\u68af\u5ea6\u68c0\u67e5\u70b9\uff09\u3002</li> </ul> </li> </ul>"},{"location":"machine/interview/#7-mini-batch","title":"7. Mini-batch \u7684\u6784\u5efa\u8981\u6709\u4ee3\u8868\u6027","text":"<ul> <li>\u5c3d\u91cf\u4fdd\u8bc1\u6bcf\u4e2a batch \u7684\u6570\u636e\u5206\u5e03\u4e0e\u6574\u4f53\u8bad\u7ec3\u96c6\u76f8\u4f3c\uff1b</li> <li>\u5bf9\u4e8e\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u5efa\u8bae\u91c7\u7528 \u5206\u5c42\u91c7\u6837\uff08stratified sampling\uff09\uff1b</li> <li>\u5bf9\u5e8f\u5217\u4efb\u52a1\uff0c\u8981\u6ce8\u610f\u6837\u672c\u957f\u5ea6\u7684\u5206\u5e03\u3002</li> </ul>"},{"location":"machine/interview/#_52","title":"\u4ec0\u4e48\u662f\u6b63\u6001\u5206\u5e03\uff1f\u4e3a\u4ec0\u4e48\u8981\u91cd\u89c6\u5b83\uff1f","text":"<p>\u6b63\u6001\u5206\u5e03\uff08\u4e5f\u53eb\u9ad8\u65af\u5206\u5e03\uff09\u662f\u4e00\u79cd\u8fde\u7eed\u6982\u7387\u5206\u5e03\uff0c\u5176\u6982\u7387\u5bc6\u5ea6\u51fd\u6570\uff08PDF\uff09\u5b9a\u4e49\u4e3a\uff1a</p> \\[ f(x \\mid \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} \\exp\\left(- \\frac{(x - \\mu)^2}{2\\sigma^2}\\right) \\] <p>\u5176\u4e2d\uff1a</p> <ul> <li>\\(x\\)\uff1a\u968f\u673a\u53d8\u91cf\uff1b</li> <li>\\(\\mu\\)\uff1a\u5747\u503c\uff08mean\uff09\uff0c\u5206\u5e03\u4e2d\u5fc3\uff1b</li> <li>\\(\\sigma^2\\)\uff1a\u65b9\u5dee\uff08variance\uff09\uff0c\u63a7\u5236\u5206\u5e03\u5bbd\u5ea6\uff1b</li> <li>\\(\\sigma\\)\uff1a\u6807\u51c6\u5dee\uff08standard deviation\uff09\u3002</li> </ul> <p>\u8bb0\u53f7\uff1a\\(X \\sim \\mathcal{N}(\\mu, \\sigma^2)\\) \u8868\u793a\u968f\u673a\u53d8\u91cf \\(X\\) \u670d\u4ece\u5747\u503c\u4e3a \\(\\mu\\)\u3001\u65b9\u5dee\u4e3a \\(\\sigma^2\\) \u7684\u6b63\u6001\u5206\u5e03\u3002</p> <p>\u6b63\u6001\u5206\u5e03\u7684\u7279\u5f81</p> <ol> <li> <p>\u5bf9\u79f0\u6027</p> <ul> <li>\u5173\u4e8e\u5747\u503c \\(\\mu\\) \u5bf9\u79f0\uff0c\\(\\mu\\) \u662f\u5206\u5e03\u7684\u5cf0\u503c\u70b9\u3002</li> </ul> </li> <li> <p>\u5355\u5cf0\u6027</p> <ul> <li>\u53ea\u6709\u4e00\u4e2a\u5cf0\uff0c\u5448\u949f\u5f62\u66f2\u7ebf\u3002</li> </ul> </li> <li> <p>68-95-99.7 \u89c4\u5219\uff08\u7ecf\u9a8c\u6cd5\u5219\uff09</p> <ul> <li>\u7ea6 68% \u7684\u6570\u636e\u843d\u5728 \\([\\mu - \\sigma, \\mu + \\sigma]\\)</li> <li>\u7ea6 95% \u7684\u6570\u636e\u843d\u5728 \\([\\mu - 2\\sigma, \\mu + 2\\sigma]\\)</li> <li>\u7ea6 99.7% \u7684\u6570\u636e\u843d\u5728 \\([\\mu - 3\\sigma, \\mu + 3\\sigma]\\)</li> </ul> </li> <li> <p>\u6e10\u8fd1\u6027</p> <ul> <li>\u66f2\u7ebf\u4e24\u7aef\u65e0\u9650\u63a5\u8fd1 x \u8f74\uff0c\u4f46\u6c38\u4e0d\u89e6\u53ca\u3002</li> </ul> </li> </ol> <p>\u6b63\u6001\u5206\u5e03\u7684\u6570\u5b66\u6027\u8d28</p> <ol> <li>\u671f\u671b\u4e0e\u65b9\u5dee</li> </ol> \\[ \\mathbb{E}[X] = \\mu, \\quad \\mathrm{Var}(X) = \\sigma^2 \\] <ol> <li>\u6807\u51c6\u5316</li> </ol> <p>\u53ef\u4ee5\u5c06\u4efb\u610f\u6b63\u6001\u5206\u5e03\u8f6c\u5316\u4e3a\u6807\u51c6\u6b63\u6001\u5206\u5e03 \\(Z \\sim \\mathcal{N}(0, 1)\\)\uff1a</p> \\[ Z = \\frac{X - \\mu}{\\sigma} \\] <ol> <li>\u7ebf\u6027\u7ec4\u5408\u4ecd\u4e3a\u6b63\u6001\u5206\u5e03</li> </ol> <p>\u5982\u679c \\(X \\sim \\mathcal{N}(\\mu_X, \\sigma_X^2)\\)\uff0c\\(Y \\sim \\mathcal{N}(\\mu_Y, \\sigma_Y^2)\\) \u72ec\u7acb\uff0c\u5219\uff1a</p> \\[ aX + bY \\sim \\mathcal{N}(a\\mu_X + b\\mu_Y, a^2\\sigma_X^2 + b^2\\sigma_Y^2) \\]"},{"location":"machine/interview/#_53","title":"\u4e3a\u4ec0\u4e48\u8981\u91cd\u89c6\u6b63\u6001\u5206\u5e03\uff1f","text":"<ol> <li> <p>\u4e2d\u5fc3\u6781\u9650\u5b9a\u7406\uff08Central Limit Theorem, CLT\uff09</p> <ul> <li>\u65e0\u8bba\u539f\u59cb\u6570\u636e\u5206\u5e03\u5982\u4f55\uff0c\u5927\u91cf\u72ec\u7acb\u540c\u5206\u5e03\u7684\u968f\u673a\u53d8\u91cf\u5e73\u5747\u503c\u8d8b\u5411\u4e8e\u6b63\u6001\u5206\u5e03\u3002</li> <li>\u8fd9\u4f7f\u5f97\u6b63\u6001\u5206\u5e03\u5728\u7edf\u8ba1\u63a8\u65ad\u4e2d\u975e\u5e38\u91cd\u8981\uff0c\u4f8b\u5982\u7f6e\u4fe1\u533a\u95f4\u3001\u5047\u8bbe\u68c0\u9a8c\u7b49\u3002</li> </ul> </li> <li> <p>\u6570\u5b66\u5206\u6790\u65b9\u4fbf</p> <ul> <li>\u6b63\u6001\u5206\u5e03\u51fd\u6570\u5149\u6ed1\u3001\u53ef\u5fae\u3001\u95ed\u5408\u5f62\u5f0f\u660e\u786e\u3002</li> <li>\u8bb8\u591a\u7edf\u8ba1\u91cf\uff08\u5982\u5747\u503c\u3001\u65b9\u5dee\u3001\u7ebf\u6027\u56de\u5f52\u4f30\u8ba1\u91cf\uff09\u5728\u5927\u6837\u672c\u4e0b\u670d\u4ece\u6b63\u6001\u5206\u5e03\u3002</li> </ul> </li> <li> <p>\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u5e94\u7528</p> <ul> <li>\u5047\u8bbe\u8bef\u5dee\u670d\u4ece\u6b63\u6001\u5206\u5e03\u662f \u7ebf\u6027\u56de\u5f52\u3001\u903b\u8f91\u56de\u5f52\u3001\u9ad8\u65af\u6df7\u5408\u6a21\u578b\uff08GMM\uff09\u7b49\u6a21\u578b\u7684\u6838\u5fc3\u5047\u8bbe\u3002</li> <li>\u566a\u58f0\u5efa\u6a21\u3001\u8d1d\u53f6\u65af\u63a8\u65ad\u3001\u6982\u7387\u751f\u6210\u6a21\u578b\u90fd\u4f9d\u8d56\u4e8e\u6b63\u6001\u5206\u5e03\u3002</li> </ul> </li> <li> <p>\u5f02\u5e38\u68c0\u6d4b\u4e0e\u6807\u51c6\u5316</p> <ul> <li>\u6570\u636e\u6807\u51c6\u5316\uff08z-score\uff09\uff1a</li> </ul> </li> </ol> \\[ z = \\frac{x - \\mu}{\\sigma} \\] <ul> <li>\u901a\u8fc7\u6b63\u6001\u5206\u5e03\u7684\u6027\u8d28\u53ef\u4ee5\u68c0\u6d4b\u5f02\u5e38\u503c\uff08\u8fdc\u79bb \\(\\mu\\) \u591a\u500d\u6807\u51c6\u5dee\uff09\u3002</li> </ul>"},{"location":"machine/interview/#_54","title":"\u5982\u4f55\u68c0\u67e5\u53d8\u91cf\u662f\u5426\u9075\u5faa\u6b63\u6001\u5206\u5e03\uff1f","text":""},{"location":"machine/interview/#1_10","title":"1. \u56fe\u793a\u6cd5\uff08\u53ef\u89c6\u5316\u5224\u65ad\uff09","text":"<ul> <li>\u76f4\u65b9\u56fe\uff1a\u89c2\u5bdf\u6570\u636e\u5206\u5e03\u662f\u5426\u5448\u73b0\u201c\u4e2d\u95f4\u9ad8\u3001\u4e24\u5934\u4f4e\u201d\u7684\u949f\u5f62\u66f2\u7ebf\uff0c\u4e14\u5de6\u53f3\u57fa\u672c\u5bf9\u79f0\u3002</li> <li>Q-Q\u56fe / P-P\u56fe\uff1a\u82e5\u6570\u636e\u70b9\u5927\u81f4\u843d\u5728\u4e00\u6761\u5bf9\u89d2\u7ebf\u4e0a\uff0c\u8868\u660e\u6570\u636e\u4e0e\u6b63\u6001\u5206\u5e03\u543b\u5408\u826f\u597d\u3002</li> <li>\u4f18\u70b9\uff1a\u76f4\u89c2\u3001\u6613\u4e8e\u7406\u89e3\uff0c\u9002\u5408\u521d\u6b65\u5224\u65ad\uff0c\u5c24\u5176\u5728\u5927\u6837\u672c\u65f6\u66f4\u7a33\u5065\u3002</li> </ul>"},{"location":"machine/interview/#2_8","title":"2. \u63cf\u8ff0\u6027\u7edf\u8ba1\u91cf\u6cd5","text":"<ul> <li>\u504f\u5ea6\uff08Skewness\uff09\u4e0e\u5cf0\u5ea6\uff08Kurtosis\uff09\uff1a</li> <li>\u504f\u5ea6\u22480 \u8868\u793a\u5bf9\u79f0\u5206\u5e03\uff08\u6b63\u6001\uff09\uff1b&gt;0 \u4e3a\u53f3\u504f\uff0c&lt;0 \u4e3a\u5de6\u504f\u3002</li> <li>\u5cf0\u5ea6\u22480 \u8868\u793a\u5cf0\u6001\u9002\u4e2d\uff08\u6b63\u6001\uff09\uff1b&gt;0 \u4e3a\u5c16\u5cf0\uff0c&lt;0 \u4e3a\u5e73\u5cf0\u3002</li> <li>\u4e00\u822c\u8ba4\u4e3a\uff1a|\u504f\u5ea6| \u3002</li> </ul>"},{"location":"machine/interview/#3_5","title":"3. \u7edf\u8ba1\u68c0\u9a8c\u6cd5\uff08\u5047\u8bbe\u68c0\u9a8c\uff09","text":"<ul> <li>Shapiro-Wilk \u68c0\u9a8c\uff08W \u68c0\u9a8c\uff09\uff1a<ul> <li>\u9002\u7528\u4e8e\u5c0f\u6837\u672c\uff08n \u2264 50\uff09\uff0c\u68c0\u9a8c\u6548\u80fd\u8f83\u9ad8\u3002</li> </ul> </li> <li>Kolmogorov-Smirnov \u68c0\u9a8c\uff08K-S \u68c0\u9a8c\uff09\uff1a<ul> <li>\u9002\u7528\u4e8e\u5927\u6837\u672c\uff08n &gt; 50 \u6216 n &gt; 2000\uff0c\u4f9d\u8f6f\u4ef6\u800c\u5b9a\uff09\uff0c\u901a\u8fc7\u6bd4\u8f83\u6837\u672c\u5206\u5e03\u4e0e\u6b63\u6001\u5206\u5e03\u7684\u7d2f\u79ef\u51fd\u6570\u5dee\u5f02\u8fdb\u884c\u5224\u65ad\u3002</li> </ul> </li> <li>\u7ed3\u679c\u89e3\u8bfb\uff1a<ul> <li>\u539f\u5047\u8bbe H\u2080\uff1a\u6570\u636e\u670d\u4ece\u6b63\u6001\u5206\u5e03\u3002</li> <li>\u82e5 p &gt; 0.05\uff0c\u4e0d\u62d2\u7edd\u539f\u5047\u8bbe\uff0c\u8ba4\u4e3a\u6570\u636e\u7b26\u5408\u6b63\u6001\u5206\u5e03\u3002</li> </ul> </li> </ul> <p>\u603b\u7ed3\u6d41\u7a0b\u56fe\uff1a</p> <pre><code>\n1. \u7ed8\u5236\u76f4\u65b9\u56fe/QQ\u56fe \u2192 \u521d\u6b65\u5224\u65ad\u5f62\u72b6\n       \u2193\n2. \u67e5\u770b\u504f\u5ea6/\u5cf0\u5ea6 \u2192 \u6570\u503c\u662f\u5426\u5728\u5408\u7406\u8303\u56f4\n       \u2193\n3. \u8fdb\u884cSW\u6216KS\u68c0\u9a8c \u2192 p &gt; 0.05\uff1f\n       \u2193\n4. \u7efc\u5408\u7ed3\u8bba\uff1a\u662f\u5426\u6ee1\u8db3\u6b63\u6001\u6027\u5047\u8bbe\n</code></pre>"},{"location":"machine/interview/#_55","title":"\u56db\u3001\u6a21\u578b\u9a8c\u8bc1","text":""},{"location":"machine/interview/#41","title":"4.1 \u8fc7\u62df\u5408 &amp; \u6b20\u62df\u5408","text":""},{"location":"machine/interview/#underfitting","title":"\u6b20\u62df\u5408\uff08Underfitting\uff09","text":"<ul> <li>\u6982\u5ff5\uff1a\u6a21\u578b\u8fc7\u4e8e\u7b80\u5355\uff0c\u65e0\u6cd5\u6355\u6349\u6570\u636e\u4e2d\u7684\u89c4\u5f8b\u3002</li> <li> <p>\u8868\u73b0\uff1a</p> <ul> <li>\u8bad\u7ec3\u96c6\u8bef\u5dee\u9ad8</li> <li>\u6d4b\u8bd5\u96c6\u8bef\u5dee\u9ad8</li> </ul> </li> <li> <p>\u539f\u56e0\uff1a</p> <ul> <li>\u6a21\u578b\u5bb9\u91cf\u4e0d\u8db3\uff08\u5982\u7ebf\u6027\u6a21\u578b\u62df\u5408\u975e\u7ebf\u6027\u6570\u636e\uff09</li> <li>\u7279\u5f81\u4e0d\u8db3</li> <li>\u8bad\u7ec3\u8f6e\u6570\u592a\u5c11\u3001\u6b63\u5219\u5316\u8fc7\u5f3a</li> </ul> </li> </ul>"},{"location":"machine/interview/#overfitting","title":"\u8fc7\u62df\u5408\uff08Overfitting\uff09","text":"<ul> <li>\u6982\u5ff5\uff1a\u6a21\u578b\u8fc7\u4e8e\u590d\u6742\uff0c\u8fc7\u5ea6\u62df\u5408\u8bad\u7ec3\u6570\u636e\u4e2d\u7684\u566a\u58f0\u3002</li> <li> <p>\u8868\u73b0\uff1a</p> <ul> <li>\u8bad\u7ec3\u96c6\u8bef\u5dee\u4f4e</li> <li>\u6d4b\u8bd5\u96c6\u8bef\u5dee\u9ad8</li> </ul> </li> <li> <p>\u539f\u56e0\uff1a</p> <ul> <li>\u6a21\u578b\u5bb9\u91cf\u592a\u5927\uff08\u5982\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\uff09</li> <li>\u7279\u5f81\u592a\u591a\u3001\u566a\u58f0\u5927</li> <li>\u8bad\u7ec3\u8f6e\u6570\u592a\u591a\u3001\u6b63\u5219\u5316\u592a\u5f31</li> </ul> </li> </ul> \u60c5\u51b5 \u8bad\u7ec3\u8bef\u5dee \u6d4b\u8bd5\u8bef\u5dee \u6b20\u62df\u5408 \u9ad8 \u9ad8 \u5408\u9002\u62df\u5408 \u4f4e \u4f4e \u8fc7\u62df\u5408 \u4f4e \u9ad8 <p>\u8bad\u7ec3\u8bef\u5dee\u548c\u6d4b\u8bd5\u8bef\u5dee\u968f\u8bad\u7ec3\u8f6e\u6570\u53d8\u5316\u66f2\u7ebf\u793a\u610f\uff1a</p> <ul> <li>\u6b20\u62df\u5408\uff1a\u8bef\u5dee\u66f2\u7ebf\u9ad8\u4e14\u51e0\u4e4e\u4e0d\u4e0b\u964d</li> <li>\u8fc7\u62df\u5408\uff1a\u8bad\u7ec3\u8bef\u5dee\u4e0d\u65ad\u4e0b\u964d\uff0c\u6d4b\u8bd5\u8bef\u5dee\u4e0b\u964d\u540e\u56de\u5347</li> </ul>"},{"location":"machine/interview/#_56","title":"\u6b20\u62df\u5408\u89e3\u51b3\u7b56\u7565","text":"<ul> <li>\u63d0\u9ad8\u6a21\u578b\u590d\u6742\u5ea6\uff08\u5982\u7528\u591a\u9879\u5f0f\u56de\u5f52\u3001\u6df1\u5c42\u795e\u7ecf\u7f51\u7edc\uff09</li> <li>\u589e\u52a0\u7279\u5f81\u6216\u5de5\u7a0b\u7279\u5f81</li> <li>\u51cf\u5c0f\u6b63\u5219\u5316\u53c2\u6570\uff08\u5982 L1/L2\uff09</li> <li>\u8bad\u7ec3\u66f4\u957f\u65f6\u95f4</li> </ul>"},{"location":"machine/interview/#_57","title":"\u8fc7\u62df\u5408\u89e3\u51b3\u7b56\u7565","text":"<ul> <li>\u6b63\u5219\u5316\uff1aL1/L2\u3001Dropout</li> <li>\u7b80\u5316\u6a21\u578b\uff1a\u51cf\u5c11\u53c2\u6570\u3001\u964d\u4f4e\u7f51\u7edc\u5c42\u6570</li> <li>\u589e\u52a0\u8bad\u7ec3\u6570\u636e</li> <li>\u6570\u636e\u589e\u5f3a\uff08\u5982\u56fe\u50cf\u7ffb\u8f6c\u3001\u566a\u58f0\uff09</li> <li>\u63d0\u524d\u505c\u6b62\uff08Early stopping\uff09</li> <li>\u4ea4\u53c9\u9a8c\u8bc1\uff1a\u5224\u65ad\u6a21\u578b\u6cdb\u5316\u6027\u80fd</li> </ul> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.pipeline import make_pipeline\n\n# \u751f\u6210\u975e\u7ebf\u6027\u6570\u636e\nnp.random.seed(0)\nX = np.sort(np.random.rand(20,1)*2 - 1, axis=0)\ny = X**3 + 0.1*np.random.randn(20,1)\n\n# \u6b20\u62df\u5408\uff1a1\u9636\u591a\u9879\u5f0f\nmodel_under = make_pipeline(PolynomialFeatures(1), LinearRegression())\nmodel_under.fit(X,y)\ny_pred_under = model_under.predict(X)\n\n# \u9002\u5408\u62df\u5408\uff1a3\u9636\u591a\u9879\u5f0f\nmodel_good = make_pipeline(PolynomialFeatures(3), LinearRegression())\nmodel_good.fit(X,y)\ny_pred_good = model_good.predict(X)\n\n# \u8fc7\u62df\u5408\uff1a15\u9636\u591a\u9879\u5f0f\nmodel_over = make_pipeline(PolynomialFeatures(15), LinearRegression())\nmodel_over.fit(X,y)\ny_pred_over = model_over.predict(X)\n\n# \u53ef\u89c6\u5316\nplt.scatter(X, y, color='black', label='data')\nplt.plot(X, y_pred_under, label='Underfit')\nplt.plot(X, y_pred_good, label='Good fit')\nplt.plot(X, y_pred_over, label='Overfit')\nplt.legend()\nplt.show()\n</code></pre>"},{"location":"machine/interview/#42","title":"4.2 \u4ea4\u53c9\u9a8c\u8bc1","text":"<p>\u5728\u673a\u5668\u5b66\u4e60\u4e2d\uff0c\u6211\u4eec\u5e0c\u671b\u6a21\u578b\u4e0d\u4ec5\u5728\u8bad\u7ec3\u96c6\u4e0a\u8868\u73b0\u597d\uff0c\u8fd8\u80fd\u5728\u672a\u89c1\u8fc7\u7684\u6570\u636e\u4e0a\u6709\u826f\u597d\u7684\u8868\u73b0\uff08\u5373\u6cdb\u5316\u80fd\u529b\uff09\u3002 \u4ea4\u53c9\u9a8c\u8bc1\u662f\u4e00\u79cd\u901a\u8fc7\u591a\u6b21\u5212\u5206\u8bad\u7ec3\u96c6\u548c\u9a8c\u8bc1\u96c6\u6765\u8bc4\u4f30\u6a21\u578b\u6027\u80fd\u7684\u6280\u672f\u3002</p> <ul> <li>\u76ee\u6807\uff1a\u51cf\u5c11\u6a21\u578b\u8bc4\u4f30\u7684\u504f\u5dee\uff0c\u4f7f\u6027\u80fd\u8bc4\u4f30\u66f4\u7a33\u5b9a\u53ef\u9760\u3002</li> </ul>"},{"location":"machine/interview/#_58","title":"\u57fa\u672c\u601d\u60f3","text":"<p>\u5047\u8bbe\u6211\u4eec\u6709\u6570\u636e\u96c6 \\(D\\)\uff0c\u5927\u5c0f\u4e3a \\(N\\)\u3002</p> <ol> <li>\u5c06 \\(D\\) \u5206\u6210 \\(k\\) \u4e2a\u5927\u5c0f\u76f8\u540c\u7684\u5b50\u96c6\uff08folds\uff09\uff1a\\(D_1, D_2, ..., D_k\\)</li> <li> <p>\u8fdb\u884c \\(k\\) \u6b21\u8bad\u7ec3\u548c\u9a8c\u8bc1\uff1a</p> </li> <li> <p>\u6bcf\u6b21\u7528 \\(k-1\\) \u4e2a\u5b50\u96c6\u4f5c\u4e3a\u8bad\u7ec3\u96c6</p> </li> <li>\u5269\u4e0b\u7684 1 \u4e2a\u5b50\u96c6\u4f5c\u4e3a\u9a8c\u8bc1\u96c6</li> <li>\u6bcf\u6b21\u8ba1\u7b97\u6027\u80fd\u6307\u6807\uff08\u5982\u51c6\u786e\u7387 \\(Acc_i\\)\uff09</li> <li>\u5e73\u5747 \\(k\\) \u6b21\u6027\u80fd\u6307\u6807\u5f97\u5230\u6700\u7ec8\u4f30\u8ba1\uff1a    $$    Acc_{CV} = \\frac{1}{k} \\sum_{i=1}^{k} Acc_i    $$</li> </ol>"},{"location":"machine/interview/#_59","title":"\u5e38\u7528\u4ea4\u53c9\u9a8c\u8bc1\u65b9\u6cd5","text":""},{"location":"machine/interview/#1-k-k-fold-cv","title":"1. k \u6298\u4ea4\u53c9\u9a8c\u8bc1\uff08k-Fold CV\uff09","text":"<ul> <li>\u5c06\u6570\u636e\u968f\u673a\u5206\u6210 \\(k\\) \u4efd\uff0c\u6bcf\u6b21\u8f6e\u6d41\u505a\u9a8c\u8bc1\u96c6\u3002</li> <li>\u5e38\u7528 \\(k=5\\) \u6216 \\(k=10\\)\u3002</li> <li>\u4f18\u70b9\uff1a\u5229\u7528\u6570\u636e\u5145\u5206\u3001\u7a33\u5b9a\u6027\u597d</li> <li>\u7f3a\u70b9\uff1a\u8bad\u7ec3\u6b21\u6570 \\(k\\) \u6b21\uff0c\u8ba1\u7b97\u91cf\u5927</li> </ul>"},{"location":"machine/interview/#2-leave-one-out-loo","title":"2. \u7559\u4e00\u6cd5\u4ea4\u53c9\u9a8c\u8bc1\uff08Leave-One-Out, LOO\uff09","text":"<ul> <li>\u6bcf\u6b21\u7559 1 \u4e2a\u6837\u672c\u505a\u9a8c\u8bc1\uff0c\u5176\u4f59 \\(N-1\\) \u4e2a\u6837\u672c\u505a\u8bad\u7ec3</li> <li>\u4f18\u70b9\uff1a\u65e0\u504f\u4f30\u8ba1</li> <li>\u7f3a\u70b9\uff1a\u8ba1\u7b97\u91cf\u975e\u5e38\u5927\uff08\u5c24\u5176\u6837\u672c\u591a\u65f6\uff09</li> </ul>"},{"location":"machine/interview/#3-p-leave-p-out-lpo","title":"3. \u7559 P \u6cd5\u4ea4\u53c9\u9a8c\u8bc1\uff08Leave-P-Out, LPO\uff09","text":"<ul> <li>\u6bcf\u6b21\u7559 \\(p\\) \u4e2a\u6837\u672c\u505a\u9a8c\u8bc1</li> <li>\u6cdb\u5316\u4e86 LOO</li> </ul>"},{"location":"machine/interview/#4-k-stratified-k-fold","title":"4. \u5206\u5c42 k \u6298\u4ea4\u53c9\u9a8c\u8bc1\uff08Stratified k-Fold\uff09","text":"<ul> <li>\u9002\u7528\u4e8e\u5206\u7c7b\u95ee\u9898</li> <li>\u4fdd\u8bc1\u6bcf\u6298\u4e2d\u5404\u7c7b\u522b\u6bd4\u4f8b\u4e0e\u6574\u4f53\u6570\u636e\u96c6\u4e00\u81f4</li> <li>Python \u5e38\u7528 <code>StratifiedKFold</code></li> </ul>"},{"location":"machine/interview/#5-shuffle-split","title":"5. \u91cd\u590d\u968f\u673a\u5212\u5206\uff08Shuffle Split\uff09","text":"<ul> <li>\u6bcf\u6b21\u968f\u673a\u5212\u5206\u8bad\u7ec3\u96c6\u548c\u9a8c\u8bc1\u96c6</li> <li>\u53ef\u4ee5\u91cd\u590d\u591a\u6b21</li> <li>\u4f18\u70b9\uff1a\u7075\u6d3b\uff0c\u8bad\u7ec3\u96c6\u6bd4\u4f8b\u53ef\u63a7</li> </ul>"},{"location":"machine/interview/#_60","title":"\u6570\u5b66\u8868\u8ff0","text":"<p>\u8bbe\u6027\u80fd\u6307\u6807\u51fd\u6570\u4e3a \\(M(\\cdot)\\)\uff08\u5982\u5747\u65b9\u8bef\u5dee MSE\u3001\u51c6\u786e\u7387 Accuracy \u7b49\uff09\uff0c\\(k\\) \u6298\u4ea4\u53c9\u9a8c\u8bc1\u7684\u4f30\u8ba1\u4e3a\uff1a</p> \\[ CV_{k} = \\frac{1}{k} \\sum_{i=1}^{k} M(\\text{model trained on } D \\setminus D_i, D_i) \\] <ul> <li>\\(D \\setminus D_i\\)\uff1a\u8bad\u7ec3\u96c6</li> <li>\\(D_i\\)\uff1a\u9a8c\u8bc1\u96c6</li> </ul> <pre><code>from sklearn.model_selection import cross_val_score, KFold, StratifiedKFold\nfrom sklearn.datasets import load_iris\nfrom sklearn.linear_model import LogisticRegression\n\n# \u6570\u636e\u96c6\nX, y = load_iris(return_X_y=True)\n\n# \u6a21\u578b\nmodel = LogisticRegression(max_iter=200)\n\n# k-Fold \u4ea4\u53c9\u9a8c\u8bc1\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\nscores = cross_val_score(model, X, y, cv=kf, scoring='accuracy')\nprint(\"5-Fold CV Accuracy:\", scores)\nprint(\"\u5e73\u5747\u51c6\u786e\u7387:\", scores.mean())\n\n# \u5206\u5c42 k-Fold\uff08\u5206\u7c7b\u95ee\u9898\uff09\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\nscores_strat = cross_val_score(model, X, y, cv=skf, scoring='accuracy')\nprint(\"Stratified 5-Fold CV Accuracy:\", scores_strat.mean())\n</code></pre>"},{"location":"machine/interview/#43","title":"4.3 \u7f51\u683c\u641c\u7d22","text":""},{"location":"machine/interview/#_61","title":"\u7f51\u683c\u641c\u7d22\u7684\u6838\u5fc3\u539f\u7406","text":"<ol> <li>\u5b9a\u4e49\u53c2\u6570\u7f51\u683c    \u521b\u5efa\u4e00\u4e2a\u5305\u542b\u8d85\u53c2\u6570\u503c\u7684\u53c2\u6570\u7f51\u683c\uff0c\u5373\u6240\u6709\u53ef\u80fd\u7684\u8d85\u53c2\u6570\u7ec4\u5408\u3002\u4f8b\u5982\uff0c\u5bf9\u4e8e\u652f\u6301\u5411\u91cf\u673a\uff08SVM\uff09\uff0c\u53ef\u4ee5\u641c\u7d22\u53c2\u6570 <code>C</code> \u548c <code>gamma</code>\uff0c\u5bf9\u4e8e\u968f\u673a\u68ee\u6797\u53ef\u4ee5\u641c\u7d22 <code>max_depth</code> \u548c <code>n_estimators</code></li> <li>\u904d\u5386\u53c2\u6570\u7ec4\u5408    \u6309\u7167\u7f51\u683c\u4e2d\u7684\u6240\u6709\u7ec4\u5408\u8bad\u7ec3\u6a21\u578b\u5e76\u8bc4\u4f30\u6027\u80fd\u3002\u5bf9\u4e8e\u6bcf\u4e00\u4e2a\u53c2\u6570\u7ec4\u5408\uff0c\u4f7f\u7528\u4ea4\u53c9\u9a8c\u8bc1\u6765\u8bc4\u4f30\u6a21\u578b\u6027\u80fd</li> <li>\u9009\u62e9\u6700\u4f73\u53c2\u6570    \u6839\u636e\u67d0\u79cd\u8bc4\u4ef7\u6307\u6807\uff08\u5982\u51c6\u786e\u7387\u3001F1\u5206\u6570\u6216\u5747\u65b9\u8bef\u5dee\uff09\uff0c\u9009\u51fa\u6027\u80fd\u6700\u597d\u7684\u53c2\u6570\u914d\u7f6e</li> </ol>"},{"location":"machine/interview/#_62","title":"\u7f51\u683c\u641c\u7d22\u7684\u6d41\u7a0b","text":"<ul> <li>\u6570\u636e\u51c6\u5907\uff1a\u51c6\u5907\u597d\u8bad\u7ec3\u96c6\u548c\u9a8c\u8bc1\u96c6\uff0c\u9a8c\u8bc1\u96c6\u7528\u4e8e\u8bc4\u4f30\u6bcf\u4e2a\u53c2\u6570\u7ec4\u5408\u7684\u6027\u80fd</li> <li>\u5b9a\u4e49\u6a21\u578b\uff1a\u6307\u5b9a\u9700\u8981\u4f18\u5316\u7684\u6a21\u578b\uff08\u4f8b\u5982\u51b3\u7b56\u6811\u3001\u652f\u6301\u5411\u91cf\u673a\u6216\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff09</li> <li>\u53c2\u6570\u8303\u56f4\uff1a\u5b9a\u4e49\u9700\u8981\u8c03\u8282\u7684\u8d85\u53c2\u6570\u53ca\u5176\u53ef\u80fd\u7684\u53d6\u503c\u8303\u56f4</li> <li>\u8bad\u7ec3\u4e0e\u8bc4\u4f30\uff1a\u904d\u5386\u6240\u6709\u53c2\u6570\u7ec4\u5408\uff0c\u8bad\u7ec3\u6a21\u578b\uff0c\u5e76\u5728\u9a8c\u8bc1\u96c6\u4e0a\u8bc4\u4f30\u6027\u80fd</li> <li>\u9009\u62e9\u6700\u4f73\u53c2\u6570\uff1a\u6839\u636e\u9a8c\u8bc1\u96c6\u7684\u8bc4\u4ef7\u6307\u6807\uff0c\u9009\u51fa\u6027\u80fd\u6700\u597d\u7684\u8d85\u53c2\u6570\u7ec4\u5408</li> </ul>"},{"location":"machine/interview/#_63","title":"\u4f18\u70b9\u4e0e\u7f3a\u70b9","text":"<p>\u4f18\u70b9\uff1a</p> <ul> <li>\u7cfb\u7edf\u5168\u9762\uff1a\u901a\u8fc7\u904d\u5386\u6240\u6709\u53c2\u6570\u7ec4\u5408\uff0c\u4fdd\u8bc1\u627e\u5230\u5168\u5c40\u6700\u4f18\u89e3\uff08\u5728\u7ed9\u5b9a\u641c\u7d22\u7a7a\u95f4\u5185\uff09</li> <li>\u6613\u4e8e\u5b9e\u73b0\uff1a\u5404\u79cd\u673a\u5668\u5b66\u4e60\u5e93\uff08\u5982 scikit-learn\uff09\u63d0\u4f9b\u4e86\u7b80\u5355\u7684\u63a5\u53e3\u6765\u5b9e\u73b0\u7f51\u683c\u641c\u7d22</li> </ul> <p>\u7f3a\u70b9\uff1a</p> <ul> <li>\u8ba1\u7b97\u6210\u672c\u9ad8\uff1a\u968f\u7740\u53c2\u6570\u6570\u91cf\u548c\u53ef\u80fd\u7684\u53d6\u503c\u589e\u52a0\uff0c\u641c\u7d22\u7a7a\u95f4\u4f1a\u5448\u6307\u6570\u7ea7\u589e\u957f\uff0c\u5bfc\u81f4\u8bad\u7ec3\u65f6\u95f4\u8fc7\u957f</li> <li>\u6548\u7387\u4f4e\u4e0b\uff1a\u5bf9\u4e8e\u5927\u578b\u6570\u636e\u96c6\u548c\u590d\u6742\u6a21\u578b\uff0c\u7f51\u683c\u641c\u7d22\u53ef\u80fd\u4f1a\u53d8\u5f97\u975e\u5e38\u8017\u65f6</li> </ul> <pre><code>from sklearn.model_selection import GridSearchCV\nfrom sklearn.svm import SVC\nfrom sklearn.datasets import load_iris\n\u52a0\u8f7d\u6570\u636e\u96c6\ndata = load_iris()\nX, y = data.data, data.target\n\u5b9a\u4e49\u6a21\u578b\nmodel = SVC()\n\u5b9a\u4e49\u53c2\u6570\u7f51\u683c\nparam_grid = {\n    'C': [0.1, 1, 10, 100],\n    'gamma': [1, 0.1, 0.01, 0.001],\n    'kernel': ['rbf']\n}\n\u7f51\u683c\u641c\u7d22\ngrid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy')\ngrid_search.fit(X, y)\n\u8f93\u51fa\u6700\u4f73\u53c2\u6570\u548c\u5bf9\u5e94\u7684\u6027\u80fd\nprint(\"\u6700\u4f73\u53c2\u6570:\", grid_search.best_params_)\nprint(\"\u6700\u4f73\u51c6\u786e\u7387:\", grid_search.best_score_)\n</code></pre>"},{"location":"machine/interview/#44","title":"4.4 \u968f\u673a\u641c\u7d22","text":""},{"location":"machine/interview/#_64","title":"\u968f\u673a\u641c\u7d22\u7684\u6838\u5fc3\u539f\u7406","text":"<ol> <li>\u968f\u673a\u91c7\u6837    \u4e0e\u7f51\u683c\u641c\u7d22\u4e0d\u540c\uff0c\u968f\u673a\u641c\u7d22\u4e0d\u4f1a\u7a77\u4e3e\u6240\u6709\u53c2\u6570\u7ec4\u5408\uff0c\u800c\u662f\u4ece\u53c2\u6570\u7684\u5019\u9009\u5206\u5e03\u4e2d\u968f\u673a\u9009\u62e9\u7ec4\u5408\u8fdb\u884c\u8bc4\u4f30\u3002\u8fd9\u6837\u53ef\u4ee5\u5927\u5927\u51cf\u5c11\u8ba1\u7b97\u91cf\uff0c\u5c24\u5176\u5728\u8d85\u53c2\u6570\u6570\u91cf\u8f83\u591a\u65f6\uff0c\u6548\u7387\u66f4\u9ad8\u3002</li> <li>\u8fed\u4ee3\u4f18\u5316    \u968f\u673a\u641c\u7d22\u901a\u8fc7\u591a\u6b21\u8fed\u4ee3\uff0c\u6bcf\u6b21\u968f\u673a\u751f\u6210\u4e00\u7ec4\u8d85\u53c2\u6570\uff0c\u8bad\u7ec3\u6a21\u578b\u5e76\u8bc4\u4f30\u6027\u80fd\uff0c\u8bb0\u5f55\u6700\u4f73\u7ed3\u679c\u3002\u968f\u7740\u8fed\u4ee3\u6b21\u6570\u589e\u52a0\uff0c\u627e\u5230\u8f83\u4f18\u89e3\u7684\u6982\u7387\u63d0\u5347\u3002</li> <li>\u7075\u6d3b\u7684\u641c\u7d22\u7a7a\u95f4    \u652f\u6301\u591a\u79cd\u6982\u7387\u5206\u5e03\uff08\u5982\u5747\u5300\u5206\u5e03\u3001\u5bf9\u6570\u5747\u5300\u5206\u5e03\u3001\u6b63\u6001\u5206\u5e03\u7b49\uff09\uff0c\u80fd\u66f4\u597d\u5730\u63a2\u7d22\u53c2\u6570\u7a7a\u95f4\uff0c\u6709\u52a9\u4e8e\u8df3\u51fa\u5c40\u90e8\u6700\u4f18\u89e3\u3002</li> </ol>"},{"location":"machine/interview/#_65","title":"\u4f18\u70b9\u4e0e\u7f3a\u70b9","text":"<p>\u4f18\u70b9\uff1a</p> <ul> <li>\u8ba1\u7b97\u6548\u7387\u9ad8\uff1a\u76f8\u6bd4\u7f51\u683c\u641c\u7d22\uff0c\u8ba1\u7b97\u6210\u672c\u663e\u8457\u964d\u4f4e\uff0c\u5c24\u5176\u9002\u5408\u9ad8\u7ef4\u53c2\u6570\u7a7a\u95f4</li> <li>\u7075\u6d3b\u5ea6\u9ad8\uff1a\u652f\u6301\u8fde\u7eed\u3001\u79bb\u6563\u53c2\u6570\u53ca\u5404\u79cd\u5206\u5e03\uff0c\u51cf\u5c11\u4eba\u4e3a\u8bbe\u5b9a\u504f\u5dee</li> <li>\u6613\u4e8e\u5e76\u884c\uff1a\u6bcf\u6b21\u91c7\u6837\u72ec\u7acb\uff0c\u53ef\u65b9\u4fbf\u5730\u5e76\u884c\u5904\u7406</li> </ul> <p>\u7f3a\u70b9\uff1a</p> <ul> <li>\u7ed3\u679c\u4e0d\u786e\u5b9a\u6027\uff1a\u7531\u4e8e\u968f\u673a\u6027\uff0c\u4e0d\u540c\u8fd0\u884c\u7ed3\u679c\u53ef\u80fd\u6709\u5dee\u5f02\uff0c\u4e0d\u4e00\u5b9a\u603b\u80fd\u627e\u5230\u5168\u5c40\u6700\u4f18\u89e3</li> <li>\u7f3a\u4e4f\u65b9\u5411\u6027\uff1a\u6bcf\u6b21\u91c7\u6837\u72ec\u7acb\uff0c\u4e0d\u80fd\u5229\u7528\u5386\u53f2\u4fe1\u606f\u6307\u5bfc\u641c\u7d22</li> </ul> <pre><code>from sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom scipy.stats import randint\n\u5b9a\u4e49\u6a21\u578b\nmodel = RandomForestClassifier()\n\u5b9a\u4e49\u53c2\u6570\u5206\u5e03\nparam_dist = {\n    'n_estimators': randint(1, 200),\n    'max_features': randint(7, 9),\n}\n\u968f\u673a\u641c\u7d22\nrandom_search = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=10, cv=5)\nrandom_search.fit(X_train, y_train)\n\u8f93\u51fa\u6700\u4f73\u53c2\u6570\nprint(\"\u6700\u4f73\u53c2\u6570:\", random_search.best_params_)\nprint(\"\u6700\u4f73\u5f97\u5206:\", random_search.best_score_)\n</code></pre>"},{"location":"machine/interview/#45","title":"4.5 \u8d1d\u53f6\u65af\u4f18\u5316","text":""},{"location":"machine/interview/#_66","title":"\u4e94\u3001\u5206\u7c7b","text":"<p>\u5206\u7c7b\u95ee\u9898\u7684\u76ee\u6807\u662f\uff1a \u5b66\u4e60\u4e00\u4e2a\u6a21\u578b \\(f(x)\\) \u6765\u9884\u6d4b\u6837\u672c\u5c5e\u4e8e\u7c7b\u522b \\(y\\) \u7684\u6982\u7387\u3002</p> <p>\u5e38\u89c1\u7c7b\u578b\uff1a</p> <ul> <li>\u4e8c\u5206\u7c7b\uff1a\\(y \\in {0,1}\\)</li> <li>\u591a\u5206\u7c7b\uff1a\\(y \\in {1,2,...,K}\\)</li> </ul> <p>\u6211\u4eec\u5b9a\u4e49\u4e00\u4e2a\u635f\u5931\u51fd\u6570 \\(L(y, \\hat{y})\\) \u8861\u91cf\u9884\u6d4b \\(\\hat{y}\\) \u4e0e\u771f\u5b9e\u6807\u7b7e \\(y\\) \u4e4b\u95f4\u7684\u5dee\u8ddd\u3002 \u5b66\u4e60\u76ee\u6807\u662f\u6700\u5c0f\u5316\u671f\u671b\u635f\u5931\uff1a</p> \\[ \\min_\\theta ; \\mathbb{E}*{(x,y)} [L(y, f*\\theta(x))] \\]"},{"location":"machine/interview/#51","title":"5.1 \u635f\u5931\u51fd\u6570","text":"\u7c7b\u578b \u635f\u5931\u51fd\u6570 \u5e38\u7528\u4e8e\u7b97\u6cd5 0-1 \u635f\u5931 \u7406\u8bba\u8bc4\u4f30 \u7406\u8bba\u6700\u4f18\u5206\u7c7b\u5668 \u5bf9\u6570\u635f\u5931 / \u4ea4\u53c9\u71b5 Logistic \u56de\u5f52\u3001\u795e\u7ecf\u7f51\u7edc \u6982\u7387\u6a21\u578b Hinge \u635f\u5931 \u652f\u6301\u5411\u91cf\u673a\uff08SVM\uff09 \u95f4\u9694\u6700\u5927\u5316 \u6307\u6570\u635f\u5931 Adaboost \u96c6\u6210\u65b9\u6cd5 Softmax + CrossEntropy \u591a\u5206\u7c7b \u795e\u7ecf\u7f51\u7edc\u3001\u591a\u7c7b\u903b\u8f91\u56de\u5f52 Focal Loss \u76ee\u6807\u68c0\u6d4b\uff08\u4e0d\u5e73\u8861\u6837\u672c\uff09 \u6df1\u5ea6\u5b66\u4e60"},{"location":"machine/interview/#1_11","title":"1\ufe0f\u20e3 \u4e8c\u5206\u7c7b\u635f\u5931\u51fd\u6570\u8be6\u89e3","text":""},{"location":"machine/interview/#1-0-1","title":"(1) 0-1 \u635f\u5931","text":"<p>\u5b9a\u4e49\uff1a</p> \\[ L(y, \\hat{y}) = \\begin{cases} 0, &amp; \\text{if } y = \\hat{y} \\\\ 1, &amp; \\text{if } y \\neq \\hat{y} \\end{cases} \\] <p>\u7279\u70b9\uff1a</p> <ul> <li>\u53cd\u6620\u5206\u7c7b\u51c6\u786e\u7387</li> <li>\u4e0d\u53ef\u5bfc\u3001\u4e0d\u8fde\u7eed\uff0c\u4e0d\u80fd\u76f4\u63a5\u7528\u4e8e\u4f18\u5316</li> </ul> <p>\u7528\u9014\uff1a</p> <ul> <li>\u7406\u8bba\u5206\u6790\uff08\u4f8b\u5982 Bayes \u6700\u4f18\u5206\u7c7b\u5668\uff09</li> </ul>"},{"location":"machine/interview/#2_9","title":"(2) \u5bf9\u6570\u635f\u5931 / \u4ea4\u53c9\u71b5\u635f\u5931","text":"<p>\u6838\u5fc3\u601d\u60f3\uff1a \u7528\u9884\u6d4b\u6982\u7387\u903c\u8fd1\u771f\u5b9e\u5206\u5e03\uff0c\u6700\u5c0f\u5316\u5b83\u4eec\u7684\u5dee\u5f02\uff08\u5373\u4ea4\u53c9\u71b5\uff09\u3002</p> <p>\u5047\u8bbe\u8f93\u51fa\u4e3a\u6982\u7387 \\(\\hat{p} = P(y=1|x)\\)\uff0c\u771f\u5b9e\u6807\u7b7e \\(y \\in {0,1}\\)\u3002</p> <p>\u516c\u5f0f\uff1a</p> \\[ L(y, \\hat{p}) = -[y \\log(\\hat{p}) + (1 - y)\\log(1 - \\hat{p})] \\] <p>\u89e3\u91ca\uff1a</p> <ul> <li>\u5f53\u9884\u6d4b\u63a5\u8fd1\u771f\u5b9e\u6807\u7b7e\u65f6\uff0c\u635f\u5931\u8d8b\u8fd1\u4e8e 0\uff1b</li> <li>\u5f53\u9884\u6d4b\u9519\u8bef\u4e14\u7f6e\u4fe1\u5ea6\u9ad8\u65f6\uff0c\u635f\u5931\u5de8\u5927\uff08\u60e9\u7f5a\u66f4\u5f3a\uff09\u3002</li> </ul> <p>\u56fe\u50cf\u7406\u89e3\uff1a \u4ea4\u53c9\u71b5\u66f2\u7ebf\u6bd4\u5e73\u65b9\u8bef\u5dee\u9661\u5ced\uff0c\u4f18\u5316\u6548\u679c\u66f4\u597d\u3002</p> <p>\u4ee3\u7801\u793a\u4f8b\uff1a</p> <pre><code>from sklearn.metrics import log_loss\ny_true = [1, 0, 1, 1]\ny_pred = [0.9, 0.1, 0.8, 0.6]\nprint(log_loss(y_true, y_pred))\n</code></pre> <p>\u9002\u7528\u573a\u666f\uff1a</p> <ul> <li>\u903b\u8f91\u56de\u5f52\uff08Logistic Regression\uff09</li> <li>\u795e\u7ecf\u7f51\u7edc\u5206\u7c7b\u5c42\uff08Softmax + CrossEntropy\uff09</li> </ul>"},{"location":"machine/interview/#3-hinge","title":"(3) Hinge \u635f\u5931\uff08\u5408\u9875\u635f\u5931\uff09","text":"<p>\u7528\u4e8e\u652f\u6301\u5411\u91cf\u673a\uff08SVM\uff09\u7b49\u6700\u5927\u95f4\u9694\u5206\u7c7b\u3002</p> <p>\u5047\u8bbe\u6807\u7b7e \\(y \\in {-1, +1}\\)\uff0c\u9884\u6d4b\u503c\u4e3a \\(f(x)\\)\u3002</p> <p>\u516c\u5f0f\uff1a</p> \\[ L(y, f(x)) = \\max(0, 1 - y \\cdot f(x)) \\] <p>\u89e3\u91ca\uff1a</p> <ul> <li>\u82e5 \\(y \\cdot f(x) \\ge 1\\)\uff0c\u8bf4\u660e\u5206\u7c7b\u6b63\u786e\u4e14\u6709\u8db3\u591f\u95f4\u9694 \u2192 \u635f\u5931\u4e3a 0\uff1b</li> <li>\u5426\u5219\uff0c\u635f\u5931\u4e0e\u8ddd\u79bb\u6210\u7ebf\u6027\u589e\u52a0\u3002</li> </ul> <p>\u51e0\u4f55\u610f\u4e49\uff1a \u5e0c\u671b\u70b9\u79bb\u5206\u754c\u9762\u201c\u66f4\u8fdc\u201d\uff0c\u4ece\u800c\u63d0\u5347\u9c81\u68d2\u6027\u3002</p> <p>\u4ee3\u7801\u793a\u4f8b\uff1a</p> <pre><code>from sklearn.svm import LinearSVC\nfrom sklearn.metrics import hinge_loss\n\ny_true = [1, -1, 1]\npred_decision = [0.8, -0.5, 0.2]\nprint(hinge_loss(y_true, pred_decision))\n</code></pre>"},{"location":"machine/interview/#4-exponential-loss","title":"(4) \u6307\u6570\u635f\u5931\uff08Exponential Loss\uff09","text":"<p>\u7528\u4e8e Adaboost \u7b97\u6cd5\u3002</p> <p>\u516c\u5f0f\uff1a</p> \\[ L(y, f(x)) = e^{-y f(x)} \\] <p>\u89e3\u91ca\uff1a</p> <ul> <li>\u9519\u8bef\u5206\u7c7b\uff08\\(y f(x) &lt; 0\\)\uff09\u65f6\u60e9\u7f5a\u5448\u6307\u6570\u589e\u957f\uff1b</li> <li>\u5bf9\u5f02\u5e38\u503c\u654f\u611f\u3002</li> </ul> <p>\u5e94\u7528\uff1a</p> <ul> <li>Boosting \u7cfb\u5217\u7b97\u6cd5\u7684\u7406\u8bba\u57fa\u7840</li> </ul>"},{"location":"machine/interview/#2_10","title":"2\ufe0f\u20e3 \u591a\u5206\u7c7b\u635f\u5931\u51fd\u6570","text":""},{"location":"machine/interview/#1-softmax-cross-entropy","title":"(1) Softmax + Cross-Entropy","text":"<p>\u8fd9\u662f\u591a\u5206\u7c7b\u6700\u5e38\u89c1\u7684\u635f\u5931\u3002</p> <p>Softmax \u5c42\uff1a \u5c06\u6a21\u578b\u8f93\u51fa \\(z_i\\) \u6620\u5c04\u4e3a\u6982\u7387\uff1a</p> \\[ \\hat{p_i} = \\frac{e^{z_i}}{\\sum_{j=1}^K e^{z_j}} \\] <p>Cross-Entropy\uff1a $$ L = - \\sum_{i=1}^K y_i \\log(\\hat{p_i}) $$</p> <p>\u5176\u4e2d \\(y_i\\) \u662f\u72ec\u70ed\u7f16\u7801\uff08one-hot\uff09\u5f62\u5f0f\u3002 \u82e5\u771f\u5b9e\u7c7b\u522b\u4e3a \\(c\\)\uff1a</p> \\[ L = -\\log(\\hat{p_c}) \\] <p>\u89e3\u91ca\uff1a \u9884\u6d4b\u771f\u5b9e\u7c7b\u522b\u7684\u6982\u7387\u8d8a\u5927\uff0c\u635f\u5931\u8d8a\u5c0f\u3002</p> <p>\u4ee3\u7801\u793a\u4f8b\uff1a</p> <pre><code>import torch\nimport torch.nn.functional as F\n\ny_true = torch.tensor([2])  # \u7c7b\u522b\u7d22\u5f15\ny_pred = torch.tensor([[2.0, 0.5, 4.0]])  # logits\nloss = F.cross_entropy(y_pred, y_true)\nprint(loss.item())\n</code></pre>"},{"location":"machine/interview/#2-hinge","title":"(2) \u591a\u7c7b Hinge \u635f\u5931","text":"<p>\u516c\u5f0f\uff1a</p> \\[ L = \\sum_{i \\ne y} \\max(0, f_i - f_y + \\Delta) \\] <p>\u5176\u4e2d\uff1a</p> <ul> <li>\\(f_i\\) \u4e3a\u7c7b\u522b \\(i\\) \u7684\u5f97\u5206</li> <li>\\(\\Delta\\) \u4e3a\u95f4\u9694\uff08\u901a\u5e38\u53d6 1\uff09</li> </ul> <p>\u7528\u9014\uff1a</p> <ul> <li>\u591a\u7c7b\u652f\u6301\u5411\u91cf\u673a\uff08Multi-class SVM\uff09</li> </ul>"},{"location":"machine/interview/#3-weighted-loss","title":"3\ufe0f\u20e3 \u5e26\u6743\u635f\u5931\uff08Weighted Loss\uff09","text":"<p>\u5728\u6837\u672c\u7c7b\u522b\u4e0d\u5e73\u8861\u65f6\uff08\u4f8b\u5982\u6b3a\u8bc8\u68c0\u6d4b\u3001\u533b\u5b66\u8bca\u65ad\uff09\uff0c \u7ed9\u4e0d\u540c\u7c7b\u522b\u4e0d\u540c\u6743\u91cd\uff1a</p> \\[ L = -[w_1 y \\log(\\hat{p}) + w_0 (1-y)\\log(1-\\hat{p})] \\] <p>\u6216\u591a\u5206\u7c7b\u7248\u672c\uff1a</p> \\[ L = -\\sum_{i=1}^K w_i y_i \\log(\\hat{p_i}) \\] <p>\u6df1\u5ea6\u5b66\u4e60\u6269\u5c55\uff1a Focal Loss\uff08\u7528\u4e8e\u76ee\u6807\u68c0\u6d4b\uff09\uff1a</p> \\[ L = - (1 - \\hat{p_t})^\\gamma \\log(\\hat{p_t}) \\] <p>\u5176\u4e2d \\(\\gamma &gt; 0\\) \u63a7\u5236\u56f0\u96be\u6837\u672c\u7684\u5173\u6ce8\u5ea6\u3002</p>"},{"location":"machine/interview/#52","title":"5.2 \u8bc4\u4f30\u6307\u6807","text":""},{"location":"machine/interview/#_67","title":"\ud83e\udded \u4e00\u3001\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u56db\u79cd\u7ed3\u679c\u7c7b\u578b\uff08\u6df7\u6dc6\u77e9\u9635\u57fa\u7840\uff09","text":"<p>\u5728\u4e8c\u5206\u7c7b\u95ee\u9898\u4e2d\uff08\u6b63\u7c7b Positive / \u8d1f\u7c7b Negative\uff09\uff0c\u6bcf\u4e2a\u6837\u672c\u9884\u6d4b\u7ed3\u679c\u53ef\u5206\u4e3a\u56db\u7c7b\uff1a</p> \u5b9e\u9645 / \u9884\u6d4b Positive Negative Positive\uff08\u771f\u5b9e\u4e3a\u6b63\uff09 True Positive (TP) False Negative (FN) Negative\uff08\u771f\u5b9e\u4e3a\u8d1f\uff09 False Positive (FP) True Negative (TN) <p>\u7531\u6b64\u5f62\u6210\u6df7\u6dc6\u77e9\u9635\uff08Confusion Matrix\uff09\uff1a</p> \\[ \\begin{bmatrix} TP &amp; FP \\ FN &amp; TN \\end{bmatrix} \\]"},{"location":"machine/interview/#accuracy","title":"\ud83e\uddee \u4e8c\u3001\u51c6\u786e\u7387\uff08Accuracy\uff09","text":""},{"location":"machine/interview/#_68","title":"\u5b9a\u4e49\uff1a","text":"\\[ \\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN} \\]"},{"location":"machine/interview/#_69","title":"\u542b\u4e49\uff1a","text":"<p>\u9884\u6d4b\u6b63\u786e\u7684\u6837\u672c\u5360\u603b\u6837\u672c\u6bd4\u4f8b\u3002</p>"},{"location":"machine/interview/#_70","title":"\u793a\u4f8b\uff1a","text":"<p>\u82e5\u6a21\u578b\u9884\u6d4b 100 \u4e2a\u6837\u672c\uff0c\u5176\u4e2d\u6b63\u786e 90 \u4e2a\uff0c\u5219\uff1a $$ \\text{Accuracy} = \\frac{90}{100} = 0.9 $$</p>"},{"location":"machine/interview/#_71","title":"\u4f18\u7f3a\u70b9\uff1a","text":"<ul> <li>\u2705 \u7b80\u5355\u76f4\u89c2\u3002</li> <li>\u274c \u5f53\u6837\u672c\u4e25\u91cd\u4e0d\u5e73\u8861\u65f6\uff08\u4f8b\u5982 99% \u4e3a\u8d1f\u7c7b\uff09\uff0c\u51c6\u786e\u7387\u4f1a\u63a9\u76d6\u9519\u8bef\u3002\u4f8b\u5982\u6a21\u578b\u5168\u9884\u6d4b\u4e3a\u8d1f\u7c7b\uff0c\u51c6\u786e\u7387\u4ecd\u53ef\u8fbe 99%\u3002</li> </ul>"},{"location":"machine/interview/#precisionrecall","title":"\ud83c\udfaf \u4e09\u3001\u7cbe\u786e\u7387\uff08Precision\uff09\u4e0e\u53ec\u56de\u7387\uff08Recall\uff09","text":""},{"location":"machine/interview/#1-precision","title":"1\ufe0f\u20e3 \u7cbe\u786e\u7387\uff08Precision\uff09","text":"<p>\u5b9a\u4e49\uff1a $$ \\text{Precision} = \\frac{TP}{TP + FP} $$</p> <p>\u542b\u4e49\uff1a \u88ab\u9884\u6d4b\u4e3a\u6b63\u7c7b\u7684\u6837\u672c\u4e2d\uff0c\u6709\u591a\u5c11\u662f\u771f\u7684\u6b63\u7c7b\u3002</p> <p>\u9ad8\u7cbe\u786e\u7387 \u2192 \u6a21\u578b\u201c\u614e\u91cd\u201d\uff0c\u9884\u6d4b\u4e3a\u6b63\u7684\u6837\u672c\u5927\u591a\u786e\u5b9e\u662f\u6b63\u3002</p>"},{"location":"machine/interview/#2-recall","title":"2\ufe0f\u20e3 \u53ec\u56de\u7387\uff08Recall\uff09","text":"<p>\u5b9a\u4e49\uff1a $$ \\text{Recall} = \\frac{TP}{TP + FN} $$</p> <p>\u542b\u4e49\uff1a \u6240\u6709\u771f\u5b9e\u6b63\u7c7b\u6837\u672c\u4e2d\uff0c\u6a21\u578b\u627e\u51fa\u4e86\u591a\u5c11\u4e2a\u3002</p> <p>\u9ad8\u53ec\u56de\u7387 \u2192 \u6a21\u578b\u201c\u654f\u611f\u201d\uff0c\u5c3d\u53ef\u80fd\u627e\u51fa\u6240\u6709\u6b63\u6837\u672c\u3002</p>"},{"location":"machine/interview/#_72","title":"\u6570\u503c\u793a\u4f8b\uff1a","text":"\u5b9e\u9645 \u9884\u6d4b 100 \u4e2a\u6b63\u6837\u672c\u4e2d\u6a21\u578b\u627e\u51fa 80 \u4e2a\uff08TP=80\uff0cFN=20\uff09 \u540c\u65f6\u9519\u8bef\u9884\u6d4b 10 \u4e2a\u8d1f\u6837\u672c\u4e3a\u6b63\uff08FP=10\uff09 <p>\u8ba1\u7b97\uff1a $$ \\text{Precision} = \\frac{80}{80+10} = 0.8889 $$ $$ \\text{Recall} = \\frac{80}{80+20} = 0.8 $$</p>"},{"location":"machine/interview/#precision-recall-tradeoff","title":"\u5e73\u8861\u5173\u7cfb\uff08Precision-Recall Tradeoff\uff09\uff1a","text":"<p>\u901a\u5e38\uff0c\u63d0\u9ad8 Recall \u4f1a\u964d\u4f4e Precision\uff08\u6a21\u578b\u66f4\u201c\u6fc0\u8fdb\u201d\uff09\uff0c\u53cd\u4e4b\u4ea6\u7136\u3002 \u9608\u503c\uff08threshold\uff09\u8c03\u8282\u80fd\u6539\u53d8\u4e24\u8005\u5e73\u8861\u3002</p>"},{"location":"machine/interview/#f1-f1-score","title":"\ud83d\udd01 \u56db\u3001F1 \u5206\u6570\uff08F1-score\uff09","text":"<p>\u4e3a\u5e73\u8861\u7cbe\u786e\u7387\u4e0e\u53ec\u56de\u7387\uff0c\u5f15\u5165\u8c03\u548c\u5e73\u5747\u6570\uff1a</p> \\[ F_1 = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}} \\]"},{"location":"machine/interview/#_73","title":"\u793a\u4f8b\uff1a","text":"\\[ \\text{Precision}=0.8889,\\quad \\text{Recall}=0.8 \\] <p>\u4ee3\u5165\uff1a</p> \\[ F_1 = 2 \\times \\frac{0.8889\\times 0.8}{0.8889+0.8} = 0.842 \\]"},{"location":"machine/interview/#_74","title":"\u7279\u70b9\uff1a","text":"<ul> <li>F1 \u9ad8 \u2192 \u6a21\u578b\u540c\u65f6\u517c\u987e\u9ad8 Precision \u548c Recall\uff1b</li> <li>\u5e38\u7528\u4e8e\u4e0d\u5e73\u8861\u5206\u7c7b\u95ee\u9898\uff1b</li> <li>\u5f53\u6b63\u8d1f\u6837\u672c\u6bd4\u4f8b\u6781\u4e0d\u5747\u8861\u65f6\uff0cF1 \u6bd4 Accuracy \u66f4\u80fd\u53cd\u6620\u6a21\u578b\u6027\u80fd\u3002</li> </ul>"},{"location":"machine/interview/#f","title":"\u2696\ufe0f \u4e94\u3001F\u03b2 \u5206\u6570\uff08\u901a\u7528\u5f62\u5f0f\uff09","text":"<p>\u82e5\u5e0c\u671b\u66f4\u5173\u6ce8 Recall \u6216 Precision\uff0c\u53ef\u7528\u52a0\u6743\u7248\uff1a</p> \\[ F_\\beta = (1+\\beta^2)\\cdot \\frac{\\text{Precision}\\cdot\\text{Recall}}{(\\beta^2\\cdot\\text{Precision})+\\text{Recall}} \\] <ul> <li>\\(\\beta&gt;1\\) \u2192 \u66f4\u6ce8\u91cd Recall\uff1b</li> <li>\\(\\beta&lt;1\\) \u2192 \u66f4\u6ce8\u91cd Precision\u3002</li> </ul> <p>\u4f8b\uff1a\\(F_{0.5}\\) \u504f\u5411\u7cbe\u786e\u7387\uff0c\\(F_2\\) \u504f\u5411\u53ec\u56de\u7387\u3002</p>"},{"location":"machine/interview/#specificityfpr","title":"\ud83d\udcca \u516d\u3001\u7279\u5f02\u5ea6\uff08Specificity\uff09\u4e0e\u5047\u9633\u7387\uff08FPR\uff09","text":""},{"location":"machine/interview/#true-negative-rate","title":"\u7279\u5f02\u5ea6\uff08True Negative Rate\uff09\uff1a","text":"\\[ \\text{Specificity} = \\frac{TN}{TN + FP} \\]"},{"location":"machine/interview/#false-positive-rate","title":"\u5047\u9633\u7387\uff08False Positive Rate\uff09\uff1a","text":"\\[ \\text{FPR} = \\frac{FP}{FP + TN} = 1 - \\text{Specificity} \\] <p>\u5728\u533b\u5b66\u573a\u666f\uff0c\u7279\u5f02\u5ea6\u8868\u793a\u6a21\u578b\u8bc6\u522b\u201c\u5065\u5eb7\u4eba\u201d\u7684\u80fd\u529b\u3002</p>"},{"location":"machine/interview/#roc-aucarea-under-curve","title":"\ud83e\udeb6 \u4e03\u3001ROC \u66f2\u7ebf\u4e0e AUC\uff08Area Under Curve\uff09","text":""},{"location":"machine/interview/#1-roc","title":"1\ufe0f\u20e3 ROC \u66f2\u7ebf\u5b9a\u4e49\uff1a","text":"<p>ROC \u66f2\u7ebf\u4ee5\uff1a</p> <ul> <li>\u6a2a\u8f74\uff1a\u5047\u9633\u7387\uff08FPR\uff09</li> <li>\u7eb5\u8f74\uff1a\u771f\u6b63\u7387\uff08TPR\uff09= Recall = \\(\\frac{TP}{TP + FN}\\)</li> </ul> <p>\u5f53\u9608\u503c\u4ece 1 \u964d\u5230 0 \u65f6\uff0c\u7ed8\u5236 \\((\\text{FPR}, \\text{TPR})\\) \u70b9\u3002</p>"},{"location":"machine/interview/#2-auc","title":"2\ufe0f\u20e3 AUC \u6307\u6807\uff1a","text":"<p>AUC \u662f ROC \u66f2\u7ebf\u4e0b\u7684\u9762\u79ef\uff1a $$ \\text{AUC} = \\int_0^1 \\text{TPR}(x),dx $$</p> <p>AUC \u53d6\u503c\u8303\u56f4 \\([0,1]\\)\uff1a</p> <ul> <li>AUC = 1\uff1a\u5b8c\u7f8e\u5206\u7c7b\u5668</li> <li>AUC = 0.5\uff1a\u968f\u673a\u731c\u6d4b</li> <li>AUC &lt; 0.5\uff1a\u6027\u80fd\u6bd4\u968f\u673a\u8fd8\u5dee\uff08\u9884\u6d4b\u7ed3\u679c\u53ef\u53cd\u8f6c\uff09</li> </ul>"},{"location":"machine/interview/#3_6","title":"3\ufe0f\u20e3 \u76f4\u89c2\u89e3\u91ca\uff1a","text":"<p>AUC = \u201c\u968f\u673a\u62bd\u53d6\u4e00\u5bf9\uff08\u6b63\u6837\u672c\u3001\u8d1f\u6837\u672c\uff09\uff0c\u6a21\u578b\u5224\u65ad\u6b63\u6837\u672c\u5f97\u5206\u66f4\u9ad8\u7684\u6982\u7387\u201d\u3002</p>"},{"location":"machine/interview/#pr-precisionrecall","title":"\ud83e\uddf1 \u516b\u3001PR \u66f2\u7ebf\uff08Precision\u2013Recall \u66f2\u7ebf\uff09","text":"<p>\u6a2a\u8f74\u4e3a Recall\uff0c\u7eb5\u8f74\u4e3a Precision\uff0c\u66f2\u7ebf\u53cd\u6620\u9608\u503c\u53d8\u5316\u4e0b\u7684\u53d6\u820d\u3002</p> <p>\u5728\u7c7b\u522b\u6781\u4e0d\u5e73\u8861\u7684\u60c5\u51b5\u4e0b\uff0cPR \u66f2\u7ebf\u66f4\u6709\u610f\u4e49\uff08\u76f8\u6bd4 ROC \u66f2\u7ebf\uff09\u3002</p>"},{"location":"machine/interview/#_75","title":"\ud83e\uddfe \u4e5d\u3001\u5b8f\u5e73\u5747\u4e0e\u5fae\u5e73\u5747\uff08\u591a\u5206\u7c7b\u6307\u6807\uff09","text":"<p>\u5f53\u5206\u7c7b\u4efb\u52a1\u662f\u591a\u7c7b\u522b\uff08\u5982 3 \u7c7b\u30015 \u7c7b\uff09\u65f6\uff0cPrecision\u3001Recall\u3001F1 \u6709\u591a\u79cd\u6c42\u6cd5\uff1a</p> <ul> <li> <p>Macro \u5e73\u5747\uff08Macro-Average\uff09\uff1a   \u5bf9\u6bcf\u4e2a\u7c7b\u522b\u72ec\u7acb\u8ba1\u7b97\u6307\u6807\uff0c\u7136\u540e\u5e73\u5747\uff1a   $$   \\text{Macro-F1} = \\frac{1}{C}\\sum_{i=1}^C F_1^{(i)}   $$   \u2192 \u5404\u7c7b\u6743\u91cd\u76f8\u540c\uff08\u4e0d\u8003\u8651\u6837\u672c\u6570\u5dee\u5f02\uff09</p> </li> <li> <p>Micro \u5e73\u5747\uff08Micro-Average\uff09\uff1a   \u7edf\u8ba1\u6240\u6709\u6837\u672c\u603b\u7684 TP\u3001FP\u3001FN \u540e\u518d\u7b97\uff1a   $$   \\text{Micro-F1} = \\frac{2TP_{\\text{total}}}{2TP_{\\text{total}} + FP_{\\text{total}} + FN_{\\text{total}}}   $$   \u2192 \u5404\u6837\u672c\u6743\u91cd\u76f8\u540c\uff08\u5927\u7c7b\u522b\u5360\u4e3b\u5bfc\uff09</p> </li> </ul>"},{"location":"machine/interview/#cohens-kappa","title":"\ud83e\udde9 \u5341\u3001Cohen\u2019s Kappa \u7cfb\u6570\uff08\u4e00\u81f4\u6027\u5ea6\u91cf\uff09","text":""},{"location":"machine/interview/#_76","title":"\u5b9a\u4e49\uff1a","text":"<p>$$ \\kappa = \\frac{p_o - p_e}{1 - p_e} $$ \u5176\u4e2d\uff1a</p> <ul> <li>\\(p_o\\) = \u5b9e\u9645\u89c2\u6d4b\u4e00\u81f4\u7387\uff08\u5373 Accuracy\uff09</li> <li>\\(p_e\\) = \u968f\u673a\u4e00\u81f4\u7684\u671f\u671b\u503c</li> </ul> <p>\u53cd\u6620\u9884\u6d4b\u4e0e\u771f\u5b9e\u6807\u7b7e\u4e4b\u95f4\u7684\u4e00\u81f4\u6027\uff0c\u5254\u9664\u4e86\u968f\u673a\u4e00\u81f4\u7684\u5f71\u54cd\u3002</p> <p>\u53d6\u503c\uff1a</p> <ul> <li>\\(\\kappa=1\\)\uff1a\u5b8c\u5168\u4e00\u81f4</li> <li>\\(\\kappa=0\\)\uff1a\u968f\u673a\u4e00\u81f4</li> <li>\\(\\kappa&lt;0\\)\uff1a\u6bd4\u968f\u673a\u8fd8\u5dee</li> </ul>"},{"location":"machine/interview/#_77","title":"\ud83e\uddee \u5341\u4e00\u3001\u793a\u4f8b\u6c47\u603b\uff08\u6570\u503c\u8ba1\u7b97\uff09","text":"<p>\u5047\u8bbe\uff1a</p> \u5b9e\u9645 / \u9884\u6d4b Positive Negative Positive 50 (TP) 10 (FN) Negative 5 (FP) 35 (TN) <p>\u8ba1\u7b97\uff1a</p> <ul> <li>Accuracy = \\((50+35)/100 = 0.85\\)</li> <li>Precision = \\(50/(50+5)=0.909\\)</li> <li>Recall = \\(50/(50+10)=0.833\\)</li> <li>F1 = \\(2\u00d7(0.909\u00d70.833)/(0.909+0.833)=0.87\\)</li> <li>Specificity = \\(35/(35+5)=0.875\\)</li> <li>FPR = \\(0.125\\)</li> </ul> \u6307\u6807 \u5173\u6ce8\u70b9 \u9002\u7528\u573a\u666f Accuracy \u6574\u4f53\u6b63\u786e\u7387 \u7c7b\u522b\u5e73\u8861\u65f6\u4f7f\u7528 Precision \u9884\u6d4b\u4e3a\u6b63\u7684\u53ef\u4fe1\u5ea6 \u6b3a\u8bc8\u68c0\u6d4b\u3001\u5783\u573e\u90ae\u4ef6\u8bc6\u522b Recall \u8986\u76d6\u6b63\u7c7b\u7684\u80fd\u529b \u75be\u75c5\u7b5b\u67e5\u3001\u98ce\u9669\u76d1\u6d4b F1 \u7cbe\u786e\u7387\u4e0e\u53ec\u56de\u7387\u5e73\u8861 \u4e0d\u5e73\u8861\u5206\u7c7b ROC\u2013AUC \u9608\u503c\u65e0\u5173\u7684\u6574\u4f53\u6027\u80fd \u5404\u7c7b\u5206\u7c7b\u4efb\u52a1\u901a\u7528 PR\u2013AUC \u5c11\u6570\u7c7b\u5173\u6ce8\u573a\u666f \u4e25\u91cd\u4e0d\u5e73\u8861\u6570\u636e Kappa \u5254\u9664\u968f\u673a\u4e00\u81f4\u5f71\u54cd \u591a\u5206\u7c7b\u4e00\u81f4\u6027\u8bc4\u4f30 <pre><code>from sklearn.metrics import (\n    accuracy_score, precision_score, recall_score, f1_score,\n    roc_auc_score, confusion_matrix, classification_report\n)\n\ny_true = [1, 0, 1, 1, 0, 1, 0]\ny_pred = [1, 0, 1, 0, 0, 1, 1]\ny_prob = [0.9, 0.2, 0.8, 0.4, 0.3, 0.95, 0.7]  # \u6982\u7387\u8f93\u51fa\n\nprint(\"Accuracy:\", accuracy_score(y_true, y_pred))\nprint(\"Precision:\", precision_score(y_true, y_pred))\nprint(\"Recall:\", recall_score(y_true, y_pred))\nprint(\"F1:\", f1_score(y_true, y_pred))\nprint(\"ROC-AUC:\", roc_auc_score(y_true, y_prob))\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\nprint(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred))\n</code></pre>"},{"location":"machine/interview/#53","title":"5.3 \u591a\u5206\u7c7b","text":"<p>\u591a\u5206\u7c7b\u95ee\u9898 \u662f\u6307\uff1a\u6bcf\u4e2a\u6837\u672c\u53ea\u80fd\u5c5e\u4e8e\u591a\u4e2a\u53ef\u80fd\u7c7b\u522b\u4e2d\u7684\u4e00\u4e2a\u4e14\u4ec5\u4e00\u4e2a\u3002</p> <p>\u4f8b\u5982\uff1a</p> <ul> <li>\u8f93\u5165\uff1a\u4e00\u5f20\u56fe\u7247</li> <li>\u8f93\u51fa\u7c7b\u522b\uff1a{\u732b, \u72d7, \u9e1f}   \u2192 \u53ea\u80fd\u5c5e\u4e8e\u5176\u4e2d\u4e00\u4e2a\u3002</li> </ul> <p>\u6570\u5b66\u4e0a\uff0c\u7ed9\u5b9a\uff1a</p> <ul> <li>\u8f93\u5165\u7279\u5f81\uff1a\\(x \\in \\mathbb{R}^d\\)</li> <li>\u8f93\u51fa\u6807\u7b7e\uff1a\\(y \\in {1, 2, \\dots, K}\\)</li> </ul> <p>\u4efb\u52a1\u76ee\u6807\u662f\u5b66\u4e60\u4e00\u4e2a\u51fd\u6570\uff1a $$ f_\\theta(x) = \\arg\\max_{k} P(y=k \\mid x; \\theta) $$</p>"},{"location":"machine/interview/#_78","title":"\u2699\ufe0f \u4e8c\u3001\u6a21\u578b\u7ed3\u6784\u4e0e\u539f\u7406","text":""},{"location":"machine/interview/#1_12","title":"1\ufe0f\u20e3 \u7ebf\u6027\u6a21\u578b","text":"<p>\u6700\u57fa\u672c\u5f62\u5f0f\uff08\u5982\u903b\u8f91\u56de\u5f52\u7684\u591a\u5206\u7c7b\u6269\u5c55\uff09\uff1a $$ z_k = w_k^\\top x + b_k, \\quad k = 1, 2, \\dots, K $$ \u5176\u4e2d\uff1a</p> <ul> <li>\\(w_k\\) \u662f\u7b2c \\(k\\) \u7c7b\u7684\u6743\u91cd\u5411\u91cf\uff1b</li> <li>\\(b_k\\) \u662f\u504f\u7f6e\uff1b</li> <li>\\(z_k\\) \u662f\u8be5\u7c7b\u522b\u7684\u201c\u6253\u5206\u201d\uff08logit\uff09\u3002</li> </ul>"},{"location":"machine/interview/#2-softmax","title":"2\ufe0f\u20e3 Softmax \u51fd\u6570\uff08\u5f52\u4e00\u5316\u6982\u7387\uff09","text":"<p>\u4e3a\u4e86\u5f97\u5230\u5404\u7c7b\u7684\u6982\u7387\u5206\u5e03\uff0c\u4f7f\u7528 Softmax\uff1a $$ p_k = P(y=k \\mid x; \\theta) = \\frac{e^{z_k}}{\\sum_{j=1}^{K} e^{z_j}} $$</p>"},{"location":"machine/interview/#softmax","title":"\ud83d\udd0d Softmax \u6027\u8d28\uff1a","text":"<ol> <li>\u6bcf\u4e2a \\(p_k \\in (0,1)\\)\uff1b</li> <li>\\(\\sum_k p_k = 1\\)\u3002</li> </ol>"},{"location":"machine/interview/#cross-entropy-loss","title":"\ud83e\uddee \u4e09\u3001\u635f\u5931\u51fd\u6570\uff08Cross-Entropy Loss\uff09","text":"<p>\u6211\u4eec\u4f7f\u7528\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\uff08Cross-Entropy Loss\uff09\uff0c\u5b83\u662f\u6781\u5927\u4f3c\u7136\u4f30\u8ba1\u7684\u8d1f\u5bf9\u6570\u5f62\u5f0f\u3002</p>"},{"location":"machine/interview/#1_13","title":"1\ufe0f\u20e3 \u6781\u5927\u4f3c\u7136\u63a8\u5bfc\uff1a","text":"<p>\u7ed9\u5b9a\u6837\u672c \\((x^{(i)}, y^{(i)})\\)\uff0c\u5176\u6982\u7387\u4e3a\uff1a $$ P(y^{(i)} \\mid x^{(i)}; \\theta) = \\prod_{k=1}^K p_k^{\\mathbf{1}(y^{(i)}=k)} $$</p> <p>\u5176\u4e2d \\(\\mathbf{1}(\\cdot)\\) \u662f\u6307\u793a\u51fd\u6570\u3002</p> <p>\u6574\u4e2a\u8bad\u7ec3\u96c6\u4f3c\u7136\u4e3a\uff1a $$ L(\\theta) = \\prod_{i=1}^m P(y^{(i)} \\mid x^{(i)}; \\theta) $$</p> <p>\u53d6\u5bf9\u6570\uff08\u5bf9\u6570\u4f3c\u7136\uff09\uff1a $$ \\log L(\\theta) = \\sum_{i=1}^m \\sum_{k=1}^K \\mathbf{1}(y^{(i)}=k) \\log p_k^{(i)} $$</p> <p>\u8d1f\u53f7\u53d6\u8d1f\u5bf9\u6570\u4f3c\u7136\uff1a $$ J(\\theta) = - \\frac{1}{m} \\sum_{i=1}^m \\sum_{k=1}^K y_k^{(i)} \\log p_k^{(i)} $$</p> <p>\u8fd9\u5c31\u662f\u4ea4\u53c9\u71b5\u635f\u5931\uff08Cross-Entropy Loss\uff09\u3002</p>"},{"location":"machine/interview/#2_11","title":"2\ufe0f\u20e3 \u635f\u5931\u51fd\u6570\u89e3\u91ca\uff1a","text":"<ul> <li>\\(y_k^{(i)}\\) \u662f one-hot \u7f16\u7801\uff08\u4f8b\u5982\u7c7b\u522b 3 \u2192 \\([0, 0, 1, 0, 0]\\)\uff09\uff1b</li> <li>\u53ea\u5728\u771f\u5b9e\u7c7b\u522b\u5bf9\u5e94\u9879\u4e0a\u8d77\u4f5c\u7528\u3002</li> </ul> <p>\u793a\u4f8b\uff1a \u5047\u8bbe 3 \u7c7b\u95ee\u9898\u4e2d\u771f\u5b9e\u7c7b\u522b\u4e3a 2\uff0c\u9884\u6d4b\u6982\u7387\u4e3a\uff1a $$ \\hat{p} = [0.2, 0.7, 0.1] $$ \u5219\u635f\u5931\u4e3a\uff1a $$ L = -\\log(0.7) = 0.357 $$</p>"},{"location":"machine/interview/#_79","title":"\ud83d\udcc8 \u56db\u3001\u68af\u5ea6\u63a8\u5bfc\uff08\u91cd\u8981\uff01\uff09","text":"<p>Softmax \u7684\u8f93\u51fa\uff1a $$ p_k = \\frac{e^{z_k}}{\\sum_{j} e^{z_j}} $$</p> <p>\u5bf9 \\(z_k\\) \u6c42\u5bfc\uff1a</p> \\[ \\frac{\\partial p_k}{\\partial z_j} = \\begin{cases} p_k(1 - p_k), &amp; \\text{if } j=k \\\\ * p_k p_j, &amp; \\text{if } j \\ne k   \\end{cases} \\] <p>\u5bf9\u635f\u5931\u51fd\u6570 \\(J\\)\uff1a $$ \\frac{\\partial J}{\\partial z_k} = p_k - y_k $$</p> <p>\u76f4\u89c2\u7406\u89e3\uff1a\u6a21\u578b\u9884\u6d4b \\(p_k\\) \u4e0e\u771f\u5b9e\u6807\u7b7e \\(y_k\\) \u7684\u5dee\u503c\u5c31\u662f\u68af\u5ea6\u3002</p> <p>\u8fd9\u4e5f\u662f\u591a\u5206\u7c7b Softmax \u56de\u5f52\u8bad\u7ec3\u7684\u6838\u5fc3\u66f4\u65b0\u89c4\u5219\u3002</p> <pre><code>from sklearn.datasets import load_iris\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report\n\n# \u52a0\u8f7d\u6570\u636e\u96c6\nX, y = load_iris(return_X_y=True)\n\n# \u903b\u8f91\u56de\u5f52\u591a\u5206\u7c7b\nmodel = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=500)\nmodel.fit(X, y)\n\n# \u9884\u6d4b\ny_pred = model.predict(X)\n\nprint(classification_report(y, y_pred))\n</code></pre>"},{"location":"machine/interview/#_80","title":"\u5e38\u89c1\u7b97\u6cd5\uff08\u7528\u4e8e\u591a\u5206\u7c7b\uff09","text":"\u7b97\u6cd5 \u601d\u8def \u4f18\u70b9 \u7f3a\u70b9 Softmax \u56de\u5f52\uff08\u591a\u9879\u903b\u8f91\u56de\u5f52\uff09 \u7ebf\u6027\u6a21\u578b + Softmax \u7b80\u5355\u53ef\u89e3\u91ca \u7ebf\u6027\u53ef\u5206\u9650\u5236 SVM\uff08\u591a\u5206\u7c7b\u6269\u5c55\uff09 \u4e00\u5bf9\u4e00 / \u4e00\u5bf9\u591a \u8f83\u9ad8\u51c6\u786e\u7387 \u8bad\u7ec3\u590d\u6742 \u51b3\u7b56\u6811 / \u968f\u673a\u68ee\u6797 \u57fa\u4e8e\u5212\u5206\u89c4\u5219 \u975e\u7ebf\u6027\u80fd\u529b\u5f3a \u53ef\u89e3\u91ca\u6027\u6709\u9650 \u795e\u7ecf\u7f51\u7edc \u591a\u5c42\u975e\u7ebf\u6027\u6620\u5c04 \u9ad8\u8868\u8fbe\u80fd\u529b \u9700\u5927\u91cf\u6570\u636e kNN \u57fa\u4e8e\u90bb\u5c45\u6295\u7968 \u65e0\u9700\u8bad\u7ec3 \u9884\u6d4b\u8017\u65f6"},{"location":"machine/interview/#54","title":"5.4 \u591a\u6807\u7b7e","text":"<p>\u5728\u591a\u6807\u7b7e\u5206\u7c7b\u95ee\u9898\u4e2d\uff0c\u4e00\u4e2a\u6837\u672c\u53ef\u4ee5\u540c\u65f6\u5c5e\u4e8e\u591a\u4e2a\u7c7b\u522b\u3002 \u4e0e\u4e4b\u76f8\u5bf9\u7684\uff0c\u591a\u5206\u7c7b\uff08Multi-Class\uff09\u4e2d\u6bcf\u4e2a\u6837\u672c\u53ea\u5c5e\u4e8e\u4e00\u4e2a\u7c7b\u522b\u3002</p> <ul> <li> <p>\u4e8c\u5206\u7c7b\uff1a\u6bcf\u4e2a\u6837\u672c\u53ea\u5c5e\u4e8e\u4e24\u4e2a\u7c7b\u522b\u4e4b\u4e00   \u4f8b\u5982\uff1a\u5783\u573e\u90ae\u4ef6\u8bc6\u522b\uff08spam / not spam\uff09</p> </li> <li> <p>\u591a\u5206\u7c7b\uff1a\u6bcf\u4e2a\u6837\u672c\u5c5e\u4e8e\u591a\u4e2a\u7c7b\u522b\u4e2d\u7684\u4e00\u4e2a   \u4f8b\u5982\uff1a\u624b\u5199\u6570\u5b57\u8bc6\u522b\uff080~9\uff09</p> </li> <li> <p>\u591a\u6807\u7b7e\u5206\u7c7b\uff1a\u6bcf\u4e2a\u6837\u672c\u53ef\u4ee5\u540c\u65f6\u5c5e\u4e8e\u591a\u4e2a\u7c7b\u522b   \u4f8b\u5982\uff1a   \u4e00\u5f20\u56fe\u7247\u53ef\u4ee5\u540c\u65f6\u5305\u542b\uff1a</p> <ul> <li>\u201c\u732b\u201d \u2705</li> <li>\u201c\u72d7\u201d \u2705</li> <li>\u201c\u8f66\u201d \u274c </li> <li>\u56e0\u6b64\u6807\u7b7e\u4e3a <code>[1, 1, 0]</code></li> </ul> </li> </ul>"},{"location":"machine/interview/#_81","title":"\u4e8c\u3001\u6570\u5b66\u5b9a\u4e49","text":"<p>\u5047\u8bbe\uff1a</p> <ul> <li>\u6837\u672c\u7279\u5f81\u4e3a \\(x_i \\in \\mathbb{R}^d\\)</li> <li>\u6807\u7b7e\u96c6\u5408\u4e3a \\(Y = {1, 2, \\dots, K}\\)</li> <li>\u6bcf\u4e2a\u6837\u672c\u7684\u771f\u5b9e\u6807\u7b7e\u4e3a \\(y_i \\subseteq Y\\)</li> </ul> <p>\u5bf9\u4e8e\u591a\u6807\u7b7e\u95ee\u9898\uff0c\u6211\u4eec\u901a\u5e38\u5c06\u6807\u7b7e\u8868\u793a\u4e3a\u4e00\u4e2a\u957f\u5ea6\u4e3a \\(K\\) \u7684\u4e8c\u8fdb\u5236\u5411\u91cf\uff1a</p> \\[ \\mathbf{y}*i = [y*{i1}, y_{i2}, \\dots, y_{iK}] \\] <p>\u5176\u4e2d\uff1a</p> \\[ y_{ik} = \\begin{cases} 1, &amp; \\text{\u5982\u679c\u6837\u672c } i \\text{ \u5c5e\u4e8e\u7c7b\u522b } k \\ 0, &amp; \\text{\u5426\u5219} \\end{cases} \\] <p>\u6a21\u578b\u8f93\u51fa\u4e3a\uff1a</p> \\[ \\hat{\\mathbf{y}}*i = [\\hat{y}*{i1}, \\hat{y}*{i2}, \\dots, \\hat{y}*{iK}] \\] <p>\u5176\u4e2d \\(\\hat{y}_{ik} \\in [0,1]\\) \u8868\u793a\u5c5e\u4e8e\u6807\u7b7e \\(k\\) \u7684\u6982\u7387\u3002</p>"},{"location":"machine/interview/#_82","title":"\u4e09\u3001\u5e38\u89c1\u5efa\u6a21\u65b9\u6cd5","text":""},{"location":"machine/interview/#1-binary-relevancebr","title":"1. Binary Relevance\uff08BR\uff09","text":"<p>\u6700\u5e38\u89c1\u3001\u6700\u7b80\u5355\u7684\u65b9\u5f0f\uff1a \u628a\u591a\u6807\u7b7e\u95ee\u9898\u62c6\u6210 K \u4e2a\u72ec\u7acb\u7684\u4e8c\u5206\u7c7b\u95ee\u9898\u3002</p> <p>\u6bcf\u4e2a\u6807\u7b7e\u72ec\u7acb\u5efa\u6a21\uff1a $$ P(y_k=1|x) = \\sigma(w_k^\\top x) $$</p> <p>\u5176\u4e2d \\(\\sigma(z)=\\frac{1}{1+e^{-z}}\\) \u662f sigmoid \u51fd\u6570\u3002</p> <p>\u4f18\u70b9\uff1a</p> <ul> <li>\u7b80\u5355\u3001\u6613\u5b9e\u73b0</li> <li>\u53ef\u4ee5\u5e76\u884c\u8bad\u7ec3</li> </ul> <p>\u7f3a\u70b9\uff1a</p> <ul> <li>\u5ffd\u7565\u4e86\u6807\u7b7e\u4e4b\u95f4\u7684\u76f8\u5173\u6027\uff08\u4f8b\u5982\u201c\u732b\u201d\u548c\u201c\u52a8\u7269\u201d\u5f3a\u76f8\u5173\uff09</li> </ul>"},{"location":"machine/interview/#2-classifier-chaincc","title":"2. Classifier Chain\uff08CC\uff09","text":"<p>\u901a\u8fc7\u5c06\u524d\u9762\u6807\u7b7e\u7684\u9884\u6d4b\u4f5c\u4e3a\u540e\u7eed\u6a21\u578b\u7684\u8f93\u5165\uff0c\u6355\u6349\u6807\u7b7e\u95f4\u4f9d\u8d56\u3002</p> <p>\u5047\u8bbe\u6807\u7b7e\u987a\u5e8f\u4e3a \\((y_1, y_2, ..., y_K)\\)\uff1a</p> \\[ P(y_1, ..., y_K | x) = \\prod_{k=1}^K P(y_k | x, y_1, ..., y_{k-1}) \\] <p>\u5373\u7b2c \\(k\\) \u4e2a\u5206\u7c7b\u5668\u4e0d\u4ec5\u4f7f\u7528\u7279\u5f81 \\(x\\)\uff0c\u8fd8\u4f7f\u7528\u4e4b\u524d\u7684\u6807\u7b7e\u9884\u6d4b\u3002</p>"},{"location":"machine/interview/#3-label-powersetlp","title":"3. Label Powerset\uff08LP\uff09","text":"<p>\u628a\u6240\u6709\u6807\u7b7e\u7ec4\u5408\u89c6\u4e3a\u4e00\u4e2a\u65b0\u7684\u201c\u590d\u5408\u7c7b\u201d\u3002</p> <p>\u4f8b\u5982\uff1a</p> <ul> <li>\u539f\u59cb\u6807\u7b7e\u7a7a\u95f4\uff1a<code>{A, B, C}</code></li> <li>\u53ef\u80fd\u7684\u7ec4\u5408\uff1a<code>{}</code>, <code>{A}</code>, <code>{B}</code>, <code>{C}</code>, <code>{A,B}</code>, <code>{A,C}</code>, <code>{B,C}</code>, <code>{A,B,C}</code></li> </ul> <p>\u2192 \u53d8\u6210\u4e00\u4e2a\u591a\u5206\u7c7b\u95ee\u9898\u3002</p> <p>\u4f18\u70b9\uff1a\u8003\u8651\u4e86\u6807\u7b7e\u76f8\u5173\u6027 \u7f3a\u70b9\uff1a\u5f53\u6807\u7b7e\u6570\u91cf\u591a\u65f6\uff0c\u7ec4\u5408\u7206\u70b8\u3002</p>"},{"location":"machine/interview/#loss-function_1","title":"\u56db\u3001\u635f\u5931\u51fd\u6570\uff08Loss Function\uff09","text":""},{"location":"machine/interview/#1-binary-cross-entropysigmoid-bce","title":"1. Binary Cross-Entropy\uff08Sigmoid + BCE\uff09","text":"<p>\u6700\u5e38\u7528\u635f\u5931\u51fd\u6570\u3002\u5bf9\u6bcf\u4e2a\u6807\u7b7e\u72ec\u7acb\u4f7f\u7528 sigmoid\uff0c\u518d\u8ba1\u7b97\u4ea4\u53c9\u71b5\u3002</p> <p>\u5bf9\u4e8e\u5355\u4e2a\u6837\u672c\uff1a $$ L_i = -\\sum_{k=1}^{K} \\Big[ y_{ik} \\log(\\hat{y}{ik}) + (1 - y{ik}) \\log(1 - \\hat{y}_{ik}) \\Big] $$</p> <p>\u6574\u4f53\u635f\u5931\u4e3a\uff1a $$ L = \\frac{1}{N} \\sum_{i=1}^{N} L_i $$</p> <p>Python \u793a\u4f8b\uff08PyTorch\uff09\uff1a</p> <pre><code>import torch\nimport torch.nn as nn\n\ncriterion = nn.BCEWithLogitsLoss()  # \u5185\u90e8\u81ea\u5e26 sigmoid\nloss = criterion(preds, labels)\n</code></pre>"},{"location":"machine/interview/#2-focal-loss","title":"2. Focal Loss\uff08\u5904\u7406\u7c7b\u522b\u4e0d\u5e73\u8861\uff09","text":"<p>\u5f53\u6b63\u8d1f\u6837\u672c\u6781\u5ea6\u4e0d\u5e73\u8861\u65f6\u4f7f\u7528\uff1a $$ L = - \\sum_k \\alpha (1 - \\hat{y}_k)^\\gamma y_k \\log(\\hat{y}_k) $$</p> <ul> <li>\\(\\alpha\\)\uff1a\u5e73\u8861\u6b63\u8d1f\u6837\u672c</li> <li>\\(\\gamma\\)\uff1a\u805a\u7126\u96be\u5206\u7c7b\u6837\u672c</li> </ul>"},{"location":"machine/interview/#evaluation-metrics","title":"\u4e94\u3001\u8bc4\u4f30\u6307\u6807\uff08Evaluation Metrics\uff09","text":"<p>\u5bf9\u4e8e\u591a\u6807\u7b7e\u4efb\u52a1\uff0c\u6211\u4eec\u9700\u8981\u6309\u6807\u7b7e\u7ef4\u5ea6\u6216\u6837\u672c\u7ef4\u5ea6\u8ba1\u7b97\u6307\u6807\u3002</p>"},{"location":"machine/interview/#1-hamming-loss","title":"1. Hamming Loss","text":"<p>\u8861\u91cf\u9519\u8bef\u9884\u6d4b\u7684\u6bd4\u4f8b\uff1a $$ \\text{Hamming Loss} = \\frac{1}{N \\times K} \\sum_{i=1}^N \\sum_{k=1}^K I[y_{ik} \\neq \\hat{y}_{ik}] $$</p> <p>\u8d8a\u5c0f\u8d8a\u597d\u3002</p>"},{"location":"machine/interview/#2-subset-accuracyexact-match-ratio","title":"2. Subset Accuracy\uff08Exact Match Ratio\uff09","text":"<p>\u6240\u6709\u6807\u7b7e\u5b8c\u5168\u5339\u914d\u624d\u7b97\u6b63\u786e\uff1a $$ \\text{Subset Accuracy} = \\frac{1}{N} \\sum_{i=1}^N I[\\mathbf{y}_i = \\hat{\\mathbf{y}}_i] $$</p> <p>\u8fc7\u4e8e\u4e25\u683c\uff0c\u5e38\u4e0d\u63a8\u8350\u5355\u72ec\u4f7f\u7528\u3002</p>"},{"location":"machine/interview/#3-precision-recall-f1-scoremicro-macro","title":"3. Precision / Recall / F1-score\uff08Micro / Macro\uff09","text":"<ul> <li>Micro-F1\uff1a\u5168\u5c40\u7edf\u8ba1 TP, FP, FN   \u66f4\u5173\u6ce8\u9891\u7e41\u6807\u7b7e\u7684\u6574\u4f53\u8868\u73b0\u3002</li> <li>Macro-F1\uff1a\u5bf9\u6bcf\u4e2a\u6807\u7b7e\u5355\u72ec\u8ba1\u7b97 F1\uff0c\u518d\u5e73\u5747\u3002   \u66f4\u5173\u6ce8\u7a00\u6709\u6807\u7b7e\u3002</li> </ul> <p>Python\uff1a</p> <pre><code>from sklearn.metrics import f1_score\nf1_micro = f1_score(y_true, y_pred, average='micro')\nf1_macro = f1_score(y_true, y_pred, average='macro')\n</code></pre> <pre><code>from sklearn.datasets import make_multilabel_classification\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.multioutput import MultiOutputClassifier\nfrom sklearn.metrics import f1_score\n\n# 1. \u6784\u9020\u6570\u636e\nX, y = make_multilabel_classification(n_samples=2000, n_features=10, n_classes=5, random_state=42)\n\n# 2. \u5212\u5206\u6570\u636e\u96c6\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# 3. \u6a21\u578b\nmodel = MultiOutputClassifier(LogisticRegression())\nmodel.fit(X_train, y_train)\n\n# 4. \u9884\u6d4b\u4e0e\u8bc4\u4f30\ny_pred = model.predict(X_test)\nprint(\"Micro-F1:\", f1_score(y_test, y_pred, average='micro'))\nprint(\"Macro-F1:\", f1_score(y_test, y_pred, average='macro'))\n</code></pre>"},{"location":"machine/interview/#_83","title":"\u516d\u3001\u56de\u5f52","text":""},{"location":"machine/interview/#61","title":"6.1 \u635f\u5931\u51fd\u6570","text":""},{"location":"machine/interview/#1_14","title":"1. \u603b\u4f53\u80cc\u666f\u4e0e\u7b26\u53f7\u7ea6\u5b9a","text":"<ul> <li>\u8bad\u7ec3\u6837\u672c \\({(x^{(i)}, y^{(i)})}_{i=1}^{m}\\)\u3002</li> <li>\u6a21\u578b\u9884\u6d4b\u4e3a \\(\\hat{y}^{(i)} = f_\\theta(x^{(i)})\\)\uff0c\u53c2\u6570\u4e3a \\(\\theta\\)\u3002</li> <li>\u5355\u6837\u672c\u635f\u5931\u8bb0\u4e3a \\(L\\big(y^{(i)},\\hat{y}^{(i)}\\big)\\)\uff0c\u603b\u4f53\uff08\u5e73\u5747\uff09\u635f\u5931\u4e3a   $$   J(\\theta)=\\frac{1}{m}\\sum_{i=1}^m L\\big(y^{(i)},\\hat{y}^{(i)}\\big).   $$</li> </ul> <p>\u6211\u4eec\u5173\u5fc3\u7684\u5e38\u89c1\u56de\u5f52\u635f\u5931\uff1aMSE\u3001MAE\u3001Huber\u3001Log-cosh\u3001Quantile Loss\uff08\u5206\u4f4d\u6570\u635f\u5931\uff09\u3001Poisson/NLL \u7b49\u3002</p>"},{"location":"machine/interview/#2-mse-mean-squared-error","title":"2. \u5747\u65b9\u8bef\u5dee\uff08MSE / Mean Squared Error\uff09","text":""},{"location":"machine/interview/#_84","title":"\u5b9a\u4e49","text":"\\[ L_{\\text{MSE}}(y,\\hat{y}) = (y - \\hat{y})^2. \\] <p>\u5e73\u5747\uff08\u6837\u672c\uff09\u635f\u5931\uff1a</p> \\[ J_{\\text{MSE}}(\\theta)=\\frac{1}{m}\\sum_{i=1}^m (y^{(i)} - \\hat{y}^{(i)})^2. \\]"},{"location":"machine/interview/#_85","title":"\u542b\u4e49","text":"<p>\u5bf9\u9884\u6d4b\u8bef\u5dee\u5e73\u65b9\u60e9\u7f5a\uff0c\u8f83\u5927\u8bef\u5dee\u88ab\u653e\u5927\uff08\u5bf9\u79bb\u7fa4\u70b9\u654f\u611f\uff09\u3002MSE \u7b49\u4ef7\u4e8e\u5047\u8bbe\u8bef\u5dee\u670d\u4ece\u5747\u503c\u4e3a 0\u3001\u65b9\u5dee\u4e3a\u5e38\u6570\u7684\u9ad8\u65af\u566a\u58f0\uff0c\u4f7f\u7528\u6781\u5927\u4f3c\u7136\u53ef\u5bfc\u51fa MSE\u3002</p>"},{"location":"machine/interview/#haty","title":"\u68af\u5ea6\uff08\u5bf9\u5355\u6837\u672c\u7684\u9884\u6d4b \\(\\hat{y}\\)\uff09","text":"<p>\u5bf9 \\(\\hat{y}\\)\uff1a $$ \\frac{\\partial L_{\\text{MSE}}}{\\partial \\hat{y}} = -2 (y - \\hat{y}). $$ \u82e5\u5bf9\u53c2\u6570 \\(\\theta\\)\uff0c\u94fe\u5f0f\u6cd5\u5219\uff1a $$ \\nabla_\\theta L_{\\text{MSE}} = -2 (y - \\hat{y}) \\nabla_\\theta \\hat{y}. $$</p>"},{"location":"machine/interview/#_86","title":"\u6570\u503c\u4f8b\u5b50\uff08\u9010\u4f4d\u7b97\uff09","text":"<p>\u53d6\u5355\u6837\u672c \\(y=3.0,\\ \\hat{y}=2.2\\)\uff1a</p> <ul> <li>\u8bef\u5dee \\(e = y - \\hat{y} = 3.0 - 2.2 = 0.8\\)\u3002</li> <li>MSE \u635f\u5931 \\(L = e^2 = 0.8^2 = 0.64\\)\u3002</li> <li>\u68af\u5ea6 w.r.t. \\(\\hat{y}\\)\uff1a\\(\\partial L/\\partial \\hat{y} = -2 \\times 0.8 = -1.6\\)\u3002</li> </ul> <p>\uff08\u6ce8\u610f\uff1a\u6570\u503c\u8ba1\u7b97\u90fd\u9010\u4f4d\u8ba1\u7b97\uff0c\u786e\u4fdd\u51c6\u786e\u3002\uff09</p>"},{"location":"machine/interview/#_87","title":"\u4f18\u7f3a\u70b9","text":"<ul> <li>\u4f18\u70b9\uff1a\u89e3\u6790\u7b80\u5355\u3001\u53ef\u5bfc\u3001\u5e38\u7528\u3002</li> <li>\u7f3a\u70b9\uff1a\u5bf9\u5927\u8bef\u5dee\uff08\u79bb\u7fa4\u70b9\uff09\u654f\u611f\u3002</li> </ul>"},{"location":"machine/interview/#3-mae-mean-absolute-error","title":"3. \u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\uff08MAE / Mean Absolute Error\uff09","text":""},{"location":"machine/interview/#_88","title":"\u5b9a\u4e49","text":"\\[ L_{\\text{MAE}}(y,\\hat{y}) = |y - \\hat{y}|. \\] <p>\u5e73\u5747\u635f\u5931\uff1a</p> \\[ J_{\\text{MAE}}(\\theta)=\\frac{1}{m}\\sum_{i=1}^m |y^{(i)} - \\hat{y}^{(i)}|. \\]"},{"location":"machine/interview/#_89","title":"\u542b\u4e49","text":"<p>\u5bf9\u8bef\u5dee\u6309\u7edd\u5bf9\u503c\u60e9\u7f5a\uff0c\u9c81\u68d2\u6027\u6bd4 MSE \u66f4\u5f3a\uff08\u5bf9\u79bb\u7fa4\u70b9\u4e0d\u90a3\u4e48\u654f\u611f\uff09\u3002\u7b49\u4ef7\u4e8e\u5047\u8bbe\u8bef\u5dee\u670d\u4ece\u62c9\u666e\u62c9\u65af\u5206\u5e03\u3002</p>"},{"location":"machine/interview/#_90","title":"\u68af\u5ea6\uff08\u5bf9\u5355\u6837\u672c\uff09","text":"<p>\u5bf9 \\(\\hat{y}\\) \u7684\u6b21\u5bfc/\u7b26\u53f7\u51fd\u6570\uff08\\(y\\neq\\hat{y}\\)\uff09\uff1a $$ \\frac{\\partial L_{\\text{MAE}}}{\\partial \\hat{y}} = \\begin{cases} -1, &amp; \\hat{y} &lt; y,\\ +1, &amp; \\hat{y} &gt; y. \\end{cases} $$ \u5728 \\(\\hat{y}=y\\) \u5904\u4e0d\u53ef\u5bfc\uff0c\u7528\u6b21\u68af\u5ea6 \\(\\in[-1,1]\\)\u3002</p>"},{"location":"machine/interview/#_91","title":"\u6570\u503c\u4f8b\u5b50","text":"<p>\\(y=3.0,\\ \\hat{y}=2.2\\)\uff1a</p> <ul> <li>\u8bef\u5dee \\(e=0.8\\)\uff1b</li> <li>MAE \\(=|0.8|=0.8\\)\uff1b</li> <li>\u68af\u5ea6\u5bf9 \\(\\hat{y}\\)\uff1a\u56e0\u4e3a \\(\\hat{y}&lt;y\\)\uff0c\\(\\partial L/\\partial \\hat{y} = -1\\)\u3002</li> </ul>"},{"location":"machine/interview/#_92","title":"\u4f18\u7f3a\u70b9","text":"<ul> <li>\u4f18\u70b9\uff1a\u5bf9\u79bb\u7fa4\u70b9\u66f4\u9c81\u68d2\u3002</li> <li>\u7f3a\u70b9\uff1a\u4e0d\u53ef\u5bfc\u70b9\u5bfc\u81f4\u7528\u68af\u5ea6\u6cd5\u65f6\u6536\u655b\u884c\u4e3a\u4e0d\u5982 MSE \u5e73\u6ed1\uff1b\u5728\u5f88\u591a\u6846\u67b6\u4e2d\u7528\u6b21\u68af\u5ea6\u5904\u7406\u5373\u53ef\u3002</li> </ul>"},{"location":"machine/interview/#4-huber-mae-mse","title":"4. Huber \u635f\u5931\uff08\u5e73\u6ed1\u7684 MAE / MSE \u6df7\u5408\uff09","text":""},{"location":"machine/interview/#delta0","title":"\u5b9a\u4e49\uff08\u5e26\u9608\u503c \\(\\delta&gt;0\\)\uff09","text":"<p>\u5355\u6837\u672c\uff1a $$ L_{\\text{Huber}}(y,\\hat{y}) = \\begin{cases} \\frac{1}{2}(y-\\hat{y})^2, &amp; \\text{if } |y-\\hat{y}|\\le \\delta,[6pt] \\delta\\big(|y-\\hat{y}| - \\tfrac{1}{2}\\delta\\big), &amp; \\text{if } |y-\\hat{y}|&gt;\\delta. \\end{cases} $$</p>"},{"location":"machine/interview/#_93","title":"\u542b\u4e49","text":"<p>\u5728\u5c0f\u8bef\u5dee\u533a\u57df\u4f7f\u7528\u4e8c\u6b21\uff08MSE\uff09\uff0c\u5728\u5927\u8bef\u5dee\uff08\u79bb\u7fa4\u70b9\uff09\u533a\u57df\u4f7f\u7528\u7ebf\u6027\uff08MAE\uff09\u60e9\u7f5a\uff0c\u56e0\u6b64\u517c\u987e\u5e73\u6ed1\u6027\u4e0e\u9c81\u68d2\u6027\u3002\\(\\delta\\) \u63a7\u5236\u4ece\u4e8c\u6b21\u5230\u7ebf\u6027\u7684\u5207\u6362\u70b9\u3002</p>"},{"location":"machine/interview/#haty_1","title":"\u68af\u5ea6\uff08\u5bf9 \\(\\hat{y}\\)\uff09","text":"\\[ \\frac{\\partial L_{\\text{Huber}}}{\\partial \\hat{y}} = \\begin{cases} -(y-\\hat{y}), &amp; |y-\\hat{y}|\\le \\delta,[4pt] -\\delta,\\mathrm{sign}(y-\\hat{y}), &amp; |y-\\hat{y}|&gt;\\delta. \\end{cases} \\]"},{"location":"machine/interview/#delta1","title":"\u6570\u503c\u4f8b\u5b50\uff08\u53d6 \\(\\delta=1\\)\uff09","text":"<ul> <li> <p>\u82e5 \\(y=3.0,\\ \\hat{y}=2.2\\)\uff0c\u8bef\u5dee \\(0.8\\le1\\)\uff1a</p> </li> <li> <p>\u635f\u5931 \\(=\\tfrac{1}{2}\\cdot 0.8^2 = 0.5 \\times 0.64 = 0.32\\)\uff1b</p> </li> <li>\u68af\u5ea6 \\(=-(3.0-2.2) = -0.8\\)\u3002</li> <li> <p>\u82e5 \\(y=10,\\ \\hat{y}=2\\)\uff0c\u8bef\u5dee \\(8&gt;1\\)\uff1a</p> </li> <li> <p>\u635f\u5931 \\(=1\\cdot(8 - 0.5\\cdot1)=8 - 0.5 = 7.5\\)\uff1b</p> </li> <li>\u68af\u5ea6 \\(=-1\\cdot \\mathrm{sign}(8) = -1\\)\uff08\u5373\u5bf9 \\(\\hat{y}\\) \u4e3a -1\uff09\u3002</li> </ul>"},{"location":"machine/interview/#_94","title":"\u4f18\u7f3a\u70b9","text":"<ul> <li>\u4f18\u70b9\uff1a\u5e73\u6ed1\u4e14\u9c81\u68d2\uff0c\u5e38\u7528\u5728\u56de\u5f52\u548c RL\uff08\u5956\u52b1\uff09\u4e2d\u3002</li> <li>\u7f3a\u70b9\uff1a\u9700\u9009\u62e9\u8d85\u53c2 \\(\\delta\\)\u3002</li> </ul>"},{"location":"machine/interview/#5-log-cosh","title":"5. Log-cosh \u635f\u5931","text":""},{"location":"machine/interview/#_95","title":"\u5b9a\u4e49","text":"\\[ L_{\\text{log-cosh}}(y,\\hat{y}) = \\log\\big(\\cosh(y - \\hat{y})\\big). \\]"},{"location":"machine/interview/#_96","title":"\u542b\u4e49","text":"<p>\u5bf9\u5c0f\u8bef\u5dee\u8fd1\u4f3c \\(\\tfrac{1}{2}(y-\\hat{y})^2\\)\uff0c\u5bf9\u5927\u8bef\u5dee\u8fd1\u4f3c \\(|y-\\hat{y}| - \\log 2\\)\uff0c\u56e0\u6b64\u884c\u4e3a\u4ecb\u4e8e MSE \u4e0e MAE \u4e4b\u95f4\u4e14\u5e73\u6ed1\u53ef\u5bfc\u3002</p>"},{"location":"machine/interview/#_97","title":"\u68af\u5ea6","text":"\\[ \\frac{\\partial L_{\\text{log-cosh}}}{\\partial \\hat{y}} = -\\tanh(y - \\hat{y}). \\]"},{"location":"machine/interview/#_98","title":"\u6570\u503c\u4f8b\u5b50","text":"<p>\\(y=3.0,\\ \\hat{y}=2.2\\)\uff0c\u8bef\u5dee \\(0.8\\)\uff1a</p> <ul> <li>\\(\\cosh(0.8) = \\tfrac{e^{0.8}+e^{-0.8}}{2}\\approx \\tfrac{2.22554+0.44933}{2}=1.337435\\)\uff08\u9010\u4f4d\u8ba1\u7b97\uff1a\\(e^{0.8}\\approx2.2255409, e^{-0.8}\\approx0.449329\\)\uff0c\u548c\u7ea6 \\(2.67487\\), \u9664\u4ee5 2 \u5f97 \\(1.337435\\)\uff09\u3002</li> <li>\\(\\log\\cosh(0.8)\\approx \\log 1.337435 \\approx 0.290\\)\uff08\u8fd1\u4f3c\uff09\u3002</li> <li>\u68af\u5ea6 \\(= -\\tanh(0.8)\\approx -0.664\\)\uff08\\(\\tanh(0.8)\\approx0.664\\)\uff09\u3002</li> </ul> <p>\uff08\u6570\u503c\u7528\u8fd1\u4f3c\u503c\u8868\u793a\uff0c\u4fdd\u7559\u793a\u4f8b\u8bf4\u660e\u76ee\u7684\u3002\uff09</p>"},{"location":"machine/interview/#6-quantile-loss","title":"6. Quantile Loss\uff08\u5206\u4f4d\u6570\u635f\u5931\uff09 \u2014 \u7528\u4e8e\u9884\u6d4b\u5206\u4f4d\u6570\uff08\u5982\u4e0a\u3001\u4e0b\u754c\uff09","text":""},{"location":"machine/interview/#tauin01","title":"\u5b9a\u4e49\uff08\u5206\u4f4d\u6570 \\(\\tau\\in(0,1)\\)\uff09","text":"<p>\u5355\u6837\u672c\uff1a</p> \\[ L_{\\tau}(y,\\hat{y}) = \\begin{cases} \\tau (y - \\hat{y}), &amp; \\text{if } y \\ge \\hat{y},\\\\[4pt] (1-\\tau)(\\hat{y} - y), &amp; \\text{if } y &lt; \\hat{y}. \\end{cases} \\]"},{"location":"machine/interview/#_99","title":"\u542b\u4e49","text":"<p>\u7528\u4e8e\u5b66\u4e60\u6761\u4ef6\u5206\u4f4d\u6570\uff08\u4f8b\u5982\u4e2d\u4f4d\u6570 \\(\\tau=0.5\\) \u5bf9\u5e94 MAE \u7684\u4e2d\u4f4d\u6570\u89e3\uff09\u3002\u5728\u9884\u6d4b\u4e0d\u5bf9\u79f0\u98ce\u9669\uff08\u5bf9\u8fc7\u9ad8\u6216\u8fc7\u4f4e\u8bef\u5dee\u60e9\u7f5a\u4e0d\u540c\uff09\u65f6\u975e\u5e38\u6709\u7528\u3002</p>"},{"location":"machine/interview/#tau09","title":"\u6570\u503c\u4f8b\u5b50\uff08\\(\\tau=0.9\\)\uff09","text":"<p>\\(y=10,\\ \\hat{y}=8\\)\uff1a\\(y\\ge\\hat{y}\\)\uff0c\u635f\u5931 \\(=0.9*(10-8)=0.9*2=1.8\\)\u3002</p> <p>\\(y=6,\\ \\hat{y}=8\\)\uff1a\\(y&lt;\\hat{y}\\)\uff0c\u635f\u5931 \\(=(1-0.9)*(8-6)=0.1*2=0.2\\)\u3002</p> <p>\u8bf4\u660e\u9ad8\u4f30\u8bef\u5dee\uff08\\(\\hat{y}&gt;y\\)\uff09\u88ab\u8f7b\u7f5a\uff0c\u4f4e\u4f30\u8bef\u5dee\uff08\\(\\hat{y}&lt;y\\)\uff09\u88ab\u91cd\u7f5a\uff08\u6216\u53cd\u4e4b\uff0c\u53d6\u51b3\u4e8e \\(\\tau\\)\uff09\u3002</p>"},{"location":"machine/interview/#7-poisson-gamma-nll","title":"7. Poisson / Gamma / NLL\uff08\u9002\u7528\u4e8e\u8ba1\u6570\u6216\u7279\u5b9a\u566a\u58f0\u6a21\u578b\uff09","text":""},{"location":"machine/interview/#poisson-nll","title":"Poisson NLL\uff08\u8ba1\u6570\u578b\u8f93\u51fa\uff09","text":"<p>\u82e5\u5047\u8bbe \\(y\\sim\\text{Poisson}(\\lambda=\\hat{y})\\)\uff0c\u8d1f\u5bf9\u6570\u4f3c\u7136\uff08\u5355\u6837\u672c\uff09\uff1a $$ L_{\\text{Poisson}}(y,\\hat{y}) = \\hat{y} - y\\log \\hat{y} + \\log(y!). $$ \uff08\u5e38\u7701\u53bb\u4e0e \\(\\hat{y}\\) \u65e0\u5173\u7684 \\(\\log(y!)\\) \u9879\u7528\u4e8e\u4f18\u5316\uff09</p> <p>\u9002\u7528\u573a\u666f\uff1a\u8ba1\u6570\u6570\u636e\uff08\u4e8b\u4ef6\u6b21\u6570\uff09\u3002</p>"},{"location":"machine/interview/#8_2","title":"8. \u635f\u5931\u9009\u62e9\u7684\u6807\u51c6\u4e0e\u5b9e\u8df5\u5efa\u8bae","text":"<ul> <li>\u82e5\u8bef\u5dee\u5448\u9ad8\u65af\u566a\u58f0\u4e14\u4f60\u5e0c\u671b\u5bf9\u5927\u8bef\u5dee\u66f4\u654f\u611f\uff1a\u9009\u62e9 MSE\u3002</li> <li>\u82e5\u6570\u636e\u542b\u79bb\u7fa4\u70b9\u6216\u5e0c\u671b\u9c81\u68d2\uff1a\u9009\u62e9 MAE \u6216 Huber\uff08\u9996\u9009\uff09 \u6216 Log-cosh\u3002</li> <li>\u82e5\u9700\u8981\u9884\u6d4b\u5206\u4f4d\u6570\u6216\u4e0d\u5bf9\u79f0\u635f\u5931\uff1a\u7528 Quantile Loss\u3002</li> <li>\u82e5\u8f93\u51fa\u662f\u8ba1\u6570\u578b\uff08\u975e\u8d1f\u6574\u6570\uff09\uff1a\u7528 Poisson NLL\u3002</li> </ul> <p>\u540c\u65f6\u5efa\u8bae\uff1a</p> <ul> <li>\u5728\u795e\u7ecf\u7f51\u7edc\u4e2d\uff0c\u82e5\u4f7f\u7528 MSE \u4e14\u8f93\u51fa\u5c3a\u5ea6\u5927\uff0c\u914d\u5408\u5408\u9002\u7684\u5b66\u4e60\u7387\u548c\u6807\u51c6\u5316\uff08target scaling\uff09\uff1b</li> <li>\u82e5\u4f7f\u7528 MAE/Hinge \u7c7b\u578b\u4e0d\u53ef\u5bfc\u70b9\u7684\u635f\u5931\uff0c\u53ef\u7528\u4f18\u5316\u5668\uff08Adam\uff09\u914d\u5408 subgradient \u6216\u4f7f\u7528 Huber \u4ee3\u66ff\u3002</li> </ul>"},{"location":"machine/interview/#9","title":"9. \u6b63\u5219\u5316\u4e0e\u635f\u5931\u7ed3\u5408","text":"<p>\u901a\u5e38\u5728\u6700\u5c0f\u5316\u635f\u5931\u65f6\u4f1a\u52a0\u6b63\u5219\u5316\u9879\uff08\u9632\u6b62\u8fc7\u62df\u5408\uff09\uff1a $$ J(\\theta) = \\frac{1}{m}\\sum_{i=1}^m L(y^{(i)},\\hat{y}^{(i)}) + \\lambda R(\\theta), $$ \u5e38\u89c1 \\(R(\\theta)=|\\theta|_2^2\\)\uff08L2\uff09\u6216 \\(|\\theta|_1\\)\uff08L1\uff09\u3002</p>"},{"location":"machine/interview/#10","title":"10. \u8bc4\u4f30\u6307\u6807\uff08\u4e0e\u635f\u5931\u4e0d\u540c\uff0c\u5e38\u7528\u4e8e\u6a21\u578b\u8bc4\u4f30\uff09","text":"<ul> <li>MSE\uff1a\\(\\text{MSE}=\\frac{1}{m}\\sum (y-\\hat{y})^2\\)\u3002</li> <li>RMSE\uff08\u5747\u65b9\u6839\u8bef\u5dee\uff09\uff1a\\(\\text{RMSE}=\\sqrt{\\text{MSE}}\\)\uff0c\u4e0e\u539f\u59cb\u5355\u4f4d\u4e00\u81f4\u3002</li> <li>MAE\uff1a\\(\\frac{1}{m}\\sum |y-\\hat{y}|\\)\u3002</li> <li>R\u00b2\uff08\u51b3\u5b9a\u7cfb\u6570\uff09\uff1a   $$   R^2 = 1 - \\frac{\\sum_i (y_i - \\hat{y}_i)^2}{\\sum_i (y_i - \\bar{y})^2},   $$   \u5176\u4e2d \\(\\bar{y}=\\frac{1}{m}\\sum_i y_i\\)\u3002\\(R^2\\) \u8d8a\u63a5\u8fd1 1 \u8d8a\u597d\uff1b\u8d1f\u503c\u8868\u793a\u6a21\u578b\u6027\u80fd\u6bd4\u5e38\u6570\u9884\u6d4b\u5dee\u3002</li> </ul>"},{"location":"machine/interview/#11-python-numpy-pytorch","title":"11. Python \u5b9e\u73b0\u793a\u4f8b\uff08NumPy / PyTorch\uff09","text":""},{"location":"machine/interview/#numpy-mse-mae-huber","title":"NumPy\uff1a\u8ba1\u7b97 MSE / MAE / Huber","text":"<pre><code>import numpy as np\n\ny = np.array([3.0, 2.0, 7.0])\ny_hat = np.array([2.2, 2.5, 6.0])\nm = len(y)\n\n# MSE\nmse = np.mean((y - y_hat)**2)  # (0.64 + 0.25 + 1.0)/3 = 1.89/3 = 0.63\n# \u9010\u4f4d\u8ba1\u7b97: 0.8^2=0.64, (-0.5)^2=0.25, 1.0^2=1.0 -&gt; sum 1.89\n\n# MAE\nmae = np.mean(np.abs(y - y_hat))  # (0.8 + 0.5 + 1.0)/3 = 2.3/3 \u2248 0.7666667\n\n# Huber (delta=1.0)\ndelta = 1.0\ndiff = np.abs(y - y_hat)\nhuber = np.where(diff &lt;= delta, 0.5 * diff**2, delta * (diff - 0.5 * delta))\nhuber_mean = np.mean(huber)\n# \u9010\u4f4d: diff = [0.8,0.5,1.0] -&gt; huber = [0.5*0.64=0.32, 0.5*0.25=0.125, 0.5*1.0=0.5] -&gt; sum=0.945 -&gt; mean=0.315\n</code></pre> <p>\u6ce8\uff1a\u4e0a\u9762 MSE \u7684\u9010\u4f4d\u548c\u8ba1\u7b97\u5df2\u660e\u786e\u5217\u51fa\uff0c\u786e\u4fdd\u6570\u503c\u51c6\u786e\u3002</p>"},{"location":"machine/interview/#pytorch","title":"PyTorch\uff1a\u5e38\u7528\u635f\u5931","text":"<pre><code>import torch\nimport torch.nn as nn\n\ny = torch.tensor([3.0, 2.0, 7.0])\ny_hat = torch.tensor([2.2, 2.5, 6.0])\n\nmse_loss = nn.MSELoss()\nmae_loss = nn.L1Loss()\nhuber_loss = nn.SmoothL1Loss()  # PyTorch \u7684 SmoothL1 \u76f8\u5f53\u4e8e Huber\uff08\u9ed8\u8ba4 beta=1.0\uff09\n\nprint(mse_loss(y_hat, y))   # \u2248 0.63\nprint(mae_loss(y_hat, y))   # \u2248 0.7667\nprint(huber_loss(y_hat, y)) # \u2248 0.315\n</code></pre>"},{"location":"machine/interview/#12_1","title":"12. \u6570\u503c\u7a33\u5b9a\u6027\u4e0e\u5b9e\u8df5\u7ec6\u8282","text":"<ul> <li>\u5bf9\u4e8e MSE\uff0c\u82e5\u76ee\u6807\u503c\u8303\u56f4\u5f88\u5927\uff0c\u68af\u5ea6\u53ef\u80fd\u5f88\u5927\uff0c\u9700\u8c03\u5c0f\u5b66\u4e60\u7387\u6216\u7f29\u653e target\u3002</li> <li>\u5bf9 MAE/Hinge \u7c7b\u578b\u7684\u4e0d\u53ef\u5bfc\u70b9\uff0c\u7528\u6b21\u68af\u5ea6\u6216\u5e73\u6ed1\u8fd1\u4f3c\uff08Huber / Log-cosh\uff09\u3002</li> <li>\u5bf9\u4e8e Poisson / NLL\uff0c\u9884\u6d4b\u503c \\(\\hat{y}\\) \u5fc5\u987b\u662f\u6b63\uff08\u53ef\u7528 softplus \u6fc0\u6d3b \\(\\log(1+e^z)\\)\uff09\uff0c\u907f\u514d \\(\\log 0\\)\u3002</li> <li>\u5728\u6df1\u5ea6\u7f51\u7edc\u8bad\u7ec3\u4e2d\uff0c\u4f7f\u7528 <code>BCEWithLogitsLoss</code>\u3001<code>CrossEntropyLoss</code> \u7b49\u5185\u7f6e\u7a33\u5b9a\u5b9e\u73b0\uff0c\u907f\u514d\u624b\u5199\u6570\u503c\u4e0d\u7a33\u3002</li> </ul>"},{"location":"machine/interview/#62","title":"6.2 \u8bc4\u4f30\u6307\u6807","text":""},{"location":"machine/interview/#_100","title":"\ud83c\udf1f \u4e00\u3001\u5e38\u89c1\u7684\u56de\u5f52\u8bc4\u4f30\u6307\u6807\u6982\u89c8","text":"\u6307\u6807\u540d\u79f0 \u82f1\u6587\u540d\u79f0 \u6570\u5b66\u516c\u5f0f \u542b\u4e49 \u5e73\u5747\u7edd\u5bf9\u8bef\u5dee MAE (Mean Absolute Error) $\\displaystyle MAE = \\frac{1}{n} \\sum_{i=1}^{n} y_i - \\hat{y}_i $ \u5e73\u5747\u7edd\u5bf9\u504f\u5dee\uff0c\u8861\u91cf\u5e73\u5747\u8bef\u5dee\u5927\u5c0f \u5747\u65b9\u8bef\u5dee MSE (Mean Squared Error) \\(\\displaystyle MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\\) \u5f3a\u8c03\u5927\u8bef\u5dee\u7684\u60e9\u7f5a \u5747\u65b9\u6839\u8bef\u5dee RMSE (Root Mean Squared Error) \\(\\displaystyle RMSE = \\sqrt{MSE}\\) \u4e0e\u539f\u76ee\u6807\u5355\u4f4d\u4e00\u81f4\uff0c\u66f4\u76f4\u89c2 \u5e73\u5747\u7edd\u5bf9\u767e\u5206\u6bd4\u8bef\u5dee MAPE (Mean Absolute Percentage Error) $\\displaystyle MAPE = \\frac{100%}{n} \\sum_{i=1}^{n} \\left \\frac{y_i - \\hat{y}_i}{y_i} \\right $ \u8861\u91cf\u76f8\u5bf9\u8bef\u5dee\uff08\u9002\u7528\u4e8e\u6bd4\u4f8b\u95ee\u9898\uff09 \u5224\u5b9a\u7cfb\u6570 \\(R^2\\) (R-squared) \\(\\displaystyle R^2 = 1 - \\frac{\\sum (y_i - \\hat{y}_i)^2}{\\sum (y_i - \\bar{y})^2}\\) \u8861\u91cf\u6a21\u578b\u5bf9\u65b9\u5dee\u7684\u89e3\u91ca\u80fd\u529b\uff08\u62df\u5408\u4f18\u5ea6\uff09"},{"location":"machine/interview/#_101","title":"\ud83e\uddee \u4e8c\u3001\u5404\u6307\u6807\u6570\u5b66\u539f\u7406\u4e0e\u89e3\u91ca","text":""},{"location":"machine/interview/#1-mae","title":"1\ufe0f\u20e3 \u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\uff08MAE\uff09","text":"\\[ MAE = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i| \\] <ul> <li>\u542b\u4e49\uff1a\u6240\u6709\u9884\u6d4b\u8bef\u5dee\u7684\u7edd\u5bf9\u503c\u5e73\u5747\u503c\u3002</li> <li> <p>\u7279\u70b9\uff1a</p> <ul> <li>\u5bf9\u5f02\u5e38\u503c\uff08outlier\uff09\u4e0d\u654f\u611f\u3002</li> <li>\u7269\u7406\u610f\u4e49\u660e\u786e\uff1a\u5e73\u5747\u9884\u6d4b\u8bef\u5dee\u662f\u591a\u5c11\u4e2a\u5355\u4f4d\u3002</li> </ul> </li> <li> <p>\u4e3e\u4f8b\uff1a</p> <ul> <li>\u82e5\u771f\u5b9e\u503c\u4e3a \\([3, 5, 7]\\)\uff0c\u9884\u6d4b\u503c\u4e3a \\([2, 6, 8]\\)\uff1a $$ MAE = \\frac{|3-2| + |5-6| + |7-8|}{3} = 1 $$</li> </ul> </li> </ul>"},{"location":"machine/interview/#2-mse","title":"2\ufe0f\u20e3 \u5747\u65b9\u8bef\u5dee\uff08MSE\uff09","text":"\\[ MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 \\] <ul> <li>\u542b\u4e49\uff1a\u8bef\u5dee\u5e73\u65b9\u7684\u5e73\u5747\u3002</li> <li> <p>\u7279\u70b9\uff1a</p> <ul> <li>\u5e73\u65b9\u9879\u4f1a\u653e\u5927\u5927\u8bef\u5dee\u7684\u5f71\u54cd\uff08\u5bf9\u5f02\u5e38\u503c\u654f\u611f\uff09\u3002</li> <li>\u4f18\u70b9\u662f\u5149\u6ed1\u53ef\u5bfc\uff0c\u4fbf\u4e8e\u4f18\u5316\u3002</li> </ul> </li> <li> <p>\u4e3e\u4f8b\uff1a   $$   MSE = \\frac{(3-2)^2 + (5-6)^2 + (7-8)^2}{3} = 1   $$</p> </li> </ul>"},{"location":"machine/interview/#3-rmse","title":"3\ufe0f\u20e3 \u5747\u65b9\u6839\u8bef\u5dee\uff08RMSE\uff09","text":"\\[ RMSE = \\sqrt{MSE} \\] <ul> <li>\u542b\u4e49\uff1aMSE \u7684\u5e73\u65b9\u6839\uff0c\u4f7f\u5355\u4f4d\u4e0e\u539f\u6570\u636e\u4e00\u81f4\u3002</li> <li> <p>\u7279\u70b9\uff1a</p> <ul> <li>\u6570\u503c\u66f4\u76f4\u89c2\uff08\u5355\u4f4d\u4e0e \\(y\\) \u76f8\u540c\uff09\u3002</li> <li>\u540c\u6837\u5bf9\u5f02\u5e38\u503c\u654f\u611f\u3002</li> </ul> </li> <li> <p>\u4e3e\u4f8b\uff1a   $$   RMSE = \\sqrt{1} = 1   $$</p> </li> </ul>"},{"location":"machine/interview/#4-mape","title":"4\ufe0f\u20e3 \u5e73\u5747\u7edd\u5bf9\u767e\u5206\u6bd4\u8bef\u5dee\uff08MAPE\uff09","text":"\\[ MAPE = \\frac{100%}{n} \\sum_{i=1}^{n} \\left| \\frac{y_i - \\hat{y}_i}{y_i} \\right| \\] <ul> <li>\u542b\u4e49\uff1a\u6bcf\u4e2a\u9884\u6d4b\u503c\u76f8\u5bf9\u771f\u5b9e\u503c\u7684\u767e\u5206\u6bd4\u8bef\u5dee\u5e73\u5747\u3002</li> <li> <p>\u7279\u70b9\uff1a</p> <ul> <li>\u9002\u5408 \u91cf\u7eb2\u4e0d\u540c \u7684\u6570\u636e\u6bd4\u8f83\u3002</li> <li>\u4f46\u5f53 \\(y_i = 0\\) \u65f6\u65e0\u5b9a\u4e49\uff0c\u9700\u6ce8\u610f\u3002</li> <li> <p>\u4e3e\u4f8b\uff1a</p> </li> <li> <p>\\(y = [100, 200, 300]\\), \\(\\hat{y} = [110, 190, 310]\\)\uff1a $$ MAPE = \\frac{1}{3}(0.1 + 0.05 + 0.0333) \\times 100% = 6.1% $$</p> </li> </ul> </li> </ul>"},{"location":"machine/interview/#5-r2","title":"5\ufe0f\u20e3 \u5224\u5b9a\u7cfb\u6570\uff08\\(R^2\\)\uff09","text":"\\[ R^2 = 1 - \\frac{SS_{res}}{SS_{tot}} = 1 - \\frac{\\sum (y_i - \\hat{y}_i)^2}{\\sum (y_i - \\bar{y})^2} \\] <p>\u5176\u4e2d\uff1a</p> <ul> <li>\\(SS_{res}\\)\uff1a\u6b8b\u5dee\u5e73\u65b9\u548c\uff08residual sum of squares\uff09</li> <li>\\(SS_{tot}\\)\uff1a\u603b\u5e73\u65b9\u548c\uff08total sum of squares\uff09</li> <li>\\(\\bar{y}\\)\uff1a\u6837\u672c\u771f\u5b9e\u503c\u7684\u5e73\u5747\u6570</li> </ul> <p>\u542b\u4e49\uff1a</p> <ul> <li>\u8861\u91cf\u6a21\u578b\u9884\u6d4b\u89e3\u91ca\u4e86\u76ee\u6807\u53d8\u91cf\u65b9\u5dee\u7684\u6bd4\u4f8b\u3002</li> <li>\\(R^2\\) \u7684\u8303\u56f4\u901a\u5e38\u5728 \\([0, 1]\\)\uff08\u4f46\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u53ef\u5c0f\u4e8e 0\uff09\u3002</li> <li>\u503c\u8d8a\u5927\u8868\u793a\u6a21\u578b\u62df\u5408\u6548\u679c\u8d8a\u597d\u3002</li> </ul> <p>\u4e3e\u4f8b\uff1a</p> <ul> <li>\u82e5\u6a21\u578b\u9884\u6d4b\u503c\u5b8c\u5168\u6b63\u786e\uff0c\\(\\sum (y_i - \\hat{y}_i)^2 = 0\\)\uff0c\u5219 \\(R^2 = 1\\)\uff1b</li> <li>\u82e5\u6a21\u578b\u4e0e\u5747\u503c\u9884\u6d4b\u65e0\u5dee\u522b\uff0c\u5219 \\(R^2 = 0\\)\u3002</li> </ul>"},{"location":"machine/interview/#_102","title":"\ud83d\udca1 \u4e09\u3001\u5404\u6307\u6807\u5bf9\u6bd4\u603b\u7ed3","text":"\u6307\u6807 \u662f\u5426\u5bf9\u5f02\u5e38\u503c\u654f\u611f \u662f\u5426\u53ef\u5bfc \u662f\u5426\u6709\u7269\u7406\u610f\u4e49 \u9002\u7528\u573a\u666f MAE \u5426 \u5426\uff08\u4e0d\u53ef\u5bfc\u70b9\uff09 \u6709 \u4e00\u822c\u8bef\u5dee\u5206\u6790 MSE \u662f \u662f \u6709 \u6a21\u578b\u8bad\u7ec3\u4f18\u5316 RMSE \u662f \u662f \u5f3a \u6a21\u578b\u6027\u80fd\u89e3\u91ca MAPE \u662f \u5426 \u5f3a \u6bd4\u4f8b\u578b\u6570\u636e \\(R^2\\) \u5426 \u5426 \u76f8\u5bf9\u89e3\u91ca\u80fd\u529b \u6a21\u578b\u6574\u4f53\u62df\u5408\u8d28\u91cf"},{"location":"machine/interview/#sklearn","title":"\ud83e\udde0 \u56db\u3001\u4ee3\u7801\u5b9e\u6218\uff08\u4ee5 <code>sklearn</code> \u4e3a\u4f8b\uff09","text":"<pre><code>from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\nimport numpy as np\n\n# \u5047\u8bbe\u771f\u5b9e\u503c\u4e0e\u9884\u6d4b\u503c\ny_true = np.array([3, 5, 7])\ny_pred = np.array([2, 6, 8])\n\nmae = mean_absolute_error(y_true, y_pred)\nmse = mean_squared_error(y_true, y_pred)\nrmse = np.sqrt(mse)\nr2 = r2_score(y_true, y_pred)\n\nprint(f\"MAE = {mae:.3f}\")\nprint(f\"MSE = {mse:.3f}\")\nprint(f\"RMSE = {rmse:.3f}\")\nprint(f\"R\u00b2 = {r2:.3f}\")\n</code></pre> <p>\u8f93\u51fa\u7ed3\u679c\uff1a</p> <pre><code>MAE = 1.000\nMSE = 1.000\nRMSE = 1.000\nR\u00b2 = 0.875\n</code></pre>"},{"location":"machine/interview/#_103","title":"\ud83d\udcd8 \u4e94\u3001\u603b\u7ed3","text":"<ul> <li>MAE\uff1a\u5e73\u5747\u8bef\u5dee\uff08\u7a33\u5065\u3001\u76f4\u89c2\uff09</li> <li>MSE / RMSE\uff1a\u5e73\u65b9\u60e9\u7f5a\uff08\u504f\u91cd\u5927\u8bef\u5dee\uff0c\u8bad\u7ec3\u5e38\u7528\uff09</li> <li>MAPE\uff1a\u767e\u5206\u6bd4\u8bef\u5dee\uff08\u9002\u5408\u6bd4\u4f8b\u578b\u95ee\u9898\uff09</li> <li>\\(R^2\\)\uff1a\u89e3\u91ca\u65b9\u5dee\u6bd4\u4f8b\uff08\u62df\u5408\u4f18\u5ea6\u6307\u6807\uff09</li> </ul>"},{"location":"machine/interview/#_104","title":"\u4e03\u3001\u7279\u5f81\u5de5\u7a0b","text":""},{"location":"machine/interview/#71","title":"7.1 \u7279\u5f81\u9009\u62e9","text":""},{"location":"machine/interview/#_105","title":"\u4e00\u3001\u4ec0\u4e48\u662f\u7279\u5f81\u9009\u62e9","text":"<p>\u7279\u5f81\u9009\u62e9\u662f\u6307\u5728 \u539f\u59cb\u7279\u5f81\u96c6\u5408\u4e2d\u9009\u62e9\u5bf9\u6a21\u578b\u6700\u6709\u7528\u7684\u5b50\u96c6\uff0c\u5220\u9664\u5197\u4f59\u6216\u65e0\u5173\u7279\u5f81\uff0c\u4ece\u800c\u63d0\u9ad8\u6a21\u578b\u6027\u80fd\u3001\u51cf\u5c11\u8fc7\u62df\u5408\u3001\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\u548c\u63d0\u9ad8\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u3002</p> <p>\u5047\u8bbe\uff1a</p> <ul> <li>\u6570\u636e\u96c6 \\(X \\in \\mathbb{R}^{n \\times d}\\)\uff0c\\(n\\) \u4e3a\u6837\u672c\u6570\uff0c\\(d\\) \u4e3a\u7279\u5f81\u6570\u3002</li> <li>\u6807\u7b7e\u4e3a \\(y \\in \\mathbb{R}^n\\)\uff08\u56de\u5f52\uff09\u6216 \\(y \\in {0,1}^n\\)\uff08\u5206\u7c7b\uff09\u3002</li> <li>\u7279\u5f81\u9009\u62e9\u7684\u76ee\u6807\u662f\u627e\u5230\u5b50\u96c6 \\(S \\subseteq {1,2,\\dots,d}\\)\uff0c\u4f7f\u5f97 \\(X_S\\) \u5bf9\u9884\u6d4b \\(y\\) \u6709\u6700\u5927\u8d21\u732e\u3002</li> </ul>"},{"location":"machine/interview/#_106","title":"\u4e8c\u3001\u7279\u5f81\u9009\u62e9\u7684\u4e09\u5927\u7c7b\u522b","text":""},{"location":"machine/interview/#1-filter","title":"1\ufe0f\u20e3 Filter\uff08\u8fc7\u6ee4\u6cd5\uff09","text":"<ul> <li>\u539f\u7406\uff1a\u72ec\u7acb\u4e8e\u6a21\u578b\uff0c\u57fa\u4e8e \u7279\u5f81\u4e0e\u6807\u7b7e\u7684\u7edf\u8ba1\u5173\u7cfb \u8fdb\u884c\u6392\u5e8f\u548c\u7b5b\u9009\u3002</li> <li>\u65b9\u6cd5\uff1a</li> </ul>"},{"location":"machine/interview/#1-variance-threshold","title":"(1) \u65b9\u5dee\u9009\u62e9\uff08Variance Threshold\uff09","text":"<ul> <li>\u539f\u7406\uff1a\u5982\u679c\u7279\u5f81\u7684\u65b9\u5dee\u5f88\u5c0f\uff0c\u8bf4\u660e\u8be5\u7279\u5f81\u51e0\u4e4e\u4e0d\u53d8\u5316\uff0c\u5bf9\u9884\u6d4b\u65e0\u7528\u3002</li> <li>\u516c\u5f0f\uff1a   $$   Var(x_j) = \\frac{1}{n} \\sum_{i=1}^n (x_{ij} - \\bar{x}_j)^2   $$</li> <li>\u9608\u503c\u8bbe\u5b9a \\(\\theta\\)\uff0c\u82e5 \\(Var(x_j) &lt; \\theta\\)\uff0c\u5219\u5220\u9664\u7279\u5f81 \\(x_j\\)\u3002</li> </ul>"},{"location":"machine/interview/#2-correlation","title":"(2) \u76f8\u5173\u7cfb\u6570\uff08Correlation\uff09","text":"<ul> <li>Pearson \u76f8\u5173\u7cfb\u6570\uff08\u8fde\u7eed\u7279\u5f81\uff09\uff1a</li> </ul> \\[   \\rho_{x_j,y} = \\frac{Cov(x_j,y)}{\\sigma_{x_j}\\sigma_y} = \\frac{\\sum_i (x_{ij}-\\bar{x}*j)(y_i-\\bar{y})}{\\sqrt{\\sum_i (x*{ij}-\\bar{x}_j)^2}\\sqrt{\\sum_i (y_i-\\bar{y})^2}} \\] <ul> <li>\u9ad8\u76f8\u5173\uff08\u7edd\u5bf9\u503c\u5927\uff09\u4fdd\u7559\uff0c\u4f4e\u76f8\u5173\u5254\u9664\u3002</li> <li>\u5bf9\u5206\u7c7b\u53ef\u7528 \u5361\u65b9\u68c0\u9a8c\uff1a   $$   \\chi^2 = \\sum_{i,j} \\frac{(O_{ij}-E_{ij})^2}{E_{ij}}   $$</li> <li>\u5bf9\u4e8c\u5206\u7c7b\u53d8\u91cf\u6216\u5206\u7c7b\u7279\u5f81\u5e38\u7528 Mutual Information\uff08\u4e92\u4fe1\u606f\uff09\uff1a   $$   I(X;Y) = \\sum_{x\\in X}\\sum_{y\\in Y} p(x,y)\\log \\frac{p(x,y)}{p(x)p(y)}   $$</li> </ul>"},{"location":"machine/interview/#2-wrapper","title":"2\ufe0f\u20e3 Wrapper\uff08\u5305\u88f9\u6cd5\uff09","text":"<ul> <li>\u539f\u7406\uff1a\u4f7f\u7528\u6a21\u578b\u6027\u80fd\u4f5c\u4e3a\u8bc4\u4ef7\u6307\u6807\uff0c\u641c\u7d22\u7279\u5f81\u5b50\u96c6\u3002</li> <li> <p>\u7279\u70b9\uff1a</p> <ul> <li>\u8017\u65f6\u8f83 Filter \u65b9\u6cd5\u9ad8\uff0c\u4f46\u901a\u5e38\u6548\u679c\u66f4\u597d\u3002</li> </ul> </li> <li> <p>\u65b9\u6cd5\uff1a</p> </li> </ul>"},{"location":"machine/interview/#1-rfe-recursive-feature-elimination","title":"(1) \u9012\u5f52\u7279\u5f81\u6d88\u9664\uff08RFE, Recursive Feature Elimination\uff09","text":"<ul> <li> <p>\u8fc7\u7a0b\uff1a</p> <ol> <li>\u8bad\u7ec3\u6a21\u578b\uff08\u5982\u7ebf\u6027\u56de\u5f52\u6216SVM\uff09</li> <li>\u6839\u636e\u7279\u5f81\u91cd\u8981\u6027\uff08\u6743\u91cd \\(w_j\\) \u6216\u7279\u5f81\u7cfb\u6570\uff09\u5220\u9664\u6700\u4e0d\u91cd\u8981\u7684\u7279\u5f81</li> <li>\u91cd\u590d\u8fed\u4ee3\u76f4\u5230\u8fbe\u5230\u671f\u671b\u7279\u5f81\u6570\u91cf</li> </ol> </li> <li> <p>\u516c\u5f0f\uff08\u7ebf\u6027\u6a21\u578b\u91cd\u8981\u6027\u793a\u4f8b\uff09\uff1a   $$   w_j = | \\theta_j |   $$</p> </li> </ul>"},{"location":"machine/interview/#2-stepwise-selection","title":"(2) \u524d\u5411/\u540e\u5411/\u9010\u6b65\u9009\u62e9\uff08Stepwise Selection\uff09","text":"<ul> <li>\u524d\u5411\u9009\u62e9\uff1a\u4ece\u7a7a\u96c6\u5f00\u59cb\uff0c\u9010\u6b65\u52a0\u5165\u4f7f\u6a21\u578b\u6027\u80fd\u63d0\u5347\u6700\u5927\u7684\u7279\u5f81</li> <li>\u540e\u5411\u9009\u62e9\uff1a\u4ece\u5168\u91cf\u7279\u5f81\u5f00\u59cb\uff0c\u9010\u6b65\u5254\u9664\u5bf9\u6a21\u578b\u5f71\u54cd\u6700\u5c0f\u7684\u7279\u5f81</li> <li>\u9010\u6b65\u9009\u62e9\uff1a\u524d\u5411 + \u540e\u5411\u4ea4\u66ff\u8fdb\u884c</li> </ul>"},{"location":"machine/interview/#3-embedded","title":"3\ufe0f\u20e3 Embedded\uff08\u5d4c\u5165\u6cd5\uff09","text":"<ul> <li>\u539f\u7406\uff1a\u7279\u5f81\u9009\u62e9\u5d4c\u5165\u6a21\u578b\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u901a\u8fc7\u6b63\u5219\u5316\u6216\u6811\u6a21\u578b\u81ea\u52a8\u8bc4\u4f30\u7279\u5f81\u91cd\u8981\u6027\u3002</li> <li>\u65b9\u6cd5\uff1a</li> </ul>"},{"location":"machine/interview/#1-l1-lasso","title":"(1) L1 \u6b63\u5219\u5316\uff08Lasso \u56de\u5f52\uff09","text":"<ul> <li>\u635f\u5931\u51fd\u6570\uff1a   $$   J(\\theta) = \\frac{1}{n}\\sum_{i=1}^{n} (y_i - X_i \\theta)^2 + \\lambda \\sum_{j=1}^{d} |\\theta_j|   $$</li> <li>\u5f53 \\(\\lambda\\) \u8db3\u591f\u5927\u65f6\uff0c\u4f1a\u5c06\u90e8\u5206 \\(\\theta_j\\) \u6536\u7f29\u4e3a 0 \u2192 \u5bf9\u5e94\u7279\u5f81\u88ab\u5254\u9664\u3002</li> </ul>"},{"location":"machine/interview/#2_12","title":"(2) \u6811\u6a21\u578b\u7279\u5f81\u91cd\u8981\u6027","text":"<ul> <li>\u51b3\u7b56\u6811\u3001\u968f\u673a\u68ee\u6797\u3001XGBoost \u7b49\u53ef\u8f93\u51fa\u6bcf\u4e2a\u7279\u5f81\u7684 Gini importance \u6216 Gain\u3002</li> <li>\u5bf9\u5206\u7c7b\u95ee\u9898\uff1a   $$   Importance(x_j) = \\sum_{t\\in T: split \\text{ on } x_j} \\Delta i(t)   $$</li> <li>\\(\\Delta i(t)\\) \u4e3a\u8282\u70b9 \\(t\\) \u5728\u5206\u88c2\u65f6\u4e0d\u7eaf\u5ea6\u4e0b\u964d\uff08Gini \u6216 Entropy\uff09</li> </ul>"},{"location":"machine/interview/#_107","title":"\u4e09\u3001\u7279\u5f81\u9009\u62e9\u7684\u6570\u5b66\u76ee\u6807","text":"<p>\u7279\u5f81\u9009\u62e9\u672c\u8d28\u662f\u4f18\u5316\u5b50\u96c6 \\(S\\)\uff1a</p> \\[ S^* = \\arg\\max_{S\\subseteq{1,\\dots,d}} Score(S) \\] <ul> <li>Filter\uff1a\\(Score(S) = \\sum_{j\\in S} |\\rho(x_j,y)|\\) \u6216\u4e92\u4fe1\u606f</li> <li>Wrapper\uff1a\\(Score(S) = CV_Score(Model(X_S, y))\\)</li> <li>Embedded\uff1a\\(Score(S) = \\sum_{j\\in S} |w_j|\\) \u6216\u6811\u6a21\u578b\u91cd\u8981\u6027</li> </ul> <p>\u7279\u5f81\u9009\u62e9\u95ee\u9898\u662fNP-hard\uff08\u7ec4\u5408\u4f18\u5316\uff09\uff0c\u5b9e\u9645\u7528\u542f\u53d1\u5f0f\u7b97\u6cd5\uff08RFE\u3001\u8d2a\u5fc3\u3001\u6b63\u5219\u5316\uff09\u8fd1\u4f3c\u6c42\u89e3\u3002</p>"},{"location":"machine/interview/#_108","title":"\u56db\u3001\u7279\u5f81\u9009\u62e9\u7684\u6ce8\u610f\u4e8b\u9879","text":"<ol> <li>\u907f\u514d\u6570\u636e\u6cc4\u6f0f\uff1a\u5728\u4ea4\u53c9\u9a8c\u8bc1/\u6d4b\u8bd5\u96c6\u4e0a\u505a\u7279\u5f81\u9009\u62e9\u4f1a\u5bfc\u81f4\u6570\u636e\u6cc4\u6f0f\uff0c\u5e94\u4ec5\u5728\u8bad\u7ec3\u96c6\u4e0a\u9009\u62e9\u7279\u5f81\u3002</li> <li>\u591a\u91cd\u5171\u7ebf\u6027\uff1a\u9ad8\u76f8\u5173\u7279\u5f81\u53ef\u80fd\u5bfc\u81f4\u6a21\u578b\u4e0d\u7a33\u5b9a\uff0c\u53ef\u5254\u9664\u5197\u4f59\u7279\u5f81\u6216\u505a PCA \u964d\u7ef4\u3002</li> <li> <p>\u7c7b\u522b\u7279\u5f81\u7f16\u7801\uff1a</p> <ul> <li>One-hot \u7f16\u7801\u540e\u7279\u5f81\u6570\u91cf\u589e\u52a0\uff0c\u9700\u7ed3\u5408\u6b63\u5219\u5316\u6216\u6811\u6a21\u578b\u8fdb\u884c\u7b5b\u9009\u3002</li> </ul> </li> <li> <p>\u7279\u5f81\u9009\u62e9\u4e0e\u6807\u51c6\u5316\uff1a</p> <ul> <li>\u5bf9 L1/L2 \u6b63\u5219\u5316\u6a21\u578b\u9700\u8981\u5148\u5bf9\u7279\u5f81\u5f52\u4e00\u5316\u3002</li> </ul> </li> <li> <p>\u7279\u5f81\u91cd\u8981\u6027\u89e3\u91ca\uff1a</p> <ul> <li>Filter \u65b9\u6cd5\u7b80\u5355\u53ef\u89e3\u91ca\uff0c\u4f46\u5ffd\u7565\u7279\u5f81\u95f4\u4ea4\u4e92\u3002</li> <li>Wrapper/Embedded \u65b9\u6cd5\u8003\u8651\u7279\u5f81\u4ea4\u4e92\uff0c\u4f46\u590d\u6742\u5ea6\u9ad8\u3002</li> </ul> </li> </ol>"},{"location":"machine/interview/#_109","title":"\u4e94\u3001\u7279\u5f81\u9009\u62e9\u793a\u4f8b\u4ee3\u7801","text":""},{"location":"machine/interview/#1-filter_1","title":"1\ufe0f\u20e3 Filter \u65b9\u6cd5\uff08\u65b9\u5dee &amp; \u76f8\u5173\u7cfb\u6570\uff09","text":"<pre><code>from sklearn.feature_selection import VarianceThreshold, SelectKBest, f_classif\nimport numpy as np\n\nX = np.random.rand(100, 10)\ny = np.random.randint(0,2,100)\n\n# \u65b9\u5dee\u9009\u62e9\nselector = VarianceThreshold(threshold=0.01)\nX_var = selector.fit_transform(X)\n\n# \u5361\u65b9\u68c0\u9a8c\uff08\u5206\u7c7b\u4efb\u52a1\uff09\nselector = SelectKBest(score_func=f_classif, k=5)\nX_best = selector.fit_transform(X, y)\n</code></pre>"},{"location":"machine/interview/#2-wrapper-rfe","title":"2\ufe0f\u20e3 Wrapper \u65b9\u6cd5\uff08RFE + \u903b\u8f91\u56de\u5f52\uff09","text":"<pre><code>from sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LogisticRegression\n\nmodel = LogisticRegression()\nrfe = RFE(model, n_features_to_select=5)\nX_rfe = rfe.fit_transform(X, y)\nprint(rfe.support_)  # \u8f93\u51fa\u4fdd\u7559\u7279\u5f81\u5e03\u5c14\u6570\u7ec4\n</code></pre>"},{"location":"machine/interview/#3-embedded-lasso","title":"3\ufe0f\u20e3 Embedded \u65b9\u6cd5\uff08Lasso + \u6811\u6a21\u578b\uff09","text":"<pre><code>from sklearn.linear_model import Lasso\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Lasso \u56de\u5f52\nlasso = Lasso(alpha=0.01)\nlasso.fit(X, y)\nselected_features = np.where(lasso.coef_ != 0)[0]\n\n# \u6811\u6a21\u578b\nrf = RandomForestClassifier()\nrf.fit(X, y)\nimportances = rf.feature_importances_\n</code></pre>"},{"location":"machine/interview/#_110","title":"\u516d\u3001\u603b\u7ed3","text":"\u65b9\u6cd5 \u4f18\u70b9 \u7f3a\u70b9 \u4f7f\u7528\u573a\u666f Filter \u5feb\u3001\u6613\u89e3\u91ca \u5ffd\u7565\u7279\u5f81\u95f4\u4ea4\u4e92 \u5927\u89c4\u6a21\u7279\u5f81\u7b5b\u9009 Wrapper \u8003\u8651\u6a21\u578b\u6027\u80fd\u3001\u4ea4\u4e92 \u8ba1\u7b97\u91cf\u5927 \u5c0f\u89c4\u6a21\u7279\u5f81\u3001\u8ffd\u6c42\u9ad8\u7cbe\u5ea6 Embedded \u6a21\u578b\u8bad\u7ec3\u81ea\u52a8\u7b5b\u9009\u3001\u6548\u7387\u9ad8 \u4f9d\u8d56\u6a21\u578b L1/L2\u56de\u5f52\u3001\u6811\u6a21\u578b <p>\u7279\u5f81\u9009\u62e9\u672c\u8d28\u662f \u964d\u4f4e\u566a\u58f0\u3001\u51cf\u5c11\u8fc7\u62df\u5408\u3001\u63d0\u5347\u6a21\u578b\u53ef\u89e3\u91ca\u6027\uff0c\u5b9e\u9645\u64cd\u4f5c\u65f6\u5e38\u4e0e\u6b63\u5219\u5316\u3001PCA\u3001\u6a21\u578b\u8c03\u53c2\u7ed3\u5408\u4f7f\u7528\u3002</p>"},{"location":"machine/interview/#72","title":"7.2 \u7279\u5f81\u63d0\u53d6","text":""},{"location":"machine/interview/#_111","title":"\u4e00\u3001\u4ec0\u4e48\u662f\u7279\u5f81\u63d0\u53d6","text":"<ul> <li>\u7279\u5f81\u9009\u62e9\uff08Feature Selection\uff09\uff1a\u4ece\u539f\u6709\u7279\u5f81\u4e2d\u9009\u62e9\u5bf9\u6a21\u578b\u6709\u7528\u7684\u7279\u5f81\u3002</li> <li>\u7279\u5f81\u63d0\u53d6\uff08Feature Extraction\uff09\uff1a\u901a\u8fc7\u53d8\u6362\u539f\u59cb\u7279\u5f81\u751f\u6210\u65b0\u7684\u7279\u5f81\uff0c\u4ee5\u66f4\u6709\u6548\u5730\u8868\u793a\u6570\u636e\u3002</li> </ul> <p>\u901a\u4fd7\u7406\u89e3\uff1a</p> <ul> <li>\u7279\u5f81\u9009\u62e9 \u2192 \u5220\u6389\u4e0d\u91cd\u8981\u7684\u7279\u5f81</li> <li>\u7279\u5f81\u63d0\u53d6 \u2192 \u751f\u6210\u65b0\u7684\u3001\u66f4\u7d27\u51d1\u6216\u66f4\u6709\u4fe1\u606f\u91cf\u7684\u7279\u5f81</li> </ul> <p>\u76ee\u6807\uff1a</p> <ul> <li>\u964d\u7ef4</li> <li>\u63d0\u5347\u6a21\u578b\u6027\u80fd</li> <li>\u6d88\u9664\u5197\u4f59\u6216\u566a\u58f0</li> <li>\u63d0\u53d6\u6570\u636e\u7684\u6f5c\u5728\u7ed3\u6784</li> </ul> <p>\u5047\u8bbe\uff1a</p> <ul> <li>\u539f\u59cb\u6570\u636e\u77e9\u9635 \\(X \\in \\mathbb{R}^{n \\times d}\\)\uff08\\(n\\) \u6837\u672c\uff0c\\(d\\) \u7279\u5f81\uff09</li> <li>\u7279\u5f81\u63d0\u53d6\u751f\u6210\u65b0\u7684\u7279\u5f81\u77e9\u9635 \\(Z \\in \\mathbb{R}^{n \\times k}\\)\uff0c\u901a\u5e38 \\(k&lt;d\\)\u3002</li> </ul>"},{"location":"machine/interview/#_112","title":"\u4e8c\u3001\u7279\u5f81\u63d0\u53d6\u7684\u6838\u5fc3\u539f\u7406","text":"<p>\u7279\u5f81\u63d0\u53d6\u901a\u5e38\u901a\u8fc7\u6570\u5b66\u53d8\u6362\u6216\u6620\u5c04\u5c06\u539f\u59cb\u7279\u5f81\u7a7a\u95f4\u6620\u5c04\u5230\u4e00\u4e2a\u65b0\u7684\u7279\u5f81\u7a7a\u95f4\uff1a</p> \\[ Z = f(X) \\] <ul> <li>\\(f\\) \u53ef\u4ee5\u662f\u7ebf\u6027\u6216\u975e\u7ebf\u6027\u6620\u5c04</li> <li>\u65b0\u7279\u5f81 \\(Z\\) \u4fdd\u7559\u539f\u59cb\u6570\u636e\u7684\u5173\u952e\u4fe1\u606f\uff0c\u53ef\u80fd\u51cf\u5c11\u566a\u58f0\u6216\u5197\u4f59</li> </ul> <p>\u7279\u5f81\u63d0\u53d6\u5e38\u4e0e \u964d\u7ef4\uff08Dimensionality Reduction\uff09 \u5bc6\u5207\u76f8\u5173\u3002</p>"},{"location":"machine/interview/#_113","title":"\u4e09\u3001\u5e38\u89c1\u7ebf\u6027\u7279\u5f81\u63d0\u53d6\u65b9\u6cd5","text":""},{"location":"machine/interview/#1-pca-principal-component-analysis","title":"1\ufe0f\u20e3 \u4e3b\u6210\u5206\u5206\u6790\uff08PCA, Principal Component Analysis\uff09","text":"<ul> <li>\u76ee\u6807\uff1a\u627e\u5230\u80fd\u6700\u5927\u5316\u6570\u636e\u65b9\u5dee\u7684\u6b63\u4ea4\u65b9\u5411</li> <li> <p>\u6570\u5b66\u5b9a\u4e49\uff1a</p> </li> <li> <p>\u6570\u636e\u4e2d\u5fc3\u5316\uff1a\\(\\tilde{X} = X - \\bar{X}\\)</p> </li> <li>\u534f\u65b9\u5dee\u77e9\u9635\uff1a     $$     \\Sigma = \\frac{1}{n} \\tilde{X}^T \\tilde{X}     $$</li> <li>\u6c42\u89e3\u7279\u5f81\u503c\u548c\u7279\u5f81\u5411\u91cf\uff1a     $$     \\Sigma v_i = \\lambda_i v_i     $$</li> <li>\u9009\u62e9\u524d \\(k\\) \u4e2a\u6700\u5927\u7279\u5f81\u503c\u5bf9\u5e94\u7684\u7279\u5f81\u5411\u91cf\u7ec4\u6210\u6295\u5f71\u77e9\u9635 \\(V_k\\)\uff1a     $$     Z = \\tilde{X} V_k     $$</li> <li>\u4f18\u70b9\uff1a\u538b\u7f29\u7ef4\u5ea6\u3001\u53bb\u76f8\u5173\u6027</li> <li>\u7f3a\u70b9\uff1a\u53ea\u6355\u6349\u7ebf\u6027\u5173\u7cfb\uff0c\u7279\u5f81\u53ef\u89e3\u91ca\u6027\u5dee</li> </ul>"},{"location":"machine/interview/#2-lda-linear-discriminant-analysis","title":"2\ufe0f\u20e3 \u7ebf\u6027\u5224\u522b\u5206\u6790\uff08LDA, Linear Discriminant Analysis\uff09","text":"<ul> <li>\u76ee\u6807\uff1a\u5728\u5206\u7c7b\u95ee\u9898\u4e2d\u6700\u5927\u5316\u7c7b\u95f4\u8ddd\u79bb\u3001\u6700\u5c0f\u5316\u7c7b\u5185\u65b9\u5dee</li> <li> <p>\u516c\u5f0f\uff1a</p> </li> <li> <p>\u7c7b\u5185\u6563\u5ea6\u77e9\u9635\uff1a     $$     S_W = \\sum_{c=1}^{C} \\sum_{x_i \\in c} (x_i - \\mu_c)(x_i - \\mu_c)^T     $$</p> </li> <li>\u7c7b\u95f4\u6563\u5ea6\u77e9\u9635\uff1a     $$     S_B = \\sum_{c=1}^{C} n_c (\\mu_c - \\mu)(\\mu_c - \\mu)^T     $$</li> <li>\u6c42\u89e3\u6295\u5f71\u77e9\u9635 \\(W\\)\uff1a     $$     W = \\arg\\max_W \\frac{|W^T S_B W|}{|W^T S_W W|}     $$</li> <li>\u4f18\u70b9\uff1a\u9002\u7528\u4e8e\u76d1\u7763\u5206\u7c7b\u95ee\u9898\uff0c\u964d\u7ef4\u540e\u7c7b\u522b\u53ef\u5206\u6027\u589e\u5f3a</li> <li>\u7f3a\u70b9\uff1a\u53ea\u80fd\u63d0\u53d6 \\(C-1\\) \u4e2a\u7279\u5f81\uff08\u7c7b\u522b\u6570\u9650\u5236\uff09\uff0c\u5047\u8bbe\u6570\u636e\u9ad8\u65af\u5206\u5e03</li> </ul>"},{"location":"machine/interview/#3-ica-independent-component-analysis","title":"3\ufe0f\u20e3 \u72ec\u7acb\u6210\u5206\u5206\u6790\uff08ICA, Independent Component Analysis\uff09","text":"<ul> <li>\u76ee\u6807\uff1a\u5c06\u6df7\u5408\u4fe1\u53f7\u5206\u89e3\u4e3a\u7edf\u8ba1\u72ec\u7acb\u7684\u6210\u5206</li> <li> <p>\u516c\u5f0f\uff1a   $$   X = A S   $$</p> </li> <li> <p>\\(X\\)\uff1a\u89c2\u6d4b\u6570\u636e</p> </li> <li>\\(A\\)\uff1a\u6df7\u5408\u77e9\u9635</li> <li>\\(S\\)\uff1a\u72ec\u7acb\u6210\u5206</li> <li>\u4f18\u5316\u76ee\u6807\uff1a\u6700\u5927\u5316\u975e\u9ad8\u65af\u6027\u6216\u6700\u5c0f\u5316\u4e92\u4fe1\u606f\uff1a   $$   \\max \\sum_i \\text{Negentropy}(s_i)   $$</li> </ul>"},{"location":"machine/interview/#_114","title":"\u56db\u3001\u5e38\u89c1\u975e\u7ebf\u6027\u7279\u5f81\u63d0\u53d6\u65b9\u6cd5","text":""},{"location":"machine/interview/#1-kernel-pca","title":"1\ufe0f\u20e3 \u6838\u4e3b\u6210\u5206\u5206\u6790\uff08Kernel PCA\uff09","text":"<ul> <li>\u601d\u60f3\uff1a\u5bf9\u539f\u59cb\u6570\u636e\u505a\u975e\u7ebf\u6027\u6620\u5c04 \\(\\phi: X \\rightarrow \\mathcal{F}\\)\uff0c\u518d\u505a PCA</li> <li>\u6838\u6280\u5de7\uff1a   $$   K_{ij} = \\phi(x_i)^T \\phi(x_j)   $$</li> <li>\u4f18\u70b9\uff1a\u53ef\u4ee5\u63d0\u53d6\u975e\u7ebf\u6027\u7ed3\u6784</li> <li>\u7f3a\u70b9\uff1a\u8ba1\u7b97\u91cf\u5927\uff0c\u6838\u9009\u62e9\u654f\u611f</li> </ul>"},{"location":"machine/interview/#2-t-snet-distributed-stochastic-neighbor-embedding","title":"2\ufe0f\u20e3 t-SNE\uff08t-Distributed Stochastic Neighbor Embedding\uff09","text":"<ul> <li>\u76ee\u6807\uff1a\u5c06\u9ad8\u7ef4\u6570\u636e\u5d4c\u5165\u4f4e\u7ef4\u7a7a\u95f4\uff08\u4e3b\u8981\u7528\u4e8e\u53ef\u89c6\u5316\uff09</li> <li> <p>\u65b9\u6cd5\uff1a</p> </li> <li> <p>\u9ad8\u7ef4\u7a7a\u95f4\u76f8\u4f3c\u5ea6\uff1a     $$     p_{j|i} = \\frac{\\exp(-|x_i - x_j|^2 / 2\\sigma_i^2)}{\\sum_{k\\neq i} \\exp(-|x_i - x_k|^2 / 2\\sigma_i^2)}     $$</p> </li> <li>\u4f4e\u7ef4\u7a7a\u95f4\u76f8\u4f3c\u5ea6\uff1a     $$     q_{ij} = \\frac{(1 + |y_i - y_j|^2)^{-1}}{\\sum_{k\\neq l} (1 + |y_k - y_l|^2)^{-1}}     $$</li> <li>\u6700\u5c0f\u5316 KL \u6563\u5ea6\uff1a     $$     KL(P|Q) = \\sum_i \\sum_j p_{ij} \\log \\frac{p_{ij}}{q_{ij}}     $$</li> <li>\u4f18\u70b9\uff1a\u4fdd\u6301\u5c40\u90e8\u7ed3\u6784\uff0c\u89c6\u89c9\u6548\u679c\u597d</li> <li>\u7f3a\u70b9\uff1a\u4e0d\u53ef\u89e3\u91ca\u3001\u9002\u5408\u5c0f\u6570\u636e\u96c6</li> </ul>"},{"location":"machine/interview/#3-autoencoder","title":"3\ufe0f\u20e3 AutoEncoder\uff08\u81ea\u7f16\u7801\u5668\uff09","text":"<ul> <li> <p>\u795e\u7ecf\u7f51\u7edc\u5b9e\u73b0\u7279\u5f81\u63d0\u53d6\uff1a</p> </li> <li> <p>\u7f16\u7801\u5668 \\(f_\\theta: X \\rightarrow Z\\)</p> </li> <li>\u89e3\u7801\u5668 \\(g_\\phi: Z \\rightarrow \\hat{X}\\)</li> <li>\u6700\u5c0f\u5316\u91cd\u5efa\u8bef\u5dee\uff1a     $$     \\min_{\\theta,\\phi} \\sum_i |x_i - g_\\phi(f_\\theta(x_i))|^2     $$</li> <li>\u4f18\u70b9\uff1a\u53ef\u5b66\u4e60\u975e\u7ebf\u6027\u4f4e\u7ef4\u8868\u793a</li> <li>\u7f3a\u70b9\uff1a\u8bad\u7ec3\u590d\u6742\uff0c\u9700\u8c03\u53c2</li> </ul>"},{"location":"machine/interview/#vs","title":"\u4e94\u3001\u7279\u5f81\u63d0\u53d6 vs \u7279\u5f81\u9009\u62e9","text":"\u7279\u70b9 \u7279\u5f81\u9009\u62e9 \u7279\u5f81\u63d0\u53d6 \u65b9\u6cd5 \u9009\u62e9\u539f\u59cb\u7279\u5f81\u5b50\u96c6 \u751f\u6210\u65b0\u7279\u5f81 \u662f\u5426\u964d\u7ef4 \u4e0d\u4e00\u5b9a \u4e00\u822c\u964d\u7ef4 \u662f\u5426\u6539\u53d8\u539f\u59cb\u6570\u636e \u5426 \u662f\uff08\u7ebf\u6027\u6216\u975e\u7ebf\u6027\u53d8\u6362\uff09 \u4f18\u70b9 \u7b80\u5355\u53ef\u89e3\u91ca \u63d0\u53d6\u6f5c\u5728\u7ed3\u6784\u3001\u51cf\u5c11\u5197\u4f59 \u7f3a\u70b9 \u5ffd\u7565\u7ec4\u5408\u5173\u7cfb \u7279\u5f81\u96be\u89e3\u91ca"},{"location":"machine/interview/#python_1","title":"\u516d\u3001\u7279\u5f81\u63d0\u53d6\u5b9e\u6218\u793a\u4f8b\uff08Python\uff09","text":""},{"location":"machine/interview/#1-pca","title":"1\ufe0f\u20e3 PCA","text":"<pre><code>from sklearn.decomposition import PCA\nimport numpy as np\n\nX = np.random.rand(100, 10)\npca = PCA(n_components=3)\nZ = pca.fit_transform(X)\nprint(\"\u65b0\u7279\u5f81\u7ef4\u5ea6:\", Z.shape)  # (100,3)\n</code></pre>"},{"location":"machine/interview/#2-lda","title":"2\ufe0f\u20e3 LDA\uff08\u76d1\u7763\u964d\u7ef4\uff09","text":"<pre><code>from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n\ny = np.random.randint(0,3,100)  # \u4e09\u7c7b\nlda = LDA(n_components=2)\nZ = lda.fit_transform(X, y)\nprint(\"\u65b0\u7279\u5f81\u7ef4\u5ea6:\", Z.shape)  # (100,2)\n</code></pre>"},{"location":"machine/interview/#3-autoencoderpytorch","title":"3\ufe0f\u20e3 AutoEncoder\uff08PyTorch\u793a\u4f8b\uff09","text":"<pre><code>import torch\nimport torch.nn as nn\n\nX_tensor = torch.rand(100,10)\n\nclass AutoEncoder(nn.Module):\n    def __init__(self, input_dim=10, hidden_dim=3):\n        super().__init__()\n        self.encoder = nn.Linear(input_dim, hidden_dim)\n        self.decoder = nn.Linear(hidden_dim, input_dim)\n    def forward(self, x):\n        z = torch.relu(self.encoder(x))\n        out = self.decoder(z)\n        return out, z\n\nmodel = AutoEncoder()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\ncriterion = nn.MSELoss()\n\nfor epoch in range(100):\n    optimizer.zero_grad()\n    out, z = model(X_tensor)\n    loss = criterion(out, X_tensor)\n    loss.backward()\n    optimizer.step()\n\n# \u63d0\u53d6\u4f4e\u7ef4\u7279\u5f81\n_, Z_new = model(X_tensor)\nprint(\"\u4f4e\u7ef4\u7279\u5f81:\", Z_new.shape)  # (100,3)\n</code></pre>"},{"location":"machine/interview/#_115","title":"\u4e03\u3001\u7279\u5f81\u63d0\u53d6\u6ce8\u610f\u4e8b\u9879","text":"<ol> <li> <p>\u6807\u51c6\u5316/\u5f52\u4e00\u5316\uff1a</p> <ul> <li>PCA\u3001LDA \u5bf9\u5c3a\u5ea6\u654f\u611f\uff0c\u9700\u5148\u6807\u51c6\u5316 \\(X\\)\u3002</li> </ul> </li> <li> <p>\u9009\u62e9\u7ef4\u5ea6 \\(k\\)\uff1a</p> <ul> <li>PCA \u53ef\u6839\u636e\u7d2f\u8ba1\u65b9\u5dee\u8d21\u732e\u7387\u9009\u62e9 \\(k\\)\u3002</li> </ul> </li> <li> <p>\u76d1\u7763 vs \u65e0\u76d1\u7763\uff1a</p> <ul> <li>LDA \u9700\u6807\u7b7e\uff0cPCA \u4e0d\u9700\u6807\u7b7e\u3002</li> </ul> </li> <li> <p>\u53ef\u89e3\u91ca\u6027\uff1a</p> <ul> <li>PCA/AutoEncoder \u7279\u5f81\u96be\u89e3\u91ca\uff0c\u9700\u8981\u7ed3\u5408\u539f\u59cb\u7279\u5f81\u7406\u89e3\u3002</li> </ul> </li> <li> <p>\u975e\u7ebf\u6027\u7279\u5f81\u63d0\u53d6\uff1a</p> <ul> <li>t-SNE \u9002\u5408\u53ef\u89c6</li> </ul> </li> </ol>"},{"location":"machine/interview/#_116","title":"\u516b\u3001\u51b3\u7b56\u6811","text":""},{"location":"machine/interview/#81","title":"8.1 \u6559\u7a0b","text":"<p>\u5728\u51b3\u7b56\u6811\u4e2d\uff0c\u6211\u4eec\u5e0c\u671b\u9009\u62e9 \u6700\u4f18\u7279\u5f81 \u6765\u8fdb\u884c\u5212\u5206\uff0c\u8ba9\u6bcf\u6b21\u5212\u5206\u540e\u7684\u5b50\u96c6\u201c\u8d8a\u7eaf\u8d8a\u597d\u201d\u3002</p> <ul> <li>\u7eaf\u7684\u610f\u601d\uff1a\u5b50\u96c6\u4e2d\u7684\u6837\u672c\u5c3d\u53ef\u80fd\u5c5e\u4e8e\u540c\u4e00\u7c7b\u522b\u3002</li> </ul> <p>\u4e0d\u540c\u7b97\u6cd5\u8861\u91cf\u201c\u7eaf\u5ea6\u201d\u7684\u65b9\u6cd5\u4e0d\u540c\uff1a</p> <ul> <li>ID3 \u2192 \u4fe1\u606f\u589e\u76ca</li> <li>C4.5 \u2192 \u4fe1\u606f\u589e\u76ca\u7387</li> <li> <p>CART \u2192 \u57fa\u5c3c\u6307\u6570</p> </li> <li> <p>\u5b9a\u4e49\uff1a\u51b3\u7b56\u6811\u662f\u4e00\u79cd \u6811\u5f62\u7ed3\u6784\u6a21\u578b\uff0c\u7528\u4e8e\u5206\u7c7b\u6216\u56de\u5f52\u4efb\u52a1\u3002</p> <ul> <li>\u8282\u70b9\uff08Node\uff09\uff1a\u8868\u793a\u7279\u5f81\u6216\u5c5e\u6027\u7684\u6761\u4ef6</li> <li>\u8fb9\uff08Edge\uff09\uff1a\u8868\u793a\u6761\u4ef6\u5224\u65ad\u7684\u7ed3\u679c</li> <li>\u53f6\u5b50\u8282\u70b9\uff08Leaf\uff09\uff1a\u8868\u793a\u6700\u7ec8\u9884\u6d4b\u7ed3\u679c</li> </ul> </li> <li> <p>\u5206\u7c7b vs \u56de\u5f52\uff1a</p> <ul> <li>\u5206\u7c7b\u6811\uff08CART\u5206\u7c7b\uff09\uff1a\u9884\u6d4b\u79bb\u6563\u6807\u7b7e</li> <li>\u56de\u5f52\u6811\uff08CART\u56de\u5f52\uff09\uff1a\u9884\u6d4b\u8fde\u7eed\u503c</li> </ul> </li> </ul> <p>\u51b3\u7b56\u6811\u7279\u70b9\uff1a</p> <ul> <li>\u975e\u7ebf\u6027\u3001\u975e\u53c2\u6570\u6a21\u578b</li> <li>\u53ef\u5904\u7406\u591a\u7c7b\u522b\u3001\u591a\u7279\u5f81</li> <li>\u6613\u89e3\u91ca\uff0c\u53ef\u53ef\u89c6\u5316</li> </ul>"},{"location":"machine/interview/#1_15","title":"1\ufe0f\u20e3 \u5206\u7c7b\u95ee\u9898","text":"<p>\u5728\u51b3\u7b56\u6811\u4e2d\uff0c\u6211\u4eec\u5e0c\u671b\u9009\u62e9 \u6700\u4f18\u7279\u5f81 \u6765\u8fdb\u884c\u5212\u5206\uff0c\u8ba9\u6bcf\u6b21\u5212\u5206\u540e\u7684\u5b50\u96c6\u201c\u8d8a\u7eaf\u8d8a\u597d\u201d\u3002</p> <ul> <li>\u7eaf\u7684\u610f\u601d\uff1a\u5b50\u96c6\u4e2d\u7684\u6837\u672c\u5c3d\u53ef\u80fd\u5c5e\u4e8e\u540c\u4e00\u7c7b\u522b\u3002</li> </ul> <p>\u4e0d\u540c\u7b97\u6cd5\u8861\u91cf\u201c\u7eaf\u5ea6\u201d\u7684\u65b9\u6cd5\u4e0d\u540c\uff1a</p> <ul> <li>ID3 \u2192 \u4fe1\u606f\u589e\u76ca</li> <li>C4.5 \u2192 \u4fe1\u606f\u589e\u76ca\u7387</li> <li>CART \u2192 \u57fa\u5c3c\u6307\u6570</li> </ul>"},{"location":"machine/interview/#id3-information-gain","title":"\u4e8c\u3001ID3 \u4e0e\u4fe1\u606f\u589e\u76ca\uff08Information Gain\uff09","text":""},{"location":"machine/interview/#1_16","title":"1. \u6982\u5ff5","text":"<p>\u4fe1\u606f\u589e\u76ca\u6765\u6e90\u4e8e\u4fe1\u606f\u8bba\u3002\u5b83\u8861\u91cf\u7684\u662f \u4f7f\u7528\u67d0\u7279\u5f81\u5212\u5206\u6570\u636e\u524d\u540e\uff0c\u4fe1\u606f\u7684\u4e0d\u786e\u5b9a\u6027\u51cf\u5c11\u4e86\u591a\u5c11\u3002</p> <ul> <li>\u71b5\uff08Entropy\uff09\uff1a\u8868\u793a\u6570\u636e\u96c6\u7684\u4e0d\u786e\u5b9a\u6027</li> </ul> \\[   H(D) = - \\sum_{i=1}^k p_i \\log_2 p_i \\] <ul> <li>\\(D\\)\uff1a\u6570\u636e\u96c6</li> <li>\\(k\\)\uff1a\u7c7b\u522b\u6570</li> <li> <p>\\(p_i\\)\uff1a\u7c7b\u522b \\(i\\) \u7684\u6982\u7387</p> </li> <li> <p>\u6761\u4ef6\u71b5\uff08Conditional Entropy\uff09\uff1a\u5728\u5df2\u77e5\u67d0\u4e2a\u7279\u5f81 \\(A\\) \u7684\u60c5\u51b5\u4e0b\uff0c\u7c7b\u522b\u7684\u4e0d\u786e\u5b9a\u6027</p> </li> </ul> \\[   H(D|A) = \\sum_{v \\in \\text{values}(A)} \\frac{|D_v|}{|D|} H(D_v) \\] <ul> <li> <p>\\(D_v\\)\uff1a\u5728\u7279\u5f81 \\(A\\) \u53d6\u503c \\(v\\) \u7684\u5b50\u96c6</p> </li> <li> <p>\u4fe1\u606f\u589e\u76ca\uff08Information Gain\uff09\uff1a\u5212\u5206\u524d\u540e\u7684\u71b5\u51cf\u5c11\u91cf</p> </li> </ul> \\[   Gain(D,A) = H(D) - H(D|A) \\]"},{"location":"machine/interview/#2_13","title":"2. \u76f4\u89c2\u89e3\u91ca","text":"<ul> <li>\u71b5\u8d8a\u5927 \u2192 \u6570\u636e\u8d8a\u6df7\u4e71</li> <li>\u5212\u5206\u540e\u71b5\u8d8a\u5c0f \u2192 \u6570\u636e\u8d8a\u7eaf \u2192 \u4fe1\u606f\u589e\u76ca\u8d8a\u5927</li> <li>ID3\u9009\u62e9 \u4fe1\u606f\u589e\u76ca\u6700\u5927\u7684\u7279\u5f81 \u4f5c\u4e3a\u5212\u5206\u8282\u70b9</li> </ul>"},{"location":"machine/interview/#3_7","title":"3. \u793a\u4f8b","text":"<p>\u5047\u8bbe\u6570\u636e\u96c6 \\(D\\) \u6709 10 \u4e2a\u6837\u672c\uff0c\u5206\u4e3a\u4e24\u7c7b\uff1a<code>Yes</code> 6 \u4e2a\uff0c<code>No</code> 4 \u4e2a\u3002</p> <ul> <li>\u603b\u71b5\uff1a $$   H(D) = - \\frac{6}{10}\\log_2 \\frac{6}{10} - \\frac{4}{10}\\log_2 \\frac{4}{10} \\approx 0.971 $$</li> </ul> <p>\u5047\u8bbe\u4e00\u4e2a\u7279\u5f81 \\(A\\) \u6709\u4e24\u4e2a\u53d6\u503c <code>a1</code> \u548c <code>a2</code>\uff0c\u5bf9\u5e94\u5b50\u96c6\u71b5\u5206\u522b\u4e3a 0.0 \u548c 1.0\uff0c\u5b50\u96c6\u6bd4\u4f8b\u4e3a 0.4 \u548c 0.6\uff1a</p> \\[ H(D|A) = 0.4 \\cdot 0 + 0.6 \\cdot 1 = 0.6 \\] <p>\u4fe1\u606f\u589e\u76ca\uff1a $$ Gain(D,A) = 0.971 - 0.6 = 0.371 $$</p>"},{"location":"machine/interview/#c45-information-gain-ratio","title":"\u4e09\u3001C4.5 \u4e0e\u4fe1\u606f\u589e\u76ca\u7387\uff08Information Gain Ratio\uff09","text":""},{"location":"machine/interview/#1_17","title":"1. \u95ee\u9898","text":"<p>ID3 \u7684\u4fe1\u606f\u589e\u76ca\u6709\u504f\u5411\u6027\uff1a</p> <ul> <li>\u503e\u5411\u9009\u62e9\u53d6\u503c \u8f83\u591a\u7684\u7279\u5f81\uff08\u5982\u8eab\u4efd\u8bc1\u53f7\u3001\u65e5\u671f\u7b49\uff09\uff0c\u5373\u4f7f\u8fd9\u4e9b\u7279\u5f81\u5bf9\u5206\u7c7b\u6ca1\u592a\u5927\u7528\u5904\u3002</li> </ul>"},{"location":"machine/interview/#2_14","title":"2. \u89e3\u51b3\u65b9\u6848","text":"<p>C4.5 \u4f7f\u7528 \u4fe1\u606f\u589e\u76ca\u7387 \u6765\u4fee\u6b63\uff1a $$ GainRatio(D,A) = \\frac{Gain(D,A)}{SplitInfo(D,A)} $$</p> <ul> <li> <p>\u5206\u88c2\u4fe1\u606f\uff08SplitInfo\uff09\uff1a $$   SplitInfo(D,A) = - \\sum_{v \\in values(A)} \\frac{|D_v|}{|D|} \\log_2 \\frac{|D_v|}{|D|} $$</p> </li> <li> <p>\u6838\u5fc3\u601d\u60f3\uff1a\u7528\u4fe1\u606f\u589e\u76ca\u9664\u4ee5\u7279\u5f81\u81ea\u8eab\u7684\u5212\u5206\u201c\u6742\u4e71\u5ea6\u201d\uff0c\u964d\u4f4e\u53d6\u503c\u591a\u7684\u7279\u5f81\u504f\u597d\u3002</p> </li> </ul>"},{"location":"machine/interview/#3_8","title":"3. \u76f4\u89c2\u7406\u89e3","text":"<ul> <li>\u7279\u5f81\u503c\u8d8a\u591a\uff0cSplitInfo \u8d8a\u5927 \u2192 GainRatio \u8d8a\u5c0f \u2192 \u51cf\u5c11\u504f\u5411</li> <li>C4.5 \u9009\u62e9 \u4fe1\u606f\u589e\u76ca\u7387\u6700\u5927\u7684\u7279\u5f81 \u8fdb\u884c\u5212\u5206</li> </ul>"},{"location":"machine/interview/#cart-gini-index","title":"\u56db\u3001CART \u4e0e\u57fa\u5c3c\u6307\u6570\uff08Gini Index\uff09","text":"<p>CART (Classification and Regression Tree) \u7528 \u57fa\u5c3c\u6307\u6570 \u6765\u8861\u91cf\u7eaf\u5ea6\u3002</p>"},{"location":"machine/interview/#1_18","title":"1. \u6982\u5ff5","text":"<p>\u57fa\u5c3c\u6307\u6570\u8868\u793a \u4ece\u6570\u636e\u96c6\u4e2d\u968f\u673a\u62bd\u53d6\u4e24\u4e2a\u6837\u672c\uff0c\u5b83\u4eec\u5c5e\u4e8e\u4e0d\u540c\u7c7b\u522b\u7684\u6982\u7387\uff1a</p> \\[ Gini(D) = 1 - \\sum_{i=1}^{k} p_i^2 \\] <ul> <li>\\(p_i\\)\uff1a\u7c7b\u522b \\(i\\) \u7684\u6982\u7387</li> <li>\u503c\u8d8a\u5c0f \u2192 \u6570\u636e\u8d8a\u7eaf</li> </ul>"},{"location":"machine/interview/#2_15","title":"2. \u5212\u5206\u540e\u7684\u57fa\u5c3c\u6307\u6570","text":"<p>\u5047\u8bbe\u7528\u7279\u5f81 \\(A\\) \u5212\u5206\u6570\u636e\u96c6\uff1a $$ Gini_{split}(D,A) = \\sum_{v \\in values(A)} \\frac{|D_v|}{|D|} Gini(D_v) $$</p> <ul> <li>\u9009\u62e9 \u57fa\u5c3c\u6307\u6570\u6700\u5c0f\u7684\u7279\u5f81\u8fdb\u884c\u5212\u5206</li> <li>CART \u751f\u6210 \u4e8c\u53c9\u6811\uff08\u6bcf\u6b21\u5206\u6210\u4e24\u4e2a\u5b50\u96c6\uff09</li> </ul>"},{"location":"machine/interview/#3_9","title":"3. \u76f4\u89c2\u7406\u89e3","text":"<ul> <li>\u4e0e\u4fe1\u606f\u589e\u76ca\u4e0d\u540c\uff1a\u57fa\u5c3c\u6307\u6570\u5173\u6ce8 \u6837\u672c\u201c\u6df7\u5408\u5ea6\u201d</li> <li>\u8d8a\u7eaf \u2192 \u57fa\u5c3c\u6307\u6570\u8d8a\u4f4e \u2192 \u66f4\u4f18\u5212\u5206</li> </ul>"},{"location":"machine/interview/#4_8","title":"4. \u793a\u4f8b","text":"<p>\u5047\u8bbe\u4e00\u4e2a\u5b50\u96c6\u6709 10 \u4e2a\u6837\u672c\uff0c\u5176\u4e2d 6 \u4e2a <code>Yes</code>\uff0c4 \u4e2a <code>No</code>\uff1a $$ Gini(D) = 1 - (0.6^2 + 0.4^2) = 1 - (0.36 + 0.16) = 0.48 $$</p>"},{"location":"machine/interview/#_117","title":"\u4e94\u3001\u603b\u7ed3\u5bf9\u6bd4\u8868","text":"\u7b97\u6cd5 \u7279\u5f81\u9009\u62e9\u6307\u6807 \u503e\u5411 \u5212\u5206\u7c7b\u578b \u4f18\u70b9 \u7f3a\u70b9 ID3 \u4fe1\u606f\u589e\u76ca Gain \u504f\u5411\u53d6\u503c\u591a\u7684\u7279\u5f81 \u591a\u53c9 \u7b80\u5355\uff0c\u6982\u5ff5\u76f4\u89c2 \u5bf9\u591a\u503c\u7279\u5f81\u6709\u504f\u5411\u6027 C4.5 \u4fe1\u606f\u589e\u76ca\u7387 GainRatio \u4fee\u6b63 ID3 \u504f\u5411 \u591a\u53c9 \u5904\u7406\u591a\u503c\u7279\u5f81\u66f4\u5408\u7406 \u9700\u8981\u8ba1\u7b97\u5206\u88c2\u4fe1\u606f\uff0c\u7565\u590d\u6742 CART \u57fa\u5c3c\u6307\u6570 Gini \u504f\u5411\u7eaf\u5ea6\u5927\u5b50\u96c6 \u4e8c\u53c9 \u8ba1\u7b97\u7b80\u5355\uff0c\u751f\u6210\u4e8c\u53c9\u6811 \u5bf9\u7c7b\u522b\u6bd4\u4f8b\u654f\u611f"},{"location":"machine/interview/#2_16","title":"2\ufe0f\u20e3 \u56de\u5f52\u95ee\u9898","text":"<ul> <li>\u5e38\u7528\u635f\u5931\u51fd\u6570\uff1a\u5747\u65b9\u8bef\u5dee\uff08MSE\uff09   $$   MSE(D) = \\frac{1}{|D|} \\sum_{i \\in D} (y_i - \\bar{y}_D)^2   $$</li> <li>\u5212\u5206\u540e\uff1a   $$   \\Delta MSE = MSE(D) - \\left( \\frac{|D_1|}{|D|} MSE(D_1) + \\frac{|D_2|}{|D|} MSE(D_2) \\right)   $$</li> <li>\u9009\u62e9\u4f7f \\(\\Delta MSE\\) \u6700\u5927\u7684\u7279\u5f81\u548c\u5207\u5206\u70b9</li> </ul>"},{"location":"machine/interview/#2_17","title":"2\ufe0f\u20e3 \u635f\u5931\u51fd\u6570","text":""},{"location":"machine/interview/#3-cart","title":"3\ufe0f\u20e3 \u51b3\u7b56\u6811\u6570\u5b66\u63a8\u5bfc\u8fc7\u7a0b\uff08\u4ee5CART\u5206\u7c7b\u6811\u4e3a\u4f8b\uff09","text":"<ol> <li> <p>\u6839\u8282\u70b9\u9009\u62e9\uff1a</p> <ul> <li>\u5bf9\u6bcf\u4e2a\u7279\u5f81 \\(A_j\\)\uff0c\u5c1d\u8bd5\u6bcf\u4e2a\u53ef\u80fd\u5212\u5206\u70b9 \\(s\\)</li> <li>\u8ba1\u7b97\u5212\u5206\u540e\u7684\u57fa\u5c3c\u6307\u6570\uff1a   $$   Gini(D, A_j, s) = \\frac{|D_{\\le s}|}{|D|} Gini(D_{\\le s}) + \\frac{|D_{&gt; s}|}{|D|} Gini(D_{&gt; s})   $$</li> </ul> </li> <li> <p>\u9009\u62e9\u6700\u5c0f \\(Gini(D,A_j,s)\\)</p> </li> <li> <p>\u9012\u5f52\u5212\u5206\uff1a</p> <ul> <li>\u5bf9\u5de6\u53f3\u5b50\u6811\u91cd\u590d\u4ee5\u4e0a\u8fc7\u7a0b</li> <li> <p>\u76f4\u5230\u6ee1\u8db3\u505c\u6b62\u6761\u4ef6\uff1a</p> <ul> <li>\u8282\u70b9\u6837\u672c\u6570 &lt; min_samples_split</li> <li>\u6811\u6df1\u5ea6\u8fbe\u5230 max_depth</li> <li>\u8282\u70b9\u7eaf\u5ea6\u8fbe\u5230\u9608\u503c</li> </ul> </li> </ul> </li> </ol>"},{"location":"machine/interview/#4_9","title":"4\ufe0f\u20e3 \u8bc4\u4f30\u6307\u6807","text":"<ul> <li> <p>\u5206\u7c7b\u6811\uff1a</p> <ul> <li>\u51c6\u786e\u7387\uff08Accuracy\uff09</li> <li>\u7cbe\u786e\u7387 / \u53ec\u56de\u7387 / F1</li> <li>ROC / AUC</li> </ul> </li> <li> <p>\u56de\u5f52\u6811\uff1a</p> <ul> <li>\u5747\u65b9\u8bef\u5dee\uff08MSE\uff09</li> <li>\u5747\u65b9\u6839\u8bef\u5dee\uff08RMSE\uff09</li> <li>\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\uff08MAE\uff09</li> <li>\u5224\u5b9a\u7cfb\u6570 \\(R^2\\)</li> </ul> </li> </ul>"},{"location":"machine/interview/#5_4","title":"5\ufe0f\u20e3 \u5b9e\u73b0\u4ee3\u7801","text":""},{"location":"machine/interview/#1_19","title":"1\ufe0f\u20e3 \u5206\u7c7b\u6811","text":"<pre><code>from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score\n\nX_train, X_test, y_train, y_test = ...\nclf = DecisionTreeClassifier(criterion='gini', max_depth=5, min_samples_split=10)\nclf.fit(X_train, y_train)\n\ny_pred = clf.predict(X_test)\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\n</code></pre>"},{"location":"machine/interview/#2_18","title":"2\ufe0f\u20e3 \u56de\u5f52\u6811","text":"<pre><code>from sklearn.tree import DecisionTreeRegressor\nfrom sklearn.metrics import mean_squared_error\n\nreg = DecisionTreeRegressor(criterion='squared_error', max_depth=5)\nreg.fit(X_train, y_train)\n\ny_pred = reg.predict(X_test)\nmse = mean_squared_error(y_test, y_pred)\nprint(\"MSE:\", mse)\n</code></pre>"},{"location":"machine/interview/#3_10","title":"3\ufe0f\u20e3 \u53ef\u89c6\u5316","text":"<pre><code>from sklearn.tree import export_text, plot_tree\nimport matplotlib.pyplot as plt\n\n# \u6587\u672c\u5c55\u793a\nprint(export_text(clf, feature_names=feature_names))\n\n# \u56fe\u5f62\u5c55\u793a\nplt.figure(figsize=(12,8))\nplot_tree(clf, feature_names=feature_names, class_names=class_names, filled=True)\nplt.show()\n</code></pre>"},{"location":"machine/interview/#6_4","title":"6\ufe0f\u20e3 \u6a21\u578b\u4f18\u5316","text":"<ol> <li> <p>\u526a\u679d\uff08Pruning\uff09\uff1a</p> <ul> <li>\u9632\u6b62\u8fc7\u62df\u5408</li> <li>\u9884\u526a\u679d\uff1a\u8bbe\u7f6e max_depth, min_samples_split, min_samples_leaf</li> <li>\u540e\u526a\u679d\uff1a\u8bad\u7ec3\u5b8c\u6210\u540e\u5220\u9664\u8d21\u732e\u4e0d\u5927\u7684\u8282\u70b9</li> </ul> </li> <li> <p>\u96c6\u6210\u65b9\u6cd5\uff1a</p> <ul> <li>Bagging \u2192 \u968f\u673a\u68ee\u6797\uff08Random Forest\uff09</li> <li>Boosting \u2192 GBDT / XGBoost</li> </ul> </li> <li> <p>\u7279\u5f81\u5904\u7406\uff1a</p> <ul> <li>\u7c7b\u522b\u7279\u5f81\u7f16\u7801\uff1aOne-hot \u6216 Ordinal</li> <li>\u8fde\u7eed\u7279\u5f81\u65e0\u9700\u6807\u51c6\u5316</li> </ul> </li> <li> <p>\u53c2\u6570\u8c03\u4f18\uff1a</p> <ul> <li>max_depth, min_samples_split, min_samples_leaf, max_features, ccp_alpha</li> </ul> </li> </ol>"},{"location":"machine/interview/#7_3","title":"7\ufe0f\u20e3 \u6ce8\u610f\u4e8b\u9879","text":"<ul> <li>\u5bb9\u6613\u8fc7\u62df\u5408 \u2192 \u63a7\u5236\u6811\u6df1\u3001\u526a\u679d\u6216\u96c6\u6210</li> <li>\u5bf9\u566a\u58f0\u654f\u611f</li> <li>\u6837\u672c\u5206\u5e03\u4e0d\u5e73\u8861 \u2192 \u5f71\u54cd\u5212\u5206\u8d28\u91cf\uff0c\u53ef\u7528 class_weight</li> <li>\u5bf9\u8fde\u7eed\u7279\u5f81\u3001\u7c7b\u522b\u7279\u5f81\u5904\u7406\u4e0d\u540c</li> </ul>"},{"location":"machine/interview/#8_3","title":"8\ufe0f\u20e3 \u4f18\u7f3a\u70b9","text":"\u4f18\u70b9 \u7f3a\u70b9 1. \u6613\u7406\u89e3\u3001\u53ef\u89e3\u91ca\uff0c\u53ef\u53ef\u89c6\u5316 1. \u5bb9\u6613\u8fc7\u62df\u5408 2. \u65e0\u9700\u7279\u5f81\u5f52\u4e00\u5316 2. \u5bf9\u566a\u58f0\u654f\u611f 3. \u53ef\u5904\u7406\u6570\u503c\u548c\u7c7b\u522b\u7279\u5f81 3. \u5355\u68f5\u6811\u4e0d\u7a33\u5b9a 4. \u53ef\u4ee5\u5904\u7406\u591a\u7c7b\u522b\u95ee\u9898 4. \u9884\u6d4b\u7cbe\u5ea6\u6709\u9650\uff08\u9700\u96c6\u6210\u63d0\u5347\uff09"},{"location":"machine/interview/#knn","title":"\u4e5d\u3001KNN","text":""},{"location":"machine/interview/#91-knn","title":"9.1 KNN\u6559\u7a0b","text":""},{"location":"machine/interview/#1_20","title":"1\ufe0f\u20e3 \u539f\u7406","text":"<p>KNN \u662f\u4e00\u79cd\u57fa\u4e8e\u5b9e\u4f8b\u7684\u76d1\u7763\u5b66\u4e60\u7b97\u6cd5\uff0c\u65e2\u53ef\u4ee5\u505a\u5206\u7c7b\uff08Classification\uff09\uff0c\u4e5f\u53ef\u4ee5\u505a\u56de\u5f52\uff08Regression\uff09\u3002 \u6838\u5fc3\u601d\u60f3\uff1a</p> <ul> <li>\u5bf9\u4e8e\u4e00\u4e2a\u65b0\u7684\u6570\u636e\u70b9 \\(x\\)\uff0c\u627e\u5230\u8bad\u7ec3\u96c6\u4e2d\u4e0e\u5b83\u6700\u8fd1\u7684 \\(K\\) \u4e2a\u70b9\u3002</li> <li> <p>\u6839\u636e\u8fd9\u4e9b\u70b9\u7684\u6807\u7b7e\u6765\u9884\u6d4b\u65b0\u6837\u672c\u7684\u6807\u7b7e\uff1a</p> </li> <li> <p>\u5206\u7c7b\uff1a\u591a\u6570\u6295\u7968\uff08majority voting\uff09\u3002</p> </li> <li>\u56de\u5f52\uff1a\u5e73\u5747\u6216\u52a0\u6743\u5e73\u5747\u3002</li> </ul>"},{"location":"machine/interview/#11_1","title":"1.1 \u8ddd\u79bb\u5ea6\u91cf","text":"<p>\u5e38\u7528\u7684\u8ddd\u79bb\u5ea6\u91cf\u65b9\u6cd5\uff1a</p> <ol> <li> <p>\u6b27\u6c0f\u8ddd\u79bb\uff08Euclidean distance\uff09\uff1a    $$    d(x_i, x_j) = \\sqrt{\\sum_{m=1}^{M} (x_{i,m} - x_{j,m})^2}    $$</p> </li> <li> <p>\u66fc\u54c8\u987f\u8ddd\u79bb\uff08Manhattan distance\uff09\uff1a    $$    d(x_i, x_j) = \\sum_{m=1}^{M} |x_{i,m} - x_{j,m}|    $$</p> </li> <li> <p>\u95f5\u53ef\u592b\u65af\u57fa\u8ddd\u79bb\uff08Minkowski distance\uff09\uff1a    $$    d(x_i, x_j) = \\left(\\sum_{m=1}^{M} |x_{i,m} - x_{j,m}|^p \\right)^{1/p}    $$</p> </li> <li> <p>\u5f53 \\(p=2\\) \u2192 \u6b27\u6c0f\u8ddd\u79bb</p> </li> <li> <p>\u5f53 \\(p=1\\) \u2192 \u66fc\u54c8\u987f\u8ddd\u79bb</p> </li> <li> <p>\u52a0\u6743\u8ddd\u79bb\uff08\u5e38\u7528\u4e8e KNN \u56de\u5f52\u6216\u52a0\u6743\u5206\u7c7b\uff09\uff1a    $$    w_i = \\frac{1}{d(x, x_i) + \\epsilon}, \\quad \\hat{y} = \\frac{\\sum_{i=1}^K w_i y_i}{\\sum_{i=1}^K w_i}    $$</p> </li> </ol>"},{"location":"machine/interview/#2_19","title":"2\ufe0f\u20e3 \u635f\u5931\u51fd\u6570","text":"<p>KNN \u672c\u8d28\u662f\u975e\u53c2\u6570\u3001\u61d2\u60f0\u5b66\u4e60\uff08lazy learning\uff09\uff0c\u6ca1\u6709\u663e\u5f0f\u7684\u53c2\u6570\u62df\u5408\uff0c\u6240\u4ee5 \u6ca1\u6709\u8bad\u7ec3\u635f\u5931\u51fd\u6570\uff0c\u4f46\u662f\u53ef\u4ee5\u7528\u4ee5\u4e0b\u65b9\u5f0f\u63cf\u8ff0\u9884\u6d4b\u8bef\u5dee\uff1a</p>"},{"location":"machine/interview/#21_2","title":"2.1 \u5206\u7c7b\u635f\u5931","text":"<p>\u5bf9\u4e8e\u4e00\u4e2a\u6d4b\u8bd5\u6837\u672c \\(x\\)\uff0c\u9884\u6d4b\u7c7b\u522b \\(\\hat{y}\\) \u4e0e\u771f\u5b9e\u7c7b\u522b \\(y\\) \u7684\u635f\u5931\u901a\u5e38\u75280-1 \u635f\u5931\uff1a $$ L(y, \\hat{y}) = \\begin{cases} 0, &amp; y = \\hat{y} \\ 1, &amp; y \\neq \\hat{y} \\end{cases} $$</p>"},{"location":"machine/interview/#22_2","title":"2.2 \u56de\u5f52\u635f\u5931","text":"<p>\u5e38\u7528 \u5e73\u65b9\u8bef\u5dee \u6216 \u7edd\u5bf9\u8bef\u5dee\uff1a</p> <ul> <li>\u5747\u65b9\u8bef\u5dee\uff08MSE\uff09\uff1a   $$   L(y, \\hat{y}) = (y - \\hat{y})^2   $$</li> <li>\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\uff08MAE\uff09\uff1a   $$   L(y, \\hat{y}) = |y - \\hat{y}|   $$</li> </ul>"},{"location":"machine/interview/#3_11","title":"3\ufe0f\u20e3 \u6570\u5b66\u63a8\u5bfc\u8fc7\u7a0b","text":""},{"location":"machine/interview/#31_1","title":"3.1 \u5206\u7c7b","text":"<p>\u5047\u8bbe\u627e\u5230 \\(K\\) \u4e2a\u6700\u8fd1\u90bb\u6837\u672c\u96c6\u5408 \\(N_K(x)\\)\uff0c\u6bcf\u4e2a\u90bb\u5c45 \\(x_i\\) \u7684\u7c7b\u522b\u4e3a \\(y_i\\)\uff1a</p> \\[ \\hat{y} = \\arg\\max_{c \\in C} \\sum_{x_i \\in N_K(x)} \\mathbf{1}(y_i = c) \\] <ul> <li>\\(\\mathbf{1}(\\cdot)\\) \u4e3a\u6307\u793a\u51fd\u6570</li> <li>\\(C\\) \u662f\u7c7b\u522b\u96c6\u5408</li> </ul> <p>\u52a0\u6743\u6295\u7968\uff1a $$ \\hat{y} = \\arg\\max_{c \\in C} \\sum_{x_i \\in N_K(x)} w_i \\mathbf{1}(y_i = c) $$ \u5176\u4e2d \\(w_i = \\frac{1}{d(x, x_i) + \\epsilon}\\)</p>"},{"location":"machine/interview/#32_3","title":"3.2 \u56de\u5f52","text":"<p>\u627e\u5230 \\(K\\) \u4e2a\u90bb\u5c45 \\(N_K(x)\\)\uff0c\u53d6\u5747\u503c\u6216\u52a0\u6743\u5747\u503c\uff1a $$ \\hat{y} = \\frac{1}{K} \\sum_{x_i \\in N_K(x)} y_i $$ \u52a0\u6743\uff1a $$ \\hat{y} = \\frac{\\sum_{x_i \\in N_K(x)} w_i y_i}{\\sum_{x_i \\in N_K(x)} w_i} $$</p>"},{"location":"machine/interview/#4_10","title":"4\ufe0f\u20e3 \u8bc4\u4f30\u6307\u6807","text":""},{"location":"machine/interview/#41_1","title":"4.1 \u5206\u7c7b","text":"<ul> <li>\u51c6\u786e\u7387\uff08Accuracy\uff09\uff1a   $$   \\text{Accuracy} = \\frac{\\text{\u9884\u6d4b\u6b63\u786e\u6837\u672c\u6570}}{\\text{\u603b\u6837\u672c\u6570}}   $$</li> <li>\u7cbe\u786e\u7387\u3001\u53ec\u56de\u7387\u3001F1-score\uff1a   $$   \\text{Precision} = \\frac{TP}{TP+FP}, \\quad   \\text{Recall} = \\frac{TP}{TP+FN}, \\quad   F1 = \\frac{2 \\cdot Precision \\cdot Recall}{Precision + Recall}   $$</li> </ul>"},{"location":"machine/interview/#42_1","title":"4.2 \u56de\u5f52","text":"<ul> <li>\u5747\u65b9\u8bef\u5dee\uff08MSE\uff09</li> <li>\u5747\u65b9\u6839\u8bef\u5dee\uff08RMSE\uff09</li> <li>\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\uff08MAE\uff09</li> <li>\\(R^2\\) \u51b3\u5b9a\u7cfb\u6570\uff1a   $$   R^2 = 1 - \\frac{\\sum_i (y_i - \\hat{y}_i)^2}{\\sum_i (y_i - \\bar{y})^2}   $$</li> </ul>"},{"location":"machine/interview/#5_5","title":"5\ufe0f\u20e3 \u5b9e\u73b0\u4ee3\u7801","text":"<pre><code>from sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# 1. \u6570\u636e\u51c6\u5907\ndata = load_iris()\nX, y = data.data, data.target\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# 2. \u7279\u5f81\u5f52\u4e00\u5316\uff08KNN \u5bf9\u8ddd\u79bb\u654f\u611f\uff09\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# 3. KNN \u5206\u7c7b\nknn = KNeighborsClassifier(n_neighbors=5, weights='distance')  # \u6743\u91cd\u8ddd\u79bb\u52a0\u6743\nknn.fit(X_train, y_train)\n\n# 4. \u9884\u6d4b\ny_pred = knn.predict(X_test)\n\n# 5. \u8bc4\u4f30\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(classification_report(y_test, y_pred))\n</code></pre> <p>\u56de\u5f52\u7c7b\u4f3c\uff0c\u53ea\u9700\u7528 <code>KNeighborsRegressor</code>\uff0c\u635f\u5931\u51fd\u6570\u6539\u4e3a MSE/MAE\u3002</p>"},{"location":"machine/interview/#6_5","title":"6\ufe0f\u20e3 \u6a21\u578b\u4f18\u5316","text":"<ol> <li> <p>\u9009\u62e9\u5408\u9002\u7684 K \u503c\uff1a</p> <ul> <li>K \u592a\u5c0f \u2192 \u6613\u53d7\u566a\u58f0\u5f71\u54cd\uff0c\u8fc7\u62df\u5408</li> <li>K \u592a\u5927 \u2192 \u8fc7\u4e8e\u5e73\u6ed1\uff0c\u6b20\u62df\u5408</li> <li>\u5e38\u7528\u4ea4\u53c9\u9a8c\u8bc1\u9009\u62e9\u6700\u4f18 K</li> </ul> </li> <li> <p>\u8ddd\u79bb\u5ea6\u91cf\uff1a</p> <ul> <li>\u5bf9\u8fde\u7eed\u53d8\u91cf\uff1a\u6b27\u6c0f\u3001\u66fc\u54c8\u987f</li> <li>\u5bf9\u7c7b\u522b\u53d8\u91cf\uff1a\u6c49\u660e\u8ddd\u79bb\uff08Hamming distance\uff09</li> </ul> </li> <li> <p>\u7279\u5f81\u7f29\u653e\uff1a</p> <ul> <li>KNN \u5bf9\u5c3a\u5ea6\u654f\u611f\uff0c\u5efa\u8bae\u6807\u51c6\u5316\uff08StandardScaler\uff09\u6216\u5f52\u4e00\u5316\uff08MinMaxScaler\uff09</li> </ul> </li> <li> <p>\u6743\u91cd\u9009\u62e9\uff1a</p> <ul> <li>\u8ddd\u79bb\u52a0\u6743\u6295\u7968\u80fd\u63d0\u5347\u9884\u6d4b\u6548\u679c\uff0c\u5c24\u5176\u662f\u6570\u636e\u5206\u5e03\u4e0d\u5747\u65f6</li> </ul> </li> <li> <p>\u964d\u7ef4\uff1a</p> <ul> <li>\u6570\u636e\u7ef4\u5ea6\u8fc7\u9ad8 \u2192 \u201c\u7ef4\u5ea6\u707e\u96be\u201d\uff0c\u53ef\u7528 PCA \u964d\u7ef4</li> </ul> </li> </ol>"},{"location":"machine/interview/#7_4","title":"7\ufe0f\u20e3 \u6ce8\u610f\u4e8b\u9879","text":"<ul> <li>KNN \u662f\u60f0\u6027\u5b66\u4e60\uff0c\u8bad\u7ec3\u5feb\uff0c\u4f46\u9884\u6d4b\u6162\uff08\u9700\u8ba1\u7b97\u6240\u6709\u8bad\u7ec3\u6837\u672c\u8ddd\u79bb\uff09</li> <li>\u9ad8\u7ef4\u6570\u636e\u4f1a\u5bfc\u81f4\u201c\u8ddd\u79bb\u96c6\u4e2d\u73b0\u8c61\u201d\uff0c\u5f71\u54cd\u6548\u679c</li> <li>\u5bf9\u5f02\u5e38\u503c\u654f\u611f\uff08\u5c24\u5176\u662f K \u5c0f\u65f6\uff09</li> <li>\u9700\u8981\u8db3\u591f\u5185\u5b58\u5b58\u50a8\u5168\u90e8\u8bad\u7ec3\u96c6</li> <li>\u7279\u5f81\u5c3a\u5ea6\u4e0d\u4e00\u81f4\u9700\u5f52\u4e00\u5316\u6216\u6807\u51c6\u5316</li> </ul>"},{"location":"machine/interview/#8_4","title":"8\ufe0f\u20e3 \u4f18\u7f3a\u70b9","text":"\u4f18\u70b9 \u7f3a\u70b9 \u7b80\u5355\u76f4\u89c2\uff0c\u5bb9\u6613\u7406\u89e3\u548c\u5b9e\u73b0 \u9884\u6d4b\u9636\u6bb5\u8ba1\u7b97\u91cf\u5927\uff0c\u5b58\u50a8\u9700\u6c42\u9ad8 \u65e0\u9700\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u65e0\u53c2\u6570\u5b66\u4e60 \u5bf9\u9ad8\u7ef4\u6570\u636e\u6548\u679c\u5dee\uff08\u7ef4\u5ea6\u707e\u96be\uff09 \u53ef\u7528\u4e8e\u5206\u7c7b\u4e0e\u56de\u5f52 \u5bf9\u5f02\u5e38\u503c\u654f\u611f \u53ef\u901a\u8fc7\u8ddd\u79bb\u52a0\u6743\u63d0\u5347\u6027\u80fd K \u503c\u9009\u62e9\u5bf9\u7ed3\u679c\u5f71\u54cd\u5927 \u53ef\u5904\u7406\u975e\u7ebf\u6027\u8fb9\u754c \u7279\u5f81\u5c3a\u5ea6\u654f\u611f\uff0c\u9700\u8981\u5f52\u4e00\u5316"},{"location":"machine/interview/#svm","title":"\u5341\u3001SVM","text":""},{"location":"machine/interview/#101-svm","title":"10.1 SVM\u6559\u7a0b","text":""},{"location":"machine/interview/#1_21","title":"1\ufe0f\u20e3 \u539f\u7406","text":"<p>SVM \u662f\u4e00\u79cd\u76d1\u7763\u5b66\u4e60\u7b97\u6cd5\uff0c\u7528\u4e8e\u5206\u7c7b\u548c\u56de\u5f52\uff08\u5206\u7c7b\u6700\u5e38\u7528\uff09\u3002\u6838\u5fc3\u601d\u60f3\u662f\uff1a</p> <ol> <li>\u5206\u7c7b\u95ee\u9898\uff1a\u5728\u7279\u5f81\u7a7a\u95f4\u4e2d\u5bfb\u627e\u4e00\u4e2a\u6700\u4f18\u8d85\u5e73\u9762\uff08Hyperplane\uff09\uff0c\u5c06\u4e0d\u540c\u7c7b\u522b\u7684\u6837\u672c\u5206\u5f00\u3002</li> <li>\u6700\u5927\u5316\u95f4\u9694\uff08Margin\uff09\uff1a\u5728\u6240\u6709\u53ef\u80fd\u7684\u5206\u9694\u8d85\u5e73\u9762\u4e2d\uff0c\u9009\u62e9\u4f7f\u4e24\u7c7b\u6837\u672c\u6700\u8fd1\u70b9\u5230\u8d85\u5e73\u9762\u8ddd\u79bb\u6700\u5927\u7684\u5e73\u9762\u3002</li> <li>\u652f\u6301\u5411\u91cf\uff1a\u79bb\u8d85\u5e73\u9762\u6700\u8fd1\u7684\u8bad\u7ec3\u6837\u672c\u70b9\u79f0\u4e3a\u652f\u6301\u5411\u91cf\uff0c\u5b83\u4eec\u51b3\u5b9a\u4e86\u8d85\u5e73\u9762\u7684\u4f4d\u7f6e\u3002</li> </ol>"},{"location":"machine/interview/#11_2","title":"1.1 \u8d85\u5e73\u9762\u516c\u5f0f","text":"<p>\u5bf9\u4e8e\u7ebf\u6027\u53ef\u5206\u7684\u60c5\u51b5\uff1a</p> \\[ \\mathbf{w} \\cdot \\mathbf{x} + b = 0 \\] <ul> <li>\\(\\mathbf{w}\\)\uff1a\u6cd5\u5411\u91cf\uff0c\u51b3\u5b9a\u8d85\u5e73\u9762\u65b9\u5411</li> <li>\\(b\\)\uff1a\u504f\u7f6e\u9879</li> <li>\u5206\u7c7b\u51b3\u7b56\u51fd\u6570\uff1a   $$   f(\\mathbf{x}) = \\text{sign}(\\mathbf{w}\\cdot \\mathbf{x} + b)   $$</li> </ul>"},{"location":"machine/interview/#2_20","title":"2\ufe0f\u20e3 \u635f\u5931\u51fd\u6570","text":""},{"location":"machine/interview/#21-svm","title":"2.1 \u7ebf\u6027\u53ef\u5206 SVM","text":"<ul> <li>\u6700\u5927\u5316\u95f4\u9694 \\(\\gamma = \\frac{2}{|\\mathbf{w}|}\\)</li> <li>\u7ea6\u675f\u6761\u4ef6\uff1a   $$   y_i (\\mathbf{w} \\cdot \\mathbf{x}_i + b) \\ge 1, \\quad i=1,\\dots,n   $$</li> <li>\u4f18\u5316\u76ee\u6807\uff08\u786c\u95f4\u9694\u6700\u5927\u5316\uff09\uff1a   $$   \\min_{\\mathbf{w},b} \\frac{1}{2}|\\mathbf{w}|^2   $$</li> </ul>"},{"location":"machine/interview/#22-svm","title":"2.2 \u7ebf\u6027\u4e0d\u53ef\u5206\uff08\u8f6f\u95f4\u9694\uff09SVM","text":"<ul> <li>\u5f15\u5165\u677e\u5f1b\u53d8\u91cf \\(\\xi_i \\ge 0\\)\uff1a   $$   y_i (\\mathbf{w} \\cdot \\mathbf{x}_i + b) \\ge 1 - \\xi_i   $$</li> <li>\u635f\u5931\u51fd\u6570\uff08\u76ee\u6807\u51fd\u6570\uff09\uff1a   $$   \\min_{\\mathbf{w},b,\\xi} \\frac{1}{2}|\\mathbf{w}|^2 + C \\sum_{i=1}^n \\xi_i   $$</li> <li>\\(C\\)\uff1a\u6b63\u5219\u5316\u53c2\u6570\uff0c\u5e73\u8861\u95f4\u9694\u6700\u5927\u5316\u548c\u5206\u7c7b\u9519\u8bef</li> </ul>"},{"location":"machine/interview/#23-hinge","title":"2.3 Hinge \u635f\u5931\u51fd\u6570","text":"<ul> <li>SVM \u7684\u5206\u7c7b\u635f\u5931\u51fd\u6570\u53ef\u8868\u793a\u4e3a hinge loss\uff1a   $$   L(y_i, f(\\mathbf{x}_i)) = \\max(0, 1 - y_i f(\\mathbf{x}_i))   $$</li> <li>\u603b\u635f\u5931\uff1a   $$   \\min_{\\mathbf{w},b} \\frac{1}{2} |\\mathbf{w}|^2 + C \\sum_{i=1}^n \\max(0, 1 - y_i (\\mathbf{w}\\cdot \\mathbf{x}_i + b))   $$</li> </ul>"},{"location":"machine/interview/#3_12","title":"3\ufe0f\u20e3 \u6570\u5b66\u63a8\u5bfc\u8fc7\u7a0b","text":""},{"location":"machine/interview/#31-primal-problem","title":"3.1 \u539f\u59cb\u95ee\u9898\uff08Primal Problem\uff09","text":"\\[ \\min_{\\mathbf{w},b,\\xi} \\frac{1}{2}|\\mathbf{w}|^2 + C \\sum_{i=1}^n \\xi_i \\] \\[ \\text{s.t. } y_i (\\mathbf{w}\\cdot \\mathbf{x}_i + b) \\ge 1 - \\xi_i, \\quad \\xi_i \\ge 0 \\]"},{"location":"machine/interview/#32-dual-problem","title":"3.2 \u5bf9\u5076\u95ee\u9898\uff08Dual Problem\uff09","text":"<p>\u901a\u8fc7\u62c9\u683c\u6717\u65e5\u4e58\u5b50 \\(\\alpha_i \\ge 0\\)\uff1a</p> \\[ L(\\mathbf{w},b,\\xi, \\alpha, \\mu) = \\frac{1}{2}|\\mathbf{w}|^2 + C \\sum_i \\xi_i - \\sum_i \\alpha_i [y_i(\\mathbf{w}\\cdot \\mathbf{x}_i+b) - 1 + \\xi_i] - \\sum_i \\mu_i \\xi_i \\] <p>\u5bf9 \\(\\mathbf{w}, b, \\xi\\) \u6c42\u504f\u5bfc\uff0c\u5f97\u5230\u5bf9\u5076\u95ee\u9898\uff1a</p> \\[ \\max_{\\alpha} \\sum_i \\alpha_i - \\frac{1}{2}\\sum_{i,j} \\alpha_i \\alpha_j y_i y_j \\mathbf{x}_i \\cdot \\mathbf{x}_j \\] \\[ \\text{s.t. } 0 \\le \\alpha_i \\le C, \\quad \\sum_i \\alpha_i y_i = 0 \\] <ul> <li>\u9884\u6d4b\u51fd\u6570\uff1a   $$   f(\\mathbf{x}) = \\text{sign}\\left(\\sum_{i \\in SV} \\alpha_i y_i \\mathbf{x}_i \\cdot \\mathbf{x} + b \\right)   $$</li> <li>\u53ea\u4f9d\u8d56\u652f\u6301\u5411\u91cf\uff08SV\uff09</li> </ul>"},{"location":"machine/interview/#33-kernel-trick","title":"3.3 \u6838\u65b9\u6cd5\uff08Kernel Trick\uff09","text":"<p>\u7ebf\u6027\u4e0d\u53ef\u5206\u65f6\uff0c\u5c06\u6570\u636e\u6620\u5c04\u5230\u9ad8\u7ef4\u7a7a\u95f4\uff1a</p> \\[ f(\\mathbf{x}) = \\text{sign}\\left(\\sum_{i \\in SV} \\alpha_i y_i K(\\mathbf{x}_i, \\mathbf{x}) + b \\right) \\] <p>\u5e38\u7528\u6838\u51fd\u6570\uff1a</p> <ol> <li>\u7ebf\u6027\u6838\uff1a\\(K(\\mathbf{x}_i,\\mathbf{x}_j) = \\mathbf{x}_i \\cdot \\mathbf{x}_j\\)</li> <li>\u591a\u9879\u5f0f\u6838\uff1a\\(K(\\mathbf{x}_i,\\mathbf{x}_j) = (\\mathbf{x}_i\\cdot \\mathbf{x}_j + 1)^d\\)</li> <li>RBF\uff08\u9ad8\u65af\u6838\uff09\uff1a\\(K(\\mathbf{x}_i,\\mathbf{x}_j) = \\exp(-\\gamma |\\mathbf{x}_i-\\mathbf{x}_j|^2)\\)</li> <li>Sigmoid \u6838\uff1a\\(K(\\mathbf{x}_i,\\mathbf{x}_j) = \\tanh(\\kappa \\mathbf{x}_i \\cdot \\mathbf{x}_j + \\theta)\\)</li> </ol>"},{"location":"machine/interview/#4_11","title":"4\ufe0f\u20e3 \u8bc4\u4f30\u6307\u6807","text":"<ul> <li>\u5206\u7c7b\u51c6\u786e\u7387\uff08Accuracy\uff09</li> <li>\u7cbe\u786e\u7387\u3001\u53ec\u56de\u7387\u3001F1-score</li> <li>ROC-AUC\uff08\u9002\u5408\u4e8c\u5206\u7c7b\uff09</li> <li>\u6df7\u6dc6\u77e9\u9635</li> </ul> <p>\u56de\u5f52\u95ee\u9898\u53ef\u7528 MSE\u3001MAE\u3001\\(R^2\\) \u7b49\u6307\u6807\uff08SVR\uff09\u3002</p>"},{"location":"machine/interview/#5_6","title":"5\ufe0f\u20e3 \u5b9e\u73b0\u4ee3\u7801","text":"<pre><code>from sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# 1. \u6570\u636e\ndata = load_iris()\nX, y = data.data, data.target\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# 2. \u7279\u5f81\u6807\u51c6\u5316\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# 3. SVM \u5206\u7c7b\u5668\nsvm_clf = SVC(kernel='rbf', C=1.0, gamma='scale')  # RBF \u6838\nsvm_clf.fit(X_train, y_train)\n\n# 4. \u9884\u6d4b\ny_pred = svm_clf.predict(X_test)\n\n# 5. \u8bc4\u4f30\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(classification_report(y_test, y_pred))\n</code></pre> <p>\u56de\u5f52\u4f7f\u7528 <code>SVR(kernel='rbf')</code>\uff0c\u635f\u5931\u51fd\u6570\u4e3a epsilon-insensitive loss\u3002</p>"},{"location":"machine/interview/#6_6","title":"6\ufe0f\u20e3 \u6a21\u578b\u4f18\u5316","text":"<ol> <li> <p>\u9009\u62e9\u6838\u51fd\u6570\uff1a</p> <ul> <li>\u7ebf\u6027\u6838\u9002\u5408\u9ad8\u7ef4\u7a00\u758f\u6570\u636e</li> <li>RBF \u6838\u9002\u5408\u5927\u591a\u6570\u975e\u7ebf\u6027\u95ee\u9898</li> </ul> </li> <li> <p>\u8c03\u8282\u53c2\u6570\uff1a</p> <ul> <li>\\(C\\)\uff1a\u6b63\u5219\u5316\u53c2\u6570\uff0c\u8fc7\u5927\u5bb9\u6613\u8fc7\u62df\u5408\uff0c\u8fc7\u5c0f\u6b20\u62df\u5408</li> <li>\\(\\gamma\\)\uff08RBF \u6838\uff09\uff1a\u6838\u5bbd\u5ea6\uff0c\u8fc7\u5927\u8fc7\u62df\u5408\uff0c\u8fc7\u5c0f\u6b20\u62df\u5408</li> </ul> </li> <li> <p>\u7279\u5f81\u7f29\u653e\uff1a</p> <ul> <li>\u5bf9\u8ddd\u79bb\u654f\u611f\uff0c\u9700\u5f52\u4e00\u5316\u6216\u6807\u51c6\u5316</li> </ul> </li> <li> <p>\u4f7f\u7528\u4ea4\u53c9\u9a8c\u8bc1\u9009\u62e9\u53c2\u6570\uff1a</p> <ul> <li><code>GridSearchCV</code> \u6216 <code>RandomizedSearchCV</code></li> </ul> </li> <li> <p>\u5904\u7406\u7c7b\u522b\u4e0d\u5e73\u8861\uff1a</p> <ul> <li>\u8bbe\u7f6e <code>class_weight='balanced'</code></li> </ul> </li> </ol>"},{"location":"machine/interview/#7_5","title":"7\ufe0f\u20e3 \u6ce8\u610f\u4e8b\u9879","text":"<ul> <li>\u5bf9\u5927\u89c4\u6a21\u6570\u636e\u8bad\u7ec3\u65f6\u95f4\u957f</li> <li>\u5bf9\u566a\u58f0\u548c\u5f02\u5e38\u503c\u654f\u611f\uff08\u5c24\u5176 C \u5927\u65f6\uff09</li> <li>\u6838\u51fd\u6570\u9009\u62e9\u548c\u53c2\u6570\u8c03\u8282\u5f88\u5173\u952e</li> <li>\u9ad8\u7ef4\u7a00\u758f\u6570\u636e\u7ebf\u6027\u6838\u66f4\u9002\u5408</li> <li>SVM \u672c\u8d28\u662f\u4e8c\u5206\u7c7b\uff0c\u591a\u5206\u7c7b\u9700\u201c\u4e00\u5bf9\u591a\u201d\u6216\u201c\u4e00\u5bf9\u4e00\u201d\u7b56\u7565</li> </ul>"},{"location":"machine/interview/#8_5","title":"8\ufe0f\u20e3 \u4f18\u7f3a\u70b9","text":"\u4f18\u70b9 \u7f3a\u70b9 \u5bf9\u9ad8\u7ef4\u6570\u636e\u6548\u679c\u597d \u5bf9\u5927\u6570\u636e\u96c6\u8bad\u7ec3\u6162\uff0c\u9884\u6d4b\u6162 \u9002\u5408\u975e\u7ebf\u6027\u8fb9\u754c\uff08\u6838\u65b9\u6cd5\uff09 \u5bf9\u53c2\u6570\uff08C, \u03b3\uff09\u654f\u611f \u5177\u6709\u5168\u5c40\u6700\u4f18\u89e3\uff08\u51f8\u4f18\u5316\uff09 \u5bf9\u566a\u58f0\u548c\u5f02\u5e38\u503c\u654f\u611f \u53ef\u4ee5\u5904\u7406\u7ebf\u6027\u548c\u975e\u7ebf\u6027\u95ee\u9898 \u6838\u65b9\u6cd5\u4e0d\u6613\u89e3\u91ca \u652f\u6301\u591a\u5206\u7c7b\u6269\u5c55 \u5bf9\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\u654f\u611f"},{"location":"machine/interview/#_118","title":"\u5341\u4e00\u3001\u96c6\u6210\u5b66\u4e60","text":""},{"location":"machine/interview/#111","title":"11.1 \u6559\u7a0b","text":""},{"location":"machine/interview/#1_22","title":"1\ufe0f\u20e3 \u539f\u7406","text":"<p>\u96c6\u6210\u5b66\u4e60\u662f\u4e00\u7c7b\u5c06\u591a\u4e2a\u6a21\u578b\u7ec4\u5408\u5728\u4e00\u8d77\u4ee5\u63d0\u9ad8\u6574\u4f53\u6027\u80fd\u7684\u7b97\u6cd5\u601d\u60f3\uff0c\u5176\u6838\u5fc3\u7406\u5ff5\u662f\uff1a</p> <p>\u201c\u591a\u4e2a\u5f31\u5b66\u4e60\u5668\u7ed3\u5408\uff0c\u53ef\u4ee5\u5f62\u6210\u4e00\u4e2a\u5f3a\u5b66\u4e60\u5668\u3002\u201d</p> <p>\u96c6\u6210\u65b9\u6cd5\u4e3b\u8981\u6709\u4e24\u7c7b\uff1a</p>"},{"location":"machine/interview/#11-baggingbootstrap-aggregating","title":"1.1 Bagging\uff08Bootstrap Aggregating\uff0c\u81ea\u52a9\u805a\u5408\uff09","text":"<ul> <li>\u6838\u5fc3\u601d\u60f3\uff1a\u901a\u8fc7\u5bf9\u8bad\u7ec3\u96c6\u8fdb\u884c\u6709\u653e\u56de\u62bd\u6837\u751f\u6210\u591a\u4e2a\u4e0d\u540c\u5b50\u96c6\uff0c\u5728\u6bcf\u4e2a\u5b50\u96c6\u4e0a\u8bad\u7ec3\u4e00\u4e2a\u6a21\u578b\uff0c\u7136\u540e\u5c06\u591a\u4e2a\u6a21\u578b\u9884\u6d4b\u7ed3\u679c\u5e73\u5747\uff08\u56de\u5f52\uff09\u6216\u6295\u7968\uff08\u5206\u7c7b\uff09\u3002</li> <li> <p>\u4ee3\u8868\u7b97\u6cd5\uff1a</p> <ul> <li>\u968f\u673a\u68ee\u6797\uff08Random Forest\uff09</li> </ul> </li> <li> <p>\u4f5c\u7528\uff1a\u964d\u4f4e\u6a21\u578b\u65b9\u5dee\uff08Variance\uff09</p> </li> </ul> <p>\u516c\u5f0f\uff1a $$ \\hat{y} = \\frac{1}{M} \\sum_{m=1}^M h_m(x) $$</p> <ul> <li>\\(h_m(x)\\)\uff1a\u7b2c \\(m\\) \u4e2a\u57fa\u6a21\u578b\u7684\u9884\u6d4b</li> <li>\\(M\\)\uff1a\u57fa\u6a21\u578b\u6570\u91cf</li> </ul>"},{"location":"machine/interview/#12-boosting","title":"1.2 Boosting\uff08\u63d0\u5347\u65b9\u6cd5\uff09","text":"<ul> <li>\u6838\u5fc3\u601d\u60f3\uff1a\u987a\u5e8f\u8bad\u7ec3\u6a21\u578b\uff0c\u6bcf\u4e2a\u65b0\u6a21\u578b\u91cd\u70b9\u5173\u6ce8\u524d\u4e00\u4e2a\u6a21\u578b\u9884\u6d4b\u9519\u8bef\u7684\u6837\u672c\u3002</li> <li> <p>\u4ee3\u8868\u7b97\u6cd5\uff1a</p> <ul> <li>AdaBoost</li> <li>Gradient Boosting / XGBoost / LightGBM / CatBoost</li> </ul> </li> <li> <p>\u4f5c\u7528\uff1a\u964d\u4f4e\u6a21\u578b\u504f\u5dee\uff08Bias\uff09</p> </li> </ul> <p>AdaBoost \u5206\u7c7b\u9884\u6d4b\u516c\u5f0f\uff1a $$ H(x) = \\text{sign}\\left(\\sum_{m=1}^M \\alpha_m h_m(x)\\right) $$</p> <ul> <li>\\(\\alpha_m\\)\uff1a\u7b2c \\(m\\) \u4e2a\u6a21\u578b\u7684\u6743\u91cd</li> <li>\\(h_m(x)\\)\uff1a\u57fa\u6a21\u578b\u9884\u6d4b\u7ed3\u679c\uff08\u901a\u5e38\u4e3a \\(\\pm 1\\)\uff09</li> </ul>"},{"location":"machine/interview/#13-stacking","title":"1.3 Stacking\uff08\u5806\u53e0\uff09","text":"<ul> <li>\u6838\u5fc3\u601d\u60f3\uff1a\u4f7f\u7528\u591a\u4e2a\u4e0d\u540c\u6a21\u578b\u751f\u6210\u4e00\u5c42\u8f93\u51fa\uff0c\u518d\u7528\u4e00\u4e2a\u201c\u5143\u5b66\u4e60\u5668\uff08Meta-learner\uff09\u201d\u7efc\u5408\u9884\u6d4b\u7ed3\u679c\u3002</li> <li>\u516c\u5f0f\uff1a</li> </ul> <p>$$   z_i = [h_1(x_i), h_2(x_i), \\dots, h_M(x_i)]   $$</p> <p>$$   \\hat{y}_i = g(z_i)   $$</p> <ul> <li>\\(h_m\\)\uff1a\u7b2c \\(m\\) \u4e2a\u57fa\u6a21\u578b</li> <li>\\(g\\)\uff1a\u5143\u5b66\u4e60\u5668\uff08\u5982\u903b\u8f91\u56de\u5f52\u3001\u7ebf\u6027\u56de\u5f52\uff09</li> </ul>"},{"location":"machine/interview/#2_21","title":"2\ufe0f\u20e3 \u635f\u5931\u51fd\u6570","text":"<p>\u96c6\u6210\u5b66\u4e60\u7684\u635f\u5931\u51fd\u6570\u53d6\u51b3\u4e8e\u57fa\u6a21\u578b\u548c\u4efb\u52a1\u7c7b\u578b\uff1a</p>"},{"location":"machine/interview/#21_3","title":"2.1 \u5206\u7c7b","text":"<ul> <li>0-1 \u635f\u5931\uff1a   $$   L(y, \\hat{y}) = \\mathbf{1}(y \\neq \\hat{y})   $$</li> <li>\u4ea4\u53c9\u71b5\u635f\u5931\uff08Soft Voting \u53ef\u7528\uff09\uff1a   $$   L(y, \\hat{p}) = - \\sum_{c} y_c \\log \\hat{p}_c   $$</li> </ul>"},{"location":"machine/interview/#22_3","title":"2.2 \u56de\u5f52","text":"<ul> <li>\u5747\u65b9\u8bef\u5dee\uff08MSE\uff09\uff1a   $$   L(y, \\hat{y}) = (y - \\hat{y})^2   $$</li> <li>\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\uff08MAE\uff09\uff1a   $$   L(y, \\hat{y}) = |y - \\hat{y}|   $$</li> </ul>"},{"location":"machine/interview/#3_13","title":"3\ufe0f\u20e3 \u6570\u5b66\u63a8\u5bfc\u8fc7\u7a0b","text":""},{"location":"machine/interview/#31-bagging","title":"3.1 Bagging \u65b9\u5dee\u51cf\u5c11\u516c\u5f0f","text":"<p>\u5047\u8bbe\u57fa\u6a21\u578b\u65b9\u5dee\u4e3a \\(\\sigma^2\\)\uff0c\u76f8\u5173\u6027\u4e3a \\(\\rho\\)\uff1a $$ \\text{Var}(\\hat{y}_{bag}) = \\rho \\sigma^2 + \\frac{1-\\rho}{M}\\sigma^2 $$</p> <ul> <li>\\(M\\)\uff1a\u57fa\u6a21\u578b\u6570\u91cf</li> <li>\u7ed3\u8bba\uff1a\u57fa\u6a21\u578b\u8d8a\u591a\uff0c\u65b9\u5dee\u8d8a\u5c0f\uff0c\u4e14\u57fa\u6a21\u578b\u76f8\u5173\u6027\u8d8a\u4f4e\u6548\u679c\u8d8a\u597d</li> </ul>"},{"location":"machine/interview/#32-boosting","title":"3.2 Boosting \u52a0\u6743\u7ec4\u5408","text":"<p>AdaBoost\uff1a</p> <ol> <li>\u521d\u59cb\u5316\u6837\u672c\u6743\u91cd \\(w_i = 1/n\\)</li> <li>\u8bad\u7ec3\u57fa\u6a21\u578b \\(h_m(x)\\)\uff0c\u8ba1\u7b97\u52a0\u6743\u9519\u8bef\u7387\uff1a    $$    \\epsilon_m = \\frac{\\sum_{i=1}^n w_i \\mathbf{1}(y_i \\neq h_m(x_i))}{\\sum_{i=1}^n w_i}    $$</li> <li>\u57fa\u6a21\u578b\u6743\u91cd\uff1a    $$    \\alpha_m = \\frac{1}{2} \\ln \\frac{1-\\epsilon_m}{\\epsilon_m}    $$</li> <li>\u66f4\u65b0\u6837\u672c\u6743\u91cd\uff1a    $$    w_i \\leftarrow w_i \\cdot \\exp(-\\alpha_m y_i h_m(x_i))    $$</li> </ol>"},{"location":"machine/interview/#4_12","title":"4\ufe0f\u20e3 \u8bc4\u4f30\u6307\u6807","text":""},{"location":"machine/interview/#41_2","title":"4.1 \u5206\u7c7b","text":"<ul> <li>Accuracy\u3001Precision\u3001Recall\u3001F1-score</li> <li>ROC-AUC</li> </ul>"},{"location":"machine/interview/#42_2","title":"4.2 \u56de\u5f52","text":"<ul> <li>MSE\u3001RMSE\u3001MAE</li> <li>\\(R^2\\)</li> </ul>"},{"location":"machine/interview/#5_7","title":"5\ufe0f\u20e3 \u5b9e\u73b0\u4ee3\u7801","text":""},{"location":"machine/interview/#51-bagging","title":"5.1 Bagging\uff08\u968f\u673a\u68ee\u6797\uff09","text":"<pre><code>from sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\n\ndata = load_iris()\nX_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2, random_state=42)\n\nrf = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\nrf.fit(X_train, y_train)\ny_pred = rf.predict(X_test)\n\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(classification_report(y_test, y_pred))\n</code></pre>"},{"location":"machine/interview/#52-boostingxgboost","title":"5.2 Boosting\uff08XGBoost\uff09","text":"<pre><code>import xgboost as xgb\nfrom sklearn.metrics import accuracy_score\n\nxg_clf = xgb.XGBClassifier(n_estimators=100, max_depth=3, learning_rate=0.1, random_state=42)\nxg_clf.fit(X_train, y_train)\ny_pred = xg_clf.predict(X_test)\n\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\n</code></pre>"},{"location":"machine/interview/#6_7","title":"6\ufe0f\u20e3 \u6a21\u578b\u4f18\u5316","text":"<ol> <li> <p>Bagging</p> <ul> <li>\u589e\u52a0\u57fa\u6a21\u578b\u6570\u91cf\uff08n_estimators\uff09</li> <li>\u964d\u4f4e\u57fa\u6a21\u578b\u6df1\u5ea6\u4ee5\u51cf\u5c11\u8fc7\u62df\u5408</li> <li>\u968f\u673a\u9009\u7279\u5f81\uff08feature subsampling\uff09</li> </ul> </li> <li> <p>Boosting</p> <ul> <li>\u8c03\u8282\u5b66\u4e60\u7387\uff08learning_rate\uff09</li> <li>\u8c03\u8282\u6811\u6df1\u5ea6\uff08max_depth\uff09</li> <li>\u8c03\u8282\u57fa\u6a21\u578b\u6570\u91cf\uff08n_estimators\uff09</li> <li>\u4f7f\u7528\u6b63\u5219\u5316\uff08L1/L2\uff09</li> </ul> </li> <li> <p>Stacking</p> <ul> <li>\u591a\u6837\u5316\u57fa\u6a21\u578b\u7c7b\u578b\uff08\u51b3\u7b56\u6811\u3001SVM\u3001\u7ebf\u6027\u56de\u5f52\u7b49\uff09</li> <li>\u4f7f\u7528\u4ea4\u53c9\u9a8c\u8bc1\u9632\u6b62\u5143\u5b66\u4e60\u5668\u8fc7\u62df\u5408</li> </ul> </li> </ol>"},{"location":"machine/interview/#7_6","title":"7\ufe0f\u20e3 \u6ce8\u610f\u4e8b\u9879","text":"<ul> <li>Bagging \u66f4\u9002\u5408\u9ad8\u65b9\u5dee\u6a21\u578b\uff08\u5982\u51b3\u7b56\u6811\uff09</li> <li>Boosting \u66f4\u9002\u5408\u9ad8\u504f\u5dee\u6a21\u578b\uff08\u5982\u6d45\u6811\uff09</li> <li>\u6837\u672c\u4e0d\u5e73\u8861\u95ee\u9898\u9700\u4f7f\u7528\u52a0\u6743\u6216\u91cd\u91c7\u6837</li> <li>\u57fa\u6a21\u578b\u9009\u62e9\u4e0e\u591a\u6837\u6027\u5f71\u54cd\u6548\u679c</li> <li>\u6837\u672c\u91cf\u5927\u65f6\u8ba1\u7b97\u5f00\u9500\u5927</li> </ul>"},{"location":"machine/interview/#8_6","title":"8\ufe0f\u20e3 \u4f18\u7f3a\u70b9","text":"\u4f18\u70b9 \u7f3a\u70b9 \u63d0\u5347\u6a21\u578b\u51c6\u786e\u6027\u548c\u7a33\u5b9a\u6027 \u8bad\u7ec3\u548c\u9884\u6d4b\u65f6\u95f4\u8f83\u957f \u964d\u4f4e\u8fc7\u62df\u5408\u98ce\u9669\uff08Bagging\uff09 \u53ef\u89e3\u91ca\u6027\u5dee \u53ef\u5904\u7406\u9ad8\u7ef4\u548c\u590d\u6742\u6570\u636e \u53c2\u6570\u8c03\u8282\u8f83\u591a\uff08Boosting\uff09 \u7075\u6d3b\uff0c\u53ef\u7ec4\u5408\u591a\u79cd\u6a21\u578b \u6837\u672c\u91cf\u5c0f\u53ef\u80fd\u6548\u679c\u4e0d\u4f73 \u9002\u7528\u4e8e\u5206\u7c7b\u4e0e\u56de\u5f52 Stacking \u9700\u4ea4\u53c9\u9a8c\u8bc1\uff0c\u590d\u6742"},{"location":"machine/interview/#_119","title":"\u5341\u4e8c\u3001\u65e0\u76d1\u7763\u5b66\u4e60","text":""},{"location":"machine/interview/#121","title":"12.1 \u805a\u7c7b","text":""},{"location":"machine/interview/#1_23","title":"1\ufe0f\u20e3 \u539f\u7406","text":"<p>\u805a\u7c7b\u7b97\u6cd5\u901a\u8fc7\u67d0\u79cd\u76f8\u4f3c\u5ea6\u6216\u8ddd\u79bb\u5ea6\u91cf\uff0c\u5c06\u6570\u636e\u96c6\u5212\u5206\u4e3a\u82e5\u5e72\u7c07\uff08Cluster\uff09\u3002</p> <p>\u5e38\u89c1\u805a\u7c7b\u65b9\u6cd5\uff1a</p> \u7c7b\u578b \u7b97\u6cd5 \u7279\u70b9 \u5212\u5206\u5f0f K-Means\u3001K-Medoids \u7b80\u5355\u9ad8\u6548\uff0c\u9002\u5408\u51f8\u5f62\u7c07 \u5c42\u6b21\u5f0f Agglomerative\u3001Divisive \u6784\u5efa\u6811\u72b6\u7ed3\u6784\uff0c\u76f4\u89c2 \u5bc6\u5ea6\u5f0f DBSCAN\u3001OPTICS \u53ef\u53d1\u73b0\u4efb\u610f\u5f62\u72b6\u7c07\uff0c\u5904\u7406\u566a\u58f0 \u6a21\u578b\u5f0f \u9ad8\u65af\u6df7\u5408\u6a21\u578b\uff08GMM\uff09 \u57fa\u4e8e\u6982\u7387\u6a21\u578b\uff0c\u8f6f\u805a\u7c7b \u8c31\u805a\u7c7b Spectral Clustering \u57fa\u4e8e\u56fe\u8bba\uff0c\u9002\u5408\u590d\u6742\u5f62\u72b6"},{"location":"machine/interview/#2_22","title":"2\ufe0f\u20e3 \u635f\u5931\u51fd\u6570","text":""},{"location":"machine/interview/#21-k-means","title":"2.1 K-Means","text":"<ul> <li>\u76ee\u6807\u662f\u6700\u5c0f\u5316\u7c07\u5185\u5e73\u65b9\u8bef\u5dee\uff08WCSS, within-cluster sum of squares\uff09\uff1a   $$   J = \\sum_{k=1}^{K} \\sum_{x_i \\in C_k} |x_i - \\mu_k|^2   $$</li> <li>\\(\\mu_k\\)\uff1a\u7b2c \\(k\\) \u4e2a\u7c07\u7684\u8d28\u5fc3</li> <li>\u4f18\u5316\u8fc7\u7a0b\u5373\u6700\u5c0f\u5316\u7c07\u5185\u5e73\u65b9\u8ddd\u79bb</li> </ul>"},{"location":"machine/interview/#22-gmm","title":"2.2 \u9ad8\u65af\u6df7\u5408\u6a21\u578b\uff08GMM\uff09","text":"<ul> <li>\u6700\u5927\u5316\u5bf9\u6570\u4f3c\u7136\uff1a   $$   \\log L(\\theta) = \\sum_{i=1}^{n} \\log \\left( \\sum_{k=1}^{K} \\pi_k \\mathcal{N}(x_i | \\mu_k, \\Sigma_k) \\right)   $$</li> <li>\\(\\pi_k\\)\uff1a\u7c07\u6743\u91cd</li> <li>\\(\\mathcal{N}\\)\uff1a\u9ad8\u65af\u5206\u5e03</li> </ul>"},{"location":"machine/interview/#23-dbscan","title":"2.3 DBSCAN","text":"<ul> <li> <p>\u6ca1\u6709\u660e\u786e\u635f\u5931\u51fd\u6570\uff0c\u57fa\u4e8e\u5bc6\u5ea6\u53ef\u8fbe\u6027\uff1a</p> <ul> <li>\u6838\u5fc3\u70b9\uff1a\u90bb\u57df\u5185\u6837\u672c\u6570 \u2265 MinPts</li> <li>\u7c07\u7531\u6838\u5fc3\u70b9\u53ca\u5176\u53ef\u8fbe\u70b9\u7ec4\u6210</li> </ul> </li> </ul>"},{"location":"machine/interview/#3_14","title":"3\ufe0f\u20e3 \u6570\u5b66\u63a8\u5bfc\u8fc7\u7a0b","text":"<ol> <li>\u521d\u59cb\u5316 \\(K\\) \u4e2a\u8d28\u5fc3 \\(\\mu_k\\)</li> <li>\u5206\u914d\u6b65\u9aa4\uff08Assignment\uff09\uff1a    $$    C_k = { x_i : |x_i - \\mu_k|^2 \\le |x_i - \\mu_j|^2, \\forall j }    $$</li> <li>\u66f4\u65b0\u6b65\u9aa4\uff08Update\uff09\uff1a    $$    \\mu_k = \\frac{1}{|C_k|} \\sum_{x_i \\in C_k} x_i    $$</li> <li>\u91cd\u590d 2-3 \u6b65\uff0c\u76f4\u5230\u8d28\u5fc3\u4e0d\u518d\u53d8\u5316\u6216\u635f\u5931\u51fd\u6570\u6536\u655b</li> </ol> <p>GMM \u4f7f\u7528 EM \u7b97\u6cd5\uff1a</p> <ul> <li>E \u6b65\uff1a\u8ba1\u7b97\u540e\u9a8c\u6982\u7387   $$   \\gamma_{ik} = \\frac{\\pi_k \\mathcal{N}(x_i|\\mu_k, \\Sigma_k)}{\\sum_{j=1}^K \\pi_j \\mathcal{N}(x_i|\\mu_j, \\Sigma_j)}   $$</li> <li>M \u6b65\uff1a\u66f4\u65b0\u53c2\u6570   $$   \\mu_k = \\frac{\\sum_i \\gamma_{ik} x_i}{\\sum_i \\gamma_{ik}}, \\quad   \\Sigma_k = \\frac{\\sum_i \\gamma_{ik} (x_i - \\mu_k)(x_i - \\mu_k)^T}{\\sum_i \\gamma_{ik}}, \\quad   \\pi_k = \\frac{\\sum_i \\gamma_{ik}}{n}   $$</li> </ul>"},{"location":"machine/interview/#4_13","title":"4\ufe0f\u20e3 \u8bc4\u4f30\u6307\u6807","text":""},{"location":"machine/interview/#41_3","title":"4.1 \u5185\u90e8\u6307\u6807\uff08\u65e0\u9700\u771f\u5b9e\u6807\u7b7e\uff09","text":"<ul> <li>\u7c07\u5185\u5e73\u65b9\u548c\uff08WCSS\uff09</li> <li>\u8f6e\u5ed3\u7cfb\u6570\uff08Silhouette Score\uff09\uff1a   $$   s(i) = \\frac{b(i) - a(i)}{\\max(a(i), b(i))}   $$</li> <li>Calinski-Harabasz \u6307\u6570</li> <li>Davies-Bouldin \u6307\u6570</li> </ul>"},{"location":"machine/interview/#42_3","title":"4.2 \u5916\u90e8\u6307\u6807\uff08\u6709\u771f\u5b9e\u6807\u7b7e\uff09","text":"<ul> <li>\u8c03\u6574\u5170\u5fb7\u6307\u6570\uff08ARI, Adjusted Rand Index\uff09</li> <li>\u4e92\u4fe1\u606f\uff08AMI, Adjusted Mutual Information\uff09</li> <li>\u7eaf\u5ea6\uff08Purity\uff09</li> </ul>"},{"location":"machine/interview/#5_8","title":"5\ufe0f\u20e3 \u5b9e\u73b0\u4ee3\u7801","text":""},{"location":"machine/interview/#51-k-means","title":"5.1 K-Means","text":"<pre><code>from sklearn.datasets import make_blobs\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\n\nX, _ = make_blobs(n_samples=300, centers=4, random_state=42)\n\nkmeans = KMeans(n_clusters=4, random_state=42)\nlabels = kmeans.fit_predict(X)\n\nprint(\"\u8d28\u5fc3:\\n\", kmeans.cluster_centers_)\nprint(\"\u8f6e\u5ed3\u7cfb\u6570:\", silhouette_score(X, labels))\n</code></pre>"},{"location":"machine/interview/#52-dbscan","title":"5.2 DBSCAN","text":"<pre><code>from sklearn.cluster import DBSCAN\n\ndb = DBSCAN(eps=0.5, min_samples=5)\nlabels = db.fit_predict(X)\n\nprint(\"\u7c07\u6807\u7b7e:\", set(labels))  # -1\u8868\u793a\u566a\u58f0\n</code></pre>"},{"location":"machine/interview/#53-gmm","title":"5.3 GMM","text":"<pre><code>from sklearn.mixture import GaussianMixture\n\ngmm = GaussianMixture(n_components=4, random_state=42)\ngmm.fit(X)\nlabels = gmm.predict(X)\n</code></pre>"},{"location":"machine/interview/#6_8","title":"6\ufe0f\u20e3 \u6a21\u578b\u4f18\u5316","text":"<ol> <li> <p>K \u503c\u9009\u62e9\uff08K-Means/GMM\uff09\uff1a</p> <ul> <li>\u8098\u90e8\u6cd5\uff08Elbow Method\uff09</li> <li>\u8f6e\u5ed3\u7cfb\u6570\u6700\u5927\u5316</li> </ul> </li> <li> <p>\u7279\u5f81\u7f29\u653e\uff1a</p> <ul> <li>\u805a\u7c7b\u5bf9\u5c3a\u5ea6\u654f\u611f\uff0c\u5efa\u8bae\u6807\u51c6\u5316\uff08StandardScaler\uff09</li> </ul> </li> <li> <p>\u521d\u59cb\u5316\u4f18\u5316\uff1a</p> <ul> <li>K-Means++ \u521d\u59cb\u5316\u8d28\u5fc3</li> </ul> </li> <li> <p>\u5f02\u5e38\u503c\u5904\u7406\uff1a</p> <ul> <li>\u5bc6\u5ea6\u7c7b\u7b97\u6cd5\uff08DBSCAN\uff09\u53ef\u5904\u7406\u566a\u58f0</li> </ul> </li> <li> <p>\u964d\u7ef4\uff1a</p> <ul> <li>PCA / t-SNE / UMAP \u7528\u4e8e\u9ad8\u7ef4\u6570\u636e\u53ef\u89c6\u5316\u6216\u964d\u7ef4\u805a\u7c7b</li> </ul> </li> </ol>"},{"location":"machine/interview/#7_7","title":"7\ufe0f\u20e3 \u6ce8\u610f\u4e8b\u9879","text":"<ul> <li>K-Means \u5bf9\u521d\u59cb\u8d28\u5fc3\u654f\u611f\uff0c\u53ef\u80fd\u9677\u5165\u5c40\u90e8\u6700\u4f18</li> <li>K-Means \u5047\u8bbe\u7c07\u4e3a\u51f8\u5f62\uff0c\u65e0\u6cd5\u5904\u7406\u4efb\u610f\u5f62\u72b6\u7c07</li> <li>DBSCAN \u5bf9\u53c2\u6570\uff08eps, min_samples\uff09\u654f\u611f</li> <li>GMM \u5047\u8bbe\u6570\u636e\u7b26\u5408\u9ad8\u65af\u5206\u5e03</li> <li>\u9ad8\u7ef4\u6570\u636e\u6613\u53d7\u201c\u7ef4\u5ea6\u707e\u96be\u201d\u5f71\u54cd</li> <li>\u805a\u7c7b\u7ed3\u679c\u53ef\u80fd\u4e0d\u552f\u4e00\uff0c\u9700\u8981\u591a\u6b21\u5c1d\u8bd5</li> </ul>"},{"location":"machine/interview/#8_7","title":"8\ufe0f\u20e3 \u4f18\u7f3a\u70b9","text":"\u4f18\u70b9 \u7f3a\u70b9 \u65e0\u9700\u6807\u7b7e\uff0c\u9002\u5408\u65e0\u76d1\u7763\u4efb\u52a1 \u7ed3\u679c\u4f9d\u8d56\u7b97\u6cd5\u548c\u53c2\u6570\u9009\u62e9 \u53ef\u53d1\u73b0\u9690\u85cf\u7ed3\u6784 K-Means \u5047\u8bbe\u7c07\u4e3a\u7403\u5f62 DBSCAN \u80fd\u53d1\u73b0\u4efb\u610f\u5f62\u72b6\u7c07 \u9ad8\u7ef4\u6570\u636e\u6548\u679c\u5dee\uff08\u9700\u964d\u7ef4\uff09 \u7b97\u6cd5\u79cd\u7c7b\u4e30\u5bcc\uff0c\u53ef\u9009\u6027\u5f3a \u5bf9\u566a\u58f0\u548c\u5f02\u5e38\u503c\u654f\u611f\uff08\u90e8\u5206\u7b97\u6cd5\uff09 \u53ef\u7ed3\u5408\u964d\u7ef4\u65b9\u6cd5\u53ef\u89c6\u5316\u6570\u636e \u805a\u7c7b\u7ed3\u679c\u89e3\u91ca\u6027\u6709\u9650"},{"location":"machine/interview/#122","title":"12.2 \u964d\u7ef4","text":""},{"location":"machine/interview/#1_24","title":"1\ufe0f\u20e3 \u539f\u7406","text":"<p>\u964d\u7ef4\u6307\u5c06\u9ad8\u7ef4\u6570\u636e\u6620\u5c04\u5230\u4f4e\u7ef4\u7a7a\u95f4\uff0c\u540c\u65f6\u5c3d\u91cf\u4fdd\u7559\u539f\u59cb\u6570\u636e\u7684\u4e3b\u8981\u7279\u5f81\u4fe1\u606f\u3002 \u76ee\u7684\u5305\u62ec\uff1a</p> <ul> <li>\u53bb\u566a\uff1a\u53bb\u9664\u5197\u4f59\u7279\u5f81</li> <li>\u53ef\u89c6\u5316\uff1a\u5c06\u9ad8\u7ef4\u6570\u636e\u6620\u5c04\u5230 2D \u6216 3D \u4fbf\u4e8e\u5c55\u793a</li> <li>\u51cf\u5c11\u8ba1\u7b97\u91cf\uff1a\u964d\u4f4e\u7b97\u6cd5\u590d\u6742\u5ea6</li> <li>\u7f13\u89e3\u7ef4\u5ea6\u707e\u96be\uff1a\u9ad8\u7ef4\u7a7a\u95f4\u4e2d\u6570\u636e\u7a00\u758f\uff0c\u964d\u4f4e\u6a21\u578b\u8fc7\u62df\u5408\u98ce\u9669</li> </ul> <p>\u5e38\u89c1\u65b9\u6cd5\u5206\u7c7b\uff1a</p> \u7c7b\u578b \u65b9\u6cd5 \u7279\u70b9 \u7ebf\u6027\u964d\u7ef4 PCA\uff08\u4e3b\u6210\u5206\u5206\u6790\uff09\u3001LDA\uff08\u7ebf\u6027\u5224\u522b\u5206\u6790\uff09 \u7b80\u5355\u3001\u6548\u7387\u9ad8\uff0c\u5047\u8bbe\u6570\u636e\u7ebf\u6027\u7ed3\u6784 \u975e\u7ebf\u6027\u964d\u7ef4 t-SNE\u3001UMAP\u3001Isomap\u3001Kernel PCA \u9002\u5408\u590d\u6742\u7ed3\u6784\uff0c\u9ad8\u7ef4\u975e\u7ebf\u6027\u5173\u7cfb"},{"location":"machine/interview/#2_23","title":"2\ufe0f\u20e3 \u635f\u5931\u51fd\u6570","text":""},{"location":"machine/interview/#21-pca","title":"2.1 PCA","text":"<ul> <li>\u76ee\u6807\u662f\u4fdd\u7559\u65b9\u5dee\u6700\u5927\uff1a   $$   \\max_{W} \\text{Tr}(W^T S W)   $$</li> <li>\\(S\\)\uff1a\u6570\u636e\u534f\u65b9\u5dee\u77e9\u9635</li> <li>\\(W\\)\uff1a\u964d\u7ef4\u6295\u5f71\u77e9\u9635</li> <li>\u7b49\u4ef7\u4e8e\u6700\u5c0f\u5316\u91cd\u6784\u8bef\u5dee\uff1a   $$   J = \\sum_{i=1}^{n} |x_i - \\hat{x}i|^2 = \\sum{i=1}^{n} |x_i - WW^T x_i|^2   $$</li> </ul>"},{"location":"machine/interview/#22-lda","title":"2.2 LDA","text":"<ul> <li>\u76ee\u6807\u662f\u6700\u5927\u5316\u7c7b\u95f4\u6563\u5ea6/\u7c7b\u5185\u6563\u5ea6\u6bd4\uff1a   $$   J(W) = \\frac{|W^T S_B W|}{|W^T S_W W|}   $$</li> <li>\\(S_B\\)\uff1a\u7c7b\u95f4\u6563\u5ea6\u77e9\u9635</li> <li>\\(S_W\\)\uff1a\u7c7b\u5185\u6563\u5ea6\u77e9\u9635</li> </ul>"},{"location":"machine/interview/#23-t-sne-umap","title":"2.3 t-SNE / UMAP","text":"<ul> <li> <p>t-SNE\uff1a\u6700\u5c0f\u5316\u9ad8\u7ef4\u6982\u7387\u5206\u5e03 \\(P\\) \u4e0e\u4f4e\u7ef4\u6982\u7387\u5206\u5e03 \\(Q\\) \u7684 KL \u6563\u5ea6\uff1a   $$   C = KL(P|Q) = \\sum_i \\sum_j p_{ij} \\log \\frac{p_{ij}}{q_{ij}}   $$</p> </li> <li> <p>UMAP\uff1a\u6700\u5c0f\u5316\u56fe\u7684\u4ea4\u53c9\u71b5\u635f\u5931\uff0c\u4fdd\u6301\u5c40\u90e8\u90bb\u57df\u7ed3\u6784\u3002</p> </li> </ul>"},{"location":"machine/interview/#3_15","title":"3\ufe0f\u20e3 \u6570\u5b66\u63a8\u5bfc\u8fc7\u7a0b","text":""},{"location":"machine/interview/#31-pca","title":"3.1 PCA","text":"<ol> <li>\u6570\u636e\u4e2d\u5fc3\u5316\uff1a    $$    X \\leftarrow X - \\bar{X}    $$</li> <li>\u8ba1\u7b97\u534f\u65b9\u5dee\u77e9\u9635\uff1a    $$    S = \\frac{1}{n} X^T X    $$</li> <li>\u7279\u5f81\u503c\u5206\u89e3\uff1a    $$    S W = W \\Lambda    $$</li> <li>\u9009\u62e9\u524d \\(k\\) \u4e2a\u6700\u5927\u7279\u5f81\u503c\u5bf9\u5e94\u7684\u7279\u5f81\u5411\u91cf \\(W_k\\)\uff0c\u6295\u5f71\uff1a    $$    Z = X W_k    $$</li> </ol>"},{"location":"machine/interview/#32-lda","title":"3.2 LDA","text":"<ol> <li>\u8ba1\u7b97\u7c7b\u5185\u6563\u5ea6\u77e9\u9635 \\(S_W\\)\uff1a    $$    S_W = \\sum_{c=1}^{C} \\sum_{x_i \\in c} (x_i - \\mu_c)(x_i - \\mu_c)^T    $$</li> <li>\u8ba1\u7b97\u7c7b\u95f4\u6563\u5ea6\u77e9\u9635 \\(S_B\\)\uff1a    $$    S_B = \\sum_{c=1}^{C} n_c (\\mu_c - \\mu)(\\mu_c - \\mu)^T    $$</li> <li>\u6c42\u5e7f\u4e49\u7279\u5f81\u503c\u95ee\u9898\uff1a    $$    S_B W = \\Lambda S_W W    $$</li> <li>\u6295\u5f71\uff1a    $$    Z = X W    $$</li> </ol>"},{"location":"machine/interview/#4_14","title":"4\ufe0f\u20e3 \u8bc4\u4f30\u6307\u6807","text":"<ul> <li>\u4fdd\u7559\u65b9\u5dee\uff08Explained Variance\uff09\uff08PCA\uff09\uff1a   $$   \\text{Explained Variance Ratio} = \\frac{\\sum_{i=1}^k \\lambda_i}{\\sum_{i=1}^d \\lambda_i}   $$</li> <li>\u91cd\u6784\u8bef\u5dee\uff08Reconstruction Error\uff09</li> <li>\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\uff1a\u964d\u7ef4\u540e\u6570\u636e\u5728\u5206\u7c7b/\u56de\u5f52\u4e0a\u7684\u51c6\u786e\u7387\u6216 \\(R^2\\)</li> <li>\u805a\u7c7b\u4fdd\u771f\u5ea6\uff1a\u964d\u7ef4\u540e\u805a\u7c7b\u8d28\u91cf\uff08\u8f6e\u5ed3\u7cfb\u6570\uff09</li> </ul>"},{"location":"machine/interview/#5_9","title":"5\ufe0f\u20e3 \u5b9e\u73b0\u4ee3\u7801","text":""},{"location":"machine/interview/#51-pca","title":"5.1 PCA","text":"<pre><code>from sklearn.decomposition import PCA\nfrom sklearn.datasets import load_iris\n\ndata = load_iris()\nX = data.data\n\npca = PCA(n_components=2)\nX_reduced = pca.fit_transform(X)\n\nprint(\"\u4fdd\u7559\u65b9\u5dee\u6bd4:\", pca.explained_variance_ratio_)\n</code></pre>"},{"location":"machine/interview/#52-lda","title":"5.2 LDA","text":"<pre><code>from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n\ny = data.target\nlda = LDA(n_components=2)\nX_lda = lda.fit_transform(X, y)\n</code></pre>"},{"location":"machine/interview/#53-t-sne","title":"5.3 t-SNE","text":"<pre><code>from sklearn.manifold import TSNE\n\ntsne = TSNE(n_components=2, random_state=42)\nX_tsne = tsne.fit_transform(X)\n</code></pre>"},{"location":"machine/interview/#6_9","title":"6\ufe0f\u20e3 \u6a21\u578b\u4f18\u5316","text":"<ul> <li> <p>\u9009\u62e9\u964d\u7ef4\u7ef4\u5ea6 \\(k\\)\uff1a</p> <ul> <li>PCA\uff1a\u7d2f\u8ba1\u65b9\u5dee &gt; 90%</li> <li>LDA\uff1a\u6700\u591a \\(C-1\\) \u7ef4\uff08\u7c7b\u522b\u6570 - 1\uff09</li> </ul> </li> <li> <p>\u6807\u51c6\u5316\uff1a</p> <ul> <li>PCA\u3001LDA \u5bf9\u5c3a\u5ea6\u654f\u611f\uff0c\u5148\u6807\u51c6\u5316\u6216\u5f52\u4e00\u5316</li> </ul> </li> <li> <p>\u975e\u7ebf\u6027\u65b9\u6cd5\uff1a</p> <ul> <li>t-SNE/UMAP \u53c2\u6570\u8c03\u8282\uff1a<code>perplexity</code>\u3001<code>learning_rate</code>\u3001\u90bb\u57df\u5927\u5c0f</li> </ul> </li> <li> <p>\u964d\u566a\u5904\u7406\uff1a</p> <ul> <li>\u53ef\u5148 PCA \u964d\u566a\uff0c\u518d\u4f7f\u7528 t-SNE \u53ef\u89c6\u5316</li> </ul> </li> </ul>"},{"location":"machine/interview/#7_8","title":"7\ufe0f\u20e3 \u6ce8\u610f\u4e8b\u9879","text":"<ul> <li>PCA \u5047\u8bbe\u6570\u636e\u7ebf\u6027\u53ef\u5206\uff0c\u5bf9\u975e\u7ebf\u6027\u7ed3\u6784\u53ef\u80fd\u5931\u6548</li> <li>LDA \u9700\u8981\u6807\u7b7e\u4fe1\u606f\uff0c\u4ec5\u7528\u4e8e\u6709\u76d1\u7763\u964d\u7ef4</li> <li>t-SNE \u968f\u673a\u6027\u8f83\u5927\uff0c\u9700\u8bbe\u7f6e <code>random_state</code></li> <li>\u975e\u7ebf\u6027\u65b9\u6cd5\u8ba1\u7b97\u91cf\u5927\uff0c\u9002\u5408\u4e2d\u5c0f\u578b\u6570\u636e</li> <li>\u9ad8\u7ef4\u7a00\u758f\u6570\u636e\u9700\u5148\u8003\u8651\u7a00\u758f\u6027\u5904\u7406</li> </ul>"},{"location":"machine/interview/#8_8","title":"8\ufe0f\u20e3 \u4f18\u7f3a\u70b9","text":"\u4f18\u70b9 \u7f3a\u70b9 \u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6 \u53ef\u80fd\u4e22\u5931\u90e8\u5206\u4fe1\u606f \u53bb\u566a\u3001\u51cf\u5c11\u5197\u4f59 \u975e\u7ebf\u6027\u65b9\u6cd5\u96be\u4ee5\u89e3\u91ca \u53ef\u89c6\u5316\u9ad8\u7ef4\u6570\u636e \u90e8\u5206\u65b9\u6cd5\u53c2\u6570\u654f\u611f\uff08t-SNE/UMAP\uff09 \u7f13\u89e3\u7ef4\u5ea6\u707e\u96be\uff0c\u6539\u5584\u6a21\u578b\u6cdb\u5316 \u9ad8\u7ef4\u6570\u636e\u4ecd\u9700\u6807\u51c6\u5316 \u53ef\u7ed3\u5408\u4e0b\u6e38\u4efb\u52a1\u63d0\u9ad8\u6027\u80fd LDA \u53d7\u7c7b\u522b\u4e0d\u5e73\u8861\u5f71\u54cd\u8f83\u5927"},{"location":"machine/interview/#_120","title":"\u5341\u4e09\u3001 \u6982\u7387\u6a21\u578b","text":""},{"location":"machine/interview/#131","title":"13.1 \u6734\u7d20\u8d1d\u53f6\u65af","text":""},{"location":"machine/interview/#1_25","title":"1\ufe0f\u20e3 \u539f\u7406","text":"<p>\u6734\u7d20\u8d1d\u53f6\u65af\u662f\u4e00\u79cd\u57fa\u4e8e\u6982\u7387\u7684\u5206\u7c7b\u65b9\u6cd5\uff0c\u6838\u5fc3\u601d\u60f3\u662f\uff1a</p> <ol> <li> <p>\u8d1d\u53f6\u65af\u5b9a\u7406\uff1a    $$    P(y|x) = \\frac{P(x|y)P(y)}{P(x)}    $$</p> </li> <li> <p>\\(P(y|x)\\)\uff1a\u540e\u9a8c\u6982\u7387</p> </li> <li>\\(P(y)\\)\uff1a\u5148\u9a8c\u6982\u7387</li> <li> <p>\\(P(x|y)\\)\uff1a\u4f3c\u7136\u6982\u7387</p> </li> <li> <p>\u6734\u7d20\u5047\u8bbe\uff1a\u5047\u8bbe\u7279\u5f81\u6761\u4ef6\u72ec\u7acb\uff1a    $$    P(x|y) = \\prod_{i=1}^{n} P(x_i | y)    $$</p> </li> <li> <p>\u5206\u7c7b\u51b3\u7b56\uff1a    $$    \\hat{y} = \\arg\\max_y P(y) \\prod_{i=1}^{n} P(x_i | y)    $$</p> </li> </ol>"},{"location":"machine/interview/#_121","title":"\u7279\u70b9","text":"<ul> <li>\u975e\u5e38\u7b80\u5355\u9ad8\u6548</li> <li>\u9002\u7528\u4e8e\u6587\u672c\u5206\u7c7b\u3001\u5783\u573e\u90ae\u4ef6\u8bc6\u522b\u3001\u60c5\u611f\u5206\u6790\u7b49</li> <li>\u5bf9\u5c0f\u6837\u672c\u4e5f\u80fd\u5de5\u4f5c\u826f\u597d</li> </ul>"},{"location":"machine/interview/#2_24","title":"2\ufe0f\u20e3 \u635f\u5931\u51fd\u6570","text":"<p>\u6734\u7d20\u8d1d\u53f6\u65af\u901a\u5e38\u662f\u6982\u7387\u6a21\u578b\uff0c\u8bad\u7ec3\u65f6\u4e0d\u663e\u5f0f\u4f18\u5316\u4f20\u7edf\u635f\u5931\u51fd\u6570\uff0c\u4f46\u53ef\u89c6\u4e3a\u6700\u5927\u5316\u4f3c\u7136\u51fd\u6570\uff08MLE, Maximum Likelihood Estimation\uff09\uff1a</p> \\[ \\mathcal{L}(\\theta) = \\prod_{i=1}^{N} P(y_i) \\prod_{j=1}^{n} P(x_{ij} | y_i) \\] <ul> <li>\u5bf9\u6570\u4f3c\u7136\uff1a   $$   \\log \\mathcal{L}(\\theta) = \\sum_{i=1}^{N} \\log P(y_i) + \\sum_{i=1}^{N} \\sum_{j=1}^{n} \\log P(x_{ij} | y_i)   $$</li> </ul> <p>\u8bad\u7ec3\u76ee\u6807\uff1a\u6700\u5927\u5316\u5bf9\u6570\u4f3c\u7136\uff0c\u5f97\u5230 \\(P(y)\\) \u548c \\(P(x_i|y)\\)\u3002</p>"},{"location":"machine/interview/#3_16","title":"3\ufe0f\u20e3 \u6570\u5b66\u63a8\u5bfc\u8fc7\u7a0b","text":""},{"location":"machine/interview/#31_2","title":"3.1 \u5206\u7c7b\u516c\u5f0f","text":"<ol> <li> <p>\u5148\u9a8c\u6982\u7387\uff1a    $$    P(y=c) = \\frac{\\text{\u6837\u672c\u6570}(y=c)}{\\text{\u603b\u6837\u672c\u6570}}    $$</p> </li> <li> <p>\u4f3c\u7136\u6982\u7387\uff1a</p> </li> <li> <p>\u79bb\u6563\u7279\u5f81\uff08\u591a\u9879\u5f0f NB\uff09\uff1a   $$   P(x_i = k | y=c) = \\frac{\\text{\u7279\u5f81 } x_i \\text{ \u5728\u7c7b } c \\text{ \u4e2d\u51fa\u73b0\u6b21\u6570} + \\alpha}{\\text{\u7c7b } c \\text{ \u603b\u6b21\u6570} + \\alpha \\cdot n_i}   $$</p> </li> <li> <p>\\(\\alpha\\)\uff1a\u5e73\u6ed1\u53c2\u6570\uff08Laplace \u5e73\u6ed1\uff09\uff0c\u907f\u514d\u96f6\u6982\u7387</p> </li> <li> <p>\u8fde\u7eed\u7279\u5f81\uff08\u9ad8\u65af NB\uff09\uff1a   $$   P(x_i | y=c) = \\frac{1}{\\sqrt{2\\pi \\sigma_{c,i}^2}} \\exp\\Big(-\\frac{(x_i - \\mu_{c,i})^2}{2\\sigma_{c,i}^2}\\Big)   $$</p> </li> <li> <p>\u9884\u6d4b\uff1a    $$    \\hat{y} = \\arg\\max_c P(y=c) \\prod_{i=1}^n P(x_i|y=c)    $$</p> </li> </ol>"},{"location":"machine/interview/#4_15","title":"4\ufe0f\u20e3 \u8bc4\u4f30\u6307\u6807","text":"<ul> <li>\u5206\u7c7b\u51c6\u786e\u7387\uff08Accuracy\uff09\uff1a   $$   \\text{Accuracy} = \\frac{\\text{\u9884\u6d4b\u6b63\u786e\u6570}}{\\text{\u603b\u6837\u672c\u6570}}   $$</li> <li>\u7cbe\u786e\u7387\u3001\u53ec\u56de\u7387\u3001F1-score</li> <li>\u6df7\u6dc6\u77e9\u9635</li> <li>\u5bf9\u591a\u5206\u7c7b\u95ee\u9898\u4e5f\u9002\u7528</li> </ul>"},{"location":"machine/interview/#5_10","title":"5\ufe0f\u20e3 \u5b9e\u73b0\u4ee3\u7801","text":""},{"location":"machine/interview/#51_1","title":"5.1 \u591a\u9879\u5f0f\u6734\u7d20\u8d1d\u53f6\u65af\uff08\u6587\u672c\u5206\u7c7b\u5e38\u7528\uff09","text":"<pre><code>from sklearn.datasets import fetch_20newsgroups\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# \u6570\u636e\ndata = fetch_20newsgroups(subset='all', categories=['sci.space','rec.sport.baseball'])\nX_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2, random_state=42)\n\n# \u7279\u5f81\u63d0\u53d6\nvectorizer = CountVectorizer()\nX_train_vec = vectorizer.fit_transform(X_train)\nX_test_vec = vectorizer.transform(X_test)\n\n# \u6a21\u578b\u8bad\u7ec3\nnb = MultinomialNB(alpha=1.0)\nnb.fit(X_train_vec, y_train)\n\n# \u9884\u6d4b\ny_pred = nb.predict(X_test_vec)\n\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(classification_report(y_test, y_pred))\n</code></pre>"},{"location":"machine/interview/#52_1","title":"5.2 \u9ad8\u65af\u6734\u7d20\u8d1d\u53f6\u65af\uff08\u8fde\u7eed\u7279\u5f81\uff09","text":"<pre><code>from sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import accuracy_score\n\ndata = load_iris()\nX_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2, random_state=42)\n\ngnb = GaussianNB()\ngnb.fit(X_train, y_train)\ny_pred = gnb.predict(X_test)\n\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\n</code></pre>"},{"location":"machine/interview/#6_10","title":"6\ufe0f\u20e3 \u6a21\u578b\u4f18\u5316","text":"<ul> <li>\u7279\u5f81\u9009\u62e9\uff1a\u53bb\u6389\u5197\u4f59\u6216\u9ad8\u5ea6\u76f8\u5173\u7279\u5f81</li> <li>\u5e73\u6ed1\u53c2\u6570 \\(\\alpha\\)\uff1a\u9632\u6b62\u96f6\u6982\u7387\u95ee\u9898</li> <li>\u7c7b\u522b\u5e73\u8861\uff1a\u6837\u672c\u4e0d\u5747\u8861\u65f6\u53ef\u52a0\u6743</li> <li>\u6570\u636e\u6e05\u6d17\uff1a\u51cf\u5c11\u566a\u58f0\uff0c\u63d0\u9ad8\u4f3c\u7136\u4f30\u8ba1\u7cbe\u5ea6</li> </ul>"},{"location":"machine/interview/#7_9","title":"7\ufe0f\u20e3 \u6ce8\u610f\u4e8b\u9879","text":"<ul> <li>\u5047\u8bbe\u7279\u5f81\u6761\u4ef6\u72ec\u7acb\uff0c\u82e5\u7279\u5f81\u76f8\u5173\u6027\u5f3a\u53ef\u80fd\u5f71\u54cd\u6027\u80fd</li> <li>\u5bf9\u8fde\u7eed\u7279\u5f81\u9700\u9009\u62e9\u5408\u9002\u5206\u5e03\uff08\u9ad8\u65af NB \u5e38\u7528\uff09</li> <li>\u5bf9\u7a00\u758f\u7279\u5f81\uff08\u5982\u6587\u672c\uff09\u6548\u679c\u975e\u5e38\u597d</li> <li>\u5bf9\u5c0f\u6837\u672c\u8868\u73b0\u7a33\u5065</li> <li>\u8f93\u51fa\u6982\u7387\u53ef\u76f4\u63a5\u7528\u4e8e\u51b3\u7b56\u9608\u503c\u8c03\u6574</li> </ul>"},{"location":"machine/interview/#8_9","title":"8\ufe0f\u20e3 \u4f18\u7f3a\u70b9","text":"\u4f18\u70b9 \u7f3a\u70b9 \u7b80\u5355\u9ad8\u6548\uff0c\u8bad\u7ec3\u5feb \u6761\u4ef6\u72ec\u7acb\u5047\u8bbe\u4e0d\u6210\u7acb\u53ef\u80fd\u964d\u4f4e\u7cbe\u5ea6 \u5bf9\u5c0f\u6837\u672c\u6570\u636e\u6709\u6548 \u5bf9\u7279\u5f81\u76f8\u5173\u6027\u654f\u611f \u53ef\u8f93\u51fa\u7c7b\u522b\u6982\u7387 \u5bf9\u8fde\u7eed\u7279\u5f81\u9700\u5206\u5e03\u5047\u8bbe \u6587\u672c\u5206\u7c7b\u6548\u679c\u4f18 \u4e0d\u9002\u5408\u590d\u6742\u975e\u7ebf\u6027\u8fb9\u754c\u95ee\u9898 \u53c2\u6570\u5c11\uff0c\u65e0\u9700\u8c03\u53c2 \u6570\u636e\u7a00\u758f\u5ea6\u4f4e\u65f6\u6027\u80fd\u4e0b\u964d"},{"location":"machine/interview/#_122","title":"\u5341\u56db\u3001\u5176\u4ed6\u95ee\u9898","text":""},{"location":"nlp/chart01/","title":"\u7b2c 1 \u7ae0 : \u6587\u672c\u8868\u793a\u4e0e\u8bcd\u5411\u91cf","text":"<p>\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff08NLP\uff09\u7684\u7b2c\u4e00\u6b65\u662f\u628a\u6587\u672c\u8f6c\u6362\u4e3a\u8ba1\u7b97\u673a\u53ef\u4ee5\u7406\u89e3\u7684\u5f62\u5f0f\uff0c\u4e5f\u5c31\u662f\u6570\u5b57\u8868\u793a\u3002\u7b2c 1 \u7ae0\u4f1a\u5e26\u4f60\u4ece\u6700\u7b80\u5355\u7684\u6587\u672c\u7f16\u7801\u5f00\u59cb\uff0c\u4e00\u6b65\u6b65\u7406\u89e3\u4e3a\u4ec0\u4e48\u8981\u7528\u8bcd\u5411\u91cf\uff0c\u4ee5\u53ca\u5982\u4f55\u8bad\u7ec3\u548c\u4f7f\u7528\u5b83\u4eec\u3002</p>"},{"location":"nlp/chart01/#11","title":"1.1 \u5b66\u4e60\u76ee\u6807","text":"<p>\u5b8c\u6210\u672c\u7ae0\u540e\uff0c\u4f60\u5c06\u80fd\uff1a</p> <ol> <li>\u7406\u89e3\u6587\u672c\u6570\u5b57\u5316\u7684\u6982\u5ff5</li> <li>\u638c\u63e1 One-Hot\u3001TF-IDF\u3001Word2Vec \u7b49\u6587\u672c\u8868\u793a\u65b9\u6cd5</li> <li>\u7406\u89e3 Word2Vec \u7684 CBOW \u548c Skip-gram \u539f\u7406</li> <li>\u80fd\u7528 Python \u5b9e\u73b0\u6587\u672c\u8868\u793a\u548c\u8bcd\u5411\u91cf\u8bad\u7ec3</li> <li>\u53ef\u89c6\u5316\u8bcd\u5411\u91cf\uff0c\u7406\u89e3\u8bed\u4e49\u5173\u7cfb</li> </ol>"},{"location":"nlp/chart01/#12","title":"1.2 \u6587\u672c\u6570\u5b57\u5316\u7684\u6982\u5ff5","text":""},{"location":"nlp/chart01/#_1","title":"\u4e3a\u4ec0\u4e48\u8981\u6570\u5b57\u5316","text":"<p>\u8ba1\u7b97\u673a\u53ea\u80fd\u7406\u89e3\u6570\u5b57\uff0c\u800c\u6587\u672c\u662f\u5b57\u7b26\u7ec4\u6210\u7684\u81ea\u7136\u8bed\u8a00\u3002\u4e3a\u4e86\u8ba9\u6a21\u578b\u5904\u7406\u6587\u672c\uff0c\u9700\u8981\u628a\u8bcd\u6216\u53e5\u5b50\u8868\u793a\u4e3a\u6570\u503c\u3002</p> <p>\u6587\u672c\u8868\u793a\u7684\u8d28\u91cf\u76f4\u63a5\u5f71\u54cd NLP \u6a21\u578b\u7684\u6027\u80fd\uff1a</p> <ul> <li>\u7b80\u5355\u8868\u793a\uff08One-Hot\uff09\u6613\u5b9e\u73b0\uff0c\u4f46\u65e0\u6cd5\u6355\u6349\u8bed\u4e49</li> <li>\u7a20\u5bc6\u8868\u793a\uff08Word2Vec / GloVe\uff09\u53ef\u4ee5\u8868\u8fbe\u8bcd\u4e4b\u95f4\u7684\u76f8\u4f3c\u6027</li> </ul>"},{"location":"nlp/chart01/#_2","title":"\u6587\u672c\u8868\u793a\u65b9\u5f0f\u6982\u89c8","text":"\u65b9\u6cd5 \u6838\u5fc3\u601d\u60f3 \u4f18\u70b9 \u7f3a\u70b9 One-Hot \u6bcf\u4e2a\u8bcd\u4e00\u4e2a\u552f\u4e00\u5411\u91cf \u7b80\u5355\uff0c\u6613\u5b9e\u73b0 \u9ad8\u7ef4\u7a00\u758f\uff0c\u65e0\u6cd5\u8868\u8fbe\u8bed\u4e49 TF-IDF \u57fa\u4e8e\u8bcd\u9891\u548c\u9006\u6587\u6863\u9891\u7387 \u5f3a\u8c03\u533a\u5206\u8bcd \u65e0\u4e0a\u4e0b\u6587\u4fe1\u606f Word2Vec / GloVe \u5c06\u8bcd\u5d4c\u5165\u4f4e\u7ef4\u5411\u91cf\u7a7a\u95f4 \u6355\u83b7\u8bed\u4e49\u5173\u7cfb \u9700\u8981\u8bad\u7ec3\u8bed\u6599"},{"location":"nlp/chart01/#13","title":"1.3 \u6587\u672c\u9884\u5904\u7406","text":"<p>\u5728\u6587\u672c\u8868\u793a\u4e4b\u524d\uff0c\u9700\u8981\u505a\u4e00\u4e9b\u6e05\u6d17\u548c\u5904\u7406\uff1a</p> <ol> <li>\u5206\u8bcd\uff1a\u628a\u53e5\u5b50\u62c6\u6210\u8bcd</li> <li>\u5c0f\u5199\u5316\uff1a\u82f1\u6587\u7edf\u4e00\u5c0f\u5199</li> <li>\u53bb\u6807\u70b9\u548c\u7279\u6b8a\u7b26\u53f7</li> <li>\u53bb\u505c\u7528\u8bcd\uff1a\u5220\u9664\u9ad8\u9891\u4f46\u65e0\u610f\u4e49\u8bcd\uff08\u5982 \"the\", \"is\"\uff09</li> <li>\u8bcd\u5f62\u8fd8\u539f\u6216\u8bcd\u5e72\u5316\uff08\u53ef\u9009\uff09</li> </ol> <p>\u793a\u4f8b\uff08\u82f1\u6587\u6587\u672c\uff09\uff1a</p> <pre><code>import nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\n\nnltk.download('punkt')\nnltk.download('stopwords')\n\ntext = \"Natural Language Processing (NLP) is fascinating and fun!\"\ntokens = word_tokenize(text.lower())  # \u5206\u8bcd\u5e76\u5c0f\u5199\u5316\nfiltered = [w for w in tokens if w.isalpha() and w not in stopwords.words('english')]\nprint(filtered)\n</code></pre> <p>\u8f93\u51fa\uff1a</p> <pre><code>['natural', 'language', 'processing', 'nlp', 'fascinating', 'fun']\n</code></pre>"},{"location":"nlp/chart01/#14-one-hot","title":"1.4 One-Hot \u8868\u793a","text":""},{"location":"nlp/chart01/#_3","title":"\u6982\u5ff5","text":"<ul> <li>\u4e3a\u6bcf\u4e2a\u8bcd\u5206\u914d\u552f\u4e00\u5411\u91cf</li> <li>\u5411\u91cf\u957f\u5ea6 = \u8bcd\u8868\u5927\u5c0f</li> <li>\u8be5\u8bcd\u4f4d\u7f6e\u4e3a 1\uff0c\u5176\u4f59\u4e3a 0</li> </ul>"},{"location":"nlp/chart01/#_4","title":"\u6570\u5b66\u8868\u793a","text":"\\[ \\text{one_hot}(w_i) = [0,0,...,1,...,0] \\]"},{"location":"nlp/chart01/#_5","title":"\u793a\u4f8b","text":"<p>\u8bcd\u8868\uff1a<code>[\"I\", \"love\", \"NLP\"]</code></p> \u8bcd One-Hot \"I\" [1,0,0] \"love\" [0,1,0] \"NLP\" [0,0,1]"},{"location":"nlp/chart01/#python","title":"Python \u5b9e\u73b0","text":"<pre><code>import numpy as np\n\nvocab = [\"I\", \"love\", \"NLP\"]\nword_to_idx = {word:i for i, word in enumerate(vocab)}\n\ndef one_hot(word):\n    vec = np.zeros(len(vocab))\n    vec[word_to_idx[word]] = 1\n    return vec\n\nprint(one_hot(\"love\"))  # \u8f93\u51fa: [0. 1. 0.]\n</code></pre> <p>\u7f3a\u70b9\uff1a\u9ad8\u7ef4\u7a00\u758f\uff0c\u65e0\u6cd5\u8868\u793a\u8bcd\u8bed\u4e4b\u95f4\u7684\u8bed\u4e49\u76f8\u4f3c\u6027\u3002</p>"},{"location":"nlp/chart01/#15-tf-idfterm-frequency-inverse-document-frequency","title":"1.5 TF-IDF\uff08Term Frequency - Inverse Document Frequency\uff09","text":""},{"location":"nlp/chart01/#_6","title":"\u6982\u5ff5","text":"<p>\u8861\u91cf\u8bcd\u5728\u6587\u6863\u4e2d\u7684\u91cd\u8981\u6027\uff1a</p> <ul> <li>TF\uff08\u8bcd\u9891\uff09\uff1a\u8bcd\u5728\u6587\u6863\u4e2d\u51fa\u73b0\u9891\u7387</li> <li>IDF\uff08\u9006\u6587\u6863\u9891\u7387\uff09\uff1a\u8bcd\u5728\u8bed\u6599\u4e2d\u51fa\u73b0\u8d8a\u9891\u7e41\uff0c\u6743\u91cd\u8d8a\u4f4e</li> </ul>"},{"location":"nlp/chart01/#_7","title":"\u6570\u5b66\u516c\u5f0f","text":"\\[ \\text{tf}(t,d) = \\frac{\\text{count}(t,d)}{\\text{total words in } d} \\] \\[ \\text{idf}(t) = \\log \\frac{N}{1 + df_t} \\] \\[ \\text{tfidf}(t,d) = \\text{tf}(t,d) \\times \\text{idf}(t) \\] <ul> <li>\\(N\\)\uff1a\u8bed\u6599\u5e93\u4e2d\u6587\u6863\u603b\u6570</li> <li>\\(df_t\\)\uff1a\u5305\u542b\u8bcd \\(t\\) \u7684\u6587\u6863\u6570</li> </ul>"},{"location":"nlp/chart01/#python_1","title":"Python \u793a\u4f8b","text":"<pre><code>from sklearn.feature_extraction.text import TfidfVectorizer\n\ndocs = [\"I love NLP\", \"NLP is fascinating\", \"I enjoy learning NLP\"]\nvectorizer = TfidfVectorizer()\nX = vectorizer.fit_transform(docs)\nprint(vectorizer.get_feature_names_out())\nprint(X.toarray())\n</code></pre> <p>\u4f18\u70b9\uff1a\u5f31\u5316\u9ad8\u9891\u8bcd\u5f71\u54cd \u7f3a\u70b9\uff1a\u65e0\u6cd5\u6355\u6349\u4e0a\u4e0b\u6587\u8bed\u4e49</p>"},{"location":"nlp/chart01/#16-word-embedding","title":"1.6 \u8bcd\u5411\u91cf\uff08Word Embedding\uff09","text":""},{"location":"nlp/chart01/#161","title":"1.6.1 \u6982\u5ff5","text":"<ul> <li>\u5c06\u8bcd\u6620\u5c04\u5230\u4f4e\u7ef4\u5411\u91cf\u7a7a\u95f4</li> <li>\u7a20\u5bc6\u5411\u91cf\u8868\u793a\uff0c\u80fd\u6355\u83b7\u8bed\u4e49\u76f8\u4f3c\u6027</li> <li>\u793a\u4f8b\uff1a</li> </ul> \\[ \\text{vec}(\"king\") - \\text{vec}(\"man\") + \\text{vec}(\"woman\") \\approx \\text{vec}(\"queen\") \\]"},{"location":"nlp/chart01/#162-word2vec","title":"1.6.2 Word2Vec \u539f\u7406","text":"<p>Word2Vec \u662f\u4e00\u79cd\u7ecf\u5178\u8bcd\u5d4c\u5165\u65b9\u6cd5\uff0c\u6709\u4e24\u79cd\u8bad\u7ec3\u7b56\u7565\uff1a</p> <ol> <li> <p>CBOW\uff08Continuous Bag-of-Words\uff09</p> </li> <li> <p>\u6839\u636e\u4e0a\u4e0b\u6587\u9884\u6d4b\u4e2d\u5fc3\u8bcd</p> </li> <li> <p>\u4e3e\u4f8b\uff1a\u53e5\u5b50 \u201cI love NLP\u201d</p> <ul> <li>\u4e0a\u4e0b\u6587 = [\"I\", \"NLP\"]</li> <li>\u4e2d\u5fc3\u8bcd = \"love\"</li> </ul> </li> </ol> <p>\u516c\u5f0f\uff1a</p> <p>$$    \\max \\sum_t \\log P(w_t | \\text{context}(w_t))    $$</p> <ol> <li> <p>Skip-gram</p> </li> <li> <p>\u6839\u636e\u4e2d\u5fc3\u8bcd\u9884\u6d4b\u4e0a\u4e0b\u6587</p> </li> <li>\u4e3e\u4f8b\uff1a\u4e2d\u5fc3\u8bcd = \"love\"\uff0c\u4e0a\u4e0b\u6587 = [\"I\", \"NLP\"]</li> </ol> <p>\u516c\u5f0f\uff1a</p> <p>$$    \\max \\sum_{t} \\sum_{-c \\le j \\le c, j\\ne 0} \\log P(w_{t+j}|w_t)    $$</p> <p>CBOW \u5bf9\u5c0f\u8bed\u6599\u8868\u73b0\u66f4\u7a33\u5b9a\uff0cSkip-gram \u5bf9\u4f4e\u9891\u8bcd\u66f4\u654f\u611f\u3002</p>"},{"location":"nlp/chart01/#163-word2vec-python","title":"1.6.3 Word2Vec Python \u5b9e\u73b0","text":"<pre><code>from gensim.models import Word2Vec\n\nsentences = [[\"I\",\"love\",\"nlp\"], [\"nlp\",\"is\",\"fun\"], [\"I\",\"enjoy\",\"learning\",\"nlp\"]]\n\n# Skip-gram \u6a21\u578b\u8bad\u7ec3\nmodel = Word2Vec(sentences, vector_size=50, window=2, min_count=1, sg=1, epochs=100)\n\n# \u67e5\u770b\u8bcd\u5411\u91cf\nprint(\"\u8bcd\u5411\u91cf nlp:\\n\", model.wv['nlp'])\n\n# \u627e\u76f8\u4f3c\u8bcd\nprint(\"\u4e0e nlp \u76f8\u4f3c\u7684\u8bcd:\", model.wv.most_similar('nlp'))\n</code></pre>"},{"location":"nlp/chart01/#164","title":"1.6.4 \u8bcd\u5411\u91cf\u53ef\u89c6\u5316","text":"<pre><code>from sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\n\nwords = ['I','love','nlp','fun','learning']\nvecs = [model.wv[w] for w in words]\n\npca = PCA(n_components=2)\nvecs_2d = pca.fit_transform(vecs)\n\nplt.figure(figsize=(6,6))\nfor i, word in enumerate(words):\n    plt.scatter(vecs_2d[i,0], vecs_2d[i,1])\n    plt.text(vecs_2d[i,0]+0.01, vecs_2d[i,1]+0.01, word)\nplt.show()\n</code></pre> <p>\u4f60\u4f1a\u770b\u5230\u8bed\u4e49\u76f8\u5173\u7684\u8bcd\u66f4\u63a5\u8fd1\uff0c\u6bd4\u5982 \u201cnlp\u201d \u548c \u201clearning\u201d\u3002</p>"},{"location":"nlp/chart01/#17","title":"1.7 \u672c\u7ae0\u5c0f\u7ed3","text":"<ol> <li>\u6587\u672c\u8868\u793a\u662f NLP \u7684\u57fa\u7840\uff0c\u5f71\u54cd\u6a21\u578b\u6548\u679c</li> <li>One-Hot \u548c TF-IDF \u7b80\u5355\uff0c\u4f46\u65e0\u6cd5\u6355\u6349\u8bed\u4e49</li> <li>Word2Vec\uff08CBOW / Skip-gram\uff09\u901a\u8fc7\u4e0a\u4e0b\u6587\u5b66\u4e60\u8bcd\u5411\u91cf</li> <li>\u8bcd\u5411\u91cf\u80fd\u5728\u4f4e\u7ef4\u7a7a\u95f4\u8868\u793a\u8bed\u4e49\u5173\u7cfb</li> <li>\u53ef\u89c6\u5316\u8bcd\u5411\u91cf\u5e2e\u52a9\u7406\u89e3\u8bed\u4e49\u8ddd\u79bb</li> </ol> <p>\u5982\u679c\u4f60\u5e0c\u671b\uff0c\u6211\u53ef\u4ee5\u63a5\u7740\u5e2e\u4f60\u751f\u6210 \u7b2c 1 \u7ae0\u5b8c\u6574 Jupyter Notebook \u7248\u672c\uff0c\u5305\u542b\uff1a</p> <ul> <li>\u6587\u672c\u9884\u5904\u7406</li> <li>One-Hot\u3001TF-IDF\u3001Word2Vec \u5b9e\u6218</li> <li>\u8bcd\u5411\u91cf\u53ef\u89c6\u5316</li> </ul> <p>\u8fd9\u6837\u4f60\u53ef\u4ee5\u76f4\u63a5\u8fd0\u884c\u3001\u4fee\u6539\u3001\u5b9e\u9a8c\uff0c\u5b66\u4e60\u4f53\u9a8c\u4f1a\u66f4\u76f4\u89c2\u3002</p> <p>\u4f60\u5e0c\u671b\u6211\u751f\u6210\u8fd9\u4e2a notebook \u5417\uff1f</p>"},{"location":"nlp/chart02/","title":"\u7b2c 2 \u7ae0 : RNN / LSTM \u5e8f\u5217\u6a21\u578b","text":"<p>\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4e2d\u7684\u8bb8\u591a\u4efb\u52a1\uff08\u5982\u6587\u672c\u751f\u6210\u3001\u673a\u5668\u7ffb\u8bd1\u3001\u60c5\u611f\u5206\u6790\uff09\u90fd\u9700\u8981\u5904\u7406\u5e8f\u5217\u6570\u636e\u3002RNN\uff08\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\uff09\u548c LSTM\uff08\u957f\u77ed\u671f\u8bb0\u5fc6\u7f51\u7edc\uff09\u662f\u7ecf\u5178\u7684\u5e8f\u5217\u6a21\u578b\uff0c\u7528\u4e8e\u6355\u6349\u6587\u672c\u7684\u65f6\u95f4\u4f9d\u8d56\u5173\u7cfb\u3002</p>"},{"location":"nlp/chart02/#21","title":"2.1 \u5b66\u4e60\u76ee\u6807","text":"<p>\u5b8c\u6210\u672c\u7ae0\u540e\uff0c\u4f60\u5c06\u80fd\u591f\uff1a</p> <ol> <li>\u7406\u89e3 RNN \u7684\u57fa\u672c\u7ed3\u6784\u548c\u539f\u7406</li> <li>\u638c\u63e1 LSTM \u89e3\u51b3\u957f\u5e8f\u5217\u4f9d\u8d56\u95ee\u9898\u7684\u65b9\u6cd5</li> <li>\u7406\u89e3 RNN / LSTM \u7684\u524d\u5411\u4f20\u64ad\u4e0e\u68af\u5ea6\u66f4\u65b0\u516c\u5f0f</li> <li>\u80fd\u7528 PyTorch \u5b9e\u73b0 RNN / LSTM\uff0c\u8fdb\u884c\u6587\u672c\u5206\u7c7b\u6216\u751f\u6210\u4efb\u52a1</li> <li>\u7406\u89e3\u68af\u5ea6\u6d88\u5931\u4e0e\u68af\u5ea6\u7206\u70b8\u95ee\u9898\uff0c\u5e76\u77e5\u9053\u5e38\u7528\u89e3\u51b3\u65b9\u6cd5</li> </ol>"},{"location":"nlp/chart02/#22-rnn","title":"2.2 \u5faa\u73af\u795e\u7ecf\u7f51\u7edc\uff08RNN\uff09","text":""},{"location":"nlp/chart02/#221-rnn","title":"2.2.1 RNN \u6982\u5ff5","text":"<p>RNN \u662f\u4e00\u79cd\u4e13\u95e8\u5904\u7406\u5e8f\u5217\u6570\u636e\u7684\u795e\u7ecf\u7f51\u7edc\uff1a</p> <ul> <li>\u5bf9\u8f93\u5165\u5e8f\u5217 \\(x_1, x_2, ..., x_T\\) \u9010\u6b65\u5904\u7406</li> <li>\u6bcf\u4e00\u6b65\u90fd\u6709\u4e00\u4e2a\u9690\u85cf\u72b6\u6001 \\(h_t\\) \u8bb0\u5fc6\u4e4b\u524d\u7684\u4fe1\u606f</li> <li>\u8f93\u51fa\u53ef\u4ee5\u662f\u6bcf\u4e00\u6b65\u7684 \\(y_t\\)\uff0c\u4e5f\u53ef\u4ee5\u53ea\u53d6\u6700\u540e\u4e00\u6b65</li> </ul> <p>RNN \u7ed3\u6784\u56fe\uff1a</p> <pre><code>x1 --&gt;[RNN]--&gt; h1 --&gt; y1\nx2 --&gt;[RNN]--&gt; h2 --&gt; y2\n...\nxT --&gt;[RNN]--&gt; hT --&gt; yT\n</code></pre>"},{"location":"nlp/chart02/#222-rnn","title":"2.2.2 RNN \u6570\u5b66\u516c\u5f0f","text":"<p>\u9690\u85cf\u72b6\u6001\u66f4\u65b0\uff1a</p> \\[ h_t = \\tanh(W_{xh} x_t + W_{hh} h_{t-1} + b_h) \\] <p>\u8f93\u51fa\u8ba1\u7b97\uff1a</p> \\[ y_t = W_{hy} h_t + b_y \\] <ul> <li>\\(x_t\\)\uff1a\u5f53\u524d\u8f93\u5165\u5411\u91cf</li> <li>\\(h_t\\)\uff1a\u5f53\u524d\u9690\u85cf\u72b6\u6001</li> <li>\\(h_{t-1}\\)\uff1a\u524d\u4e00\u6b65\u9690\u85cf\u72b6\u6001</li> <li>\\(W_{xh}, W_{hh}, W_{hy}\\)\uff1a\u6743\u91cd\u77e9\u9635</li> <li>\\(b_h, b_y\\)\uff1a\u504f\u7f6e</li> </ul> <p>\u76f4\u89c2\u7406\u89e3\uff1a\u6bcf\u4e2a \\(h_t\\) \u4e0d\u4ec5\u5305\u542b\u5f53\u524d\u8f93\u5165 \\(x_t\\) \u7684\u4fe1\u606f\uff0c\u8fd8\u8bb0\u4f4f\u524d\u9762\u6240\u6709\u6b65\u9aa4\u7684\u4fe1\u606f\u3002</p>"},{"location":"nlp/chart02/#223-rnn","title":"2.2.3 RNN \u7684\u8bad\u7ec3","text":"<p>\u4f7f\u7528 BPTT\uff08Backpropagation Through Time\uff09 \u8fdb\u884c\u68af\u5ea6\u66f4\u65b0\uff1a</p> \\[ \\frac{\\partial L}{\\partial W_{hh}} = \\sum_{t=1}^T \\frac{\\partial L}{\\partial h_t} \\prod_{k=1}^t \\frac{\\partial h_k}{\\partial h_{k-1}} \\] <ul> <li>\u957f\u5e8f\u5217\u4f1a\u5bfc\u81f4\u68af\u5ea6\u4e58\u79ef\u8fc7\u591a</li> <li>\u68af\u5ea6\u6d88\u5931\uff1a\\(\\prod \\partial h_k/\\partial h_{k-1} \\to 0\\)</li> <li>\u68af\u5ea6\u7206\u70b8\uff1a\\(\\prod \\partial h_k/\\partial h_{k-1} \\to \\infty\\)</li> </ul> <p>\u8fd9\u662f RNN \u96be\u4ee5\u6355\u6349\u957f\u8ddd\u79bb\u4f9d\u8d56\u7684\u539f\u56e0\u3002</p>"},{"location":"nlp/chart02/#224-rnn-python-pytorch","title":"2.2.4 RNN Python \u793a\u4f8b\uff08PyTorch\uff09","text":"<pre><code>import torch\nimport torch.nn as nn\n\n# \u5047\u8bbe\u8f93\u5165\u5e8f\u5217\u957f\u5ea6=5\uff0c\u8f93\u5165\u7ef4\u5ea6=10\uff0c\u9690\u85cf\u72b6\u6001=20\nrnn = nn.RNN(input_size=10, hidden_size=20, batch_first=True)\n\nx = torch.randn(3,5,10)  # batch_size=3\nout, h_n = rnn(x)\nprint(out.shape)  # (3, 5, 20)\nprint(h_n.shape)  # (1, 3, 20)\n</code></pre>"},{"location":"nlp/chart02/#23-lstm","title":"2.3 \u957f\u77ed\u671f\u8bb0\u5fc6\u7f51\u7edc\uff08LSTM\uff09","text":""},{"location":"nlp/chart02/#231-lstm","title":"2.3.1 LSTM \u6982\u5ff5","text":"<p>LSTM \u662f RNN \u7684\u6539\u8fdb\u7248\u672c\uff0c\u4e13\u95e8\u89e3\u51b3\u957f\u5e8f\u5217\u4f9d\u8d56\u95ee\u9898\uff1a</p> <ul> <li>\u5f15\u5165 \u8bb0\u5fc6\u5355\u5143 \\(C_t\\) \u4fdd\u5b58\u957f\u671f\u4fe1\u606f</li> <li>\u589e\u52a0\u4e09\u4e2a\u95e8\u63a7\u673a\u5236\uff1a\u9057\u5fd8\u95e8 \\(f_t\\)\u3001\u8f93\u5165\u95e8 \\(i_t\\)\u3001\u8f93\u51fa\u95e8 \\(o_t\\)</li> <li>\u63a7\u5236\u4fe1\u606f\u6d41\u52a8\uff0c\u9632\u6b62\u68af\u5ea6\u6d88\u5931</li> </ul>"},{"location":"nlp/chart02/#232-lstm","title":"2.3.2 LSTM \u516c\u5f0f","text":"<p>\u9057\u5fd8\u95e8\uff1a\u51b3\u5b9a\u4fdd\u7559\u591a\u5c11\u524d\u4e00\u72b6\u6001\u4fe1\u606f</p> \\[ f_t = \\sigma(W_f [h_{t-1}, x_t] + b_f) \\] <p>\u8f93\u5165\u95e8\uff1a\u51b3\u5b9a\u5f53\u524d\u8f93\u5165\u6709\u591a\u5c11\u66f4\u65b0\u5230\u8bb0\u5fc6\u5355\u5143</p> \\[ i_t = \\sigma(W_i [h_{t-1}, x_t] + b_i) \\] \\[ \\tilde{C}*t = \\tanh(W_C [h*{t-1}, x_t] + b_C) \\] <p>\u8bb0\u5fc6\u5355\u5143\u66f4\u65b0\uff1a</p> \\[ C_t = f_t \\odot C_{t-1} + i_t \\odot \\tilde{C}_t \\] <p>\u8f93\u51fa\u95e8\uff1a\u51b3\u5b9a\u8f93\u51fa\u9690\u85cf\u72b6\u6001 \\(h_t\\)</p> \\[ o_t = \\sigma(W_o [h_{t-1}, x_t] + b_o) \\] \\[ h_t = o_t \\odot \\tanh(C_t) \\] <ul> <li>\\(\\sigma\\)\uff1aSigmoid \u51fd\u6570</li> <li>\\(\\odot\\)\uff1a\u9010\u5143\u7d20\u4e58\u6cd5</li> <li>\\(C_t\\)\uff1a\u8bb0\u5fc6\u5355\u5143</li> <li>\\(h_t\\)\uff1a\u9690\u85cf\u72b6\u6001</li> </ul> <p>LSTM \u7684\u95e8\u63a7\u673a\u5236\u8ba9\u6a21\u578b\u53ef\u4ee5\u957f\u65f6\u95f4\u4fdd\u7559\u4fe1\u606f\uff0c\u89e3\u51b3 RNN \u7684\u68af\u5ea6\u6d88\u5931\u95ee\u9898\u3002</p>"},{"location":"nlp/chart02/#233-lstm-python-pytorch","title":"2.3.3 LSTM Python \u793a\u4f8b\uff08PyTorch\uff09","text":"<pre><code>import torch\nimport torch.nn as nn\n\n# \u8f93\u5165\u7ef4\u5ea6=10\uff0c\u9690\u85cf\u72b6\u6001=20\uff0c\u5e8f\u5217\u957f\u5ea6=5\nlstm = nn.LSTM(input_size=10, hidden_size=20, batch_first=True)\n\nx = torch.randn(3,5,10)  # batch_size=3\nout, (h_n, c_n) = lstm(x)\nprint(out.shape)  # (3, 5, 20)\nprint(h_n.shape)   # (1, 3, 20)\nprint(c_n.shape)   # (1, 3, 20)\n</code></pre>"},{"location":"nlp/chart02/#234-lstm","title":"2.3.4 LSTM \u7684\u76f4\u89c2\u7406\u89e3","text":"<ul> <li>\u8bb0\u5fc6\u5355\u5143 \\(C_t\\)\uff1a\u50cf\u4e00\u4e2a\u957f\u671f\u8bb0\u5fc6\uff0c\u51b3\u5b9a\u4fe1\u606f\u4fdd\u7559\u591a\u5c11</li> <li>\u9057\u5fd8\u95e8 \\(f_t\\)\uff1a\u4e22\u6389\u65e0\u5173\u4fe1\u606f</li> <li>\u8f93\u5165\u95e8 \\(i_t\\)\uff1a\u66f4\u65b0\u65b0\u4fe1\u606f</li> <li>\u8f93\u51fa\u95e8 \\(o_t\\)\uff1a\u51b3\u5b9a\u9690\u85cf\u72b6\u6001\u8f93\u51fa</li> </ul> <p>LSTM \u53ef\u4ee5\u6355\u6349\u6587\u672c\u4e2d\u7684\u957f\u8ddd\u79bb\u4f9d\u8d56\uff0c\u6bd4\u5982 \u201cThe movie that I watched yesterday was amazing\u201d \u4e2d\uff0c\u201cmovie\u201d \u548c \u201camazing\u201d \u7684\u5173\u7cfb\u3002</p>"},{"location":"nlp/chart02/#24-rnn-lstm","title":"2.4 RNN / LSTM \u7684\u5e94\u7528\u4e3e\u4f8b","text":"<ol> <li>\u6587\u672c\u5206\u7c7b\uff1a\u60c5\u611f\u5206\u6790\u3001\u5783\u573e\u90ae\u4ef6\u8bc6\u522b</li> <li>\u5e8f\u5217\u751f\u6210\uff1a\u6587\u672c\u751f\u6210\u3001\u4ee3\u7801\u751f\u6210</li> <li>\u673a\u5668\u7ffb\u8bd1\uff1a\u5e8f\u5217\u5230\u5e8f\u5217\uff08Seq2Seq\uff09\u4efb\u52a1</li> <li>\u8bed\u97f3\u8bc6\u522b\uff1a\u5c06\u8bed\u97f3\u4fe1\u53f7\u6620\u5c04\u5230\u6587\u672c</li> </ol>"},{"location":"nlp/chart02/#241-pytorch-lstm","title":"2.4.1 \u7b80\u5355\u6587\u672c\u5206\u7c7b\u793a\u4f8b\uff08PyTorch LSTM\uff09","text":"<pre><code>import torch\nimport torch.nn as nn\n\nclass LSTMClassifier(nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim):\n        super().__init__()\n        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n        self.fc = nn.Linear(hidden_dim, output_dim)\n    def forward(self, x):\n        out, (h_n, c_n) = self.lstm(x)\n        return self.fc(h_n[-1])  # \u7528\u6700\u540e\u4e00\u4e2a\u9690\u85cf\u72b6\u6001\u505a\u5206\u7c7b\n\nmodel = LSTMClassifier(input_dim=10, hidden_dim=20, output_dim=2)\nx = torch.randn(3,5,10)\ny = model(x)\nprint(y.shape)  # (3,2)\n</code></pre>"},{"location":"nlp/chart02/#25","title":"2.5 \u672c\u7ae0\u5c0f\u7ed3","text":"<ol> <li>RNN \u53ef\u4ee5\u5904\u7406\u5e8f\u5217\u6570\u636e\uff0c\u4f46\u957f\u5e8f\u5217\u5bb9\u6613\u68af\u5ea6\u6d88\u5931/\u7206\u70b8</li> <li>LSTM \u901a\u8fc7\u95e8\u63a7\u673a\u5236\u89e3\u51b3\u957f\u8ddd\u79bb\u4f9d\u8d56\u95ee\u9898</li> <li>RNN / LSTM \u9002\u5408\u5206\u7c7b\u3001\u751f\u6210\u3001\u7ffb\u8bd1\u7b49 NLP \u4efb\u52a1</li> <li>PyTorch \u63d0\u4f9b\u9ad8\u6548\u5b9e\u73b0\uff0c\u53ef\u76f4\u63a5\u7528\u4e8e\u6587\u672c\u5b9e\u9a8c</li> </ol> <p>\u6211\u53ef\u4ee5\u7ee7\u7eed\u5e2e\u4f60\u751f\u6210 \u7b2c 2 \u7ae0\u5b8c\u6574 Jupyter Notebook\uff0c\u5305\u542b\uff1a</p> <ul> <li>RNN \u548c LSTM \u8bad\u7ec3\u793a\u4f8b</li> <li>\u6587\u672c\u5206\u7c7b\u4efb\u52a1</li> <li>\u53ef\u89c6\u5316\u9690\u85cf\u72b6\u6001</li> </ul> <p>\u8fd9\u6837\u4f60\u53ef\u4ee5\u76f4\u63a5\u8fd0\u884c\u5b9e\u9a8c\uff0c\u66f4\u76f4\u89c2\u7406\u89e3\u5e8f\u5217\u6a21\u578b\u3002</p> <p>\u4f60\u5e0c\u671b\u6211\u751f\u6210 notebook \u5417\uff1f</p>"},{"location":"nlp/chart03/","title":"\u7b2c 3 \u7ae0 \u2014 Transformer \u4e0e Self-Attention","text":"<p>Transformer \u662f\u73b0\u4ee3 NLP \u7684\u6838\u5fc3\u67b6\u6784\uff0c\u5e7f\u6cdb\u5e94\u7528\u4e8e BERT\u3001GPT \u7b49\u6a21\u578b\u3002\u5b83\u7684\u6700\u5927\u7279\u70b9\u662f\u5f7b\u5e95\u6446\u8131\u4e86 RNN/LSTM \u7684\u987a\u5e8f\u8ba1\u7b97\uff0c\u901a\u8fc7 Self-Attention \u540c\u65f6\u5904\u7406\u6574\u4e2a\u5e8f\u5217\uff0c\u5b9e\u73b0\u9ad8\u6548\u5e76\u884c\u548c\u5168\u5c40\u4e0a\u4e0b\u6587\u5efa\u6a21\u3002</p>"},{"location":"nlp/chart03/#31","title":"3.1 \u5b66\u4e60\u76ee\u6807","text":"<p>\u5b8c\u6210\u672c\u7ae0\u540e\uff0c\u4f60\u5c06\u80fd\u591f\uff1a</p> <ol> <li>\u7406\u89e3 Transformer \u7684\u6574\u4f53\u67b6\u6784\uff08Encoder \u4e0e Decoder\uff09</li> <li>\u638c\u63e1 Self-Attention \u7684\u539f\u7406\u3001\u516c\u5f0f\u4e0e\u76f4\u89c2\u7406\u89e3</li> <li>\u7406\u89e3 Multi-Head Attention \u548c\u4f4d\u7f6e\u7f16\u7801</li> <li>\u7528 PyTorch \u5b9e\u73b0\u57fa\u672c\u7684 Self-Attention \u548c Transformer</li> <li>\u7406\u89e3 Transformer \u76f8\u8f83\u4e8e RNN \u7684\u4f18\u52bf</li> </ol>"},{"location":"nlp/chart03/#32-transformer","title":"3.2 Transformer \u6982\u89c8","text":""},{"location":"nlp/chart03/#321","title":"3.2.1 \u67b6\u6784\u7ec4\u6210","text":"<p>Transformer \u7531 Encoder \u548c Decoder \u4e24\u90e8\u5206\u7ec4\u6210\uff1a</p> <ul> <li>Encoder\uff1a\u5904\u7406\u8f93\u5165\u5e8f\u5217\uff0c\u751f\u6210\u4e0a\u4e0b\u6587\u8868\u793a</li> <li>Decoder\uff1a\u63a5\u6536 Encoder \u8f93\u51fa\uff0c\u751f\u6210\u76ee\u6807\u5e8f\u5217</li> </ul> <p>Encoder \u6838\u5fc3\u6a21\u5757\uff1a</p> <ol> <li>Multi-Head Self-Attention</li> <li>\u524d\u9988\u5168\u8fde\u63a5\u7f51\u7edc\uff08Feed-Forward Network\uff09</li> <li>\u6b8b\u5dee\u8fde\u63a5 + \u5c42\u5f52\u4e00\u5316</li> </ol> <p>Decoder \u6838\u5fc3\u6a21\u5757\uff1a</p> <ol> <li>Masked Multi-Head Self-Attention\uff08\u907f\u514d\u770b\u5230\u672a\u6765\u4fe1\u606f\uff09</li> <li>Encoder-Decoder Attention\uff08\u5c06\u8f93\u5165\u5e8f\u5217\u4fe1\u606f\u4e0e\u5f53\u524d\u751f\u6210\u5e8f\u5217\u5bf9\u9f50\uff09</li> <li>\u524d\u9988\u5168\u8fde\u63a5\u7f51\u7edc + \u6b8b\u5dee\u8fde\u63a5</li> </ol> <p>Encoder-Decoder \u67b6\u6784\u5e38\u7528\u4e8e\u673a\u5668\u7ffb\u8bd1\uff0c\u5355\u72ec Encoder\uff08\u5982 BERT\uff09\u7528\u4e8e\u7406\u89e3\u4efb\u52a1\uff0c\u5355\u72ec Decoder\uff08\u5982 GPT\uff09\u7528\u4e8e\u751f\u6210\u4efb\u52a1\u3002</p>"},{"location":"nlp/chart03/#33-self-attention","title":"3.3 Self-Attention \u539f\u7406","text":"<p>Self-Attention \u662f Transformer \u7684\u6838\u5fc3\uff0c\u5b83\u8ba9\u6bcf\u4e2a\u8bcd\u53ef\u4ee5\u5173\u6ce8\u5e8f\u5217\u4e2d\u6240\u6709\u5176\u4ed6\u8bcd\uff0c\u4ece\u800c\u6355\u83b7\u5168\u5c40\u4e0a\u4e0b\u6587\u3002</p>"},{"location":"nlp/chart03/#331","title":"3.3.1 \u8f93\u5165\u4e0e\u8f93\u51fa","text":"<ul> <li>\u8f93\u5165\u5e8f\u5217\uff1a\\(X = [x_1, x_2, ..., x_n]\\)\uff0c\u6bcf\u4e2a \\(x_i\\) \u662f\u8bcd\u5411\u91cf</li> <li>\u8f93\u51fa\u5e8f\u5217\uff1a\\(Z = [z_1, z_2, ..., z_n]\\)\uff0c\u6bcf\u4e2a \\(z_i\\) \u662f\u4e0a\u4e0b\u6587\u5411\u91cf</li> </ul> <p>\u76f4\u89c2\u7406\u89e3\uff1aSelf-Attention \u5c31\u50cf\u6bcf\u4e2a\u8bcd\u90fd\u5728\u95ee\u201c\u5728\u7406\u89e3\u6211\u81ea\u5df1\u7684\u610f\u4e49\u65f6\uff0c\u5176\u4ed6\u8bcd\u7684\u91cd\u8981\u6027\u662f\u591a\u5c11\u201d\uff0c\u7136\u540e\u6839\u636e\u6743\u91cd\u6574\u5408\u4fe1\u606f\u3002</p>"},{"location":"nlp/chart03/#332-self-attention","title":"3.3.2 Self-Attention \u8ba1\u7b97\u516c\u5f0f","text":"<ol> <li>\u751f\u6210 Query\u3001Key\u3001Value \u5411\u91cf\uff1a</li> </ol> \\[ Q = X W^Q, \\quad K = X W^K, \\quad V = X W^V \\] <ul> <li>\\(W^Q, W^K, W^V\\)\uff1a\u53ef\u5b66\u4e60\u7684\u6743\u91cd\u77e9\u9635</li> <li>\\(Q\\)\uff1aQuery\uff08\u63d0\u95ee\uff09</li> <li>\\(K\\)\uff1aKey\uff08\u56de\u7b54\u7684\u5173\u952e\uff09</li> <li> <p>\\(V\\)\uff1aValue\uff08\u5b9e\u9645\u4fe1\u606f\uff09</p> </li> <li> <p>\u8ba1\u7b97\u6ce8\u610f\u529b\u5206\u6570\uff1a</p> </li> </ul> \\[ \\text{Attention}(Q,K,V) = \\text{softmax}\\Big(\\frac{Q K^\\top}{\\sqrt{d_k}}\\Big) V \\] <ul> <li>\\(d_k\\)\uff1aKey \u5411\u91cf\u7ef4\u5ea6\uff0c\u7528 \\(\\sqrt{d_k}\\) \u7f29\u653e\u907f\u514d\u5206\u6570\u8fc7\u5927</li> <li>\\(Q K^\\top\\)\uff1a\u8861\u91cf Query \u4e0e\u6bcf\u4e2a Key \u7684\u76f8\u4f3c\u5ea6</li> <li>softmax\uff1a\u5c06\u76f8\u4f3c\u5ea6\u8f6c\u6362\u4e3a\u6743\u91cd</li> </ul> <p>\u76f4\u89c2\u7406\u89e3\uff1a\u6bcf\u4e2a\u8bcd\u5bf9\u5e8f\u5217\u4e2d\u6240\u6709\u8bcd\u7684\u201c\u5173\u6ce8\u7a0b\u5ea6\u201d\u88ab\u91cf\u5316\uff0c\u5f97\u5230\u52a0\u6743\u4fe1\u606f\u3002</p>"},{"location":"nlp/chart03/#333-self-attention","title":"3.3.3 Self-Attention \u4e3e\u4f8b","text":"<p>\u53e5\u5b50\uff1a\"The cat sat on the mat\"</p> <ul> <li>Query: \"cat\"</li> <li>Key/Value: \u6240\u6709\u8bcd</li> <li> <p>Attention \u6743\u91cd\u53ef\u80fd\u663e\u793a\uff1a</p> </li> <li> <p>\"sat\": 0.4</p> </li> <li>\"mat\": 0.3</li> <li>\"The\": 0.05</li> </ul> <p>\u8bf4\u660e\u201ccat\u201d\u4f1a\u66f4\u5173\u6ce8\u4e0e\u5176\u8bed\u4e49\u76f8\u5173\u7684\u8bcd\uff0c\u201csat\u201d\u548c\u201cmat\u201d\u7684\u6743\u91cd\u8f83\u9ad8\u3002</p>"},{"location":"nlp/chart03/#34-multi-head-attention","title":"3.4 Multi-Head Attention","text":"<p>\u5355\u4e2a\u6ce8\u610f\u529b\u5934\u53ef\u80fd\u6355\u6349\u7684\u4fe1\u606f\u6709\u9650\uff0cMulti-Head Attention \u7528\u591a\u4e2a\u6ce8\u610f\u529b\u5934\u6355\u6349\u4e0d\u540c\u8bed\u4e49\u5173\u7cfb\uff1a</p> \\[ \\text{MultiHead}(Q,K,V) = \\text{Concat}(\\text{head}_1, ..., \\text{head}_h) W^O \\] <ul> <li>\u6bcf\u4e2a head \u6709\u72ec\u7acb\u7684 \\(W^Q, W^K, W^V\\)</li> <li>\u53ef\u4ee5\u5728\u4e0d\u540c\u5b50\u7a7a\u95f4\u5173\u6ce8\u4e0d\u540c\u4fe1\u606f</li> <li>\u6700\u540e\u901a\u8fc7 \\(W^O\\) \u6574\u5408\u591a\u5934\u4fe1\u606f</li> </ul> <p>\u7c7b\u6bd4\uff1a\u4e00\u7fa4\u4e13\u5bb6\u5206\u522b\u5173\u6ce8\u5e8f\u5217\u7684\u4e0d\u540c\u89d2\u5ea6\uff0c\u7136\u540e\u6c47\u603b\u610f\u89c1\u3002</p>"},{"location":"nlp/chart03/#35-positional-encoding","title":"3.5 \u4f4d\u7f6e\u7f16\u7801\uff08Positional Encoding\uff09","text":"<p>Transformer \u4e0d\u50cf RNN \u90a3\u6837\u81ea\u7136\u611f\u77e5\u987a\u5e8f\uff0c\u56e0\u6b64\u9700\u8981\u663e\u5f0f\u4f4d\u7f6e\u7f16\u7801\uff1a</p> \\[ PE_{(pos,2i)} = \\sin\\Big(\\frac{pos}{10000^{2i/d_\\text{model}}}\\Big), \\quad PE_{(pos,2i+1)} = \\cos\\Big(\\frac{pos}{10000^{2i/d_\\text{model}}}\\Big) \\] <ul> <li>\\(pos\\)\uff1a\u8bcd\u5728\u5e8f\u5217\u7684\u4f4d\u7f6e</li> <li>\\(i\\)\uff1a\u5411\u91cf\u7ef4\u5ea6\u7d22\u5f15</li> </ul> <p>\u76f4\u89c2\u7406\u89e3\uff1a\u6b63\u5f26/\u4f59\u5f26\u6ce2\u4e0d\u540c\u9891\u7387\u7f16\u7801\u4f4d\u7f6e\uff0c\u4f7f\u6a21\u578b\u533a\u5206\u987a\u5e8f\uff0c\u540c\u65f6\u5141\u8bb8\u63d2\u503c\u9884\u6d4b\u3002</p>"},{"location":"nlp/chart03/#36-feed-forward","title":"3.6 \u524d\u9988\u5168\u8fde\u63a5\u7f51\u7edc\uff08Feed-Forward\uff09","text":"<p>\u6bcf\u4e2a Encoder/Decoder \u5c42\u8fd8\u5305\u542b\u4e00\u4e2a\u524d\u9988\u7f51\u7edc\uff1a</p> \\[ \\text{FFN}(x) = \\text{ReLU}(x W_1 + b_1) W_2 + b_2 \\] <ul> <li>\u72ec\u7acb\u5904\u7406\u6bcf\u4e2a\u4f4d\u7f6e</li> <li>\u589e\u52a0\u975e\u7ebf\u6027\u8868\u8fbe\u80fd\u529b</li> <li>\u914d\u5408\u6b8b\u5dee\u8fde\u63a5\u548c LayerNorm</li> </ul>"},{"location":"nlp/chart03/#37","title":"3.7 \u6b8b\u5dee\u8fde\u63a5\u4e0e\u5c42\u5f52\u4e00\u5316","text":"<p>\u6bcf\u4e00\u5c42\u4f7f\u7528\u6b8b\u5dee\u8fde\u63a5\u548c Layer Normalization\uff1a</p> \\[ \\text{Output} = \\text{LayerNorm}(x + \\text{Sublayer}(x)) \\] <ul> <li>\u9632\u6b62\u68af\u5ea6\u6d88\u5931</li> <li>\u52a0\u5feb\u8bad\u7ec3\u6536\u655b</li> <li>\u4fdd\u6301\u4fe1\u606f\u6d41\u901a\u987a\u7545</li> </ul>"},{"location":"nlp/chart03/#38-transformer-python-pytorch","title":"3.8 Transformer Python \u793a\u4f8b\uff08PyTorch\uff09","text":"<pre><code>import torch\nimport torch.nn as nn\n\n# \u8f93\u5165\uff1abatch_size=2, seq_len=5, embedding_dim=512\nx = torch.randn(2,5,512)\n\n# Multi-Head Attention\nmha = nn.MultiheadAttention(embed_dim=512, num_heads=8, batch_first=True)\nout, attn_weights = mha(x, x, x)\n\nprint(\"\u8f93\u51fa\u5f62\u72b6:\", out.shape)        # (2,5,512)\nprint(\"\u6ce8\u610f\u529b\u6743\u91cd\u5f62\u72b6:\", attn_weights.shape)  # (2,8,5,5)\n</code></pre> <p>\u6ce8\u610f\u529b\u6743\u91cd\u53ef\u4ee5\u53ef\u89c6\u5316\uff0c\u89c2\u5bdf\u6bcf\u4e2a\u8bcd\u5173\u6ce8\u5e8f\u5217\u4e2d\u54ea\u4e9b\u8bcd\u3002</p>"},{"location":"nlp/chart03/#39-transformer","title":"3.9 Transformer \u4f18\u52bf","text":"\u7279\u6027 RNN Transformer \u5e76\u884c\u8ba1\u7b97 \u5426\uff0c\u5fc5\u987b\u987a\u5e8f\u5904\u7406 \u662f\uff0c\u5168\u5e8f\u5217\u5e76\u884c \u957f\u8ddd\u79bb\u4f9d\u8d56 \u96be\u6355\u6349 \u6613\u6355\u6349\uff0c\u5168\u5c40\u6ce8\u610f\u529b \u8bad\u7ec3\u901f\u5ea6 \u6162 \u5feb \u8868\u8fbe\u80fd\u529b \u6709\u9650 \u5f3a\uff0c\u591a\u5934\u6ce8\u610f\u529b\u6355\u6349\u590d\u6742\u8bed\u4e49 \u9002\u7528\u4efb\u52a1 \u5c0f\u89c4\u6a21\u5e8f\u5217 \u5927\u89c4\u6a21\u9884\u8bad\u7ec3 &amp; \u751f\u6210"},{"location":"nlp/chart03/#310-transformer","title":"3.10 Transformer \u76f4\u89c2\u7406\u89e3","text":"<ul> <li>Self-Attention\uff1a\u6bcf\u4e2a\u8bcd\u201c\u770b\u201d\u6574\u4e2a\u5e8f\u5217\uff0c\u627e\u51fa\u76f8\u5173\u4fe1\u606f</li> <li>Multi-Head Attention\uff1a\u591a\u4e2a\u201c\u4e13\u5bb6\u201d\uff0c\u6355\u6349\u4e0d\u540c\u8bed\u4e49</li> <li>\u524d\u9988\u7f51\u7edc + \u6b8b\u5dee\u8fde\u63a5\uff1a\u5904\u7406\u590d\u6742\u975e\u7ebf\u6027\u5173\u7cfb\uff0c\u540c\u65f6\u4fdd\u8bc1\u4fe1\u606f\u6d41</li> <li>\u4f4d\u7f6e\u7f16\u7801\uff1a\u544a\u8bc9\u6a21\u578b\u8bcd\u7684\u987a\u5e8f</li> </ul> <p>Transformer \u7684\u5e76\u884c\u5904\u7406\u548c\u5168\u5c40\u6ce8\u610f\u529b\u8ba9\u6a21\u578b\u80fd\u591f\u5feb\u901f\u7406\u89e3\u957f\u6587\u672c\u8bed\u4e49\u3002</p>"},{"location":"nlp/chart03/#311","title":"3.11 \u672c\u7ae0\u5c0f\u7ed3","text":"<ol> <li>Transformer \u5f7b\u5e95\u6539\u53d8\u4e86 NLP \u5e8f\u5217\u5904\u7406\u65b9\u5f0f</li> <li>Self-Attention \u662f\u6838\u5fc3\u601d\u60f3\uff0c\u5b9e\u73b0\u5168\u5c40\u4e0a\u4e0b\u6587\u5efa\u6a21</li> <li>Multi-Head Attention \u63d0\u5347\u4e86\u8bed\u4e49\u6355\u6349\u80fd\u529b</li> <li>\u4f4d\u7f6e\u7f16\u7801\u89e3\u51b3\u5e8f\u5217\u987a\u5e8f\u95ee\u9898</li> <li>PyTorch \u63d0\u4f9b\u9ad8\u6548\u5b9e\u73b0\uff0c\u53ef\u76f4\u63a5\u5b9e\u9a8c\u548c\u53ef\u89c6\u5316</li> </ol> <p>\u6211\u53ef\u4ee5\u5e2e\u4f60\u751f\u6210 \u7b2c 3 \u7ae0\u5b8c\u6574 Jupyter Notebook\uff0c\u5305\u542b\uff1a</p> <ul> <li>Self-Attention \u53ef\u89c6\u5316</li> <li>Multi-Head Attention \u793a\u4f8b</li> <li>\u4f4d\u7f6e\u7f16\u7801\u53ef\u89c6\u5316</li> <li>\u7b80\u5355 Transformer \u524d\u5411\u4f20\u64ad\u5b9e\u9a8c</li> </ul> <p>\u8fd9\u6837\u4f60\u53ef\u4ee5\u76f4\u63a5\u8fd0\u884c\u5b9e\u9a8c\uff0c\u66f4\u76f4\u89c2\u7406\u89e3 Transformer \u5de5\u4f5c\u539f\u7406\u3002</p> <p>\u4f60\u5e0c\u671b\u6211\u751f\u6210\u8fd9\u4e2a notebook \u5417\uff1f</p>"},{"location":"nlp/chart04/","title":"\u7b2c 4 \u7ae0 : BERT / GPT \u539f\u7406\u4e0e\u5fae\u8c03","text":"<p>BERT \u4e0e GPT \u662f\u73b0\u4ee3 NLP \u4e2d\u6700\u7ecf\u5178\u7684\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u3002\u5b83\u4eec\u90fd\u57fa\u4e8e Transformer\uff0c\u4f46\u5728\u4efb\u52a1\u8bbe\u8ba1\u3001\u8bad\u7ec3\u65b9\u5f0f\u548c\u5e94\u7528\u573a\u666f\u4e0a\u6709\u660e\u663e\u533a\u522b\u3002\u672c\u7ae0\u5c06\u8be6\u7ec6\u8bb2\u89e3\u5b83\u4eec\u7684\u539f\u7406\uff0c\u5e76\u6f14\u793a\u5982\u4f55\u5fae\u8c03\u5b83\u4eec\u8fdb\u884c\u4e0b\u6e38\u4efb\u52a1\u3002</p>"},{"location":"nlp/chart04/#41","title":"4.1 \u5b66\u4e60\u76ee\u6807","text":"<p>\u5b8c\u6210\u672c\u7ae0\u540e\uff0c\u4f60\u5c06\u80fd\u591f\uff1a</p> <ol> <li>\u7406\u89e3 BERT \u548c GPT \u7684\u57fa\u672c\u539f\u7406\u4e0e\u5dee\u5f02</li> <li>\u638c\u63e1\u9884\u8bad\u7ec3\u4efb\u52a1\uff1aMasked Language Model (BERT) \u4e0e Autoregressive LM (GPT)</li> <li>\u7406\u89e3 Transformer \u5728 BERT/GPT \u4e2d\u7684\u4f5c\u7528</li> <li>\u5b66\u4f1a\u5728 Python \u4e2d\u52a0\u8f7d\u9884\u8bad\u7ec3\u6a21\u578b\u5e76\u8fdb\u884c\u5fae\u8c03</li> <li>\u7406\u89e3\u5982\u4f55\u5c06\u9884\u8bad\u7ec3\u6a21\u578b\u5e94\u7528\u4e8e\u6587\u672c\u5206\u7c7b\u3001\u6587\u672c\u751f\u6210\u7b49\u4efb\u52a1</li> </ol>"},{"location":"nlp/chart04/#42-bert","title":"4.2 BERT \u6982\u5ff5","text":"<p>BERT\uff08Bidirectional Encoder Representations from Transformers\uff09\u662f\u53cc\u5411 Transformer Encoder\uff1a</p> <ul> <li>\u53cc\u5411\uff1a\u540c\u65f6\u8003\u8651\u4e0a\u4e0b\u6587\u7684\u5de6\u4fa7\u548c\u53f3\u4fa7\u4fe1\u606f</li> <li> <p>\u9884\u8bad\u7ec3\u4efb\u52a1\uff1a</p> <ol> <li>Masked Language Model (MLM)\uff1a\u968f\u673a\u906e\u76d6\u4e00\u4e9b\u8bcd\uff0c\u9884\u6d4b\u88ab\u906e\u76d6\u7684\u8bcd      $$      P(x_{\\text{masked}} | x_{\\text{context}})      $$</li> <li>Next Sentence Prediction (NSP)\uff1a\u9884\u6d4b\u53e5\u5b50 B \u662f\u5426\u7d27\u8ddf\u53e5\u5b50 A</li> </ol> </li> <li> <p>\u5e94\u7528\uff1a\u6587\u672c\u5206\u7c7b\u3001\u95ee\u7b54\u3001\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u7b49\u7406\u89e3\u4efb\u52a1</p> </li> </ul> <p>BERT \u662f Encoder-only \u7ed3\u6784\uff0c\u4e0d\u7528\u4e8e\u6587\u672c\u751f\u6210\u3002</p>"},{"location":"nlp/chart04/#421-masked-language-model","title":"4.2.1 Masked Language Model \u793a\u4f8b","text":"<p>\u53e5\u5b50\uff1a\"The cat sat on the mat\"</p> <ul> <li>\u968f\u673a\u906e\u76d6\u8bcd\uff1a\"The cat [MASK] on the mat\"</li> <li>BERT \u5b66\u4e60\u9884\u6d4b <code>[MASK]</code> \u5bf9\u5e94\u7684\u8bcd <code>\"sat\"</code></li> </ul>"},{"location":"nlp/chart04/#43-gpt","title":"4.3 GPT \u6982\u5ff5","text":"<p>GPT\uff08Generative Pre-trained Transformer\uff09\u662f\u5355\u5411 Transformer Decoder\uff1a</p> <ul> <li>\u5355\u5411\uff1a\u4ece\u5de6\u5230\u53f3\u751f\u6210\u6587\u672c</li> <li>\u9884\u8bad\u7ec3\u4efb\u52a1\uff1aAutoregressive Language Model (\u81ea\u56de\u5f52\u8bed\u8a00\u6a21\u578b)   $$   P(x_t | x_1, x_2, ..., x_{t-1})   $$</li> <li>\u5e94\u7528\uff1a\u6587\u672c\u751f\u6210\u3001\u5bf9\u8bdd\u751f\u6210\u3001\u4ee3\u7801\u751f\u6210\u7b49\u4efb\u52a1</li> </ul> <p>GPT \u662f Decoder-only \u7ed3\u6784\uff0c\u9002\u5408\u751f\u6210\u4efb\u52a1\u3002</p>"},{"location":"nlp/chart04/#44-bert-gpt","title":"4.4 BERT \u4e0e GPT \u7684\u5dee\u5f02","text":"\u7279\u6027 BERT GPT Transformer \u90e8\u5206 Encoder Decoder \u4e0a\u4e0b\u6587\u65b9\u5411 \u53cc\u5411 \u5355\u5411 \u9884\u8bad\u7ec3\u4efb\u52a1 MLM + NSP Autoregressive LM \u9002\u7528\u4efb\u52a1 \u7406\u89e3\u4efb\u52a1 \u751f\u6210\u4efb\u52a1 \u5178\u578b\u5e94\u7528 \u6587\u672c\u5206\u7c7b\u3001\u95ee\u7b54 \u6587\u672c\u751f\u6210\u3001\u5bf9\u8bdd\u3001\u4ee3\u7801\u751f\u6210"},{"location":"nlp/chart04/#45-bert-gpt","title":"4.5 BERT / GPT \u7684\u5fae\u8c03","text":""},{"location":"nlp/chart04/#451","title":"4.5.1 \u5fae\u8c03\u539f\u7406","text":"<ul> <li>\u9884\u8bad\u7ec3\uff1a\u5728\u5927\u89c4\u6a21\u8bed\u6599\u4e0a\u5b66\u4e60\u901a\u7528\u8bed\u8a00\u8868\u793a</li> <li>\u5fae\u8c03\uff1a\u5728\u4e0b\u6e38\u4efb\u52a1\u4e0a\u8bad\u7ec3\u5c11\u91cf\u53c2\u6570\uff0c\u4f7f\u6a21\u578b\u9002\u5e94\u7279\u5b9a\u4efb\u52a1</li> </ul> <p>\u5fae\u8c03\u901a\u5e38\u6bd4\u4ece\u96f6\u8bad\u7ec3\u6548\u679c\u597d\uff0c\u4e14\u6570\u636e\u9700\u6c42\u66f4\u5c11\u3002</p>"},{"location":"nlp/chart04/#452-bert","title":"4.5.2 \u6587\u672c\u5206\u7c7b\u5fae\u8c03\uff08BERT \u793a\u4f8b\uff09","text":"<pre><code>from transformers import BertTokenizer, BertForSequenceClassification\nfrom transformers import Trainer, TrainingArguments\nimport torch\n\n# \u52a0\u8f7d\u9884\u8bad\u7ec3\u6a21\u578b\u548c\u5206\u8bcd\u5668\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nmodel = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n\n# \u793a\u4f8b\u6587\u672c\ntexts = [\"I love NLP\", \"I hate bugs\"]\nlabels = torch.tensor([1,0])\n\n# \u7f16\u7801\nencodings = tokenizer(texts, padding=True, truncation=True, return_tensors='pt')\ndataset = torch.utils.data.TensorDataset(encodings['input_ids'], encodings['attention_mask'], labels)\n\n# Trainer \u7b80\u5355\u8bad\u7ec3\u793a\u4f8b\ntraining_args = TrainingArguments(output_dir='./results', num_train_epochs=1, per_device_train_batch_size=2)\ntrainer = Trainer(model=model, args=training_args, train_dataset=dataset)\ntrainer.train()\n</code></pre>"},{"location":"nlp/chart04/#453-gpt","title":"4.5.3 \u6587\u672c\u751f\u6210\u5fae\u8c03\uff08GPT \u793a\u4f8b\uff09","text":"<pre><code>from transformers import GPT2Tokenizer, GPT2LMHeadModel\n\ntokenizer = GPT2Tokenizer.from_pretrained('gpt2')\nmodel = GPT2LMHeadModel.from_pretrained('gpt2')\n\ntext = \"Once upon a time\"\ninputs = tokenizer(text, return_tensors='pt')\n\n# \u751f\u6210\u6587\u672c\noutputs = model.generate(**inputs, max_length=20)\nprint(tokenizer.decode(outputs[0], skip_special_tokens=True))\n</code></pre>"},{"location":"nlp/chart04/#46-bert-gpt","title":"4.6 BERT / GPT \u7684\u6838\u5fc3\u539f\u7406\u603b\u7ed3","text":"<ol> <li> <p>Transformer \u662f\u5e95\u5c42\u67b6\u6784</p> <ul> <li>BERT \u7528 Encoder</li> <li>GPT \u7528 Decoder</li> </ul> </li> <li> <p>\u9884\u8bad\u7ec3\u4efb\u52a1\u5b66\u4e60\u8bed\u8a00\u77e5\u8bc6</p> <ul> <li>BERT\uff1aMasked LM + NSP</li> <li>GPT\uff1a\u81ea\u56de\u5f52 LM</li> </ul> </li> <li> <p>\u5fae\u8c03\u5728\u4e0b\u6e38\u4efb\u52a1\u4e0a\u5c11\u91cf\u8bad\u7ec3\u5373\u53ef\u83b7\u5f97\u9ad8\u6027\u80fd</p> </li> <li> <p>\u5e94\u7528\u5e7f\u6cdb\uff1a</p> <ul> <li>BERT\uff1a\u5206\u7c7b\u3001\u95ee\u7b54\u3001\u547d\u540d\u5b9e\u4f53\u8bc6\u522b</li> <li>GPT\uff1a\u6587\u672c\u751f\u6210\u3001\u5bf9\u8bdd\u3001\u4ee3\u7801\u751f\u6210</li> </ul> </li> </ol>"},{"location":"nlp/chart04/#47","title":"4.7 \u672c\u7ae0\u5c0f\u7ed3","text":"<ul> <li>BERT \u5f3a\u8c03\u8bed\u8a00\u7406\u89e3\uff0c\u5229\u7528\u53cc\u5411\u4e0a\u4e0b\u6587</li> <li>GPT \u5f3a\u8c03\u6587\u672c\u751f\u6210\uff0c\u5229\u7528\u5de6\u5230\u53f3\u9884\u6d4b</li> <li>\u9884\u8bad\u7ec3 + \u5fae\u8c03\u662f\u73b0\u4ee3 NLP \u7684\u4e3b\u6d41\u65b9\u6cd5</li> <li>PyTorch + Transformers \u5e93\u63d0\u4f9b\u4fbf\u6377\u5de5\u5177\uff0c\u5feb\u901f\u5fae\u8c03\u548c\u5e94\u7528</li> </ul>"},{"location":"nlp/chart05/","title":"\u7b2c 5 \u7ae0 : NLP \u5b9e\u6218\u4e0e\u90e8\u7f72\uff08\u8be6\u7ec6\u6559\u7a0b\uff09","text":"<p>\u8fd9\u4e00\u7ae0\u5c06\u5e26\u4f60\u8d70\u51fa\u7406\u8bba\u4e0e\u6a21\u578b\u8bad\u7ec3\uff0c\u8fdb\u5165 NLP \u9879\u76ee\u5b9e\u6218\u4e0e\u843d\u5730\u90e8\u7f72\u9636\u6bb5\u3002\u76ee\u6807\u662f\u8ba9\u4f60\u80fd\u628a\u524d\u9762\u5b66\u7684\u6a21\u578b\uff08\u8bcd\u5411\u91cf\u3001RNN/LSTM\u3001Transformer\u3001BERT/GPT\uff09\u5e94\u7528\u5230\u771f\u5b9e\u4efb\u52a1\uff0c\u5e76\u5c06\u6a21\u578b\u90e8\u7f72\u4e3a\u53ef\u7528\u7684\u670d\u52a1\u3002</p>"},{"location":"nlp/chart05/#_1","title":"\u4e00\u3001\u5b66\u4e60\u76ee\u6807","text":"<p>\u5b8c\u6210\u672c\u7ae0\u540e\uff0c\u4f60\u5c06\u80fd\uff1a</p> <ol> <li>\u8bbe\u8ba1\u548c\u5b9e\u73b0\u5b8c\u6574\u7684 NLP \u9879\u76ee\u6d41\u7a0b\uff08\u6570\u636e \u2192 \u6a21\u578b \u2192 \u90e8\u7f72\uff09\u3002</li> <li>\u719f\u7ec3\u5904\u7406\u6587\u672c\u6570\u636e\u6e05\u6d17\u3001\u5206\u8bcd\u3001\u7f16\u7801\u3001\u7279\u5f81\u5de5\u7a0b\u3002</li> <li>\u8bad\u7ec3\u5e76\u4f18\u5316\u4e0d\u540c\u7c7b\u578b\u7684 NLP \u6a21\u578b\uff08\u5206\u7c7b\u3001\u751f\u6210\u3001\u95ee\u7b54\uff09\u3002</li> <li>\u5b9e\u73b0\u6a21\u578b\u5728\u7ebf\u90e8\u7f72\uff0c\u5305\u62ec API \u63a5\u53e3\u3001\u63a8\u7406\u4f18\u5316\u3001\u5bb9\u5668\u5316\u3002</li> <li>\u638c\u63e1\u5e38\u89c1\u90e8\u7f72\u5de5\u5177\u4e0e\u6280\u672f\uff0c\u5982 FastAPI\u3001Docker\u3001ONNX\u3001GPU/CPU \u63a8\u7406\u4f18\u5316\u3002</li> </ol>"},{"location":"nlp/chart05/#nlp","title":"\u4e8c\u3001NLP \u9879\u76ee\u6d41\u7a0b\u6982\u89c8","text":"<ol> <li> <p>\u6570\u636e\u6536\u96c6\u4e0e\u6e05\u6d17</p> <ul> <li>\u6587\u672c\u6e05\u6d17\uff1a\u53bb\u6389 HTML\u3001\u6807\u70b9\u7b26\u53f7\u3001\u8868\u60c5\u7b49</li> <li>\u5206\u8bcd\u4e0e\u6807\u51c6\u5316\uff1a\u4e2d\u6587\u4f7f\u7528\u7ed3\u5df4\u3001HanLP\uff0c\u82f1\u6587\u53ef\u7528 NLTK\u3001Spacy</li> <li>\u6570\u636e\u6807\u6ce8\uff1a\u5206\u7c7b\u6807\u7b7e\u3001\u751f\u6210\u4efb\u52a1\u7684 prompt-completion \u5bf9\u7b49</li> </ul> </li> <li> <p>\u7279\u5f81\u5de5\u7a0b / \u6587\u672c\u8868\u793a</p> <ul> <li>\u7a00\u758f\u8868\u793a\uff1aTF-IDF / Bag-of-Words</li> <li>\u5206\u5e03\u5f0f\u8868\u793a\uff1aWord2Vec\u3001GloVe\u3001fastText</li> <li>\u9884\u8bad\u7ec3 Transformer \u8868\u793a\uff1aBERT\u3001GPT\u3001RoBERTa</li> </ul> </li> <li> <p>\u6a21\u578b\u9009\u62e9\u4e0e\u8bad\u7ec3</p> <ul> <li>\u6587\u672c\u5206\u7c7b\uff1aBERT\u3001LSTM</li> <li>\u6587\u672c\u751f\u6210\uff1aGPT\u3001Transformer Decoder</li> <li>\u95ee\u7b54\u7cfb\u7edf\uff1aBERT + QA Head</li> </ul> </li> <li> <p>\u6a21\u578b\u8bc4\u4f30</p> <ul> <li>\u5206\u7c7b\u4efb\u52a1\uff1aAccuracy\u3001F1\u3001Precision\u3001Recall</li> <li>\u751f\u6210\u4efb\u52a1\uff1aBLEU\u3001ROUGE\u3001Perplexity</li> <li>\u53ef\u89c6\u5316\uff1a\u6df7\u6dc6\u77e9\u9635\u3001t-SNE / PCA</li> </ul> </li> </ol>"},{"location":"nlp/chart05/#nlp_1","title":"\u4e09\u3001NLP \u5b9e\u6218\u793a\u4f8b","text":""},{"location":"nlp/chart05/#1","title":"1. \u6587\u672c\u5206\u7c7b\uff08\u60c5\u611f\u5206\u6790\uff09","text":"<pre><code>from transformers import BertTokenizer, BertForSequenceClassification\nfrom torch.utils.data import DataLoader, Dataset\nimport torch\n\n# \u81ea\u5b9a\u4e49 Dataset\nclass MyDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_len=128):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n    def __len__(self):\n        return len(self.texts)\n    def __getitem__(self, idx):\n        enc = self.tokenizer(self.texts[idx], \n                             padding='max_length', \n                             truncation=True, \n                             max_length=self.max_len,\n                             return_tensors='pt')\n        return { 'input_ids': enc['input_ids'].squeeze(),\n                 'attention_mask': enc['attention_mask'].squeeze(),\n                 'labels': torch.tensor(self.labels[idx]) }\n\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nmodel = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n\n# \u8bad\u7ec3\u5faa\u73af\u7701\u7565\uff0c\u53ef\u4f7f\u7528 Trainer API\n</code></pre>"},{"location":"nlp/chart05/#2-gpt","title":"2. \u6587\u672c\u751f\u6210\uff08GPT\uff09","text":"<pre><code>from transformers import GPT2Tokenizer, GPT2LMHeadModel\n\ntokenizer = GPT2Tokenizer.from_pretrained('gpt2')\nmodel = GPT2LMHeadModel.from_pretrained('gpt2')\n\nprompt = \"Once upon a time\"\ninputs = tokenizer(prompt, return_tensors=\"pt\")\noutputs = model.generate(**inputs, max_length=50)\nprint(tokenizer.decode(outputs[0]))\n</code></pre>"},{"location":"nlp/chart05/#_2","title":"\u56db\u3001\u6a21\u578b\u4f18\u5316\u4e0e\u63a8\u7406","text":"<ol> <li>\u91cf\u5316\uff08Quantization\uff09\uff1a\u964d\u4f4e\u6a21\u578b\u7cbe\u5ea6\uff08float32 \u2192 int8\uff09\u51cf\u5c11\u5185\u5b58\u5360\u7528</li> <li>\u84b8\u998f\uff08Distillation\uff09\uff1a\u7528\u5c0f\u6a21\u578b\u903c\u8fd1\u5927\u6a21\u578b\uff0c\u63d0\u5347\u901f\u5ea6</li> <li>ONNX / TensorRT\uff1a\u8de8\u5e73\u53f0\u90e8\u7f72\u4e0e GPU \u52a0\u901f</li> <li>\u6279\u91cf\u63a8\u7406 / \u5e76\u884c\u5904\u7406\uff1a\u63d0\u9ad8\u541e\u5410\u91cf</li> <li>\u7f13\u5b58\u673a\u5236\uff1a\u5bf9\u751f\u6210\u4efb\u52a1\u53ef\u7f13\u5b58\u524d\u7f00\u5411\u91cf</li> </ol>"},{"location":"nlp/chart05/#nlp_2","title":"\u4e94\u3001NLP \u6a21\u578b\u90e8\u7f72","text":""},{"location":"nlp/chart05/#1-api","title":"1. API \u90e8\u7f72","text":"<p>\u4f7f\u7528 FastAPI \u521b\u5efa\u6a21\u578b\u63a8\u7406\u63a5\u53e3\uff1a</p> <pre><code>from fastapi import FastAPI\nfrom pydantic import BaseModel\n\napp = FastAPI()\nclass TextInput(BaseModel):\n    text: str\n\n@app.post(\"/predict\")\ndef predict(input: TextInput):\n    tokens = tokenizer(input.text, return_tensors=\"pt\")\n    outputs = model(**tokens)\n    pred = torch.argmax(outputs.logits, dim=-1).item()\n    return {\"prediction\": pred}\n</code></pre>"},{"location":"nlp/chart05/#2-docker","title":"2. Docker \u5bb9\u5668\u5316","text":"<pre><code>FROM python:3.10-slim\nWORKDIR /app\nCOPY requirements.txt .\nRUN pip install -r requirements.txt\nCOPY . .\nCMD [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n</code></pre> <ul> <li>\u6253\u5305\u6210\u955c\u50cf\uff0c\u65b9\u4fbf\u5728\u4e91\u670d\u52a1\u5668\u6216 Kubernetes \u4e0a\u90e8\u7f72</li> </ul>"},{"location":"nlp/chart05/#3","title":"3. \u4e91\u7aef\u90e8\u7f72\u5efa\u8bae","text":"<ul> <li>CPU \u63a8\u7406\uff1a\u5c0f\u6a21\u578b / \u91cf\u5316\u6a21\u578b</li> <li>GPU \u63a8\u7406\uff1a\u5927\u6a21\u578b / \u751f\u6210\u4efb\u52a1</li> <li>\u4f7f\u7528\u8d1f\u8f7d\u5747\u8861\u4e0e\u5f02\u6b65\u8bf7\u6c42\u63d0\u9ad8\u541e\u5410\u91cf</li> </ul>"},{"location":"nlp/chart05/#_3","title":"\u516d\u3001\u5b9e\u6218\u7ec3\u4e60","text":"<ol> <li>\u5bf9\u4e2d\u6587\u77ed\u6587\u672c\u8fdb\u884c\u5206\u7c7b\uff0c\u4f7f\u7528 BERT \u5fae\u8c03\u5e76\u90e8\u7f72 FastAPI \u63a5\u53e3</li> <li>\u5bf9\u82f1\u6587\u77ed\u6545\u4e8b\u8fdb\u884c\u751f\u6210\uff0c\u4f7f\u7528 GPT \u5fae\u8c03\u5e76\u5b9e\u73b0 REST API</li> <li>\u5bf9\u6a21\u578b\u8f93\u51fa\u505a\u65e5\u5fd7\u8bb0\u5f55\u548c\u53ef\u89c6\u5316\u5206\u6790\uff08\u51c6\u786e\u7387\u3001\u751f\u6210\u6837\u672c\uff09</li> <li>\u5c1d\u8bd5\u5c06\u6a21\u578b\u8f6c\u6362\u4e3a ONNX \u6216 TorchScript\uff0c\u52a0\u901f\u63a8\u7406</li> </ol>"},{"location":"nlp/chart05/#_4","title":"\u4e03\u3001\u63a8\u8350\u9605\u8bfb\u4e0e\u5de5\u5177","text":"<ol> <li>Hugging Face Transformers \u6587\u6863\uff1ahttps://huggingface.co/docs/transformers</li> <li>FastAPI \u5b98\u65b9\u6587\u6863\uff1ahttps://fastapi.tiangolo.com</li> <li>Docker \u5b98\u65b9\u6587\u6863\uff1ahttps://www.docker.com</li> <li>NVIDIA TensorRT\u3001ONNX Runtime \u4f18\u5316\u6307\u5357</li> </ol> <p>\u5982\u679c\u4f60\u5e0c\u671b\uff0c\u6211\u53ef\u4ee5\u5e2e\u4f60\u751f\u6210 \u5b8c\u6574\u7684 Jupyter Notebook \u5b9e\u6218\u7248\uff0c\u5305\u542b\uff1a</p> <ul> <li>\u4e2d\u6587\u6587\u672c\u5206\u7c7b\uff08BERT \u5fae\u8c03 + FastAPI \u90e8\u7f72\uff09</li> <li>\u82f1\u6587\u6587\u672c\u751f\u6210\uff08GPT \u5fae\u8c03 + API\uff09</li> <li>\u6a21\u578b\u4f18\u5316\u4e0e\u63a8\u7406\u793a\u4f8b</li> </ul> <p>\u662f\u5426\u751f\u6210\u8fd9\u4e2a notebook\uff1f</p>"},{"location":"nlp/nltk/","title":"\ud83e\udde9 \u7b2c 1 \u7ae0\uff1a\u8ba4\u8bc6 NLTK","text":""},{"location":"nlp/nltk/#nltk","title":"\u4ec0\u4e48\u662f NLTK\uff1f","text":"<p>NLTK\uff08Natural Language Toolkit\uff09\u662f Python \u6700\u7ecf\u5178\u7684 NLP \u6559\u5b66\u4e0e\u5b9e\u9a8c\u5e93\u3002\u5b83\u63d0\u4f9b\u4e86\uff1a</p> <ul> <li>\u4e0a\u767e\u4e2a\u8bed\u6599\u5e93\uff08corpus\uff09\u548c\u8bcd\u5178\u8d44\u6e90\uff08\u5982 WordNet\uff09\uff1b</li> <li>\u5404\u7c7b\u6587\u672c\u5904\u7406\u5de5\u5177\uff08\u5206\u8bcd\u3001\u6807\u6ce8\u3001\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u7b49\uff09\uff1b</li> <li>\u7edf\u8ba1\u6a21\u578b\u548c\u5206\u7c7b\u7b97\u6cd5\uff08\u6734\u7d20\u8d1d\u53f6\u65af\u3001\u51b3\u7b56\u6811\u7b49\uff09\uff1b</li> <li>\u5f3a\u5927\u7684\u53ef\u89c6\u5316\u529f\u80fd\uff08\u53e5\u6cd5\u6811\u3001\u9891\u7387\u5206\u5e03\u7b49\uff09\u3002</li> </ul> <p>\u7b80\u800c\u8a00\u4e4b\uff0cNLTK \u5c31\u50cf\u662f NLP \u7684\u201c\u79ef\u6728\u76d2\u201d\u2014\u2014\u4f60\u53ef\u4ee5\u7528\u5b83\u62fc\u51fa\u5404\u79cd\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7cfb\u7edf\u3002</p>"},{"location":"nlp/nltk/#_1","title":"\u5b89\u88c5\u4e0e\u914d\u7f6e","text":"<pre><code>pip install nltk\n</code></pre> <p>\u7b2c\u4e00\u6b21\u4f7f\u7528\uff1a</p> <pre><code>import nltk\nnltk.download('all')  # \u6216\u6309\u9700\u4e0b\u8f7d\u90e8\u5206\u8d44\u6e90\n</code></pre>"},{"location":"nlp/nltk/#2-text-preprocessing","title":"\ud83e\udde9 \u7b2c 2 \u7ae0\uff1a\u6587\u672c\u9884\u5904\u7406\uff08Text Preprocessing\uff09","text":"<p>\u8bed\u8a00\u6a21\u578b\u7684\u8f93\u5165\u5fc5\u987b\u662f\u5e72\u51c0\u3001\u7ed3\u6784\u5316\u7684\u6587\u672c\u3002 \u800c\u539f\u59cb\u6587\u672c\u901a\u5e38\u5145\u6ee1\u566a\u97f3\uff1a\u6807\u70b9\u7b26\u53f7\u3001HTML \u6807\u7b7e\u3001\u5927\u5c0f\u5199\u4e0d\u7edf\u4e00\u2026\u2026 \u8fd9\u4e00\u6b65\u7684\u76ee\u6807\u662f\u628a\u81ea\u7136\u8bed\u8a00\u8f6c\u5316\u4e3a\u201c\u8ba1\u7b97\u673a\u80fd\u7406\u89e3\u7684\u8bcd\u5e8f\u5217\u201d\u3002</p>"},{"location":"nlp/nltk/#21-tokenization","title":"2.1 \u5206\u8bcd\uff08Tokenization\uff09","text":"<pre><code>from nltk.tokenize import word_tokenize, sent_tokenize\n\ntext = \"Natural Language Processing lets computers understand human language.\"\nprint(sent_tokenize(text))\nprint(word_tokenize(text))\n</code></pre> <p>\u8f93\u51fa\uff1a</p> <pre><code>['Natural Language Processing lets computers understand human language.']\n['Natural', 'Language', 'Processing', 'lets', 'computers', 'understand', 'human', 'language', '.']\n</code></pre>"},{"location":"nlp/nltk/#22-stopwords","title":"2.2 \u505c\u7528\u8bcd\uff08Stopwords\uff09","text":"<p>\u505c\u7528\u8bcd\u6307\u5982 \u201cthe\u201d\u3001\u201cis\u201d\u3001\u201cand\u201d \u8fd9\u7c7b\u8bed\u4e49\u8d21\u732e\u5f88\u5c0f\u7684\u5e38\u7528\u8bcd\u3002</p> <pre><code>from nltk.corpus import stopwords\n\nstop_words = set(stopwords.words('english'))\ntokens = [w for w in word_tokenize(text.lower()) if w.isalpha() and w not in stop_words]\nprint(tokens)\n</code></pre>"},{"location":"nlp/nltk/#23-stemminglemmatization","title":"2.3 \u8bcd\u5e72\u63d0\u53d6\uff08Stemming\uff09\u4e0e\u8bcd\u5f62\u8fd8\u539f\uff08Lemmatization\uff09","text":"<p>\u4e24\u79cd\u8bcd\u5f62\u6807\u51c6\u5316\u65b9\u5f0f\uff1a</p> <pre><code>from nltk.stem import PorterStemmer, WordNetLemmatizer\n\nstemmer = PorterStemmer()\nlemmatizer = WordNetLemmatizer()\n\nprint(stemmer.stem(\"studies\"))     # stem: study\nprint(lemmatizer.lemmatize(\"studies\", pos='v'))  # lemma: study\n</code></pre>"},{"location":"nlp/nltk/#3-pos-tagging","title":"\ud83e\udde9 \u7b2c 3 \u7ae0\uff1a\u8bcd\u6027\u6807\u6ce8\uff08POS Tagging\uff09","text":"<p>\u8bcd\u6027\u6807\u6ce8\u8ba9\u8ba1\u7b97\u673a\u77e5\u9053\u6bcf\u4e2a\u8bcd\u5728\u53e5\u5b50\u4e2d\u7684\u8bed\u6cd5\u529f\u80fd\u3002</p> <pre><code>import nltk\nsentence = \"The quick brown fox jumps over the lazy dog.\"\ntokens = nltk.word_tokenize(sentence)\ntagged = nltk.pos_tag(tokens)\nprint(tagged)\n</code></pre> <p>\u8f93\u51fa\uff1a</p> <pre><code>[('The', 'DT'), ('quick', 'JJ'), ('brown', 'JJ'), ('fox', 'NN'), ...]\n</code></pre> <p>\u5e38\u89c1\u6807\u7b7e\uff1a</p> <ul> <li>NN\uff1a\u540d\u8bcd</li> <li>JJ\uff1a\u5f62\u5bb9\u8bcd</li> <li>VB\uff1a\u52a8\u8bcd</li> <li>RB\uff1a\u526f\u8bcd</li> </ul> <p>NLTK \u7684\u8bcd\u6027\u6807\u6ce8\u5668\u5e95\u5c42\u662f\u4e00\u4e2a \u9690\u9a6c\u5c14\u53ef\u592b\u6a21\u578b\uff08HMM\uff09\u3002</p>"},{"location":"nlp/nltk/#4-ner","title":"\ud83e\udde9 \u7b2c 4 \u7ae0\uff1a\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\uff08NER\uff09","text":"<p>NER = Named Entity Recognition\uff0c\u7528\u6765\u8bc6\u522b\u6587\u672c\u4e2d\u7684\u5b9e\u4f53\uff0c\u5982\u4eba\u540d\u3001\u5730\u70b9\u3001\u7ec4\u7ec7\u7b49\u3002</p> <pre><code>from nltk import ne_chunk\n\nsentence = \"Elon Musk founded SpaceX in California.\"\ntokens = nltk.word_tokenize(sentence)\ntags = nltk.pos_tag(tokens)\ntree = ne_chunk(tags)\nprint(tree)\n</code></pre> <p>\u8f93\u51fa\u6811\u4e2d\u4f1a\u6807\u6ce8\u5b9e\u4f53\u7c7b\u522b\uff0c\u5982\uff1a</p> <pre><code>(ORGANIZATION SpaceX)\n(GPE California)\n(PERSON Elon Musk)\n</code></pre>"},{"location":"nlp/nltk/#5-parsing","title":"\ud83e\udde9 \u7b2c 5 \u7ae0\uff1a\u53e5\u6cd5\u5206\u6790\uff08Parsing\uff09","text":"<p>\u53e5\u6cd5\u5206\u6790\u662f\u8bed\u8a00\u7406\u89e3\u7684\u201c\u7ed3\u6784\u201d\u90e8\u5206\u3002</p>"},{"location":"nlp/nltk/#cfg","title":"\u4f8b\uff1a\u4f7f\u7528\u4e0a\u4e0b\u6587\u65e0\u5173\u6587\u6cd5\uff08CFG\uff09","text":"<pre><code>from nltk import CFG\nfrom nltk.parse import ChartParser\n\ngrammar = CFG.fromstring(\"\"\"\nS -&gt; NP VP\nNP -&gt; DT NN\nVP -&gt; VB NP\nDT -&gt; 'the'\nNN -&gt; 'cat' | 'dog'\nVB -&gt; 'chased' | 'saw'\n\"\"\")\n\nparser = ChartParser(grammar)\nsentence = ['the', 'dog', 'chased', 'the', 'cat']\n\nfor tree in parser.parse(sentence):\n    print(tree)\n    tree.draw()\n</code></pre> <p>\u8fd9\u4f1a\u7ed8\u5236\u51fa\u4e00\u68f5\u53e5\u6cd5\u6811\uff0c\u8ba9\u4f60\u770b\u5230\u201c\u4e3b\u8bed-\u8c13\u8bed-\u5bbe\u8bed\u201d\u7684\u7ed3\u6784\u3002</p>"},{"location":"nlp/nltk/#6-wordnet","title":"\ud83e\udde9 \u7b2c 6 \u7ae0\uff1a\u8bed\u4e49\u5206\u6790\uff08WordNet\uff09","text":"<p>NLTK \u5185\u7f6e WordNet \u2014\u2014 \u4e00\u4e2a\u5e9e\u5927\u7684\u82f1\u8bed\u8bed\u4e49\u7f51\u3002</p> <pre><code>from nltk.corpus import wordnet as wn\n\nword = 'car'\nsynsets = wn.synsets(word)\nprint(synsets[0].definition())       # \u5b9a\u4e49\nprint(synsets[0].lemmas())           # \u540c\u4e49\u8bcd\nprint(synsets[0].hypernyms())        # \u4e0a\u4f4d\u8bcd\nprint(synsets[0].hyponyms())         # \u4e0b\u4f4d\u8bcd\n</code></pre> <p>\u4f60\u53ef\u4ee5\u5229\u7528 WordNet \u5b9e\u73b0\uff1a</p> <ul> <li>\u540c\u4e49\u8bcd\u6269\u5c55\uff08synonym expansion\uff09</li> <li>\u8bed\u4e49\u76f8\u4f3c\u5ea6\u8ba1\u7b97</li> <li>\u6982\u5ff5\u5c42\u7ea7\u5206\u6790</li> </ul>"},{"location":"nlp/nltk/#7","title":"\ud83e\udde9 \u7b2c 7 \u7ae0\uff1a\u6587\u672c\u7279\u5f81\u63d0\u53d6\u4e0e\u5206\u7c7b","text":""},{"location":"nlp/nltk/#71","title":"7.1 \u8bcd\u9891\u7edf\u8ba1","text":"<pre><code>from nltk import FreqDist\n\ntext = \"Data science is the study of data using statistics and machine learning.\"\ntokens = word_tokenize(text.lower())\nfdist = FreqDist(tokens)\nprint(fdist.most_common(5))\nfdist.plot(20)\n</code></pre>"},{"location":"nlp/nltk/#72","title":"7.2 \u7b80\u5355\u6587\u672c\u5206\u7c7b\uff08\u6734\u7d20\u8d1d\u53f6\u65af\uff09","text":"<p>\u4f7f\u7528 NLTK \u81ea\u5e26\u7684\u7535\u5f71\u8bc4\u8bba\u8bed\u6599\uff1a</p> <pre><code>from nltk.corpus import movie_reviews\nfrom nltk.classify import NaiveBayesClassifier\n\ndef extract_features(words):\n    return {word: True for word in words}\n\ndata = [(extract_features(movie_reviews.words(fileid)), category)\n        for category in movie_reviews.categories()\n        for fileid in movie_reviews.fileids(category)]\n\ntrain, test = data[:1900], data[1900:]\nclassifier = NaiveBayesClassifier.train(train)\nprint(\"Accuracy:\", nltk.classify.accuracy(classifier, test))\nclassifier.show_most_informative_features(10)\n</code></pre>"},{"location":"nlp/nltk/#8","title":"\ud83e\udde9 \u7b2c 8 \u7ae0\uff1a\u8fdb\u9636\u4e0e\u7efc\u5408\u5e94\u7528","text":""},{"location":"nlp/nltk/#81-collocations","title":"8.1 \u642d\u914d\u5206\u6790\uff08Collocations\uff09","text":"<p>\u627e\u51fa\u8bcd\u8bed\u642d\u914d\u9891\u7e41\u7684\u7ec4\u5408\uff1a</p> <pre><code>from nltk.collocations import BigramCollocationFinder\nfrom nltk.metrics import BigramAssocMeasures\n\ntokens = word_tokenize(\"She sells sea shells by the sea shore.\")\nfinder = BigramCollocationFinder.from_words(tokens)\nprint(finder.nbest(BigramAssocMeasures.likelihood_ratio, 5))\n</code></pre>"},{"location":"nlp/nltk/#82","title":"8.2 \u5173\u952e\u8bcd\u63d0\u53d6\u4e0e\u5171\u73b0\u7f51\u7edc","text":"<p>\u4f60\u53ef\u4ee5\u57fa\u4e8e\u8bcd\u9891\u3001TF-IDF\u3001\u4e92\u4fe1\u606f\uff08PMI\uff09\u6784\u5efa\u8bcd\u56fe\uff0c\u63a2\u7d22\u8bed\u4e49\u7ed3\u6784\u3002</p>"},{"location":"nlp/nltk/#83-lda","title":"8.3 \u4e3b\u9898\u5efa\u6a21\uff08LDA\uff09","text":"<p>\u867d\u7136 NLTK \u4e0d\u76f4\u63a5\u5b9e\u73b0 LDA\uff0c\u4f46\u4f60\u53ef\u4ee5\u7528\u5b83\u9884\u5904\u7406\u6587\u672c\uff0c\u7136\u540e\u4ea4\u7ed9 gensim \u8bad\u7ec3\u4e3b\u9898\u6a21\u578b\u3002</p>"},{"location":"nlp/nltk/#9-sentiment-analysis","title":"\ud83e\udde9 \u7b2c 9 \u7ae0\uff1a\u60c5\u611f\u5206\u6790\uff08Sentiment Analysis\uff09","text":"<p>\u60c5\u611f\u5206\u6790\u662f NLP \u7684\u7ecf\u5178\u4efb\u52a1\u4e4b\u4e00\u3002\u76ee\u6807\u662f\u5224\u65ad\u6587\u672c\u7684\u60c5\u7eea\u6781\u6027\uff08\u6b63\u9762\u3001\u8d1f\u9762\u3001\u4e2d\u6027\uff09\u3002</p> <p>NLTK \u63d0\u4f9b\u4e86\u4e24\u6761\u8def\u5f84\uff1a</p> <ol> <li>\u7528\u81ea\u5e26\u8bed\u6599 + \u4f20\u7edf\u5206\u7c7b\u5668\uff08\u5982\u6734\u7d20\u8d1d\u53f6\u65af\uff09</li> <li>\u7528\u5185\u7f6e\u7684 VADER \u6a21\u578b\uff08\u4e13\u4e3a\u793e\u4ea4\u5a92\u4f53\u77ed\u6587\u672c\u4f18\u5316\uff09</li> </ol>"},{"location":"nlp/nltk/#91","title":"9.1 \u7528\u7535\u5f71\u8bc4\u8bba\u8bed\u6599\u8bad\u7ec3\u6734\u7d20\u8d1d\u53f6\u65af\u60c5\u611f\u5206\u7c7b\u5668","text":"<pre><code>import nltk\nfrom nltk.corpus import movie_reviews\nfrom nltk.classify import NaiveBayesClassifier\nfrom nltk.classify.util import accuracy\n\ndef extract_features(words):\n    return {word: True for word in words}\n\n# \u52a0\u8f7d\u8bed\u6599\u5e93\ndocuments = [(extract_features(movie_reviews.words(fileid)), category)\n             for category in movie_reviews.categories()\n             for fileid in movie_reviews.fileids(category)]\n\ntrain_set, test_set = documents[:1900], documents[1900:]\nclassifier = NaiveBayesClassifier.train(train_set)\n\nprint(\"Accuracy:\", accuracy(classifier, test_set))\nclassifier.show_most_informative_features(10)\n</code></pre> <p>\u8f93\u51fa\u793a\u4f8b\uff1a</p> <pre><code>Accuracy: 0.82\nMost Informative Features\n   outstanding = True           pos : neg = 9.0 : 1.0\n   awful = True                 neg : pos = 8.0 : 1.0\n   ...\n</code></pre> <p>\u539f\u7406\u7b80\u8ff0\uff1a \u6734\u7d20\u8d1d\u53f6\u65af\u5206\u7c7b\u5668\u57fa\u4e8e\u8bcd\u8bed\u7684\u6761\u4ef6\u6982\u7387\uff1a [ P(\\text{label}|\\text{words}) \\propto P(\\text{label}) \\times \\prod_i P(w_i|\\text{label}) ] \u5047\u8bbe\u8bcd\u8bed\u72ec\u7acb\uff08\u8fd9\u662f\u201c\u6734\u7d20\u201d\u7684\u5730\u65b9\uff09\uff0c\u5728\u5927\u8bed\u6599\u4e0a\u6548\u679c\u4ecd\u7136\u60ca\u4eba\u5730\u7a33\u5065\u3002</p>"},{"location":"nlp/nltk/#92-vader","title":"9.2 \u4f7f\u7528 VADER \u505a\u793e\u4ea4\u5a92\u4f53\u60c5\u611f\u5206\u6790","text":"<p>VADER\uff08Valence Aware Dictionary for sEntiment Reasoning\uff09\u662f\u4e00\u4e2a\u57fa\u4e8e\u8bcd\u5178 + \u89c4\u5219\u7684\u60c5\u611f\u5206\u6790\u5668\uff0c\u5c24\u5176\u64c5\u957f\u5904\u7406\u5e26\u8868\u60c5\u7b26\u53f7\u3001\u7f29\u5199\u3001\u611f\u53f9\u53f7\u7684\u77ed\u6587\u672c\uff08\u5982\u63a8\u7279\u3001\u8bc4\u8bba\uff09\u3002</p> <pre><code>from nltk.sentiment import SentimentIntensityAnalyzer\n\nsia = SentimentIntensityAnalyzer()\n\nsentences = [\n    \"I love this movie! It's amazing \ud83d\ude0a\",\n    \"The plot was terrible and boring...\",\n    \"Not bad, but not great either.\"\n]\n\nfor s in sentences:\n    print(s, \"\u2192\", sia.polarity_scores(s))\n</code></pre> <p>\u8f93\u51fa\uff1a</p> <pre><code>I love this movie! ... \u2192 {'neg': 0.0, 'neu': 0.3, 'pos': 0.7, 'compound': 0.85}\nThe plot was terrible ... \u2192 {'neg': 0.6, 'neu': 0.4, 'pos': 0.0, 'compound': -0.78}\n</code></pre> <p><code>compound</code> \u5206\u6570\u5728 [-1, 1] \u95f4\uff0c\u8868\u793a\u6574\u4f53\u60c5\u7eea\u5f3a\u5ea6\u3002 VADER \u4e0d\u9700\u8981\u8bad\u7ec3\uff0c\u9002\u5408\u5feb\u901f\u5206\u6790\u63a8\u7279\u3001\u8bc4\u8bba\u3001\u5f39\u5e55\u7b49\u6587\u672c\u3002</p>"},{"location":"nlp/nltk/#93-nltk","title":"9.3 \u7528 NLTK \u6784\u5efa\u60c5\u611f\u8bcd\u5178","text":"<p>\u5982\u679c\u60f3\u81ea\u5b9a\u4e49\u60c5\u611f\u5206\u6790\u89c4\u5219\uff0c\u4f60\u53ef\u4ee5\u4ece WordNet \u6784\u5efa\u81ea\u5df1\u7684\u60c5\u7eea\u8bcd\u5178\u3002</p> <pre><code>from nltk.corpus import wordnet as wn\n\npositive = ['good', 'happy', 'excellent', 'fortunate', 'correct', 'superior']\nnegative = ['bad', 'sad', 'terrible', 'poor', 'wrong', 'inferior']\n\ndef get_synonyms(word):\n    syns = set()\n    for s in wn.synsets(word):\n        for lemma in s.lemmas():\n            syns.add(lemma.name())\n    return syns\n\npos_lexicon = set()\nneg_lexicon = set()\nfor w in positive: pos_lexicon.update(get_synonyms(w))\nfor w in negative: neg_lexicon.update(get_synonyms(w))\n\nprint(\"Positive words:\", list(pos_lexicon)[:10])\nprint(\"Negative words:\", list(neg_lexicon)[:10])\n</code></pre> <p>\u4f60\u53ef\u4ee5\u57fa\u4e8e\u8fd9\u4e9b\u8bcd\u96c6\u5408\u505a\u8bcd\u9891\u7edf\u8ba1\u6216 TF-IDF \u8ba1\u7b97\uff0c\u4ece\u800c\u624b\u5de5\u6784\u9020\u201c\u60c5\u611f\u5f97\u5206\u201d\u3002</p>"},{"location":"nlp/nltk/#10-nltk-nlpbert-gpt","title":"\ud83e\udde9 \u7b2c 10 \u7ae0\uff1aNLTK \u4e0e\u73b0\u4ee3 NLP\uff08BERT / GPT \u7684\u8854\u63a5\uff09","text":"<p>NLTK \u662f\u4f20\u7edf NLP \u7684\u57fa\u77f3\uff0c \u800c\u73b0\u4ee3 NLP \u6a21\u578b\uff08\u5982 BERT\u3001GPT\u3001T5\uff09\u4ee3\u8868\u7684\u662f\u6df1\u5ea6\u8bed\u4e49\u7406\u89e3\u7684\u65b0\u65f6\u4ee3\u3002 \u8fd9\u4e00\u7ae0\u8bb2\u5982\u4f55\u628a NLTK \u7684\u6570\u636e\u7ba1\u7ebf\u4e0e\u6df1\u5ea6\u6a21\u578b\u7ed3\u5408\u3002</p>"},{"location":"nlp/nltk/#101-nltk-transformer","title":"10.1 \u4f7f\u7528 NLTK \u505a\u524d\u5904\u7406\uff0c\u9001\u5165 Transformer \u6a21\u578b","text":"<pre><code>from nltk.tokenize import word_tokenize\nfrom transformers import pipeline\n\n# 1. \u7528 NLTK \u505a\u5206\u8bcd\u3001\u6e05\u6d17\ntext = \"Natural language processing is fascinating but complex!\"\ntokens = [w.lower() for w in word_tokenize(text) if w.isalpha()]\nprint(\"Cleaned tokens:\", tokens)\n\n# 2. \u7528\u73b0\u4ee3\u6a21\u578b\u5206\u6790\nanalyzer = pipeline(\"sentiment-analysis\")\nprint(analyzer(text))\n</code></pre> <p>\u8f93\u51fa\uff1a</p> <pre><code>Cleaned tokens: ['natural', 'language', 'processing', 'is', 'fascinating', 'but', 'complex']\n[{'label': 'POSITIVE', 'score': 0.9998}]\n</code></pre> <p>NLTK \u8d1f\u8d23\u9884\u5904\u7406\u4e0e\u7279\u5f81\u5316\uff1bTransformers \u8d1f\u8d23\u8bed\u4e49\u5efa\u6a21\u4e0e\u63a8\u7406\u3002 \u8fd9\u6b63\u662f\u73b0\u4ee3 NLP \u7684\u6700\u4f73\u5b9e\u8df5\u3002</p>"},{"location":"nlp/nltk/#102","title":"10.2 \u4ece\u8bcd\u888b\u5230\u8bcd\u5411\u91cf\u7684\u6f14\u8fdb","text":"<p>NLTK \u4e3b\u8981\u5904\u7406\u7b26\u53f7\u7ea7\u6587\u672c\uff1a\u5355\u8bcd\u3001\u6807\u70b9\u3001\u53e5\u6cd5\u6811\u3002 \u4f46\u5728\u6df1\u5ea6\u5b66\u4e60\u4e2d\uff0c\u6211\u4eec\u9700\u8981\u6570\u503c\u5316\u8868\u793a\uff08word embeddings\uff09\u3002</p> <p>\u8bcd\u888b\u6a21\u578b\uff08Bag-of-Words, BoW\uff09 \u2192 Word2Vec \u2192 GloVe \u2192 Transformer Embeddings \u8fd9\u662f\u4e00\u6761\u201c\u4ece\u7edf\u8ba1\u5230\u8bed\u4e49\u201d\u7684\u6f14\u5316\u8def\u5f84\u3002</p> <p>\u53ef\u4ee5\u7528 NLTK \u6784\u9020 BoW \u7279\u5f81\uff1a</p> <pre><code>from nltk import FreqDist\nfrom sklearn.feature_extraction.text import CountVectorizer\n\ncorpus = [\"I love NLP\", \"NLP loves deep learning\"]\nvectorizer = CountVectorizer()\nX = vectorizer.fit_transform(corpus)\nprint(vectorizer.get_feature_names_out())\nprint(X.toarray())\n</code></pre> <p>\u8f93\u51fa\uff1a</p> <pre><code>['deep' 'learning' 'love' 'loves' 'nlp']\n[[0 0 1 0 1]\n [1 1 0 1 1]]\n</code></pre>"},{"location":"nlp/nltk/#103-wordnet","title":"10.3 \u8bed\u4e49\u76f8\u4f3c\u5ea6\uff1a\u7528 WordNet + \u9884\u8bad\u7ec3\u6a21\u578b\u7ed3\u5408","text":"<pre><code>from nltk.corpus import wordnet as wn\n\ndog = wn.synset('dog.n.01')\ncat = wn.synset('cat.n.01')\ncar = wn.synset('car.n.01')\n\nprint(\"dog-cat:\", dog.wup_similarity(cat))\nprint(\"dog-car:\", dog.wup_similarity(car))\n</code></pre> <p>\u8f93\u51fa\uff1a</p> <pre><code>dog-cat: 0.857\ndog-car: 0.6\n</code></pre> <p>WordNet \u7684\u76f8\u4f3c\u5ea6\u57fa\u4e8e\u8bed\u4e49\u5c42\u7ea7\u8ddd\u79bb\u3002 \u82e5\u914d\u5408 BERT \u8bcd\u5d4c\u5165\uff08transformers\uff09\uff0c\u4f60\u53ef\u4ee5\u6784\u5efa\u6df7\u5408\u6a21\u578b\uff0c\u5b9e\u73b0\uff1a</p> <ul> <li>\u6982\u5ff5\u5c42\u7ea7\u7684\u63a8\u7406\uff08WordNet\uff09</li> <li>\u8bed\u5883\u5316\u8bed\u4e49\u8ddd\u79bb\uff08BERT Embedding\uff09</li> </ul>"},{"location":"nlp/nltk/#104-nlp-nltk","title":"10.4 \u73b0\u4ee3 NLP \u4e0e NLTK \u7684\u54f2\u5b66\u5dee\u522b","text":"\u5c42\u9762 NLTK Transformers \u6838\u5fc3\u601d\u60f3 \u8bed\u8a00\u89c4\u5219 + \u7edf\u8ba1 \u8bed\u4e49\u8868\u5f81 + \u795e\u7ecf\u7f51\u7edc \u6570\u636e\u5f62\u5f0f \u7b26\u53f7\uff08tokens, trees\uff09 \u5411\u91cf\uff08embeddings\uff09 \u53ef\u89e3\u91ca\u6027 \u5f3a \u5f31 \u7cbe\u5ea6 \u4e2d \u6781\u9ad8 \u9002\u7528\u573a\u666f \u6559\u5b66\u3001\u53ef\u89c6\u5316\u3001\u57fa\u7840NLP \u5546\u4e1a\u5e94\u7528\u3001\u5927\u6a21\u578b\u5fae\u8c03 <p>NLTK \u6559\u4f60\u7406\u89e3\u8bed\u8a00\u7684\u7ed3\u6784\uff1b Transformer \u8ba9\u673a\u5668\u201c\u611f\u53d7\u201d\u8bed\u8a00\u7684\u8bed\u4e49\u3002 \u4e8c\u8005\u7ed3\u5408\uff0c\u624d\u662f\u771f\u6b63\u7684\u201c\u7cbe\u901a NLP\u201d\u3002</p>"},{"location":"nlp/nltk/#_2","title":"\ud83c\udf93 \u5b8c\u6574\u5b66\u4e60\u5efa\u8bae\u8def\u7ebf","text":"<ol> <li>\u638c\u63e1\u8bed\u8a00\u5b66\u57fa\u7840\uff1a    \u5206\u8bcd \u2192 \u8bcd\u6027\u6807\u6ce8 \u2192 \u53e5\u6cd5\u6811</li> <li>\u7406\u89e3\u7edf\u8ba1 NLP\uff1a    \u6734\u7d20\u8d1d\u53f6\u65af\u3001TF-IDF\u3001\u642d\u914d\u5206\u6790</li> <li>\u5b66\u4e60\u8bed\u4e49\u7f51\u7edc\uff1a    WordNet\u3001\u76f8\u4f3c\u5ea6\u8ba1\u7b97\u3001\u540c\u4e49\u8bcd\u6269\u5c55</li> <li>\u8fc7\u6e21\u5230\u6df1\u5ea6\u6a21\u578b\uff1a    \u4e86\u89e3 word2vec\u3001Transformer\u3001BERT</li> <li>\u7efc\u5408\u5b9e\u8df5\u9879\u76ee\uff1a    \u60c5\u611f\u5206\u6790\u3001\u5173\u952e\u8bcd\u63d0\u53d6\u3001\u4e3b\u9898\u5efa\u6a21</li> </ol> <p>NLTK \u5c31\u50cf\u81ea\u7136\u8bed\u8a00\u4e16\u754c\u7684\u663e\u5fae\u955c\u2014\u2014 \u900f\u8fc7\u5b83\uff0c\u4f60\u80fd\u770b\u5230\u8bed\u8a00\u7684\u7ed3\u6784\u3001\u89c4\u5f8b\u4e0e\u5947\u5999\u7684\u6df7\u6c8c\u3002 \u800c\u5f53\u4f60\u628a\u5b83\u4e0e\u73b0\u4ee3\u795e\u7ecf\u7f51\u7edc\u7ed3\u5408\uff0c\u4f60\u5c31\u80fd\u5728\u8ba1\u7b97\u673a\u4e2d\u201c\u91cd\u5efa\u610f\u4e49\u201d\u3002</p> <p>\u662f\u5426\u5e0c\u671b\u6211\u5728\u6b64\u57fa\u7840\u4e0a\uff0c\u7ee7\u7eed\u6269\u5c55\u51fa\u4e00\u4efd \u300cNLTK \u5b9e\u6218\u9879\u76ee\u96c6\u300d\uff08\u4f8b\u5982\uff1a\u6587\u672c\u5206\u7c7b\u3001\u8206\u60c5\u5206\u6790\u3001\u5173\u952e\u8bcd\u63d0\u53d6\u3001\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u7b49\u5b9e\u6218\u6559\u7a0b\uff09\uff1f</p>"},{"location":"nlp/peft/","title":"peft\u5e93","text":"<p>\u597d\u7684\uff0c\u6211\u4eec\u6765\u7cfb\u7edf\u8bb2\u89e3\u4e00\u4e0b PEFT\uff08Parameter-Efficient Fine-Tuning\uff09\u5e93\u3002\u8fd9\u662f\u4e00\u4e2a\u5728\u5927\u6a21\u578b\uff08\u5982 GPT\u3001BERT\u3001LLaMA \u7b49\uff09\u5fae\u8c03\u4e2d\u6781\u5177\u4ef7\u503c\u7684\u5de5\u5177\u2014\u2014\u5b83\u8ba9\u4f60\u4e0d\u7528\u201c\u642c\u8d77\u6574\u5ea7\u5c71\u201d\uff0c\u53ea\u6539\u52a8\u51e0\u4e2a\u201c\u5173\u952e\u87ba\u4e1d\u201d\uff0c\u5c31\u80fd\u9ad8\u6548\u5730\u5b9a\u5236\u6a21\u578b\u3002\u4e0b\u9762\u662f\u4ece\u5165\u95e8\u5230\u8fdb\u9636\u7684\u8be6\u7ec6\u6559\u7a0b\u3002</p>"},{"location":"nlp/peft/#peft","title":"\u4e00\u3001PEFT \u662f\u4ec0\u4e48\uff1f","text":"<p>PEFT\uff08Parameter-Efficient Fine-Tuning\uff09 \u662f Hugging Face \u63a8\u51fa\u7684\u4e00\u4e2a\u5e93\uff0c\u7528\u6765\u5728 \u4e0d\u5fae\u8c03\u6574\u4e2a\u6a21\u578b\u53c2\u6570 \u7684\u60c5\u51b5\u4e0b\uff0c\u53ea\u66f4\u65b0\u4e00\u5c0f\u90e8\u5206\u53c2\u6570 \u6765\u9002\u914d\u65b0\u4efb\u52a1\u3002</p> <p>\u4f20\u7edf\u5fae\u8c03\uff08Full Fine-tuning\uff09\u7684\u95ee\u9898\u662f\uff1a</p> <ul> <li>\u6a21\u578b\u592a\u5927\uff08\u5982\u51e0\u5341\u4ebf\u53c2\u6570\uff09\uff1b</li> <li>\u663e\u5b58\u6d88\u8017\u5de8\u5927\uff1b</li> <li>\u6bcf\u4e2a\u4efb\u52a1\u90fd\u8981\u4fdd\u5b58\u6574\u5957\u6a21\u578b\u3002</li> </ul> <p>\u800c PEFT \u7684\u7406\u5ff5\u662f\uff1a</p> <p>\u201c\u51bb\u7ed3\u5927\u90e8\u5206\u53c2\u6570\uff0c\u53ea\u8bad\u7ec3\u5c11\u91cf\u65b0\u589e\u53c2\u6570\u6a21\u5757\u3002\u201d</p> <p>\u8fd9\u6837\u663e\u5b58\u66f4\u7701\u3001\u8bad\u7ec3\u66f4\u5feb\u3001\u8fc1\u79fb\u66f4\u65b9\u4fbf\u3002</p>"},{"location":"nlp/peft/#peft_1","title":"\u4e8c\u3001PEFT \u7684\u5b89\u88c5\u4e0e\u73af\u5883\u51c6\u5907","text":"<pre><code>pip install peft transformers accelerate datasets\n</code></pre> <p>\u5efa\u8bae\u914d\u5408 <code>transformers</code> \u4e00\u8d77\u4f7f\u7528\uff0c\u56e0\u4e3a PEFT \u6a21\u5757\u76f4\u63a5\u4e0e Hugging Face \u7684\u6a21\u578b\u67b6\u6784\u96c6\u6210\u3002</p>"},{"location":"nlp/peft/#peft_2","title":"\u4e09\u3001PEFT \u7684\u4e3b\u8981\u65b9\u6cd5","text":"<p>PEFT \u63d0\u4f9b\u4e86\u51e0\u79cd\u4e3b\u6d41\u7684\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u7b56\u7565\uff1a</p> \u65b9\u6cd5 \u6838\u5fc3\u601d\u60f3 \u4f18\u70b9 LoRA (Low-Rank Adaptation) \u7ed9\u7ebf\u6027\u5c42\u589e\u52a0\u4f4e\u79e9\u77e9\u9635 \u6700\u5e38\u7528\uff0c\u8bad\u7ec3\u5feb\uff0c\u8282\u7701\u663e\u5b58 Prefix Tuning \u5728\u8f93\u5165\u5e8f\u5217\u524d\u52a0\u53ef\u8bad\u7ec3\u524d\u7f00\u5411\u91cf \u9002\u5408\u8bed\u8a00\u5efa\u6a21\u7c7b\u4efb\u52a1 Prompt Tuning \u7c7b\u4f3c Prefix\uff0c\u4f46\u53ef\u7528\u4e8e\u66f4\u5e7f\u6cdb\u4efb\u52a1 \u5c0f\u53c2\u6570\u91cf\uff0c\u53ef\u5feb\u901f\u8fc1\u79fb IA\u00b3 \u5b66\u4e60\u6807\u91cf\u7cfb\u6570\u8c03\u6574\u6fc0\u6d3b\u503c \u53c2\u6570\u6781\u5c11\uff0c\u6027\u80fd\u4e0d\u9519 Adapters \u5728\u5c42\u95f4\u63d2\u5165\u5c0f\u578b\u9002\u914d\u5c42 \u53ef\u6a21\u5757\u5316\u52a0\u8f7d\u591a\u4e2a\u4efb\u52a1"},{"location":"nlp/peft/#lora-bert","title":"\u56db\u3001LoRA \u5b9e\u6218\uff1a\u5fae\u8c03\u4e00\u4e2a BERT \u5206\u7c7b\u6a21\u578b","text":""},{"location":"nlp/peft/#1","title":"1. \u52a0\u8f7d\u6a21\u578b\u4e0e\u6570\u636e","text":"<pre><code>from transformers import AutoModelForSequenceClassification, AutoTokenizer\nfrom datasets import load_dataset\n\nmodel_name = \"bert-base-uncased\"\ndataset = load_dataset(\"imdb\")\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\ndef preprocess(example):\n    return tokenizer(example[\"text\"], truncation=True, padding=\"max_length\", max_length=128)\n\nencoded = dataset.map(preprocess, batched=True)\n</code></pre>"},{"location":"nlp/peft/#2","title":"2. \u521d\u59cb\u5316\u57fa\u7840\u6a21\u578b\uff08\u51bb\u7ed3\u53c2\u6570\uff09","text":"<pre><code>model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\nfor param in model.parameters():\n    param.requires_grad = False  # \u51bb\u7ed3\u6240\u6709\u53c2\u6570\n</code></pre>"},{"location":"nlp/peft/#3-lora","title":"3. \u5e94\u7528 LoRA","text":"<pre><code>from peft import LoraConfig, get_peft_model\n\n# LoRA\u914d\u7f6e\nlora_config = LoraConfig(\n    r=8,                         # \u4f4e\u79e9\u7ef4\u5ea6\n    lora_alpha=32,               # \u7f29\u653e\u56e0\u5b50\n    target_modules=[\"query\", \"value\"],  # \u5e94\u7528\u4e8e\u6ce8\u610f\u529b\u5c42\n    lora_dropout=0.1,\n    bias=\"none\",\n    task_type=\"SEQ_CLS\"          # \u5e8f\u5217\u5206\u7c7b\u4efb\u52a1\n)\n\npeft_model = get_peft_model(model, lora_config)\npeft_model.print_trainable_parameters()\n</code></pre> <p>\u8f93\u51fa\u7c7b\u4f3c\uff1a</p> <pre><code>trainable params: 590,000 || all params: 110,000,000 || trainable%: 0.5%\n</code></pre> <p>\u8fd9\u610f\u5473\u7740\u53ea\u8bad\u7ec3\u4e86 0.5% \u7684\u53c2\u6570\uff01</p>"},{"location":"nlp/peft/#4","title":"4. \u8bad\u7ec3\u4e0e\u4fdd\u5b58","text":"<pre><code>from transformers import TrainingArguments, Trainer\n\ntraining_args = TrainingArguments(\n    output_dir=\"./lora-bert-imdb\",\n    per_device_train_batch_size=8,\n    num_train_epochs=1,\n    learning_rate=2e-4,\n    logging_steps=50,\n    save_steps=1000,\n)\n\ntrainer = Trainer(\n    model=peft_model,\n    args=training_args,\n    train_dataset=encoded[\"train\"].select(range(2000)),\n    eval_dataset=encoded[\"test\"].select(range(1000)),\n)\ntrainer.train()\n\npeft_model.save_pretrained(\"./lora-bert-imdb\")\n</code></pre> <p>\u8bad\u7ec3\u901f\u5ea6\u6781\u5feb\uff0c\u663e\u5b58\u538b\u529b\u663e\u8457\u51cf\u8f7b\u3002</p>"},{"location":"nlp/peft/#5-peft","title":"5. \u52a0\u8f7d PEFT \u6a21\u578b\u7ee7\u7eed\u4f7f\u7528","text":"<pre><code>from peft import PeftModel\nfrom transformers import AutoModelForSequenceClassification\n\nbase_model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\nmodel = PeftModel.from_pretrained(base_model, \"./lora-bert-imdb\")\n</code></pre> <p>\u73b0\u5728\u53ef\u4ee5\u50cf\u666e\u901a\u6a21\u578b\u4e00\u6837\u8fdb\u884c\u63a8\u7406\uff1a</p> <pre><code>inputs = tokenizer(\"This movie was fantastic!\", return_tensors=\"pt\")\npred = model(**inputs).logits.argmax().item()\nprint(\"Positive\" if pred else \"Negative\")\n</code></pre>"},{"location":"nlp/peft/#peft_3","title":"\u4e94\u3001PEFT \u7684\u9ad8\u7ea7\u6280\u5de7","text":"<ol> <li>\u5408\u5e76\u6743\u91cd\u4ee5\u5bfc\u51fa\u5b8c\u6574\u6a21\u578b\uff1a</li> </ol> <p><code>python    model = peft_model.merge_and_unload()    model.save_pretrained(\"merged_model\")</code></p> <ol> <li>\u591a\u4efb\u52a1 LoRA \u9002\u914d\uff1a    \u4f60\u53ef\u4ee5\u5728\u4e0d\u540c\u4efb\u52a1\u4e0a\u8bad\u7ec3\u591a\u4e2a LoRA adapter\uff0c\u7136\u540e\u52a8\u6001\u52a0\u8f7d\u4e0d\u540c adapter\u3002</li> </ol> <p><code>python    model.load_adapter(\"adapter_path\", adapter_name=\"sentiment\")    model.set_adapter(\"sentiment\")</code></p> <ol> <li>\u4e0e\u91cf\u5316\uff08bitsandbytes\uff09\u7ed3\u5408\uff1a    \u5728\u5927\u6a21\u578b\uff08\u5982 LLaMA\u3001GPT-J\uff09\u4e0a\uff0c\u53ef\u4ee5\u7ed3\u5408 <code>bitsandbytes</code> \u91cf\u5316 + LoRA \u5fae\u8c03\u3002</li> </ol> <p>```python    from transformers import BitsAndBytesConfig</p> <p>quant_config = BitsAndBytesConfig(load_in_8bit=True)    model = AutoModelForCausalLM.from_pretrained(model_name, quantization_config=quant_config)    ```</p>"},{"location":"nlp/peft/#peft_4","title":"\u516d\u3001\u4e3a\u4ec0\u4e48 PEFT \u5982\u6b64\u91cd\u8981\uff1f","text":"<p>PEFT \u662f\u901a\u5f80 \u201c\u4e2a\u6027\u5316 AI\u201d \u7684\u5173\u952e\u8def\u5f84\u3002 \u5728\u7b97\u529b\u53d7\u9650\u7684\u73af\u5883\u4e0b\uff0c\u5b83\u8ba9\u7814\u7a76\u8005\u548c\u5f00\u53d1\u8005\u80fd\u5728\u7b14\u8bb0\u672c\u7535\u8111\u6216\u5355\u5361 GPU \u4e0a\u5feb\u901f\u5b9a\u5236\u51fa\u4e13\u7528\u6a21\u578b\u3002</p> <p>\u5728\u4e1a\u754c\uff0c\u5982 LLaMA-LoRA\u3001Alpaca\u3001Baichuan-Finetune \u7b49\u6a21\u578b\uff0c\u51e0\u4e4e\u90fd\u91c7\u7528\u4e86 PEFT \u7684 LoRA \u7b56\u7565\u3002</p>"},{"location":"nlp/peft/#_1","title":"\u4e03\u3001\u5b66\u4e60\u5ef6\u4f38\u65b9\u5411","text":"<ol> <li>\u9605\u8bfb\u8bba\u6587\uff1aLoRA: Low-Rank Adaptation of Large Language Models (Hu et al., 2021)</li> <li>\u6df1\u5165\u4e86\u89e3\u591a\u9002\u914d\u7b56\u7565\uff1aAdapters, Prefix, Prompt, IA\u00b3</li> <li>\u5c1d\u8bd5\u5728 LLM \u6307\u4ee4\u5fae\u8c03\uff08Instruction Tuning\uff09 \u4efb\u52a1\u4e0a\u4f7f\u7528 PEFT\u3002</li> </ol> <p>\u60f3\u66f4\u6df1\u5165\u5417\uff1f\u6211\u53ef\u4ee5\u5e2e\u4f60\u5199\u4e00\u4e2a\u4ece \u96f6\u5b9e\u73b0 LoRA \u5fae\u8c03 LLaMA \u6216 ChatGLM \u7684\u5b8c\u6574 notebook \u6559\u7a0b\uff08\u542b\u63a8\u7406\u63a5\u53e3\uff09\u3002 \u662f\u5426\u5e0c\u671b\u6211\u7ee7\u7eed\u8fd9\u4e2a\u65b9\u5411\uff1f</p>"},{"location":"others/wsl/","title":"Windows WSL \u8be6\u7ec6\u6559\u7a0b","text":""},{"location":"others/wsl/#wsl","title":"\u4ec0\u4e48\u662f WSL\uff1f","text":"<p>Windows Subsystem for Linux\uff08WSL\uff09\u662f\u5fae\u8f6f\u5728 Windows 10/11 \u4e2d\u63a8\u51fa\u7684\u529f\u80fd\uff0c\u5141\u8bb8\u7528\u6237\u5728 Windows \u4e0a\u76f4\u63a5\u8fd0\u884c Linux \u73af\u5883\uff0c\u65e0\u9700\u865a\u62df\u673a\u6216\u53cc\u7cfb\u7edf\u3002</p>"},{"location":"others/wsl/#wsl-1-vs-wsl-2","title":"WSL 1 vs WSL 2","text":"\u7279\u6027 WSL 1 WSL 2 \u67b6\u6784 \u8f6c\u6362\u5c42 \u5b8c\u6574 Linux \u5185\u6838 \u6027\u80fd \u6587\u4ef6\u7cfb\u7edf\u64cd\u4f5c\u8f83\u6162 \u6587\u4ef6\u7cfb\u7edf\u64cd\u4f5c\u5feb \u517c\u5bb9\u6027 \u8f83\u597d \u5b8c\u5168\u7cfb\u7edf\u8c03\u7528\u517c\u5bb9 \u542f\u52a8\u901f\u5ea6 \u5feb \u7a0d\u6162"},{"location":"others/wsl/#wsl_1","title":"\u5b89\u88c5 WSL","text":""},{"location":"others/wsl/#_1","title":"\u65b9\u6cd5\u4e00\uff1a\u7b80\u5355\u5b89\u88c5\uff08\u63a8\u8350\uff09","text":"<pre><code># \u4ee5\u7ba1\u7406\u5458\u8eab\u4efd\u8fd0\u884c PowerShell\nwsl --install\n</code></pre> <p>\u6b64\u547d\u4ee4\u4f1a\uff1a - \u542f\u7528 WSL \u529f\u80fd - \u5b89\u88c5\u9ed8\u8ba4\u7684 Ubuntu \u53d1\u884c\u7248 - \u5b89\u88c5 WSL 2 \u5185\u6838</p>"},{"location":"others/wsl/#_2","title":"\u65b9\u6cd5\u4e8c\uff1a\u5206\u6b65\u5b89\u88c5","text":"<pre><code># \u542f\u7528 WSL \u529f\u80fd\ndism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart\n\n# \u542f\u7528\u865a\u62df\u673a\u5e73\u53f0\ndism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart\n\n# \u91cd\u542f\u8ba1\u7b97\u673a\n</code></pre>"},{"location":"others/wsl/#linux","title":"\u5b89\u88c5\u7279\u5b9a Linux \u53d1\u884c\u7248","text":"<pre><code># \u67e5\u770b\u53ef\u7528\u7684\u53d1\u884c\u7248\nwsl --list --online\n\n# \u5b89\u88c5\u7279\u5b9a\u53d1\u884c\u7248\nwsl --install -d Ubuntu-22.04\nwsl --install -d Debian\nwsl --install -d Kali-Linux\n</code></pre>"},{"location":"others/wsl/#_3","title":"\u57fa\u672c\u4f7f\u7528","text":""},{"location":"others/wsl/#wsl_2","title":"\u542f\u52a8 WSL","text":"<pre><code># \u542f\u52a8\u9ed8\u8ba4\u53d1\u884c\u7248\nwsl\n\n# \u542f\u52a8\u7279\u5b9a\u53d1\u884c\u7248\nwsl -d Ubuntu-22.04\n\n# \u4ee5\u7279\u5b9a\u7528\u6237\u542f\u52a8\nwsl -u username\n</code></pre>"},{"location":"others/wsl/#wsl_3","title":"\u5728 WSL \u4e2d\u64cd\u4f5c","text":"<pre><code># \u66f4\u65b0\u8f6f\u4ef6\u5305\nsudo apt update &amp;&amp; sudo apt upgrade\n\n# \u5b89\u88c5\u8f6f\u4ef6\nsudo apt install git python3 nodejs\n\n# \u67e5\u770b WSL \u4fe1\u606f\ncat /etc/os-release\n\n# \u8bbf\u95ee Windows \u6587\u4ef6\ncd /mnt/c/Users/YourUsername\n</code></pre>"},{"location":"others/wsl/#wsl_4","title":"WSL \u914d\u7f6e","text":""},{"location":"others/wsl/#wsl_5","title":"\u67e5\u770b WSL \u72b6\u6001","text":"<pre><code># \u67e5\u770b\u5df2\u5b89\u88c5\u7684\u53d1\u884c\u7248\nwsl --list --verbose\n\n# \u67e5\u770b WSL \u7248\u672c\nwsl --status\n</code></pre>"},{"location":"others/wsl/#wsl_6","title":"\u8bbe\u7f6e\u9ed8\u8ba4 WSL \u7248\u672c","text":"<pre><code># \u8bbe\u7f6e WSL 2 \u4e3a\u9ed8\u8ba4\u7248\u672c\nwsl --set-default-version 2\n</code></pre>"},{"location":"others/wsl/#_4","title":"\u8f6c\u6362\u53d1\u884c\u7248\u7248\u672c","text":"<pre><code># \u5c06\u53d1\u884c\u7248\u8f6c\u6362\u4e3a WSL 2\nwsl --set-version Ubuntu-22.04 2\n\n# \u5c06\u53d1\u884c\u7248\u8f6c\u6362\u4e3a WSL 1\nwsl --set-version Ubuntu-22.04 1\n</code></pre>"},{"location":"others/wsl/#_5","title":"\u6587\u4ef6\u7cfb\u7edf\u4e92\u64cd\u4f5c","text":""},{"location":"others/wsl/#wsl-windows","title":"\u5728 WSL \u4e2d\u8bbf\u95ee Windows \u6587\u4ef6","text":"<pre><code># Windows C \u76d8\u6302\u8f7d\u5728 /mnt/c\ncd /mnt/c/Users/YourUsername\n\n# \u5728 WSL \u4e2d\u8fd0\u884c Windows \u7a0b\u5e8f\n/mnt/c/Windows/System32/notepad.exe\n</code></pre>"},{"location":"others/wsl/#windows-wsl_1","title":"\u5728 Windows \u4e2d\u8bbf\u95ee WSL \u6587\u4ef6","text":"<pre><code># \u5728\u6587\u4ef6\u8d44\u6e90\u7ba1\u7406\u5668\u4e2d\u8bbf\u95ee\n\\\\wsl$\\Ubuntu-22.04\\home\\username\n\n# \u6216\u5728 WSL \u4e2d\u6253\u5f00 Windows \u6587\u4ef6\u7ba1\u7406\u5668\nexplorer.exe .\n</code></pre>"},{"location":"others/wsl/#_6","title":"\u7f51\u7edc\u529f\u80fd","text":""},{"location":"others/wsl/#_7","title":"\u7aef\u53e3\u8f6c\u53d1","text":"<p>WSL 2 \u6709\u72ec\u7acb\u7684 IP\uff0c\u4f46 Windows \u4f1a\u81ea\u52a8\u8f6c\u53d1\u7aef\u53e3\u3002</p> <pre><code># \u5728 WSL \u4e2d\u542f\u52a8 web \u670d\u52a1\u5668\npython3 -m http.server 8000\n\n# \u5728 Windows \u6d4f\u89c8\u5668\u4e2d\u8bbf\u95ee\n# http://localhost:8000\n</code></pre>"},{"location":"others/wsl/#_8","title":"\u9ad8\u7ea7\u914d\u7f6e","text":""},{"location":"others/wsl/#wsl_7","title":"WSL \u914d\u7f6e\u6587\u4ef6","text":"<p>\u521b\u5efa <code>%UserProfile%\\.wslconfig</code> \u6587\u4ef6\uff1a</p> <pre><code>[wsl2]\nmemory=4GB\nprocessors=2\nlocalhostForwarding=true\n</code></pre>"},{"location":"others/wsl/#_9","title":"\u5bfc\u51fa\u548c\u5bfc\u5165\u53d1\u884c\u7248","text":"<pre><code># \u5bfc\u51fa\u53d1\u884c\u7248\nwsl --export Ubuntu-22.04 Ubuntu-backup.tar\n\n# \u5bfc\u5165\u53d1\u884c\u7248\nwsl --import Ubuntu-new .\\Ubuntu-new\\ Ubuntu-backup.tar\n</code></pre>"},{"location":"others/wsl/#_10","title":"\u5378\u8f7d\u53d1\u884c\u7248","text":"<pre><code># \u6ce8\u9500\u5e76\u5220\u9664\u53d1\u884c\u7248\nwsl --unregister Ubuntu-22.04\n</code></pre>"},{"location":"others/wsl/#_11","title":"\u5f00\u53d1\u73af\u5883\u914d\u7f6e","text":""},{"location":"others/wsl/#_12","title":"\u5b89\u88c5\u5f00\u53d1\u5de5\u5177","text":"<pre><code># \u66f4\u65b0\u7cfb\u7edf\nsudo apt update &amp;&amp; sudo apt upgrade -y\n\n# \u5b89\u88c5\u5f00\u53d1\u5de5\u5177\nsudo apt install build-essential git curl wget\n\n# \u5b89\u88c5 Node.js\ncurl -fsSL https://deb.nodesource.com/setup_lts.x | sudo -E bash -\nsudo apt-get install -y nodejs\n\n# \u5b89\u88c5 Python \u5f00\u53d1\u73af\u5883\nsudo apt install python3-pip python3-venv\n</code></pre>"},{"location":"others/wsl/#vs-code-wsl","title":"\u914d\u7f6e VS Code \u4e0e WSL","text":"<ol> <li>\u5b89\u88c5 VS Code \u7684 \"Remote - WSL\" \u6269\u5c55</li> <li>\u5728 WSL \u7ec8\u7aef\u4e2d\u8f93\u5165 <code>code .</code></li> <li>VS Code \u5c06\u5728 WSL \u73af\u5883\u4e2d\u6253\u5f00</li> </ol>"},{"location":"others/wsl/#_13","title":"\u5e38\u89c1\u95ee\u9898\u89e3\u51b3","text":""},{"location":"others/wsl/#1-wsl","title":"1. WSL \u5b89\u88c5\u5931\u8d25","text":"<pre><code># \u91cd\u7f6e WSL\nwsl --shutdown\nwsl --unregister Ubuntu-22.04\nwsl --install\n</code></pre>"},{"location":"others/wsl/#2","title":"2. \u7f51\u7edc\u8fde\u63a5\u95ee\u9898","text":"<pre><code># \u91cd\u542f WSL \u670d\u52a1\nwsl --shutdown\n</code></pre>"},{"location":"others/wsl/#3","title":"3. \u6587\u4ef6\u6743\u9650\u95ee\u9898","text":"<pre><code># \u5728 WSL \u4e2d\u4fee\u590d Windows \u6587\u4ef6\u6743\u9650\nsudo chmod -R 755 /mnt/c/your/project/path\n</code></pre>"},{"location":"others/wsl/#_14","title":"\u6027\u80fd\u4f18\u5316\u6280\u5de7","text":"<ol> <li>\u5c06\u9879\u76ee\u6587\u4ef6\u653e\u5728 WSL \u6587\u4ef6\u7cfb\u7edf\u4e2d \u800c\u4e0d\u662f Windows \u6587\u4ef6\u7cfb\u7edf</li> <li>\u4f7f\u7528 WSL 2 \u83b7\u5f97\u66f4\u597d\u7684\u6027\u80fd</li> <li>\u5408\u7406\u914d\u7f6e\u5185\u5b58\u548c CPU \u9650\u5236 \u5728 <code>.wslconfig</code> \u4e2d</li> <li>\u5b9a\u671f\u66f4\u65b0 WSL \u548c Linux \u53d1\u884c\u7248</li> </ol>"},{"location":"others/wsl/#_15","title":"\u5b9e\u7528\u547d\u4ee4\u603b\u7ed3","text":"<pre><code># WSL \u7ba1\u7406\u547d\u4ee4\nwsl --list --verbose          # \u5217\u51fa\u6240\u6709\u53d1\u884c\u7248\nwsl --shutdown               # \u5173\u95ed\u6240\u6709 WSL \u5b9e\u4f8b\nwsl --terminate &lt;Distro&gt;     # \u7ec8\u6b62\u7279\u5b9a\u53d1\u884c\u7248\nwsl --set-version &lt;Distro&gt; 2 # \u8bbe\u7f6e\u7248\u672c\n\n# \u5728 WSL \u4e2d\nwsl --update                # \u66f4\u65b0 WSL \u5185\u6838\nwsl --status                # \u67e5\u770b WSL \u72b6\u6001\n</code></pre> <p>\u8fd9\u4e2a\u6559\u7a0b\u6db5\u76d6\u4e86 WSL \u7684\u4e3b\u8981\u529f\u80fd\u548c\u4f7f\u7528\u65b9\u6cd5\u3002WSL \u4e3a\u5f00\u53d1\u8005\u548c\u7cfb\u7edf\u7ba1\u7406\u5458\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684 Linux \u73af\u5883\uff0c\u540c\u65f6\u4fdd\u6301\u4e86 Windows \u7684\u4fbf\u5229\u6027\u3002</p>"}]}