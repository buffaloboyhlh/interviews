# LangChain æµå¼ä¼ è¾“

## æ¦‚è¿°

LangChain çš„æµå¼ä¼ è¾“ç³»ç»Ÿå¯ä»¥å®æ—¶å±•ç¤ºæ›´æ–°ï¼Œè¿™å¯¹äºæ„å»ºå“åº”è¿…é€Ÿçš„ LLM åº”ç”¨è‡³å…³é‡è¦ã€‚é€šè¿‡é€æ­¥æ˜¾ç¤ºè¾“å‡ºï¼ˆå³ä½¿åœ¨å®Œæ•´å“åº”å‡†å¤‡å¥½ä¹‹å‰ï¼‰ï¼Œæµå¼ä¼ è¾“æ˜¾è‘—æ”¹å–„äº†ç”¨æˆ·ä½“éªŒï¼Œç‰¹åˆ«æ˜¯åœ¨å¤„ç† LLM çš„å»¶è¿Ÿæ—¶ã€‚

### æµå¼ä¼ è¾“çš„ä¼˜åŠ¿

- **å®æ—¶åé¦ˆ**ï¼šç”¨æˆ·å¯ä»¥çœ‹åˆ°å¤„ç†è¿›åº¦
- **é™ä½æ„ŸçŸ¥å»¶è¿Ÿ**ï¼šå³ä½¿æ€»æ—¶é—´ç›¸åŒï¼Œç”¨æˆ·ä½“éªŒæ›´å¥½
- **è°ƒè¯•å‹å¥½**ï¼šå¯ä»¥è§‚å¯Ÿæ¯ä¸ªæ­¥éª¤çš„æ‰§è¡Œæƒ…å†µ
- **çµæ´»æ§åˆ¶**ï¼šæ”¯æŒå¤šç§æµå¼ä¼ è¾“æ¨¡å¼

## åŸºç¡€è®¾ç½®

### åˆ›å»ºåŸºç¡€ Agent

```python
from langchain.agents import create_agent

# åˆ›å»ºä¸€ä¸ªç®€å•çš„å·¥å…·å‡½æ•°
def get_weather(city: str) -> str:
    """è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”"""
    return f"{city}çš„å¤©æ°”æ˜¯æ™´æœ—çš„ï¼Œ25Â°C"

# åˆ›å»º Agent
agent = create_agent(
    model="openai:gpt-4o",
    tools=[get_weather],
)
```

## æµå¼ä¼ è¾“æ¨¡å¼

### 1. ä»£ç†è¿›åº¦æµ (Agent Progress)

ä½¿ç”¨ `stream_mode="updates"` æ¥æµå¼ä¼ è¾“ä»£ç†çš„æ¯ä¸ªæ­¥éª¤è¿›åº¦ã€‚

```python
def stream_agent_progress():
    """æµå¼ä¼ è¾“ä»£ç†æ‰§è¡Œè¿›åº¦"""
    print("=== ä»£ç†è¿›åº¦æµå¼ä¼ è¾“ ===")
    
    for chunk in agent.stream(
        {"messages": [{"role": "user", "content": "åŒ—äº¬å’Œä¸Šæµ·çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"}]},
        stream_mode="updates",  # å…³é”®å‚æ•°
    ):
        for step, data in chunk.items():
            print(f"æ­¥éª¤: {step}")
            if 'messages' in data and data['messages']:
                last_message = data['messages'][-1]
                print(f"å†…å®¹: {last_message.content}")
                if hasattr(last_message, 'tool_calls') and last_message.tool_calls:
                    print(f"å·¥å…·è°ƒç”¨: {last_message.tool_calls}")
            print("-" * 50)

# è°ƒç”¨ç¤ºä¾‹
stream_agent_progress()
```

**è¾“å‡ºç¤ºä¾‹ï¼š**
```
æ­¥éª¤: model
å†…å®¹: 
å·¥å…·è°ƒç”¨: [{'name': 'get_weather', 'args': {'city': 'åŒ—äº¬'}, 'id': 'call_123'}]
--------------------------------------------------
æ­¥éª¤: tools
å†…å®¹: åŒ—äº¬çš„å¤©æ°”æ˜¯æ™´æœ—çš„ï¼Œ25Â°C
--------------------------------------------------
æ­¥éª¤: model
å†…å®¹: åŒ—äº¬å¤©æ°”æ™´æœ—ï¼Œ25Â°Cã€‚æ¥ä¸‹æ¥æŸ¥è¯¢ä¸Šæµ·å¤©æ°”...
å·¥å…·è°ƒç”¨: [{'name': 'get_weather', 'args': {'city': 'ä¸Šæµ·'}, 'id': 'call_456'}]
--------------------------------------------------
æ­¥éª¤: tools
å†…å®¹: ä¸Šæµ·çš„å¤©æ°”æ˜¯æ™´æœ—çš„ï¼Œ25Â°C
--------------------------------------------------
æ­¥éª¤: model
å†…å®¹: åŒ—äº¬å’Œä¸Šæµ·éƒ½æ˜¯æ™´æœ—å¤©æ°”ï¼Œ25Â°Cã€‚
--------------------------------------------------
```

### 2. LLM Token æµ (LLM Tokens)

ä½¿ç”¨ `stream_mode="messages"` æ¥æµå¼ä¼ è¾“ LLM ç”Ÿæˆçš„æ¯ä¸ª tokenã€‚

```python
def stream_llm_tokens():
    """æµå¼ä¼ è¾“ LLM ç”Ÿæˆçš„ tokens"""
    print("=== LLM Token æµå¼ä¼ è¾“ ===")
    
    for token, metadata in agent.stream(
        {"messages": [{"role": "user", "content": "ä¸Šæµ·çš„å¤©æ°”å¦‚ä½•ï¼Ÿ"}]},
        stream_mode="messages",  # å…³é”®å‚æ•°
    ):
        node_name = metadata.get('langgraph_node', 'unknown')
        
        if hasattr(token, 'content_blocks') and token.content_blocks:
            for block in token.content_blocks:
                if block.get('type') == 'text' and block.get('text'):
                    print(f"[{node_name}] {block['text']}", end='', flush=True)
                elif block.get('type') == 'tool_call_chunk':
                    print(f"\n[å·¥å…·è°ƒç”¨] {block.get('name', '')} {block.get('args', '')}")
        
    print()  # æœ€ç»ˆæ¢è¡Œ

# è°ƒç”¨ç¤ºä¾‹
stream_llm_tokens()
```

**è¾“å‡ºç¤ºä¾‹ï¼š**
```
[model] è®©æˆ‘
[model] æ¥æŸ¥è¯¢
[model] ä¸€ä¸‹
[model] ä¸Šæµ·
[model] çš„å¤©æ°”
[model] ...
[å·¥å…·è°ƒç”¨] get_weather {"city":"ä¸Šæµ·"}
[tools] ä¸Šæµ·çš„å¤©æ°”æ˜¯æ™´æœ—çš„ï¼Œ25Â°C
[model] ä¸Šæµ·
[model] çš„å¤©æ°”
[model] æ˜¯æ™´æœ—çš„
[model] ï¼Œ25Â°C
[model] ã€‚
```

### 3. è‡ªå®šä¹‰æ›´æ–°æµ (Custom Updates)

åœ¨å·¥å…·ä¸­ä½¿ç”¨ `get_stream_writer()` æ¥å‘é€è‡ªå®šä¹‰çš„æµå¼æ›´æ–°ã€‚

```python
from langgraph.config import get_stream_writer

def create_custom_streaming_tool():
    """åˆ›å»ºæ”¯æŒè‡ªå®šä¹‰æµå¼ä¼ è¾“çš„å·¥å…·"""
    
    def search_products(query: str, max_results: int = 5) -> str:
        """æœç´¢äº§å“ä¿¡æ¯"""
        writer = get_stream_writer()
        
        # å‘é€è‡ªå®šä¹‰è¿›åº¦æ›´æ–°
        writer(f"ğŸ” å¼€å§‹æœç´¢: {query}")
        writer(f"ğŸ“Š æœ€å¤§ç»“æœæ•°: {max_results}")
        
        # æ¨¡æ‹Ÿæœç´¢è¿‡ç¨‹
        writer("â³ è¿æ¥æ•°æ®åº“...")
        # æ¨¡æ‹Ÿæ•°æ®åº“æŸ¥è¯¢
        writer("âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ")
        
        writer("ğŸ” æ‰§è¡Œæœç´¢æŸ¥è¯¢...")
        # æ¨¡æ‹Ÿæœç´¢é€»è¾‘
        import time
        time.sleep(0.5)
        
        writer(f"ğŸ“¦ æ‰¾åˆ° 3 ä¸ªç›¸å…³äº§å“")
        
        # è¿”å›æœ€ç»ˆç»“æœ
        return f"æœç´¢ '{query}' æ‰¾åˆ° 3 ä¸ªäº§å“: äº§å“A, äº§å“B, äº§å“C"
    
    return search_products

def stream_custom_updates():
    """æµå¼ä¼ è¾“è‡ªå®šä¹‰æ›´æ–°"""
    print("=== è‡ªå®šä¹‰æ›´æ–°æµå¼ä¼ è¾“ ===")
    
    search_tool = create_custom_streaming_tool()
    custom_agent = create_agent(
        model="openai:gpt-4o",
        tools=[search_tool],
    )
    
    for chunk in custom_agent.stream(
        {"messages": [{"role": "user", "content": "æœç´¢ç¬”è®°æœ¬ç”µè„‘"}]},
        stream_mode="custom"  # å…³é”®å‚æ•°
    ):
        print(f"è‡ªå®šä¹‰æ›´æ–°: {chunk}")

# è°ƒç”¨ç¤ºä¾‹
stream_custom_updates()
```

**è¾“å‡ºç¤ºä¾‹ï¼š**
```
è‡ªå®šä¹‰æ›´æ–°: ğŸ” å¼€å§‹æœç´¢: ç¬”è®°æœ¬ç”µè„‘
è‡ªå®šä¹‰æ›´æ–°: ğŸ“Š æœ€å¤§ç»“æœæ•°: 5
è‡ªå®šä¹‰æ›´æ–°: â³ è¿æ¥æ•°æ®åº“...
è‡ªå®šä¹‰æ›´æ–°: âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ
è‡ªå®šä¹‰æ›´æ–°: ğŸ” æ‰§è¡Œæœç´¢æŸ¥è¯¢...
è‡ªå®šä¹‰æ›´æ–°: ğŸ“¦ æ‰¾åˆ° 3 ä¸ªç›¸å…³äº§å“
```

### 4. å¤šæ¨¡å¼æµå¼ä¼ è¾“

å¯ä»¥åŒæ—¶ä½¿ç”¨å¤šç§æµå¼ä¼ è¾“æ¨¡å¼ã€‚

```python
def stream_multiple_modes():
    """åŒæ—¶ä½¿ç”¨å¤šç§æµå¼ä¼ è¾“æ¨¡å¼"""
    print("=== å¤šæ¨¡å¼æµå¼ä¼ è¾“ ===")
    
    # åˆ›å»ºæ”¯æŒè‡ªå®šä¹‰æµçš„å·¥å…·
    def advanced_weather_tool(city: str) -> str:
        """é«˜çº§å¤©æ°”æŸ¥è¯¢å·¥å…·"""
        writer = get_stream_writer()
        writer(f"ğŸŒ¤ï¸  å¼€å§‹æŸ¥è¯¢ {city} çš„å¤©æ°”")
        writer("ğŸ“¡ è¿æ¥æ°”è±¡API...")
        writer("ğŸ” è·å–å®æ—¶æ•°æ®...")
        return f"{city}çš„å¤©æ°”ï¼šæ™´æœ—ï¼Œ25Â°Cï¼Œæ¹¿åº¦60%"
    
    multi_agent = create_agent(
        model="openai:gpt-4o",
        tools=[advanced_weather_tool],
    )
    
    for stream_mode, chunk in multi_agent.stream(
        {"messages": [{"role": "user", "content": "æŸ¥è¯¢æ­å·çš„å¤©æ°”"}]},
        stream_mode=["updates", "custom", "messages"]  # å¤šç§æ¨¡å¼
    ):
        print(f"æ¨¡å¼: {stream_mode}")
        print(f"å†…å®¹: {chunk}")
        print("-" * 30)

# è°ƒç”¨ç¤ºä¾‹
stream_multiple_modes()
```

## å®é™…åº”ç”¨åœºæ™¯

### åœºæ™¯1ï¼šå®æ—¶èŠå¤©åº”ç”¨

```python
import asyncio
from langchain.agents import create_agent

class StreamingChatApp:
    """æ”¯æŒæµå¼ä¼ è¾“çš„èŠå¤©åº”ç”¨"""
    
    def __init__(self):
        self.agent = create_agent(
            model="openai:gpt-4o",
            tools=[self.get_weather, self.search_web],
        )
    
    def get_weather(self, city: str) -> str:
        """è·å–å¤©æ°”ä¿¡æ¯"""
        writer = get_stream_writer()
        writer(f"æŸ¥è¯¢{city}çš„å¤©æ°”...")
        # æ¨¡æ‹ŸAPIè°ƒç”¨
        return f"{city}: 25Â°C, æ™´æœ—"
    
    def search_web(self, query: str) -> str:
        """ç½‘é¡µæœç´¢"""
        writer = get_stream_writer()
        writer(f"æœç´¢: {query}")
        writer("æ­£åœ¨è·å–æœ€æ–°ä¿¡æ¯...")
        return f"å…³äº'{query}'çš„æœç´¢ç»“æœ..."
    
    async def chat_stream(self, message: str):
        """æµå¼èŠå¤©"""
        print(f"ç”¨æˆ·: {message}")
        print("åŠ©æ‰‹: ", end="", flush=True)
        
        full_response = ""
        for token, metadata in self.agent.stream(
            {"messages": [{"role": "user", "content": message}]},
            stream_mode="messages",
        ):
            if hasattr(token, 'content_blocks'):
                for block in token.content_blocks:
                    if block.get('type') == 'text' and block.get('text'):
                        text = block['text']
                        print(text, end='', flush=True)
                        full_response += text
        
        print()  # æ¢è¡Œ
        return full_response

# ä½¿ç”¨ç¤ºä¾‹
async def demo_chat():
    app = StreamingChatApp()
    await app.chat_stream("ä»Šå¤©æ­å·å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿç„¶åæœç´¢AIæœ€æ–°å‘å±•")
```

### åœºæ™¯2ï¼šè¿›åº¦ç›‘æ§ä»ªè¡¨æ¿

```python
from typing import Dict, Any
import json

class ProgressMonitor:
    """è¿›åº¦ç›‘æ§å™¨"""
    
    def __init__(self):
        self.progress_data = {
            'total_steps': 0,
            'completed_steps': 0,
            'current_step': '',
            'details': []
        }
    
    def update_progress(self, step: str, details: str = ""):
        """æ›´æ–°è¿›åº¦"""
        self.progress_data['current_step'] = step
        self.progress_data['details'].append({
            'step': step,
            'details': details,
            'timestamp': str(datetime.now())
        })
        self.progress_data['completed_steps'] += 1
        
        # å‘é€åˆ°å‰ç«¯ï¼ˆæ¨¡æ‹Ÿï¼‰
        print(f"è¿›åº¦æ›´æ–°: {json.dumps(self.progress_data, ensure_ascii=False)}")

def create_monitored_tools(monitor: ProgressMonitor):
    """åˆ›å»ºè¢«ç›‘æ§çš„å·¥å…·"""
    
    def research_topic(topic: str) -> str:
        """ç ”ç©¶ä¸»é¢˜"""
        writer = get_stream_writer()
        
        monitor.update_progress('research', f"å¼€å§‹ç ”ç©¶: {topic}")
        writer(f"ğŸ”¬ ç ”ç©¶ä¸»é¢˜: {topic}")
        
        # æ¨¡æ‹Ÿç ”ç©¶æ­¥éª¤
        steps = [
            "æ”¶é›†ç›¸å…³èµ„æ–™",
            "åˆ†æå…³é”®ä¿¡æ¯", 
            "æ•´ç†ç ”ç©¶ç»“æœ",
            "ç”Ÿæˆæ€»ç»“æŠ¥å‘Š"
        ]
        
        for step in steps:
            monitor.update_progress('research', step)
            writer(f"âœ… {step}")
            import time
            time.sleep(0.3)
        
        return f"å…³äº{topic}çš„ç ”ç©¶å®Œæˆ"
    
    return research_topic

def monitored_agent_demo():
    """è¢«ç›‘æ§çš„Agentæ¼”ç¤º"""
    monitor = ProgressMonitor()
    research_tool = create_monitored_tools(monitor)
    
    agent = create_agent(
        model="openai:gpt-4o",
        tools=[research_tool],
    )
    
    print("å¼€å§‹ç›‘æ§Agentæ‰§è¡Œ...")
    for stream_mode, chunk in agent.stream(
        {"messages": [{"role": "user", "content": "ç ”ç©¶äººå·¥æ™ºèƒ½åœ¨åŒ»ç–—é¢†åŸŸçš„åº”ç”¨"}]},
        stream_mode=["updates", "custom"]
    ):
        if stream_mode == "custom":
            print(f"è‡ªå®šä¹‰äº‹ä»¶: {chunk}")

# è°ƒç”¨ç¤ºä¾‹
monitored_agent_demo()
```

### åœºæ™¯3ï¼šå®æ—¶æ•°æ®æµå¤„ç†

```python
import time
from datetime import datetime

class RealTimeDataProcessor:
    """å®æ—¶æ•°æ®å¤„ç†å™¨"""
    
    def __init__(self):
        self.agent = create_agent(
            model="openai:gpt-4o",
            tools=[self.process_data_stream],
        )
        self.data_buffer = []
    
    def process_data_stream(self, data_type: str, count: int = 10) -> str:
        """å¤„ç†æ•°æ®æµ"""
        writer = get_stream_writer()
        
        writer(f"å¼€å§‹å¤„ç† {data_type} æ•°æ®æµ...")
        writer(f"é¢„è®¡å¤„ç† {count} æ¡æ•°æ®")
        
        # æ¨¡æ‹Ÿæ•°æ®æµå¤„ç†
        for i in range(count):
            # æ¨¡æ‹Ÿæ•°æ®å¤„ç†
            processed_item = f"{data_type}_item_{i+1}"
            self.data_buffer.append(processed_item)
            
            # å‘é€è¿›åº¦æ›´æ–°
            progress = (i + 1) / count * 100
            writer(f"ğŸ“Š è¿›åº¦: {progress:.1f}% - å·²å¤„ç†: {processed_item}")
            
            # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
            time.sleep(0.1)
        
        writer("âœ… æ•°æ®æµå¤„ç†å®Œæˆ")
        return f"æˆåŠŸå¤„ç† {count} æ¡{data_type}æ•°æ®"
    
    def start_processing(self, data_type: str):
        """å¼€å§‹å¤„ç†"""
        print(f"å¼€å§‹å®æ—¶å¤„ç† {data_type} æ•°æ®...")
        
        for stream_mode, chunk in self.agent.stream(
            {"messages": [{"role": "user", "content": f"å¤„ç†{data_type}æ•°æ®æµ"}]},
            stream_mode=["custom", "updates"]
        ):
            if stream_mode == "custom":
                print(f"{datetime.now().strftime('%H:%M:%S')} - {chunk}")

# ä½¿ç”¨ç¤ºä¾‹
processor = RealTimeDataProcessor()
processor.start_processing("ä¼ æ„Ÿå™¨")
```

## é«˜çº§åŠŸèƒ½

### 1. é”™è¯¯å¤„ç†å’Œé‡è¯•

```python
def create_robust_streaming_tool():
    """åˆ›å»ºå¥å£®çš„æµå¼ä¼ è¾“å·¥å…·"""
    
    def robust_operation(operation: str) -> str:
        """å¥å£®çš„æ“ä½œ"""
        writer = get_stream_writer()
        
        try:
            writer(f"ğŸŸ¡ å¼€å§‹æ‰§è¡Œ: {operation}")
            
            # æ¨¡æ‹Ÿå¯èƒ½å¤±è´¥çš„æ“ä½œ
            if "fail" in operation:
                raise Exception("æ¨¡æ‹Ÿæ“ä½œå¤±è´¥")
            
            writer("ğŸŸ¢ æ“ä½œæ‰§è¡Œä¸­...")
            time.sleep(1)
            writer("âœ… æ“ä½œå®Œæˆ")
            
            return f"æ“ä½œ '{operation}' æˆåŠŸå®Œæˆ"
            
        except Exception as e:
            writer(f"ğŸ”´ æ“ä½œå¤±è´¥: {str(e)}")
            writer("ğŸ”„ å°è¯•é‡è¯•...")
            # è¿™é‡Œå¯ä»¥æ·»åŠ é‡è¯•é€»è¾‘
            return f"æ“ä½œ '{operation}' å¤±è´¥: {str(e)}"
    
    return robust_operation

def error_handling_demo():
    """é”™è¯¯å¤„ç†æ¼”ç¤º"""
    robust_tool = create_robust_streaming_tool()
    agent = create_agent(
        model="openai:gpt-4o",
        tools=[robust_tool],
    )
    
    print("æµ‹è¯•æ­£å¸¸æ“ä½œ:")
    for chunk in agent.stream(
        {"messages": [{"role": "user", "content": "æ‰§è¡Œæ­£å¸¸æ“ä½œ"}]},
        stream_mode="custom"
    ):
        print(chunk)
    
    print("\næµ‹è¯•å¤±è´¥æ“ä½œ:")
    for chunk in agent.stream(
        {"messages": [{"role": "user", "content": "æ‰§è¡Œå¤±è´¥æ“ä½œ"}]},
        stream_mode="custom"
    ):
        print(chunk)
```

### 2. æ€§èƒ½ä¼˜åŒ–

```python
class OptimizedStreaming:
    """ä¼˜åŒ–æµå¼ä¼ è¾“æ€§èƒ½"""
    
    def __init__(self):
        self.batch_size = 5
        self.message_buffer = []
    
    def batch_process_tool(self, items: list) -> str:
        """æ‰¹é‡å¤„ç†å·¥å…·"""
        writer = get_stream_writer()
        
        writer(f"ğŸ”„ å¼€å§‹æ‰¹é‡å¤„ç† {len(items)} ä¸ªé¡¹ç›®")
        
        for i, item in enumerate(items):
            # å¤„ç†æ¯ä¸ªé¡¹ç›®
            writer(f"å¤„ç†é¡¹ç›® {i+1}/{len(items)}: {item}")
            
            # æ¨¡æ‹Ÿå¤„ç†
            time.sleep(0.1)
            
            # æ¯å¤„ç†å®Œä¸€æ‰¹å‘é€æ›´æ–°
            if (i + 1) % self.batch_size == 0:
                writer(f"ğŸ“¦ å·²å®Œæˆ {i+1} ä¸ªé¡¹ç›®")
        
        writer("âœ… æ‰¹é‡å¤„ç†å®Œæˆ")
        return f"æˆåŠŸå¤„ç† {len(items)} ä¸ªé¡¹ç›®"
    
    def optimized_stream_demo(self):
        """ä¼˜åŒ–æµå¼ä¼ è¾“æ¼”ç¤º"""
        agent = create_agent(
            model="openai:gpt-4o",
            tools=[self.batch_process_tool],
        )
        
        items = [f"item_{i}" for i in range(1, 16)]
        
        for chunk in agent.stream(
            {"messages": [{"role": "user", "content": f"æ‰¹é‡å¤„ç†è¿™äº›é¡¹ç›®: {items}"}]},
            stream_mode="custom"
        ):
            print(chunk)
```

## æœ€ä½³å®è·µ

### 1. é€‰æ‹©åˆé€‚çš„æµå¼ä¼ è¾“æ¨¡å¼

```python
def choose_stream_mode(use_case: str):
    """æ ¹æ®ä½¿ç”¨åœºæ™¯é€‰æ‹©åˆé€‚çš„æµå¼ä¼ è¾“æ¨¡å¼"""
    mode_recommendations = {
        "chat_application": "messages",  # èŠå¤©åº”ç”¨ï¼šéœ€è¦å®æ—¶æ˜¾ç¤ºæ–‡å­—
        "progress_tracking": ["updates", "custom"],  # è¿›åº¦è·Ÿè¸ªï¼šéœ€è¦æ­¥éª¤å’Œè‡ªå®šä¹‰æ›´æ–°
        "debugging": "updates",  # è°ƒè¯•ï¼šéœ€è¦çœ‹åˆ°æ¯ä¸ªæ­¥éª¤
        "data_processing": ["custom", "messages"],  # æ•°æ®å¤„ç†ï¼šéœ€è¦è¿›åº¦å’Œç»“æœ
        "real_time_monitoring": ["updates", "custom", "messages"]  # å®æ—¶ç›‘æ§ï¼šå…¨éƒ¨ä¿¡æ¯
    }
    
    return mode_recommendations.get(use_case, "updates")

# ä½¿ç”¨ç¤ºä¾‹
chat_mode = choose_stream_mode("chat_application")
debug_mode = choose_stream_mode("debugging")
```

### 2. å¤„ç†æµå¼ä¼ è¾“é”™è¯¯

```python
def safe_stream_invoke(agent, input_data, stream_mode="updates", max_retries=3):
    """å®‰å…¨çš„æµå¼è°ƒç”¨"""
    for attempt in range(max_retries):
        try:
            for chunk in agent.stream(input_data, stream_mode=stream_mode):
                yield chunk
            break  # æˆåŠŸå®Œæˆï¼Œé€€å‡ºé‡è¯•å¾ªç¯
        except Exception as e:
            print(f"æµå¼ä¼ è¾“é”™è¯¯ (å°è¯• {attempt + 1}/{max_retries}): {e}")
            if attempt == max_retries - 1:
                raise  # æœ€åä¸€æ¬¡å°è¯•ä»ç„¶å¤±è´¥ï¼ŒæŠ›å‡ºå¼‚å¸¸
            time.sleep(1)  # ç­‰å¾…åé‡è¯•

# ä½¿ç”¨ç¤ºä¾‹
for chunk in safe_stream_invoke(
    agent,
    {"messages": [{"role": "user", "content": "æŸ¥è¯¢å¤©æ°”"}]},
    stream_mode="messages"
):
    print(chunk)
```

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜åŠè§£å†³æ–¹æ¡ˆ

1. **æµå¼ä¼ è¾“ä¸å·¥ä½œ**
   - æ£€æŸ¥æ¨¡å‹æ˜¯å¦æ”¯æŒæµå¼ä¼ è¾“
   - ç¡®è®¤ `stream_mode` å‚æ•°è®¾ç½®æ­£ç¡®
   - éªŒè¯ç½‘ç»œè¿æ¥

2. **è‡ªå®šä¹‰æ›´æ–°ä¸æ˜¾ç¤º**
   - ç¡®ä¿åœ¨å·¥å…·ä¸­æ­£ç¡®ä½¿ç”¨ `get_stream_writer()`
   - æ£€æŸ¥ `stream_mode` åŒ…å« "custom"
   - ç¡®è®¤åœ¨ LangGraph æ‰§è¡Œä¸Šä¸‹æ–‡ä¸­è°ƒç”¨

3. **æ€§èƒ½é—®é¢˜**
   - å‡å°‘ä¸å¿…è¦çš„æµå¼æ›´æ–°
   - ä½¿ç”¨åˆé€‚çš„æ‰¹å¤„ç†å¤§å°
   - è€ƒè™‘ç¦ç”¨æŸäº›æµå¼æ¨¡å¼

## æ€»ç»“

LangChain çš„æµå¼ä¼ è¾“ç³»ç»Ÿæä¾›äº†å¼ºå¤§çš„å®æ—¶æ›´æ–°èƒ½åŠ›ï¼š

- **å¤šç§æ¨¡å¼**ï¼šä»£ç†è¿›åº¦ã€LLM tokensã€è‡ªå®šä¹‰æ›´æ–°
- **çµæ´»ç»„åˆ**ï¼šå¯ä»¥åŒæ—¶ä½¿ç”¨å¤šç§æµå¼æ¨¡å¼
- **å®é™…åº”ç”¨**ï¼šé€‚ç”¨äºèŠå¤©ã€ç›‘æ§ã€æ•°æ®å¤„ç†ç­‰åœºæ™¯
- **å¥å£®æ€§**ï¼šåŒ…å«é”™è¯¯å¤„ç†å’Œæ€§èƒ½ä¼˜åŒ–

é€šè¿‡åˆç†ä½¿ç”¨æµå¼ä¼ è¾“ï¼Œå¯ä»¥æ˜¾è‘—æå‡åº”ç”¨çš„å“åº”æ€§å’Œç”¨æˆ·ä½“éªŒã€‚