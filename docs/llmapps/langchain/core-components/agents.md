# LangChain Agentsï¼ˆæ™ºèƒ½ä½“ï¼‰

## æ¦‚è¿°

Agentsï¼ˆä»£ç†ï¼‰å°†è¯­è¨€æ¨¡å‹ä¸å·¥å…·ç›¸ç»“åˆï¼Œåˆ›å»ºèƒ½å¤Ÿæ¨ç†ä»»åŠ¡ã€å†³å®šä½¿ç”¨å“ªäº›å·¥å…·å¹¶è¿­ä»£å·¥ä½œä»¥æ‰¾åˆ°è§£å†³æ–¹æ¡ˆçš„ç³»ç»Ÿã€‚

### æ ¸å¿ƒæ¦‚å¿µ

- **æ¨ç†å¼•æ“**ï¼šè¯­è¨€æ¨¡å‹è´Ÿè´£æ€è€ƒå’Œå†³ç­–
- **å·¥å…·è°ƒç”¨**ï¼šä»£ç†å¯ä»¥è°ƒç”¨å¤–éƒ¨å·¥å…·æ‰§è¡Œæ“ä½œ
- **è¿­ä»£è¿‡ç¨‹**ï¼šä»£ç†åœ¨å¾ªç¯ä¸­å·¥ä½œç›´åˆ°è¾¾åˆ°åœæ­¢æ¡ä»¶
- **çŠ¶æ€ç®¡ç†**ï¼šä»£ç†ç»´æŠ¤å¯¹è¯å†å²å’Œè‡ªå®šä¹‰çŠ¶æ€

## åŸºç¡€ Agent åˆ›å»º

### 1. ç®€å• Agent

```python
from langchain.agents import create_agent
from langchain.tools import tool

@tool
def search_web(query: str) -> str:
    """åœ¨ç½‘ç»œä¸Šæœç´¢ä¿¡æ¯ã€‚"""
    return f"å…³äº '{query}' çš„æœç´¢ç»“æœï¼šç›¸å…³æ–‡ç« ã€æ–°é—»å’Œä¿¡æ¯"

@tool
def get_weather(location: str) -> str:
    """è·å–æŒ‡å®šä½ç½®çš„å¤©æ°”ä¿¡æ¯ã€‚"""
    return f"{location}çš„å¤©æ°”ï¼šæ™´æœ—ï¼Œ25Â°C"

# åˆ›å»ºåŸºç¡€ Agent
agent = create_agent(
    model="openai:gpt-4o",
    tools=[search_web, get_weather]
)
```

### 2. è°ƒç”¨ Agent

```python
# åŸºç¡€è°ƒç”¨
result = agent.invoke(
    {"messages": [{"role": "user", "content": "åŒ—äº¬ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"}]}
)

print(result["messages"][-1].content)
```

## æ ¸å¿ƒç»„ä»¶è¯¦è§£

### 1. æ¨¡å‹é…ç½®

#### é™æ€æ¨¡å‹é…ç½®

```python
from langchain.agents import create_agent
from langchain_openai import ChatOpenAI

# æ–¹æ³•1ï¼šä½¿ç”¨æ¨¡å‹æ ‡è¯†ç¬¦å­—ç¬¦ä¸²
agent1 = create_agent(
    "openai:gpt-4o",  # è‡ªåŠ¨æ¨æ–­ä¸º OpenAI GPT-4o
    tools=[search_web, get_weather]
)

# æ–¹æ³•2ï¼šä½¿ç”¨æ¨¡å‹å®ä¾‹ï¼ˆæ¨èç”¨äºç”Ÿäº§ç¯å¢ƒï¼‰
model = ChatOpenAI(
    model="gpt-4o",
    temperature=0.1,      # æ§åˆ¶åˆ›é€ æ€§
    max_tokens=1000,      # æœ€å¤§è¾“å‡ºé•¿åº¦
    timeout=30,           # è¶…æ—¶è®¾ç½®
    # å…¶ä»–å‚æ•°...
)

agent2 = create_agent(
    model=model,
    tools=[search_web, get_weather]
)
```

#### åŠ¨æ€æ¨¡å‹é€‰æ‹©

```python
from langchain.agents.middleware import wrap_model_call, ModelRequest
from langchain_openai import ChatOpenAI

# å®šä¹‰ä¸åŒæ¨¡å‹
basic_model = ChatOpenAI(model="gpt-4o-mini")  # ç»æµå‹æ¨¡å‹
advanced_model = ChatOpenAI(model="gpt-4o")    # é«˜çº§æ¨¡å‹

@wrap_model_call
def dynamic_model_selection(request: ModelRequest, handler):
    """åŸºäºå¯¹è¯å¤æ‚åº¦é€‰æ‹©æ¨¡å‹"""
    messages = request.state["messages"]
    message_count = len(messages)
    
    # å¤æ‚å¯¹è¯ä½¿ç”¨é«˜çº§æ¨¡å‹
    if message_count > 5 or any("å¤æ‚" in msg.content for msg in messages if hasattr(msg, 'content')):
        request.model = advanced_model
    else:
        request.model = basic_model
    
    return handler(request)

# åˆ›å»ºæ”¯æŒåŠ¨æ€æ¨¡å‹é€‰æ‹©çš„ Agent
agent = create_agent(
    model=basic_model,  # é»˜è®¤æ¨¡å‹
    tools=[search_web, get_weather],
    middleware=[dynamic_model_selection]
)
```

### 2. å·¥å…·ç³»ç»Ÿ

#### åŸºç¡€å·¥å…·å®šä¹‰

```python
from langchain.tools import tool
from datetime import datetime

@tool
def calculator(expression: str) -> str:
    """è®¡ç®—æ•°å­¦è¡¨è¾¾å¼ã€‚"""
    try:
        result = eval(expression)
        return f"{expression} = {result}"
    except Exception as e:
        return f"è®¡ç®—é”™è¯¯: {str(e)}"

@tool
def get_current_time(timezone: str = "UTC") -> str:
    """è·å–æŒ‡å®šæ—¶åŒºçš„å½“å‰æ—¶é—´ã€‚"""
    now = datetime.now()
    return f"{timezone}æ—¶åŒºå½“å‰æ—¶é—´: {now.strftime('%Y-%m-%d %H:%M:%S')}"

@tool
def search_products(query: str, category: str = "all") -> str:
    """æœç´¢äº§å“ä¿¡æ¯ã€‚"""
    return f"åœ¨ '{category}' ç±»åˆ«ä¸­æ‰¾åˆ°å…³äº '{query}' çš„äº§å“"

# åˆ›å»ºåŒ…å«å¤šä¸ªå·¥å…·çš„ Agent
agent = create_agent(
    model="openai:gpt-4o",
    tools=[calculator, get_current_time, search_products]
)
```

#### å·¥å…·é”™è¯¯å¤„ç†

```python
from langchain.agents.middleware import wrap_tool_call
from langchain_core.messages import ToolMessage

@wrap_tool_call
def handle_tool_errors(request, handler):
    """è‡ªå®šä¹‰å·¥å…·é”™è¯¯å¤„ç†"""
    try:
        return handler(request)
    except Exception as e:
        # è¿”å›å‹å¥½çš„é”™è¯¯ä¿¡æ¯
        error_message = f"å·¥å…·æ‰§è¡Œå¤±è´¥ï¼š{str(e)}ã€‚è¯·æ£€æŸ¥è¾“å…¥å‚æ•°å¹¶é‡è¯•ã€‚"
        
        return ToolMessage(
            content=error_message,
            tool_call_id=request.tool_call["id"]
        )

agent = create_agent(
    model="openai:gpt-4o",
    tools=[calculator, get_current_time],
    middleware=[handle_tool_errors]
)
```

### 3. ç³»ç»Ÿæç¤ºè¯

#### é™æ€ç³»ç»Ÿæç¤ºè¯

```python
agent = create_agent(
    model="openai:gpt-4o",
    tools=[search_web, get_weather],
    system_prompt="""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šã€å‹å¥½çš„åŠ©æ‰‹ã€‚è¯·éµå¾ªä»¥ä¸‹æŒ‡å¯¼åŸåˆ™ï¼š
    1. å›ç­”è¦å‡†ç¡®ã€ç®€æ´
    2. ä½¿ç”¨å·¥å…·è·å–æœ€æ–°ä¿¡æ¯
    3. å¦‚æœç”¨æˆ·é—®é¢˜æ¶‰åŠä¸“ä¸šé¢†åŸŸï¼Œè¯·è¯´æ˜ä¿¡æ¯æ¥æº
    4. å¯¹ä¸ç¡®å®šçš„ä¿¡æ¯è¦æ˜ç¡®è¯´æ˜
    """
)
```

#### åŠ¨æ€ç³»ç»Ÿæç¤ºè¯

```python
from langchain.agents.middleware import dynamic_prompt, ModelRequest
from typing import TypedDict

class UserContext(TypedDict):
    user_level: str  # "beginner", "intermediate", "expert"
    language: str

@dynamic_prompt
def adaptive_system_prompt(request: ModelRequest) -> str:
    """åŸºäºç”¨æˆ·æ°´å¹³å’Œè¯­è¨€ç”ŸæˆåŠ¨æ€ç³»ç»Ÿæç¤ºè¯"""
    context = request.runtime.context
    user_level = context.get("user_level", "beginner")
    language = context.get("language", "zh-CN")
    
    base_prompt = "ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„AIåŠ©æ‰‹ã€‚"
    
    # æ ¹æ®ç”¨æˆ·æ°´å¹³è°ƒæ•´æç¤ºè¯
    level_prompts = {
        "beginner": "è¯·ç”¨ç®€å•æ˜“æ‡‚çš„è¯­è¨€è§£é‡Šæ¦‚å¿µï¼Œé¿å…ä¸“ä¸šæœ¯è¯­ã€‚",
        "intermediate": "æä¾›å¹³è¡¡çš„è§£ç­”ï¼ŒåŒ…å«åŸºæœ¬æ¦‚å¿µå’Œä¸€äº›è¿›é˜¶ä¿¡æ¯ã€‚",
        "expert": "æä¾›è¯¦ç»†çš„æŠ€æœ¯åˆ†æï¼Œå¯ä»¥ä½¿ç”¨ä¸“ä¸šæœ¯è¯­ã€‚"
    }
    
    level_prompt = level_prompts.get(user_level, level_prompts["beginner"])
    
    # è¯­è¨€ç‰¹å®šæç¤º
    if language == "zh-CN":
        language_prompt = "è¯·ä½¿ç”¨ä¸­æ–‡å›å¤ï¼Œä¿æŒè¯­è¨€çš„è‡ªç„¶å’Œæµç•…ã€‚"
    else:
        language_prompt = "Please respond in natural and fluent language."
    
    return f"{base_prompt} {level_prompt} {language_prompt}"

# åˆ›å»ºæ”¯æŒåŠ¨æ€æç¤ºè¯çš„ Agent
agent = create_agent(
    model="openai:gpt-4o",
    tools=[search_web, get_weather],
    middleware=[adaptive_system_prompt],
    context_schema=UserContext
)

# ä½¿ç”¨ä¸Šä¸‹æ–‡è°ƒç”¨
result = agent.invoke(
    {"messages": [{"role": "user", "content": "è§£é‡Šæœºå™¨å­¦ä¹ "}]},
    context={"user_level": "beginner", "language": "zh-CN"}
)
```

## é«˜çº§åŠŸèƒ½

### 1. ç»“æ„åŒ–è¾“å‡º

```python
from pydantic import BaseModel, Field
from langchain.agents import create_agent
from langchain.agents.structured_output import ToolStrategy

class ProductReview(BaseModel):
    """äº§å“è¯„ä»·åˆ†æ"""
    product_name: str = Field(description="äº§å“åç§°")
    rating: int = Field(description="è¯„åˆ†(1-5)", ge=1, le=5)
    positive_points: list[str] = Field(description="ä¼˜ç‚¹åˆ—è¡¨")
    negative_points: list[str] = Field(description="ç¼ºç‚¹åˆ—è¡¨")
    summary: str = Field(description="æ€»ä½“è¯„ä»·æ€»ç»“")

class CustomerInfo(BaseModel):
    """å®¢æˆ·ä¿¡æ¯æå–"""
    name: str = Field(description="å®¢æˆ·å§“å")
    email: str = Field(description="é‚®ç®±åœ°å€")
    phone: str = Field(description="ç”µè¯å·ç ")
    interests: list[str] = Field(description="å…´è¶£åˆ—è¡¨")

# ä½¿ç”¨ ToolStrategy å®ç°ç»“æ„åŒ–è¾“å‡º
agent = create_agent(
    model="openai:gpt-4o",
    tools=[search_web],
    response_format=ToolStrategy(ProductReview)  # æˆ– CustomerInfo
)

# è°ƒç”¨å¹¶è·å–ç»“æ„åŒ–è¾“å‡º
result = agent.invoke({
    "messages": [{
        "role": "user", 
        "content": "åˆ†æè¿™ä¸ªäº§å“è¯„ä»·ï¼š'iPhone 15 Pro å¤ªæ£’äº†ï¼ç›¸æœºè´¨é‡ä¼˜ç§€ï¼Œç”µæ± ç»­èˆªä¹Ÿå¾ˆå¥½ï¼Œå°±æ˜¯ä»·æ ¼æœ‰ç‚¹è´µã€‚è¯„åˆ†5/5'"
    }]
})

structured_data = result["structured_response"]
print(f"äº§å“: {structured_data.product_name}")
print(f"è¯„åˆ†: {structured_data.rating}")
print(f"ä¼˜ç‚¹: {', '.join(structured_data.positive_points)}")
```

### 2. å†…å­˜ç®¡ç†

#### è‡ªå®šä¹‰çŠ¶æ€ç®¡ç†

```python
from typing import TypedDict, List, Optional
from langchain.agents import AgentState, create_agent

class CustomAgentState(AgentState):
    """è‡ªå®šä¹‰ Agent çŠ¶æ€"""
    user_preferences: dict
    conversation_topics: List[str]
    interaction_count: int = 0
    last_active: Optional[str] = None

# é€šè¿‡ state_schema å®šä¹‰çŠ¶æ€
agent = create_agent(
    model="openai:gpt-4o",
    tools=[search_web, get_weather],
    state_schema=CustomAgentState
)

# ä½¿ç”¨è‡ªå®šä¹‰çŠ¶æ€è°ƒç”¨
result = agent.invoke({
    "messages": [{"role": "user", "content": "æˆ‘å–œæ¬¢æŠ€æœ¯ç±»å†…å®¹"}],
    "user_preferences": {"category": "technology", "detail_level": "high"},
    "conversation_topics": ["AI", "ç¼–ç¨‹"],
    "interaction_count": 1
})
```

#### é€šè¿‡ä¸­é—´ä»¶ç®¡ç†çŠ¶æ€

```python
from langchain.agents.middleware import AgentMiddleware
from typing import Any

class UserPreferencesMiddleware(AgentMiddleware):
    """ç”¨æˆ·åå¥½ç®¡ç†ä¸­é—´ä»¶"""
    state_schema = CustomAgentState
    
    def before_model(self, state: CustomAgentState, runtime) -> dict[str, Any] | None:
        """åœ¨æ¨¡å‹è°ƒç”¨å‰å¤„ç†ç”¨æˆ·åå¥½"""
        preferences = state.get("user_preferences", {})
        
        # åŸºäºç”¨æˆ·åå¥½è°ƒæ•´è¡Œä¸º
        if preferences.get("detail_level") == "high":
            # å¯ä»¥åœ¨è¿™é‡Œä¿®æ”¹æ¶ˆæ¯æˆ–æ·»åŠ ä¸Šä¸‹æ–‡
            pass
            
        return None
    
    def after_model(self, state: CustomAgentState, runtime) -> dict[str, Any] | None:
        """åœ¨æ¨¡å‹è°ƒç”¨åæ›´æ–°äº¤äº’ç»Ÿè®¡"""
        return {
            "interaction_count": state.get("interaction_count", 0) + 1,
            "last_active": "2024-01-01T10:00:00"  # å®é™…ä½¿ç”¨ä¸­åº”ä¸ºå½“å‰æ—¶é—´
        }

agent = create_agent(
    model="openai:gpt-4o",
    tools=[search_web, get_weather],
    middleware=[UserPreferencesMiddleware()]
)
```

### 3. æµå¼ä¼ è¾“

```python
def stream_agent_progress():
    """æµå¼ä¼ è¾“ Agent æ‰§è¡Œè¿›åº¦"""
    print("å¼€å§‹æµå¼ä¼ è¾“ Agent æ‰§è¡Œ...")
    
    for chunk in agent.stream(
        {"messages": [{"role": "user", "content": "æœç´¢AIæœ€æ–°å‘å±•å¹¶æ€»ç»“è¦ç‚¹"}]},
        stream_mode="values"  # ä¹Ÿå¯ä»¥ä½¿ç”¨ "updates" æˆ– "messages"
    ):
        # è·å–æœ€æ–°æ¶ˆæ¯
        latest_message = chunk["messages"][-1]
        
        # å¤„ç†AIå›å¤
        if hasattr(latest_message, 'content') and latest_message.content:
            print(f"ğŸ¤– AI: {latest_message.content}")
        
        # å¤„ç†å·¥å…·è°ƒç”¨
        elif hasattr(latest_message, 'tool_calls') and latest_message.tool_calls:
            for tool_call in latest_message.tool_calls:
                print(f"ğŸ› ï¸  è°ƒç”¨å·¥å…·: {tool_call['name']}")
                print(f"   å‚æ•°: {tool_call['args']}")

# è°ƒç”¨æµå¼ä¼ è¾“
stream_agent_progress()
```

### 4. ä¸­é—´ä»¶ç³»ç»Ÿ

```python
from langchain.agents.middleware import before_model, after_model, wrap_tool_call
from langchain.messages import RemoveMessage
from langgraph.graph.message import REMOVE_ALL_MESSAGES

@before_model
def trim_long_conversations(state, runtime):
    """ä¿®å‰ªè¿‡é•¿çš„å¯¹è¯å†å²"""
    messages = state["messages"]
    
    if len(messages) > 10:
        # ä¿ç•™ç³»ç»Ÿæ¶ˆæ¯å’Œæœ€è¿‘5æ¡æ¶ˆæ¯
        system_messages = [msg for msg in messages if msg.type == "system"]
        recent_messages = messages[-5:]
        
        return {
            "messages": [
                RemoveMessage(id=REMOVE_ALL_MESSAGES),
                *system_messages,
                *recent_messages
            ]
        }
    
    return None

@after_model
def validate_response_content(state, runtime):
    """éªŒè¯æ¨¡å‹å“åº”å†…å®¹"""
    last_message = state["messages"][-1]
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«ä¸å½“å†…å®¹
    inappropriate_keywords = ["æš´åŠ›", "ä»‡æ¨", "æ­§è§†"]
    if any(keyword in last_message.content for keyword in inappropriate_keywords):
        return {
            "messages": [
                RemoveMessage(id=last_message.id),
                *state["messages"][:-1]
            ]
        }
    
    return None

@wrap_tool_call
def log_tool_execution(request, handler):
    """è®°å½•å·¥å…·æ‰§è¡Œæ—¥å¿—"""
    tool_name = request.tool_call["name"]
    tool_args = request.tool_call["args"]
    
    print(f"ğŸ“ å¼€å§‹æ‰§è¡Œå·¥å…·: {tool_name}")
    print(f"   å‚æ•°: {tool_args}")
    
    start_time = time.time()
    result = handler(request)
    execution_time = time.time() - start_time
    
    print(f"âœ… å·¥å…·æ‰§è¡Œå®Œæˆ: {tool_name} (è€—æ—¶: {execution_time:.2f}s)")
    
    return result

# åˆ›å»ºåŒ…å«å¤šä¸ªä¸­é—´ä»¶çš„ Agent
agent = create_agent(
    model="openai:gpt-4o",
    tools=[search_web, get_weather, calculator],
    middleware=[
        trim_long_conversations,
        validate_response_content,
        log_tool_execution
    ]
)
```

## å®é™…åº”ç”¨åœºæ™¯

### åœºæ™¯1ï¼šå®¢æˆ·æœåŠ¡ Agent

```python
from langchain.tools import tool
from datetime import datetime

class CustomerServiceAgent:
    """å®¢æˆ·æœåŠ¡ Agent"""
    
    def __init__(self):
        self.agent = self._create_agent()
    
    @tool
    def check_order_status(self, order_id: str) -> str:
        """æ£€æŸ¥è®¢å•çŠ¶æ€ã€‚"""
        # æ¨¡æ‹Ÿè®¢å•æ•°æ®åº“
        orders = {
            "ORD001": {"status": "å·²å‘è´§", "tracking": "SF123456789"},
            "ORD002": {"status": "å¤„ç†ä¸­", "tracking": None},
            "ORD003": {"status": "å·²é€è¾¾", "tracking": "SF987654321"}
        }
        
        if order_id in orders:
            order = orders[order_id]
            result = f"è®¢å• {order_id} çŠ¶æ€: {order['status']}"
            if order['tracking']:
                result += f"\nç‰©æµå•å·: {order['tracking']}"
            return result
        return f"æœªæ‰¾åˆ°è®¢å• {order_id}"
    
    @tool
    def process_refund(self, order_id: str, reason: str) -> str:
        """å¤„ç†é€€æ¬¾ç”³è¯·ã€‚"""
        return f"è®¢å• {order_id} çš„é€€æ¬¾ç”³è¯·å·²æäº¤ã€‚åŸå› : {reason}\né¢„è®¡3-5ä¸ªå·¥ä½œæ—¥å¤„ç†å®Œæˆã€‚"
    
    @tool
    def get_faq(self, category: str) -> str:
        """è·å–å¸¸è§é—®é¢˜è§£ç­”ã€‚"""
        faqs = {
            "shipping": "é…é€æ—¶é—´ï¼šæ™®é€šå¿«é€’3-5å¤©ï¼ŒåŠ æ€¥å¿«é€’1-2å¤©",
            "returns": "é€€æ¢è´§æ”¿ç­–ï¼š7å¤©æ— ç†ç”±é€€è´§ï¼Œ30å¤©è´¨é‡é—®é¢˜çš„æ¢è´§",
            "payment": "æ”¯ä»˜æ–¹å¼ï¼šæ”¯æŒæ”¯ä»˜å®ã€å¾®ä¿¡æ”¯ä»˜ã€é“¶è¡Œå¡"
        }
        return faqs.get(category, "æš‚æ— è¯¥ç±»åˆ«å¸¸è§é—®é¢˜")
    
    def _create_agent(self):
        """åˆ›å»ºå®¢æˆ·æœåŠ¡ Agent"""
        return create_agent(
            model="openai:gpt-4o",
            tools=[self.check_order_status, self.process_refund, self.get_faq],
            system_prompt="""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å®¢æˆ·æœåŠ¡ä»£è¡¨ã€‚è¯·éµå¾ªä»¥ä¸‹åŸåˆ™ï¼š
            1. å§‹ç»ˆä¿æŒå‹å¥½å’Œä¸“ä¸šçš„æ€åº¦
            2. å‡†ç¡®å›ç­”å®¢æˆ·é—®é¢˜
            3. ä½¿ç”¨å·¥å…·è·å–æœ€æ–°ä¿¡æ¯
            4. å¯¹äºå¤æ‚é—®é¢˜ï¼Œæä¾›æ¸…æ™°çš„åç»­æ­¥éª¤
            5. å¦‚æœæ— æ³•è§£å†³é—®é¢˜ï¼Œå»ºè®®è”ç³»äººå·¥å®¢æœ
            """,
            state_schema=CustomAgentState
        )
    
    def handle_customer_query(self, query: str, user_id: str):
        """å¤„ç†å®¢æˆ·æŸ¥è¯¢"""
        return self.agent.invoke({
            "messages": [{"role": "user", "content": query}],
            "user_preferences": {"user_id": user_id}
        })

# ä½¿ç”¨ç¤ºä¾‹
service_agent = CustomerServiceAgent()
result = service_agent.handle_customer_query("æˆ‘çš„è®¢å•ORD001çŠ¶æ€å¦‚ä½•ï¼Ÿ", "user123")
```

### åœºæ™¯2ï¼šæ•°æ®åˆ†æ Agent

```python
import pandas as pd
import numpy as np
from io import StringIO

class DataAnalysisAgent:
    """æ•°æ®åˆ†æ Agent"""
    
    def __init__(self):
        self.agent = self._create_agent()
        self.current_dataset = None
    
    @tool
    def load_csv_data(self, csv_content: str) -> str:
        """åŠ è½½CSVæ•°æ®ã€‚"""
        try:
            self.current_dataset = pd.read_csv(StringIO(csv_content))
            stats = {
                "è¡Œæ•°": len(self.current_dataset),
                "åˆ—æ•°": len(self.current_dataset.columns),
                "åˆ—å": list(self.current_dataset.columns)
            }
            return f"æ•°æ®åŠ è½½æˆåŠŸï¼ç»Ÿè®¡ä¿¡æ¯: {stats}"
        except Exception as e:
            return f"æ•°æ®åŠ è½½å¤±è´¥: {str(e)}"
    
    @tool
    def describe_dataset(self) -> str:
        """æè¿°æ•°æ®é›†åŸºæœ¬ä¿¡æ¯ã€‚"""
        if self.current_dataset is None:
            return "è¯·å…ˆåŠ è½½æ•°æ®"
        
        description = self.current_dataset.describe()
        return f"æ•°æ®é›†æè¿°:\n{description}"
    
    @tool
    def calculate_correlation(self, column1: str, column2: str) -> str:
        """è®¡ç®—ä¸¤åˆ—ä¹‹é—´çš„ç›¸å…³æ€§ã€‚"""
        if self.current_dataset is None:
            return "è¯·å…ˆåŠ è½½æ•°æ®"
        
        if column1 not in self.current_dataset.columns or column2 not in self.current_dataset.columns:
            return "æŒ‡å®šçš„åˆ—ä¸å­˜åœ¨"
        
        correlation = self.current_dataset[column1].corr(self.current_dataset[column2])
        return f"{column1} å’Œ {column2} çš„ç›¸å…³æ€§: {correlation:.3f}"
    
    @tool
    def filter_data(self, condition: str) -> str:
        """æ ¹æ®æ¡ä»¶è¿‡æ»¤æ•°æ®ã€‚"""
        if self.current_dataset is None:
            return "è¯·å…ˆåŠ è½½æ•°æ®"
        
        try:
            filtered_data = self.current_dataset.query(condition)
            return f"è¿‡æ»¤åæ•°æ®: {len(filtered_data)} è¡Œ"
        except Exception as e:
            return f"è¿‡æ»¤æ¡ä»¶é”™è¯¯: {str(e)}"
    
    def _create_agent(self):
        """åˆ›å»ºæ•°æ®åˆ†æ Agent"""
        return create_agent(
            model="openai:gpt-4o",
            tools=[
                self.load_csv_data, 
                self.describe_dataset, 
                self.calculate_correlation,
                self.filter_data
            ],
            system_prompt="""ä½ æ˜¯ä¸€ä¸ªæ•°æ®åˆ†æä¸“å®¶ã€‚è¯·å¸®åŠ©ç”¨æˆ·ï¼š
            1. åŠ è½½å’Œåˆ†ææ•°æ®
            2. æä¾›æ•°æ®ç»Ÿè®¡ä¿¡æ¯
            3. è®¡ç®—æŒ‡æ ‡å’Œç›¸å…³æ€§
            4. è§£é‡Šåˆ†æç»“æœçš„å«ä¹‰
            5. ç”¨é€šä¿—æ˜“æ‡‚çš„è¯­è¨€è§£é‡ŠæŠ€æœ¯æ¦‚å¿µ
            """
        )

# ä½¿ç”¨ç¤ºä¾‹
analysis_agent = DataAnalysisAgent()

# æ¨¡æ‹ŸCSVæ•°æ®
sample_data = """name,age,salary,department
å¼ ä¸‰,25,50000,æŠ€æœ¯éƒ¨
æå››,30,60000,é”€å”®éƒ¨
ç‹äº”,35,70000,æŠ€æœ¯éƒ¨
èµµå…­,28,55000,å¸‚åœºéƒ¨"""

result = analysis_agent.agent.invoke({
    "messages": [{"role": "user", "content": f"è¯·åˆ†æä»¥ä¸‹æ•°æ®:\n{sample_data}"}]
})
```

### åœºæ™¯3ï¼šç ”ç©¶åŠ©æ‰‹ Agent

```python
class ResearchAssistantAgent:
    """ç ”ç©¶åŠ©æ‰‹ Agent"""
    
    def __init__(self):
        self.agent = self._create_agent()
        self.research_topics = []
    
    @tool
    def search_academic_papers(self, topic: str, max_results: int = 5) -> str:
        """æœç´¢å­¦æœ¯è®ºæ–‡ã€‚"""
        # æ¨¡æ‹Ÿå­¦æœ¯æœç´¢
        papers = [
            f"ã€Š{topic}çš„æœ€æ–°ç ”ç©¶è¿›å±•ã€‹- ä½œè€…A et al.",
            f"ã€Š{topic}åœ¨å®è·µä¸­çš„åº”ç”¨ã€‹- ä½œè€…B et al.", 
            f"ã€Š{topic}çš„æœªæ¥å‘å±•è¶‹åŠ¿ã€‹- ä½œè€…C et al."
        ]
        return f"æ‰¾åˆ° {len(papers)} ç¯‡ç›¸å…³è®ºæ–‡:\n" + "\n".join(papers[:max_results])
    
    @tool
    def summarize_research_topic(self, topic: str) -> str:
        """æ€»ç»“ç ”ç©¶ä¸»é¢˜ã€‚"""
        self.research_topics.append(topic)
        return f"""
        {topic} ç ”ç©¶æ€»ç»“ï¼š
        1. æ ¸å¿ƒæ¦‚å¿µï¼š{topic}æ¶‰åŠå¤šä¸ªäº¤å‰å­¦ç§‘é¢†åŸŸ
        2. å½“å‰çƒ­ç‚¹ï¼šAIé©±åŠ¨çš„{topic}ç ”ç©¶æ­£åœ¨å…´èµ·
        3. ä¸»è¦æŒ‘æˆ˜ï¼šæ•°æ®è´¨é‡å’Œç®—æ³•å¯è§£é‡Šæ€§
        4. æœªæ¥æ–¹å‘ï¼šè‡ªåŠ¨åŒ–ã€æ™ºèƒ½åŒ–{topic}è§£å†³æ–¹æ¡ˆ
        """
    
    @tool
    def compare_topics(self, topic1: str, topic2: str) -> str:
        """æ¯”è¾ƒä¸¤ä¸ªç ”ç©¶ä¸»é¢˜ã€‚"""
        return f"""
        {topic1} vs {topic2} æ¯”è¾ƒï¼š
        
        ç›¸ä¼¼ç‚¹ï¼š
        - éƒ½æ˜¯å‰æ²¿æŠ€æœ¯é¢†åŸŸ
        - éƒ½éœ€è¦è·¨å­¦ç§‘çŸ¥è¯†
        - éƒ½æœ‰å¹¿æ³›çš„åº”ç”¨åœºæ™¯
        
        ä¸åŒç‚¹ï¼š
        - {topic1}æ›´æ³¨é‡ç†è®ºå‘å±•
        - {topic2}æ›´æ³¨é‡å®è·µåº”ç”¨
        - æŠ€æœ¯æ ˆå’Œç ”ç©¶æ–¹æ³•æœ‰æ‰€ä¸åŒ
        """
    
    @tool
    def generate_research_questions(self, topic: str) -> str:
        """ç”Ÿæˆç ”ç©¶é—®é¢˜ã€‚"""
        questions = [
            f"{topic}å¦‚ä½•å½±å“ç›¸å…³è¡Œä¸šï¼Ÿ",
            f"{topic}é¢ä¸´çš„ä¸»è¦æŠ€æœ¯æŒ‘æˆ˜æ˜¯ä»€ä¹ˆï¼Ÿ",
            f"{topic}çš„æœªæ¥å‘å±•æ–¹å‘æœ‰å“ªäº›ï¼Ÿ",
            f"å¦‚ä½•è¯„ä¼°{topic}çš„å®é™…æ•ˆæœï¼Ÿ"
        ]
        return "æ½œåœ¨ç ”ç©¶é—®é¢˜:\n" + "\n".join([f"{i+1}. {q}" for i, q in enumerate(questions)])
    
    def _create_agent(self):
        """åˆ›å»ºç ”ç©¶åŠ©æ‰‹ Agent"""
        return create_agent(
            model="openai:gpt-4o",
            tools=[
                self.search_academic_papers,
                self.summarize_research_topic, 
                self.compare_topics,
                self.generate_research_questions
            ],
            system_prompt="""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç ”ç©¶åŠ©æ‰‹ã€‚è¯·å¸®åŠ©ç”¨æˆ·ï¼š
            1. æœç´¢ç›¸å…³å­¦æœ¯æ–‡çŒ®
            2. æ€»ç»“ç ”ç©¶ä¸»é¢˜å’Œè¶‹åŠ¿
            3. æ¯”è¾ƒä¸åŒç ”ç©¶æ–¹å‘
            4. ç”Ÿæˆæœ‰ä»·å€¼çš„ç ”ç©¶é—®é¢˜
            5. æä¾›ç ”ç©¶æ–¹æ³•å’Œå»ºè®®
            
            è¯·ä¿æŒä¸“ä¸šæ€§å’Œå‡†ç¡®æ€§ï¼Œå¼•ç”¨å¯é çš„æ¥æºã€‚
            """
        )

# ä½¿ç”¨ç¤ºä¾‹
research_agent = ResearchAssistantAgent()
result = research_agent.agent.invoke({
    "messages": [{"role": "user", "content": "å¸®æˆ‘ç ”ç©¶äººå·¥æ™ºèƒ½åœ¨åŒ»ç–—é¢†åŸŸçš„åº”ç”¨"}]
})
```

## æœ€ä½³å®è·µ

### 1. Agent è®¾è®¡åŸåˆ™

```python
def create_well_designed_agent():
    """åˆ›å»ºè‰¯å¥½è®¾è®¡çš„ Agent"""
    
    # 1. æ˜ç¡®çš„å·¥å…·å®šä¹‰
    @tool
    def specific_tool(param1: str, param2: int = 10) -> str:
        """æ‰§è¡Œç‰¹å®šä»»åŠ¡çš„å·¥å…·ã€‚
        
        Args:
            param1: ä¸»è¦å‚æ•°æè¿°
            param2: å¯é€‰å‚æ•°ï¼Œé»˜è®¤å€¼10
        """
        return f"å¤„ç†ç»“æœ: {param1} * {param2}"
    
    # 2. æ¸…æ™°çš„ç³»ç»Ÿæç¤ºè¯
    system_prompt = """
    ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŠ©æ‰‹ã€‚è¯·éµå¾ªï¼š
    - å‡†ç¡®å›ç­”ï¼Œä¸ç¼–é€ ä¿¡æ¯
    - ä½¿ç”¨å·¥å…·è·å–çœŸå®æ•°æ®
    - å¯¹ä¸ç¡®å®šçš„å†…å®¹è¦è¯´æ˜
    - ä¿æŒå‹å¥½å’Œä¸“ä¸š
    """
    
    # 3. é€‚å½“çš„ä¸­é—´ä»¶
    @before_model
    def ensure_proper_context(state, runtime):
        """ç¡®ä¿é€‚å½“çš„ä¸Šä¸‹æ–‡"""
        messages = state["messages"]
        if len(messages) > 0:
            last_message = messages[-1]
            # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ ä¸Šä¸‹æ–‡éªŒè¯é€»è¾‘
            pass
        return None
    
    # åˆ›å»º Agent
    return create_agent(
        model="openai:gpt-4o",
        tools=[specific_tool],
        system_prompt=system_prompt,
        middleware=[ensure_proper_context]
    )
```

### 2. é”™è¯¯å¤„ç†ç­–ç•¥

```python
class RobustAgent:
    """å¥å£®çš„ Agent å®ç°"""
    
    def __init__(self):
        self.agent = self._create_robust_agent()
    
    def _create_robust_agent(self):
        """åˆ›å»ºå¥å£®çš„ Agent"""
        
        @wrap_tool_call
        def comprehensive_error_handling(request, handler):
            """å…¨é¢çš„é”™è¯¯å¤„ç†"""
            try:
                # å‚æ•°éªŒè¯
                tool_call = request.tool_call
                if not self._validate_tool_inputs(tool_call):
                    return ToolMessage(
                        content="å‚æ•°éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥è¾“å…¥æ ¼å¼",
                        tool_call_id=tool_call["id"]
                    )
                
                return handler(request)
                
            except Exception as e:
                # è®°å½•é”™è¯¯
                print(f"å·¥å…·æ‰§è¡Œé”™è¯¯: {e}")
                
                # è¿”å›ç”¨æˆ·å‹å¥½çš„é”™è¯¯ä¿¡æ¯
                return ToolMessage(
                    content="æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•",
                    tool_call_id=request.tool_call["id"]
                )
        
        @wrap_model_call  
        def model_fallback(request, handler):
            """æ¨¡å‹è°ƒç”¨é™çº§ç­–ç•¥"""
            try:
                return handler(request)
            except Exception as e:
                # å¦‚æœä¸»è¦æ¨¡å‹å¤±è´¥ï¼Œå¯ä»¥åœ¨è¿™é‡Œåˆ‡æ¢åˆ°å¤‡ç”¨æ¨¡å‹
                print(f"æ¨¡å‹è°ƒç”¨å¤±è´¥: {e}")
                raise  # æˆ–å®ç°é™çº§é€»è¾‘
        
        return create_agent(
            model="openai:gpt-4o",
            tools=[search_web, get_weather],
            middleware=[comprehensive_error_handling, model_fallback]
        )
    
    def _validate_tool_inputs(self, tool_call):
        """éªŒè¯å·¥å…·è¾“å…¥å‚æ•°"""
        # å®ç°å‚æ•°éªŒè¯é€»è¾‘
        return True
```

### 3. æ€§èƒ½ä¼˜åŒ–

```python
class OptimizedAgent:
    """æ€§èƒ½ä¼˜åŒ–çš„ Agent"""
    
    def __init__(self):
        self.agent = self._create_optimized_agent()
        self.response_cache = {}  # ç®€å•ç¼“å­˜
    
    def _create_optimized_agent(self):
        """åˆ›å»ºæ€§èƒ½ä¼˜åŒ–çš„ Agent"""
        
        @before_model
        def check_cache(state, runtime):
            """æ£€æŸ¥ç¼“å­˜ä»¥é¿å…é‡å¤å¤„ç†"""
            user_message = state["messages"][-1].content
            cache_key = hash(user_message)
            
            if cache_key in self.response_cache:
                # è¿”å›ç¼“å­˜å“åº”
                return self.response_cache[cache_key]
            
            return None
        
        @after_model
        def update_cache(state, runtime):
            """æ›´æ–°å“åº”ç¼“å­˜"""
            if len(state["messages"]) > 0:
                last_message = state["messages"][-1]
                user_message = state["messages"][-2].content  # å‡è®¾ä¸Šä¸€æ¡æ˜¯ç”¨æˆ·æ¶ˆæ¯
                cache_key = hash(user_message)
                self.response_cache[cache_key] = {"messages": [last_message]}
            
            return None
        
        @wrap_tool_call
        def timeout_protection(request, handler):
            """å·¥å…·è°ƒç”¨è¶…æ—¶ä¿æŠ¤"""
            import signal
            import time
            
            def timeout_handler(signum, frame):
                raise TimeoutError("å·¥å…·æ‰§è¡Œè¶…æ—¶")
            
            # è®¾ç½®è¶…æ—¶ï¼ˆ5ç§’ï¼‰
            signal.signal(signal.SIGALRM, timeout_handler)
            signal.alarm(5)
            
            try:
                result = handler(request)
                signal.alarm(0)  # å–æ¶ˆè¶…æ—¶
                return result
            except TimeoutError:
                return ToolMessage(
                    content="å·¥å…·æ‰§è¡Œè¶…æ—¶ï¼Œè¯·ç®€åŒ–è¯·æ±‚æˆ–ç¨åé‡è¯•",
                    tool_call_id=request.tool_call["id"]
                )
        
        return create_agent(
            model="openai:gpt-4o",
            tools=[search_web, get_weather],
            middleware=[check_cache, update_cache, timeout_protection]
        )
```

## æ€»ç»“

LangChain Agents æä¾›äº†å¼ºå¤§çš„AIåº”ç”¨æ„å»ºèƒ½åŠ›ï¼š

- **çµæ´»é…ç½®**ï¼šæ”¯æŒå¤šç§æ¨¡å‹ã€å·¥å…·å’Œæç¤ºè¯é…ç½®
- **å¼ºå¤§æ‰©å±•**ï¼šé€šè¿‡ä¸­é—´ä»¶ç³»ç»Ÿå®ç°é«˜åº¦å®šåˆ¶åŒ–
- **çŠ¶æ€ç®¡ç†**ï¼šå†…ç½®å¯¹è¯çŠ¶æ€å’Œè‡ªå®šä¹‰çŠ¶æ€ç®¡ç†
- **ç”Ÿäº§å°±ç»ª**ï¼šåŒ…å«é”™è¯¯å¤„ç†ã€æ€§èƒ½ä¼˜åŒ–ç­‰ç”Ÿäº§çº§ç‰¹æ€§
- **å®æ—¶äº¤äº’**ï¼šæ”¯æŒæµå¼ä¼ è¾“å’Œè¿›åº¦ç›‘æ§

é€šè¿‡åˆç†è®¾è®¡å’Œä½¿ç”¨ Agentsï¼Œå¯ä»¥æ„å»ºå‡ºèƒ½å¤Ÿå¤„ç†å¤æ‚ä»»åŠ¡ã€ä¸å¤–éƒ¨ç³»ç»Ÿäº¤äº’å¹¶æä¾›æ™ºèƒ½æœåŠ¡çš„AIåº”ç”¨ç³»ç»Ÿã€‚