# LangChain Tools 

## æ¦‚è¿°

Toolsï¼ˆå·¥å…·ï¼‰æ˜¯ AI Agent è°ƒç”¨ä»¥æ‰§è¡Œæ“ä½œçš„ç»„ä»¶ã€‚å®ƒä»¬é€šè¿‡å®šä¹‰è‰¯å¥½çš„è¾“å…¥å’Œè¾“å‡ºæ¥æ‰©å±•æ¨¡å‹èƒ½åŠ›ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿä¸å¤–éƒ¨ç³»ç»Ÿï¼ˆå¦‚ APIã€æ•°æ®åº“ã€æ–‡ä»¶ç³»ç»Ÿï¼‰è¿›è¡Œäº¤äº’ã€‚

### æ ¸å¿ƒæ¦‚å¿µ

- **ç»“æ„åŒ–äº¤äº’**ï¼šTools æä¾›æ¨¡å‹ä¸å¤–éƒ¨ç³»ç»Ÿçš„ç»“æ„åŒ–æ¥å£
- **å°è£…æ€§**ï¼šå°è£…å¯è°ƒç”¨å‡½æ•°åŠå…¶è¾“å…¥æ¨¡å¼
- **æ™ºèƒ½è°ƒç”¨**ï¼šæ¨¡å‹å†³å®šæ˜¯å¦è°ƒç”¨å·¥å…·ä»¥åŠä½¿ç”¨ä»€ä¹ˆå‚æ•°

## åˆ›å»ºå·¥å…·

### 1. åŸºç¡€å·¥å…·å®šä¹‰

ä½¿ç”¨ `@tool` è£…é¥°å™¨åˆ›å»ºå·¥å…·ï¼Œå‡½æ•°æ–‡æ¡£å­—ç¬¦ä¸²ä¼šè‡ªåŠ¨æˆä¸ºå·¥å…·æè¿°ï¼š

```python
from langchain.tools import tool

@tool
def search_database(query: str, limit: int = 10) -> str:
    """åœ¨å®¢æˆ·æ•°æ®åº“ä¸­æœç´¢åŒ¹é…æŸ¥è¯¢çš„è®°å½•ã€‚

    Args:
        query: è¦æŸ¥æ‰¾çš„æœç´¢è¯
        limit: è¿”å›çš„æœ€å¤§ç»“æœæ•°
    """
    # æ¨¡æ‹Ÿæ•°æ®åº“æœç´¢
    return f"æ‰¾åˆ° {limit} æ¡å…³äº '{query}' çš„ç»“æœ"

# ä½¿ç”¨å·¥å…·
result = search_database.invoke({"query": "å®¢æˆ·æŠ•è¯‰", "limit": 5})
print(result)
```

### 2. è‡ªå®šä¹‰å·¥å…·å±æ€§

#### è‡ªå®šä¹‰å·¥å…·åç§°

```python
@tool("web_search")  # è‡ªå®šä¹‰åç§°
def search_web(query: str) -> str:
    """åœ¨ç½‘ç»œä¸Šæœç´¢ä¿¡æ¯ã€‚"""
    return f"æœç´¢ '{query}' çš„ç»“æœ"

print(search_web.name)  # è¾“å‡º: web_search
```

#### è‡ªå®šä¹‰å·¥å…·æè¿°

```python
@tool("calculator", description="æ‰§è¡Œç®—æœ¯è®¡ç®—ã€‚ç”¨äºä»»ä½•æ•°å­¦é—®é¢˜ã€‚")
def calculate(expression: str) -> str:
    """è¯„ä¼°æ•°å­¦è¡¨è¾¾å¼ã€‚"""
    return str(eval(expression))
```

### 3. é«˜çº§æ¨¡å¼å®šä¹‰

#### ä½¿ç”¨ Pydantic æ¨¡å‹å®šä¹‰å¤æ‚è¾“å…¥

```python
from pydantic import BaseModel, Field
from typing import Literal, List

class WeatherInput(BaseModel):
    """å¤©æ°”æŸ¥è¯¢çš„è¾“å…¥å‚æ•°ã€‚"""
    location: str = Field(description="åŸå¸‚åç§°æˆ–åæ ‡")
    units: Literal["celsius", "fahrenheit"] = Field(
        default="celsius",
        description="æ¸©åº¦å•ä½åå¥½"
    )
    include_forecast: bool = Field(
        default=False,
        description="åŒ…å«5å¤©é¢„æŠ¥"
    )
    forecast_days: int = Field(
        default=5,
        ge=1,
        le=10,
        description="é¢„æŠ¥å¤©æ•°ï¼ˆ1-10ï¼‰"
    )

@tool(args_schema=WeatherInput)
def get_weather(
    location: str, 
    units: str = "celsius", 
    include_forecast: bool = False,
    forecast_days: int = 5
) -> str:
    """è·å–å½“å‰å¤©æ°”å’Œå¯é€‰é¢„æŠ¥ã€‚"""
    temp = 22 if units == "celsius" else 72
    result = f"{location}å½“å‰å¤©æ°”: {temp}åº¦ {units}"
    
    if include_forecast:
        result += f"\næœªæ¥{forecast_days}å¤©é¢„æŠ¥: æ™´æœ—"
    
    return result
```

#### ä½¿ç”¨ JSON Schema å®šä¹‰

```python
weather_schema = {
    "type": "object",
    "properties": {
        "location": {"type": "string"},
        "units": {"type": "string", "enum": ["celsius", "fahrenheit"]},
        "include_forecast": {"type": "boolean"},
        "forecast_days": {"type": "integer", "minimum": 1, "maximum": 10}
    },
    "required": ["location"]
}

@tool(args_schema=weather_schema)
def get_weather_json(
    location: str, 
    units: str = "celsius", 
    include_forecast: bool = False,
    forecast_days: int = 5
) -> str:
    """ä½¿ç”¨ JSON Schema å®šä¹‰è·å–å¤©æ°”ä¿¡æ¯ã€‚"""
    temp = 22 if units == "celsius" else 72
    result = f"{location}å½“å‰å¤©æ°”: {temp}åº¦ {units}"
    
    if include_forecast:
        result += f"\næœªæ¥{forecast_days}å¤©é¢„æŠ¥: æ™´æœ—"
    
    return result
```

## è®¿é—®ä¸Šä¸‹æ–‡

Tools æœ€å¼ºå¤§çš„åŠŸèƒ½æ˜¯èƒ½å¤Ÿè®¿é—® Agent çŠ¶æ€ã€è¿è¡Œæ—¶ä¸Šä¸‹æ–‡å’Œé•¿æœŸè®°å¿†ï¼Œä»è€Œå®ç°ä¸Šä¸‹æ–‡æ„ŸçŸ¥å†³ç­–å’Œä¸ªæ€§åŒ–å“åº”ã€‚

### ToolRuntime æ¦‚è¿°

`ToolRuntime` æ˜¯ä¸€ä¸ªç»Ÿä¸€çš„å‚æ•°ï¼Œæä¾›å·¥å…·è®¿é—®ä»¥ä¸‹ä¿¡æ¯çš„èƒ½åŠ›ï¼š

- **State**ï¼šæ‰§è¡Œè¿‡ç¨‹ä¸­çš„å¯å˜æ•°æ®ï¼ˆæ¶ˆæ¯ã€è®¡æ•°å™¨ã€è‡ªå®šä¹‰å­—æ®µï¼‰
- **Context**ï¼šä¸å¯å˜é…ç½®ï¼ˆç”¨æˆ· IDã€ä¼šè¯è¯¦æƒ…ã€åº”ç”¨ç‰¹å®šé…ç½®ï¼‰
- **Store**ï¼šè·¨å¯¹è¯çš„æŒä¹…é•¿æœŸè®°å¿†
- **Stream Writer**ï¼šå·¥å…·æ‰§è¡Œæ—¶æµå¼ä¼ è¾“è‡ªå®šä¹‰æ›´æ–°
- **Config**ï¼šæ‰§è¡Œçš„ RunnableConfig
- **Tool Call ID**ï¼šå½“å‰å·¥å…·è°ƒç”¨çš„ ID

### è®¿é—®çŠ¶æ€ï¼ˆStateï¼‰

```python
from langchain.tools import tool, ToolRuntime

@tool
def analyze_conversation(runtime: ToolRuntime) -> str:
    """åˆ†æå½“å‰å¯¹è¯çŠ¶æ€ã€‚"""
    messages = runtime.state["messages"]
    
    # ç»Ÿè®¡ä¸åŒç±»å‹çš„æ¶ˆæ¯
    human_count = sum(1 for m in messages if m.type == "human")
    ai_count = sum(1 for m in messages if m.type == "ai")
    tool_count = sum(1 for m in messages if m.type == "tool")
    
    return f"å¯¹è¯ç»Ÿè®¡: {human_count}æ¡ç”¨æˆ·æ¶ˆæ¯, {ai_count}æ¡AIå›å¤, {tool_count}æ¡å·¥å…·ç»“æœ"

@tool
def get_user_preference(pref_name: str, runtime: ToolRuntime) -> str:
    """è·å–ç”¨æˆ·åå¥½è®¾ç½®ã€‚"""
    preferences = runtime.state.get("user_preferences", {})
    return preferences.get(pref_name, "æœªè®¾ç½®")
```

**é‡è¦æç¤º**ï¼š`runtime` å‚æ•°å¯¹æ¨¡å‹ä¸å¯è§ï¼Œæ¨¡å‹åªèƒ½çœ‹åˆ°å…¶ä»–å‚æ•°ã€‚

### æ›´æ–°çŠ¶æ€ï¼ˆä½¿ç”¨ Commandï¼‰

```python
from langgraph.types import Command
from langchain.messages import RemoveMessage
from langgraph.graph.message import REMOVE_ALL_MESSAGES

@tool
def clear_conversation(runtime: ToolRuntime) -> Command:
    """æ¸…é™¤å¯¹è¯å†å²ã€‚"""
    return Command(
        update={
            "messages": [RemoveMessage(id=REMOVE_ALL_MESSAGES)],
        }
    )

@tool
def update_user_profile(name: str, age: int, runtime: ToolRuntime) -> Command:
    """æ›´æ–°ç”¨æˆ·æ¡£æ¡ˆã€‚"""
    return Command(
        update={
            "user_profile": {
                "name": name,
                "age": age,
                "updated_at": "2024-01-01"
            }
        }
    )
```

### è®¿é—®ä¸Šä¸‹æ–‡ï¼ˆContextï¼‰

```python
from dataclasses import dataclass
from langchain.agents import create_agent
from langchain.tools import tool, ToolRuntime

# æ¨¡æ‹Ÿç”¨æˆ·æ•°æ®åº“
USER_DATABASE = {
    "user123": {
        "name": "å¼ ä¸‰",
        "account_type": "é«˜çº§ä¼šå‘˜",
        "balance": 5000,
        "email": "zhangsan@example.com"
    },
    "user456": {
        "name": "æå››",
        "account_type": "æ ‡å‡†ä¼šå‘˜",
        "balance": 1200,
        "email": "lisi@example.com"
    }
}

@dataclass
class UserContext:
    user_id: str

@tool
def get_account_info(runtime: ToolRuntime[UserContext]) -> str:
    """è·å–å½“å‰ç”¨æˆ·çš„è´¦æˆ·ä¿¡æ¯ã€‚"""
    user_id = runtime.context.user_id
    
    if user_id in USER_DATABASE:
        user = USER_DATABASE[user_id]
        return f"""
        è´¦æˆ·ä¿¡æ¯:
        - å§“å: {user['name']}
        - è´¦æˆ·ç±»å‹: {user['account_type']}
        - ä½™é¢: Â¥{user['balance']}
        - é‚®ç®±: {user['email']}
        """
    return "ç”¨æˆ·æœªæ‰¾åˆ°"

@tool
def transfer_funds(amount: float, to_user: str, runtime: ToolRuntime[UserContext]) -> str:
    """è½¬è´¦åˆ°å…¶ä»–ç”¨æˆ·ã€‚"""
    from_user_id = runtime.context.user_id
    
    if from_user_id not in USER_DATABASE or to_user not in USER_DATABASE:
        return "ç”¨æˆ·ä¸å­˜åœ¨"
    
    from_user = USER_DATABASE[from_user_id]
    to_user_info = USER_DATABASE[to_user]
    
    if from_user["balance"] < amount:
        return "ä½™é¢ä¸è¶³"
    
    # æ¨¡æ‹Ÿè½¬è´¦æ“ä½œ
    from_user["balance"] -= amount
    to_user_info["balance"] += amount
    
    return f"æˆåŠŸè½¬è´¦ Â¥{amount} ç»™ {to_user_info['name']}"

# åˆ›å»ºä½¿ç”¨ä¸Šä¸‹æ–‡çš„ Agent
agent = create_agent(
    model="openai:gpt-4o",
    tools=[get_account_info, transfer_funds],
    context_schema=UserContext,
    system_prompt="ä½ æ˜¯ä¸€ä¸ªé‡‘èåŠ©æ‰‹ã€‚"
)

# ä½¿ç”¨ä¸Šä¸‹æ–‡è°ƒç”¨
result = agent.invoke(
    {"messages": [{"role": "user", "content": "æŸ¥çœ‹æˆ‘çš„è´¦æˆ·ä½™é¢"}]},
    context=UserContext(user_id="user123")
)
```

### è®¿é—®å­˜å‚¨ï¼ˆStoreï¼‰- é•¿æœŸè®°å¿†

```python
from typing import Any
from langgraph.store.memory import InMemoryStore
from langchain.agents import create_agent
from langchain.tools import tool, ToolRuntime

@tool
def save_user_preferences(user_id: str, preferences: dict, runtime: ToolRuntime) -> str:
    """ä¿å­˜ç”¨æˆ·åå¥½è®¾ç½®åˆ°é•¿æœŸå­˜å‚¨ã€‚"""
    store = runtime.store
    store.put(("user_preferences",), user_id, preferences)
    return "ç”¨æˆ·åå¥½è®¾ç½®å·²ä¿å­˜"

@tool
def get_user_preferences(user_id: str, runtime: ToolRuntime) -> str:
    """ä»é•¿æœŸå­˜å‚¨è·å–ç”¨æˆ·åå¥½è®¾ç½®ã€‚"""
    store = runtime.store
    preferences = store.get(("user_preferences",), user_id)
    
    if preferences and preferences.value:
        prefs = preferences.value
        return f"ç”¨æˆ· {user_id} çš„åå¥½è®¾ç½®: {prefs}"
    else:
        return f"æœªæ‰¾åˆ°ç”¨æˆ· {user_id} çš„åå¥½è®¾ç½®"

@tool
def save_conversation_summary(conversation_id: str, summary: str, runtime: ToolRuntime) -> str:
    """ä¿å­˜å¯¹è¯æ€»ç»“åˆ°é•¿æœŸå­˜å‚¨ã€‚"""
    store = runtime.store
    store.put(("conversations",), conversation_id, {
        "summary": summary,
        "timestamp": "2024-01-01T10:00:00"
    })
    return "å¯¹è¯æ€»ç»“å·²ä¿å­˜"

# åˆ›å»ºä½¿ç”¨å­˜å‚¨çš„ Agent
store = InMemoryStore()
agent = create_agent(
    model="openai:gpt-4o",
    tools=[save_user_preferences, get_user_preferences, save_conversation_summary],
    store=store
)

# ç¬¬ä¸€æ¬¡ä¼šè¯ï¼šä¿å­˜ç”¨æˆ·åå¥½
agent.invoke({
    "messages": [{
        "role": "user", 
        "content": "ä¿å­˜ç”¨æˆ·123çš„åå¥½ï¼šè¯­è¨€=ä¸­æ–‡ï¼Œä¸»é¢˜=æ·±è‰²ï¼Œé€šçŸ¥=å¼€å¯"
    }]
})

# åç»­ä¼šè¯ï¼šè·å–ç”¨æˆ·åå¥½
agent.invoke({
    "messages": [{
        "role": "user", 
        "content": "è·å–ç”¨æˆ·123çš„åå¥½è®¾ç½®"
    }]
})
```

### ä½¿ç”¨æµå†™å…¥å™¨ï¼ˆStream Writerï¼‰

```python
from langchain.tools import tool, ToolRuntime
import time

@tool
def process_large_data(data_source: str, runtime: ToolRuntime) -> str:
    """å¤„ç†å¤§å‹æ•°æ®é›†çš„å·¥å…·ï¼Œå¸¦è¿›åº¦åé¦ˆã€‚"""
    writer = runtime.stream_writer
    
    writer(f"ğŸ”„ å¼€å§‹å¤„ç†æ•°æ®æº: {data_source}")
    writer("ğŸ“Š è¿æ¥æ•°æ®æº...")
    time.sleep(0.5)
    
    writer("ğŸ” è¯»å–æ•°æ®...")
    time.sleep(1)
    
    # æ¨¡æ‹Ÿå¤„ç†æ­¥éª¤
    steps = ["æ•°æ®æ¸…æ´—", "ç‰¹å¾æå–", "æ¨¡å‹è®­ç»ƒ", "ç»“æœåˆ†æ"]
    for i, step in enumerate(steps, 1):
        writer(f"â³ æ­¥éª¤ {i}/{len(steps)}: {step}")
        time.sleep(0.8)
    
    writer("âœ… æ•°æ®å¤„ç†å®Œæˆ")
    return f"æˆåŠŸå¤„ç† {data_source}ï¼Œç”Ÿæˆåˆ†ææŠ¥å‘Š"

@tool
def search_with_progress(query: str, runtime: ToolRuntime) -> str:
    """å¸¦è¿›åº¦åé¦ˆçš„æœç´¢å·¥å…·ã€‚"""
    writer = runtime.stream_writer
    
    writer(f"ğŸ” å¼€å§‹æœç´¢: {query}")
    writer("ğŸŒ è¿æ¥æœç´¢å¼•æ“...")
    time.sleep(0.3)
    
    writer("ğŸ“¡ å‘é€æœç´¢è¯·æ±‚...")
    time.sleep(0.5)
    
    writer("ğŸ“„ è§£ææœç´¢ç»“æœ...")
    time.sleep(0.7)
    
    writer("âœ… æœç´¢å®Œæˆ")
    return f"æ‰¾åˆ°å…³äº '{query}' çš„ 15 ä¸ªç›¸å…³ç»“æœ"
```

## å®é™…åº”ç”¨åœºæ™¯

### åœºæ™¯1ï¼šç”µå•†å®¢æœç³»ç»Ÿ

```python
from datetime import datetime
from typing import Dict, List
from langchain.tools import tool, ToolRuntime

class EcommerceTools:
    """ç”µå•†å®¢æœå·¥å…·é›†"""
    
    @staticmethod
    @tool
    def check_order_status(order_id: str, runtime: ToolRuntime) -> str:
        """æ£€æŸ¥è®¢å•çŠ¶æ€ã€‚"""
        # æ¨¡æ‹Ÿè®¢å•æ•°æ®åº“
        orders = {
            "ORD001": {"status": "å·²å‘è´§", "tracking": "SF123456789", "items": ["å•†å“A", "å•†å“B"]},
            "ORD002": {"status": "å¤„ç†ä¸­", "tracking": None, "items": ["å•†å“C"]},
            "ORD003": {"status": "å·²é€è¾¾", "tracking": "SF987654321", "items": ["å•†å“D"]}
        }
        
        if order_id in orders:
            order = orders[order_id]
            result = f"è®¢å• {order_id} çŠ¶æ€: {order['status']}"
            if order['tracking']:
                result += f"\nç‰©æµå•å·: {order['tracking']}"
            result += f"\nå•†å“: {', '.join(order['items'])}"
            return result
        else:
            return f"æœªæ‰¾åˆ°è®¢å• {order_id}"
    
    @staticmethod
    @tool
    def get_product_info(product_id: str, runtime: ToolRuntime) -> str:
        """è·å–å•†å“ä¿¡æ¯ã€‚"""
        products = {
            "P001": {"name": "æ™ºèƒ½æ‰‹æœº", "price": 2999, "stock": 50, "description": "æœ€æ–°æ¬¾æ™ºèƒ½æ‰‹æœº"},
            "P002": {"name": "ç¬”è®°æœ¬ç”µè„‘", "price": 5999, "stock": 25, "description": "é«˜æ€§èƒ½ç¬”è®°æœ¬ç”µè„‘"},
            "P003": {"name": "æ— çº¿è€³æœº", "price": 399, "stock": 100, "description": "é™å™ªæ— çº¿è€³æœº"}
        }
        
        if product_id in products:
            product = products[product_id]
            return f"""
            {product['name']}
            - ä»·æ ¼: Â¥{product['price']}
            - åº“å­˜: {product['stock']}ä»¶
            - æè¿°: {product['description']}
            """
        else:
            return f"æœªæ‰¾åˆ°å•†å“ {product_id}"
    
    @staticmethod
    @tool
    def process_return(request_id: str, reason: str, runtime: ToolRuntime) -> Command:
        """å¤„ç†é€€è´§ç”³è¯·ã€‚"""
        from langgraph.types import Command
        
        # æ¨¡æ‹Ÿå¤„ç†é€€è´§
        return_info = {
            "request_id": request_id,
            "reason": reason,
            "status": "å¤„ç†ä¸­",
            "processed_at": datetime.now().isoformat()
        }
        
        return Command(
            update={
                "return_requests": runtime.state.get("return_requests", []) + [return_info]
            }
        )

# åˆ›å»ºç”µå•†å®¢æœ Agent
ecommerce_agent = create_agent(
    model="openai:gpt-4o",
    tools=[
        EcommerceTools.check_order_status,
        EcommerceTools.get_product_info,
        EcommerceTools.process_return
    ],
    system_prompt="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç”µå•†å®¢æœåŠ©æ‰‹ã€‚"
)
```

### åœºæ™¯2ï¼šæ™ºèƒ½æ•°æ®åˆ†æå·¥å…·

```python
import pandas as pd
import numpy as np
from io import StringIO
from langchain.tools import tool, ToolRuntime

class DataAnalysisTools:
    """æ•°æ®åˆ†æå·¥å…·é›†"""
    
    @staticmethod
    @tool
    def load_csv_data(csv_content: str, runtime: ToolRuntime) -> Command:
        """åŠ è½½ CSV æ•°æ®åˆ°åˆ†æç¯å¢ƒã€‚"""
        from langgraph.types import Command
        
        try:
            # ä» CSV å­—ç¬¦ä¸²åˆ›å»º DataFrame
            df = pd.read_csv(StringIO(csv_content))
            
            # è¿”å›æ•°æ®ç»Ÿè®¡ä¿¡æ¯
            stats = {
                "rows": len(df),
                "columns": len(df.columns),
                "columns_list": list(df.columns),
                "memory_usage": df.memory_usage(deep=True).sum()
            }
            
            return Command(
                update={
                    "current_dataset": df.to_dict(),
                    "dataset_stats": stats
                }
            )
        except Exception as e:
            return f"åŠ è½½æ•°æ®å¤±è´¥: {str(e)}"
    
    @staticmethod
    @tool
    def describe_dataset(runtime: ToolRuntime) -> str:
        """æè¿°å½“å‰æ•°æ®é›†çš„åŸºæœ¬ä¿¡æ¯ã€‚"""
        stats = runtime.state.get("dataset_stats", {})
        
        if not stats:
            return "æ²¡æœ‰åŠ è½½çš„æ•°æ®é›†"
        
        return f"""
        æ•°æ®é›†ä¿¡æ¯:
        - è¡Œæ•°: {stats['rows']}
        - åˆ—æ•°: {stats['columns']}
        - åˆ—å: {', '.join(stats['columns_list'])}
        - å†…å­˜ä½¿ç”¨: {stats['memory_usage']} å­—èŠ‚
        """
    
    @staticmethod
    @tool
    def calculate_statistics(column: str, runtime: ToolRuntime) -> str:
        """è®¡ç®—æŒ‡å®šåˆ—çš„ç»Ÿè®¡ä¿¡æ¯ã€‚"""
        dataset = runtime.state.get("current_dataset", {})
        
        if not dataset:
            return "æ²¡æœ‰åŠ è½½çš„æ•°æ®é›†"
        
        try:
            df = pd.DataFrame(dataset)
            
            if column not in df.columns:
                return f"åˆ— '{column}' ä¸å­˜åœ¨"
            
            series = df[column]
            stats = {
                "count": len(series),
                "mean": series.mean(),
                "std": series.std(),
                "min": series.min(),
                "max": series.max(),
                "null_count": series.isnull().sum()
            }
            
            return f"""
            {column} åˆ—ç»Ÿè®¡ä¿¡æ¯:
            - æ•°é‡: {stats['count']}
            - å¹³å‡å€¼: {stats['mean']:.2f}
            - æ ‡å‡†å·®: {stats['std']:.2f}
            - æœ€å°å€¼: {stats['min']}
            - æœ€å¤§å€¼: {stats['max']}
            - ç©ºå€¼æ•°é‡: {stats['null_count']}
            """
        except Exception as e:
            return f"è®¡ç®—ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}"

# åˆ›å»ºæ•°æ®åˆ†æ Agent
data_analysis_agent = create_agent(
    model="openai:gpt-4o",
    tools=[
        DataAnalysisTools.load_csv_data,
        DataAnalysisTools.describe_dataset,
        DataAnalysisTools.calculate_statistics
    ],
    system_prompt="ä½ æ˜¯ä¸€ä¸ªæ•°æ®åˆ†æåŠ©æ‰‹ï¼Œå¸®åŠ©ç”¨æˆ·åˆ†æå’Œç†è§£æ•°æ®ã€‚"
)
```

### åœºæ™¯3ï¼šé¡¹ç›®ç®¡ç†å·¥å…·

```python
from typing import List, Dict
from datetime import datetime, timedelta
from langchain.tools import tool, ToolRuntime

class ProjectManagementTools:
    """é¡¹ç›®ç®¡ç†å·¥å…·é›†"""
    
    @staticmethod
    @tool
    def create_task(title: str, description: str, assignee: str, due_date: str, runtime: ToolRuntime) -> Command:
        """åˆ›å»ºæ–°ä»»åŠ¡ã€‚"""
        from langgraph.types import Command
        
        task = {
            "id": f"TASK_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            "title": title,
            "description": description,
            "assignee": assignee,
            "due_date": due_date,
            "status": "å¾…å¼€å§‹",
            "created_at": datetime.now().isoformat()
        }
        
        return Command(
            update={
                "project_tasks": runtime.state.get("project_tasks", []) + [task]
            }
        )
    
    @staticmethod
    @tool
    def update_task_status(task_id: str, new_status: str, runtime: ToolRuntime) -> Command:
        """æ›´æ–°ä»»åŠ¡çŠ¶æ€ã€‚"""
        from langgraph.types import Command
        
        tasks = runtime.state.get("project_tasks", [])
        updated_tasks = []
        task_found = False
        
        for task in tasks:
            if task["id"] == task_id:
                task["status"] = new_status
                task["updated_at"] = datetime.now().isoformat()
                task_found = True
            updated_tasks.append(task)
        
        if task_found:
            return Command(update={"project_tasks": updated_tasks})
        else:
            return f"æœªæ‰¾åˆ°ä»»åŠ¡ {task_id}"
    
    @staticmethod
    @tool
    def get_project_progress(runtime: ToolRuntime) -> str:
        """è·å–é¡¹ç›®è¿›åº¦æ¦‚è§ˆã€‚"""
        tasks = runtime.state.get("project_tasks", [])
        
        if not tasks:
            return "é¡¹ç›®ä¸­æ²¡æœ‰ä»»åŠ¡"
        
        status_count = {}
        for task in tasks:
            status = task["status"]
            status_count[status] = status_count.get(status, 0) + 1
        
        total_tasks = len(tasks)
        completed_tasks = status_count.get("å·²å®Œæˆ", 0)
        progress_percentage = (completed_tasks / total_tasks) * 100
        
        return f"""
        é¡¹ç›®è¿›åº¦æ¦‚è§ˆ:
        - æ€»ä»»åŠ¡æ•°: {total_tasks}
        - å·²å®Œæˆ: {completed_tasks}
        - è¿›è¡Œä¸­: {status_count.get('è¿›è¡Œä¸­', 0)}
        - å¾…å¼€å§‹: {status_count.get('å¾…å¼€å§‹', 0)}
        - æ€»ä½“è¿›åº¦: {progress_percentage:.1f}%
        """
    
    @staticmethod
    @tool
    def assign_task(task_id: str, new_assignee: str, runtime: ToolRuntime) -> Command:
        """é‡æ–°åˆ†é…ä»»åŠ¡ã€‚"""
        from langgraph.types import Command
        
        tasks = runtime.state.get("project_tasks", [])
        updated_tasks = []
        task_found = False
        
        for task in tasks:
            if task["id"] == task_id:
                old_assignee = task["assignee"]
                task["assignee"] = new_assignee
                task["updated_at"] = datetime.now().isoformat()
                task_found = True
            updated_tasks.append(task)
        
        if task_found:
            return Command(
                update={
                    "project_tasks": updated_tasks
                }
            )
        else:
            return f"æœªæ‰¾åˆ°ä»»åŠ¡ {task_id}"

# åˆ›å»ºé¡¹ç›®ç®¡ç† Agent
project_agent = create_agent(
    model="openai:gpt-4o",
    tools=[
        ProjectManagementTools.create_task,
        ProjectManagementTools.update_task_status,
        ProjectManagementTools.get_project_progress,
        ProjectManagementTools.assign_task
    ],
    system_prompt="ä½ æ˜¯ä¸€ä¸ªé¡¹ç›®ç®¡ç†åŠ©æ‰‹ï¼Œå¸®åŠ©å›¢é˜Ÿç®¡ç†ä»»åŠ¡å’Œè·Ÿè¸ªè¿›åº¦ã€‚"
)
```

## æœ€ä½³å®è·µ

### 1. å·¥å…·è®¾è®¡åŸåˆ™

```python
from pydantic import BaseModel, Field
from typing import Optional

class WellDesignedTool:
    """è‰¯å¥½è®¾è®¡çš„å·¥å…·ç¤ºä¾‹"""
    
    @staticmethod
    @tool
    def search_products(
        query: str,
        category: Optional[str] = None,
        price_range: Optional[str] = None,
        sort_by: str = "relevance",
        runtime: ToolRuntime
    ) -> str:
        """æœç´¢äº§å“ä¿¡æ¯ã€‚
        
        Args:
            query: æœç´¢å…³é”®è¯ï¼ˆå¿…éœ€ï¼‰
            category: äº§å“ç±»åˆ«ç­›é€‰ï¼ˆå¯é€‰ï¼‰
            price_range: ä»·æ ¼èŒƒå›´ç­›é€‰ï¼Œå¦‚ "100-500"ï¼ˆå¯é€‰ï¼‰
            sort_by: æ’åºæ–¹å¼ï¼šrelevanceï¼ˆç›¸å…³åº¦ï¼‰ã€price_ascï¼ˆä»·æ ¼å‡åºï¼‰ã€price_descï¼ˆä»·æ ¼é™åºï¼‰
        """
        # æ¸…æ™°çš„å‚æ•°è¯´æ˜
        # åˆç†çš„é»˜è®¤å€¼
        # å®Œæ•´çš„é”™è¯¯å¤„ç†
        
        writer = runtime.stream_writer
        writer(f"ğŸ” æœç´¢äº§å“: {query}")
        
        if category:
            writer(f"ğŸ“ ç­›é€‰ç±»åˆ«: {category}")
        if price_range:
            writer(f"ğŸ’° ä»·æ ¼èŒƒå›´: {price_range}")
        
        # æ¨¡æ‹Ÿæœç´¢é€»è¾‘
        writer("ğŸ“Š è·å–æœç´¢ç»“æœ...")
        
        return f"æ‰¾åˆ° 15 ä¸ªåŒ¹é… '{query}' çš„äº§å“"
```

### 2. é”™è¯¯å¤„ç†

```python
from langchain.tools import tool, ToolRuntime

class RobustTools:
    """å¥å£®çš„å·¥å…·è®¾è®¡"""
    
    @staticmethod
    @tool
    def safe_api_call(api_endpoint: str, params: dict, runtime: ToolRuntime) -> str:
        """å®‰å…¨çš„ API è°ƒç”¨å·¥å…·ã€‚"""
        import requests
        import time
        
        writer = runtime.stream_writer
        writer(f"ğŸŒ è°ƒç”¨ API: {api_endpoint}")
        
        max_retries = 3
        for attempt in range(max_retries):
            try:
                response = requests.get(api_endpoint, params=params, timeout=10)
                response.raise_for_status()
                return f"API è°ƒç”¨æˆåŠŸ: {response.json()}"
                
            except requests.exceptions.Timeout:
                writer(f"â° è¯·æ±‚è¶…æ—¶ (å°è¯• {attempt + 1}/{max_retries})")
                if attempt == max_retries - 1:
                    return "é”™è¯¯: API è¯·æ±‚è¶…æ—¶"
                time.sleep(1)
                
            except requests.exceptions.RequestException as e:
                return f"API è°ƒç”¨é”™è¯¯: {str(e)}"
    
    @staticmethod
    @tool
    def validate_and_process_data(data: str, runtime: ToolRuntime) -> str:
        """éªŒè¯å’Œå¤„ç†æ•°æ®ã€‚"""
        writer = runtime.stream_writer
        
        # æ•°æ®éªŒè¯
        if not data or not data.strip():
            return "é”™è¯¯: æ•°æ®ä¸èƒ½ä¸ºç©º"
        
        writer("âœ… æ•°æ®éªŒè¯é€šè¿‡")
        writer("ğŸ”„ å¤„ç†æ•°æ®...")
        
        try:
            # æ¨¡æ‹Ÿæ•°æ®å¤„ç†
            processed = data.upper()
            return f"å¤„ç†åçš„æ•°æ®: {processed}"
        except Exception as e:
            return f"æ•°æ®å¤„ç†é”™è¯¯: {str(e)}"
```

### 3. æ€§èƒ½ä¼˜åŒ–

```python
from langchain.tools import tool, ToolRuntime
import functools

class OptimizedTools:
    """æ€§èƒ½ä¼˜åŒ–çš„å·¥å…·"""
    
    # ä½¿ç”¨ç¼“å­˜é¿å…é‡å¤è®¡ç®—
    @functools.lru_cache(maxsize=100)
    def _expensive_calculation(self, input_data: str) -> str:
        """æ¨¡æ‹Ÿæ˜‚è´µçš„è®¡ç®—ã€‚"""
        # æ¨¡æ‹Ÿå¤æ‚è®¡ç®—
        return f"è®¡ç®—ç»“æœ: {input_data.upper()}"
    
    @tool
    def cached_calculation(self, input_data: str, runtime: ToolRuntime) -> str:
        """ä½¿ç”¨ç¼“å­˜çš„æ˜‚è´µè®¡ç®—ã€‚"""
        writer = runtime.stream_writer
        writer("âš¡ ä½¿ç”¨ç¼“å­˜è®¡ç®—...")
        
        return self._expensive_calculation(input_data)
    
    @tool
    def batch_processing(self, items: list, runtime: ToolRuntime) -> str:
        """æ‰¹é‡å¤„ç†å·¥å…·ã€‚"""
        writer = runtime.stream_writer
        
        writer(f"ğŸ“¦ å¼€å§‹æ‰¹é‡å¤„ç† {len(items)} ä¸ªé¡¹ç›®")
        
        results = []
        batch_size = 5
        
        for i in range(0, len(items), batch_size):
            batch = items[i:i + batch_size]
            writer(f"å¤„ç†æ‰¹æ¬¡ {i//batch_size + 1}/{(len(items)-1)//batch_size + 1}")
            
            # æ¨¡æ‹Ÿæ‰¹é‡å¤„ç†
            batch_results = [f"å¤„ç†: {item}" for item in batch]
            results.extend(batch_results)
        
        writer("âœ… æ‰¹é‡å¤„ç†å®Œæˆ")
        return f"æˆåŠŸå¤„ç† {len(results)} ä¸ªé¡¹ç›®"
```

## æ€»ç»“

LangChain Tools æä¾›äº†å¼ºå¤§çš„èƒ½åŠ›æ¥æ‰©å±• AI Agent çš„åŠŸèƒ½ï¼š

- **ç®€å•åˆ›å»º**ï¼šä½¿ç”¨ `@tool` è£…é¥°å™¨å¿«é€Ÿå®šä¹‰å·¥å…·
- **çµæ´»å®šåˆ¶**ï¼šæ”¯æŒè‡ªå®šä¹‰åç§°ã€æè¿°å’Œå¤æ‚è¾“å…¥æ¨¡å¼
- **ä¸Šä¸‹æ–‡æ„ŸçŸ¥**ï¼šé€šè¿‡ `ToolRuntime` è®¿é—®çŠ¶æ€ã€ä¸Šä¸‹æ–‡ã€å­˜å‚¨ç­‰
- **å®æ—¶åé¦ˆ**ï¼šä½¿ç”¨æµå†™å…¥å™¨æä¾›æ‰§è¡Œè¿›åº¦
- **ç”Ÿäº§å°±ç»ª**ï¼šåŒ…å«é”™è¯¯å¤„ç†ã€æ€§èƒ½ä¼˜åŒ–ç­‰æœ€ä½³å®è·µ

é€šè¿‡åˆç†è®¾è®¡å’Œä½¿ç”¨ Toolsï¼Œå¯ä»¥æ„å»ºå‡ºèƒ½å¤Ÿä¸å„ç§å¤–éƒ¨ç³»ç»Ÿäº¤äº’çš„æ™ºèƒ½ Agentï¼Œå®ç°çœŸæ­£çš„è‡ªåŠ¨åŒ–å·¥ä½œæµç¨‹ã€‚